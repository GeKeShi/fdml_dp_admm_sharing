\section{The ADMM Sharing Algorithm}
\label{sec:admmSharing}
We present an ADMM sharing algorithm \cite{boyd2011distributed,hong2016convergence} to solve Problem~\eqref{eq:analysis_problem} and establish a convergence guarantee for the algorithm. Our algorithm requires each party only share a single value to other parties in each iteration, thus requiring the minimum message passing. 
In particular, Problem~\eqref{eq:analysis_problem} is equivalent to
\begin{align}
\underset{x}{\text{minimize}} &\quad l\left(z\right) + \lambda\sum_{m=1}^{M} R_m(x_m),\\
\text{s.t.} &\quad \sum_{m=1}^{M} \mathcal{D}_m x_m - z = 0,\quad x_m\in X_M, m=1,\ldots,M,
\end{align}
where $z$ is an auxiliary variable. 
% Define $\{x\}=\{x_1,\cdots,x_M\}$.
The corresponding augmented Lagrangian is given by
\begin{align}
\mathcal{L}(\{x\}, z; y) =& l(z) + \lambda\sum_{m=1}^{M} R_m(x_m) + \langle y, \sum_{m=1}^{M}\mathcal{D}_m x_m - z\rangle \nonumber\\
    &+ \frac{\rho}{2}\|\sum_{m=1}^{M} \mathcal{D}_m x_m - z\|^2, \label{eq:lagragian}
\end{align}
where $y$ is the dual variable and $\rho$ is the penalty factor.
In the $t^{th}$ iteration of the algorithm, variables are updated according to
% {\bf the sequential updating algorithm}
% \begin{align}
% &x_j^{t+1}:=\underset{x_j\in X_j}{\text{argmin}}\quad\lambda R_j(x_j) + \langle y^t, D_jx_j\rangle + \frac{\rho}{2}\big\|\sum_{k<j}D_kx_k^{t+1} + \sum_{k>j}D_kx_k^t + D_jx_j - z^t\big\|^2\label{eq:seq_algo_x}\\
% &z^{t+1}:=\underset{z}{\text{argmin}}\quad l(z) - \langle y^t, z \rangle + \frac{\rho}{2} \big\|\sum_jD_jx_j^{t+1} - z\big\|^2\label{eq:seq_algo_z}\\
% &y^{t+1}:=y^t + \rho\big(\sum_jD_jx_j^{t+1} - z^{t+1}\big),\label{eq:seq_algo_y}
% \end{align}
% and  {\bf the parallel updating algorithm}

\begin{align}
&x_m^{t+1}:=\underset{x_m\in X_m}{\text{argmin}}\quad\lambda R_m(x_m) + \langle y^t, \mathcal{D}_mx_m\rangle\nonumber\\
& \quad\quad\quad\quad\quad\quad\quad+ \frac{\rho}{2}\big\|\sum_{\substack{k=1,~k\neq m}}^{M}\mathcal{D}_kx_k^{t} + \mathcal{D}_mx_m - z^t\big\|^2, \nonumber\\
&\hspace*{36pt} m=1,\cdots,M\label{eq:pal_algo_x}\\
&z^{t+1}:=\underset{z}{\text{argmin}}\quad l(z)  - \langle y^t, z \rangle + \frac{\rho}{2} \big\|\sum_{m=1}^{M}\mathcal{D}_mx_m^{t+1} - z\big\|^2\label{eq:pal_algo_z}\\
&y^{t+1}:=y^t + \rho\big(\sum_{m=1}^{M}\mathcal{D}_mx_m^{t+1} - z^{t+1}\big).\label{eq:pal_algo_y}
\end{align}

Formally, in a distributed and fully parallel manner, the algorithm is described in Algorithm~\ref{alg:ADMM_sharing}. Note that each party $m$ needs the value $\sum_{k\neq m}\mathcal{D}_kx_k^{t} - z^{t}$ to complete the update, and Lines~\ref{alg:line_1}, \ref{alg:line_2} and \ref{alg:line_8} in Algorithm~\ref{alg:ADMM_sharing} present a trick to reduce communication overhead. On each local party , \eqref{eq:pal_algo_x} is computed where a proper $x_m$ is derived to simultaneously minimize the regularizer and bring the global prediction close to $z^t$, given the local predictions from other parties. When $R_m(\cdot)$ is $l_2$ norm, \eqref{eq:pal_algo_x} becomes a trivial quadratic program which can be efficiently solved. On the central node, the global prediction $z$ is found in \eqref{eq:pal_algo_z} by minimizing the loss $l(\cdot)$ while bringing $z$ close to the aggregated local predictions from all local parties. Therefore, the computational complexity of \eqref{eq:pal_algo_z} is independent of the number of features, thus making the proposed algorithm scalable to a large number of features, as compared to SGD or Frank-Wolfe algorithms. %The central node updates $y$ by \eqref{eq:pal_algo_y} after it updates $z$.

\begin{algorithm}[t]
\caption{The ADMM Sharing Algorithm}
\begin{algorithmic}[1]
    \STATE -----\emph{Each party $m$ performs in parallel:}
    % \bindent
    \FOR {$t$ in $1, \ldots, T$}
        \STATE Pull  $\sum_k\mathcal{D}_kx_k^{t} - z^{t}$  and $y^{t}$ from central node \label{alg:line_1}
        \STATE Obtain $\sum_{k\neq m}\mathcal{D}_kx_k^{t} - z^{t}$ by subtracting the locally cached $\mathcal{D}_mx_m^{t}$ from  the pulled value $\sum_k\mathcal{D}_kx_k^{t} - z^{t}$ \label{alg:line_2}
        \STATE Compute $x_m^{t+1}$ according to \eqref{eq:pal_algo_x} \label{alg:line_3}
        \STATE Push $\mathcal{D}_mx_m^{t+1}$ to the central node \label{alg:line_4}
    \ENDFOR
    % \eindent
    \STATE -----\emph{Central node:}
    % \bindent
    \FOR{$t$ in $1, \ldots, T$}
        \STATE Collect $\mathcal{D}_mx_m^{t+1}$ for all $m=1,\ldots,M$\label{alg:line_5}
        \STATE Compute $z^{t+1}$ according to \eqref{eq:pal_algo_z}\label{alg:line_6}
        \STATE Compute $y^{t+1}$ according to \eqref{eq:pal_algo_y}\label{alg:line_7}
        \STATE Distribute $\sum_k\mathcal{D}_kx_k^{t+1} - z^{t+1}$  and $y^{t+1}$ to all the parties. \label{alg:line_8}
    \ENDFOR
    % \eindent
\end{algorithmic}
\label{alg:ADMM_sharing}
\end{algorithm}

% \subsection{Privacy Concern and Differential Privacy}

% Random noise added to the query. Variance is correlated to the DP guarantee.
% {\bf Laplace Mechanism}
% \begin{align}
% \eta\sim\text{Lap}(\frac{\Delta f}{\epsilon})
% \end{align}

% ADMM sharing with differential privacy.
% \begin{align}
% &x_m^{t+1}:=\underset{x_m\in X_m}{\text{argmin}}\quad\lambda R_m(x_m) + \langle y^t, \mathcal{D}_mx_m\rangle + \frac{\rho}{2}\big\|\sum_{\substack{k=1\\k\neq m}}^M\mathcal{D}_kx_k + \mathcal{D}_mx_m - z^t\big\|^2\text{~for~all}~ m=1,\cdots,M\label{eq:pri_algo_x}\\
% & \text{Generate~} \xi_m^{t+1}\sim\mathcal{N}(0, \sigma^2_{m, t+1})\text{~for~all}~ m=1,\cdots,M\label{eq:pri_algo_xi}\\
% %%%&Q_m^{t+1} = \mathcal{D}_mx_m^{t+1} + \xi_m^{t+1} \text{~for~all}~ m=1,\cdots,M\label{eq:pri_algo_M} \\
% &\tilde{x}_m^{t+1}\leftarrow x_m^{t+1}+\xi_m^{t+1}\text{~for~all}~ m=1,\cdots,M\label{eq:pri_algo_M} \\
% &z^{t+1}:=\underset{z}{\text{argmin}}\quad l(z)  - \langle y^t, z \rangle + \frac{\rho}{2} \big\|\sum_{m=1}^{M}\mathcal{D}_m\tilde{x}_m^{t+1} - z\big\|^2\label{eq:pri_algo_z}\\
% &y^{t+1}:=y^t + \rho\big(\sum_{m=1}^{M}\mathcal{D}_m\tilde{x}_m^{t+1} - z^{t+1}\big).\label{eq:pri_algo_y}
% \end{align}

\subsection{Convergence Analysis}
We follow Hong et al. \cite{hong2016convergence} to establish the convergence guarantee of the proposed algorithm under mild assumptions. Note that \cite{hong2016convergence} provides convergence analysis for the Gauss-Seidel version of the ADMM sharing, where $x_1,\ldots,x_M$ are updated sequentially, which is not naturally suitable to parallel implementation.
In~\eqref{eq:pal_algo_x} of our algorithm, $x_m$'s can be updated by different parties in parallel in each iteration.
We establish convergence as well as iteration complexity results for this parallel scenario, which is more realistic in distributed learning. We need the following set of common assumptions. 
\begin{assume}\label{theo:assumptions_pri}
% \newline
\begin{enumerate}
    \item There exists a positive constant $L>0$ such that
        \[
            \|\nabla l(x)-\nabla l(z)\| \le L\|x-z\|\quad \forall x, z.
        \]
        Moreover, for all $m\in\{1,2,\cdots,M\}$, $X_m$'s are closed convex sets; each $\mathcal{D}_m$ is of full column rank so that the minimum eigenvalue $\sigma_{\text{min}}(\mathcal{D}_m^\top \mathcal{D}_m)$ of matrix $\mathcal{D}_m^\top \mathcal{D}_m$ is positive.\label{item:assum_1_pri}
    \item The penalty parameter $\rho$ is chosen large enough such that
    \begin{enumerate}
        \item each $x_m$ subproblem~\eqref{eq:pal_algo_x} as well as the $z$ subproblem~\eqref{eq:pal_algo_z} is strongly convex, with modulus $\{\gamma_m(\rho)\}_{m=1}^M$ and $\gamma(\rho)$, respectively. \label{item:asusum_2_1_pri}
        \item $\gamma_m(\rho)\ge 2\sigma_{\text{max}}(\mathcal{D}_m^\top \mathcal{D}_m), \forall m$, where $\sigma_{\text{max}}(\mathcal{D}_m^\top \mathcal{D}_m)$ is the maximum eigenvalue for matrix $\mathcal{D}_m^\top \mathcal{D}_m$.
        \item$\rho\gamma(\rho)>2L^2$ and $\rho\ge L$.
    \end{enumerate}
    \label{item:assum_2_pri}
    \item The objective function $l\left(\sum_{m=1}^{M} \mathcal{D}_mx_m\right) + \lambda\sum_{m=1}^{M} R_m(x_m)$ in Problem~\ref{eq:analysis_problem} is lower bounded over $\Pi_{m=1}^MX_m$ and we denote the lower bound as $\underline{f}$.\label{item:assum_3_pri}
    \item $R_m$ is either smooth nonconvex or convex (possibly nonsmooth). For the former case, there exists $L_m>0$ such that $\|\nabla R_m(x_m) - \nabla R_m(z_m)\|\le L_m\|x_m-z_m\|$ for all $x_m, z_m\in X_m$.\label{item:assum_4_pri}
\end{enumerate}
\end{assume}
Specifically, \ref{item:assum_1_pri}, \ref{item:assum_3_pri} and \ref{item:assum_4_pri} in Assumptions~\ref{theo:assumptions_pri} are common settings in the literature. Assumptions~\ref{theo:assumptions_pri}.\ref{item:assum_2_pri} is achievable if the $\rho$ is chosen large enough.

Denote $\mathcal{M}\subset\{1,2,\ldots, M\}$ as the index set, such that when $ m\in\mathcal{M}$, $R_m$ is convex, otherwise, $R_m$ is nonconvex but smooth. Our convergence results show that under mild assumptions, the iteratively updated variables eventually converge to the set of primal-dual stationary solutions. Theorem~\ref{theo:convergence} formally states this result.
\begin{theorem}\label{theo:convergence}
Suppose Assumption~\ref{theo:assumptions_pri} holds true, we have the following results:
\begin{enumerate}
    \item $\lim_{t\rightarrow\infty}\|\sum_{m=1}^{M} \mathcal{D}_mx_m^{t+1} - z^{t+1}\|$=0.\label{item:primal_cond_limit}
    \item Any limit point $\{\{x^*\}, z^*; y^*\}$ of the sequence $\{\{x^{t+1}\}, z^{t+1}; y^{t+1}\}$ is a stationary solution of problem~\eqref{eq:analysis_problem} in the sense that
    \begin{align}
        & x_m^* \in \underset{x_m\in X_m}{\text{argmin}}\quad \lambda R_m(x_m) + \langle y^*, \mathcal{D}_mx_m\rangle, m\in\mathcal{M},\label{eq:cond_x_opt_conv}\\
        & \langle x_m - x_m^*, \lambda\nabla l(x_m^*) - \mathcal{D}_m^T y^* \rangle\le 0\quad\forall x_m\in X_m, m\not\in\mathcal{M}, \label{eq:cond_x_opt_nonconv}\\
        & \nabla l(z^*) - y^* = 0,\label{eq:cond_dual}\\
        & \sum_{m=1}^{M}\mathcal{D}_mx_m^* = z^*.\label{eq:cond_primal}
    \end{align}
    \item If $\mathcal{D}_m$ is a compact set for all $m$, then $\{\{x_m^t\}, z^t; y^t\}$ converges to the set of stationary solutions of problem~\eqref{eq:analysis_problem}, i.e.,
    \begin{align}
        \underset{t\rightarrow\infty}{\lim}\quad\text{dist}\big((\{x^t\}, z^t; y^t);Z^*\big) = 0,\nonumber
    \end{align}
    where $Z^*$ is the set of primal-dual stationary solutions for problem~\eqref{eq:analysis_problem}.
\end{enumerate}
\end{theorem}

\subsection{Iteration Complexity Analysis}
We evaluate the iteration complexity over a \emph{Lyapunov function}. More specifically, we define $V^t$ as
\begin{align}
    V^t:=&\sum_{m=1}^{M} \|\tilde{\nabla}_{x_m} \mathcal{L}(\{x_m^t\}, z^t; y^t)\|^2 + \|\nabla_z \mathcal{L}(\{x_m^t\}, z^t; y^t)\|^2\nonumber\\
    & + \|\sum_{m=1}^{M} \mathcal{D}_mx_m^t - z^t\|^2,\label{eq:Lyapunov}
\end{align}
where
\begin{align}
    & \tilde{\nabla}_{x_m} \mathcal{L}(\{x_m^t\}, z^t; y^t) = \nabla_{x_m} \mathcal{L}(\{x_m^t\}, z^t; y^t)\quad\hfill\text{when}~ m\not\in\mathcal{M},\nonumber\\
    & \tilde{\nabla}_{x_m} \mathcal{L}(\{x_m^t\}, z^t; y^t) = x_m^t\nonumber\\
    &  - \text{prox}_{\lambda R_m} \big[x_m^t-\nabla_{x_m}\big(\mathcal{L}(\{x_m^t\}, z^t; y^t) - \lambda\sum_{m=1}^{M} R_m(x_m^t)\big)\big]\nonumber\\ 
    &\quad\hfill \text{when} ~m\in\mathcal{M},\nonumber
\end{align}
with $\text{prox}_h[z] := \text{argmin}_x h(x)+\frac{1}{2}\|x-z\|^2$. It is easy to verify that when $V^t\rightarrow 0$, a stationary solution is achieved. The result for the iteration complexity is stated in the following theorem, which provides a quantification of how fast our algorithm converges. Theorem~\ref{theo:iter_complexity} shows that the algorithm converges in the sense that the \emph{Lyapunov function} $V^t$ will be less than any $\epsilon>0$ within $O(1/\epsilon)$ iterations. 
\begin{theorem}\label{theo:iter_complexity}
    Suppose Assumption~\ref{theo:assumptions_pri} holds. Let $T(\epsilon)$ denote the iteration index in which:
    \begin{align}
        T(\epsilon):=\text{min}\{t|V^t\le\epsilon, t\ge0\},\nonumber
    \end{align}
    for any $\epsilon>0$. Then there exists a constant $C>0$, such that
    \begin{align}
        T(\epsilon)\epsilon\le C(\mathcal{L}(\{x^1\}, z^1; y^1 - \underline{f}),
    \end{align}
    where $\underline{f}$ is the lower bound defined in Assumption~\ref{theo:assumptions_pri}.%\ref{item:assum_3_pri}.
\end{theorem} 