Using default parameters in config
iteration 0 batch 0 training_loss 0.6857275420239741
iteration 0 batch 10 training_loss 0.6886953974383626
iteration 0 batch 20 training_loss 0.6842436143167799
iteration 0 batch 30 training_loss 0.6901793251455568
iteration 0 batch 40 training_loss 0.6901793251455568
iteration 0 batch 50 training_loss 0.6872114697311684
iteration 0 batch 60 training_loss 0.6901793251455568
iteration 0 batch 70 training_loss 0.6827596866095857
iteration 0 batch 80 training_loss 0.6857275420239741
iteration 0 batch 90 training_loss 0.6901793251455568
iteration 0 batch 100 training_loss 0.6886953974383626
iteration 0 batch 110 training_loss 0.6901793251455568
iteration 0 batch 120 training_loss 0.6886953974383626
iteration 0 batch 130 training_loss 0.6857275420239741
iteration 0 batch 140 training_loss 0.6857275420239741
iteration 0 batch 150 training_loss 0.6901793251455568
iteration 0 batch 160 training_loss 0.6916632528527511
iteration 0 batch 170 training_loss 0.6931471805599453
iteration 0 batch 180 training_loss 0.6901793251455568
iteration 0 batch 190 training_loss 0.6901793251455568
iteration 0 batch 200 training_loss 0.6872114697311684
iteration 0 batch 210 training_loss 0.6872114697311684
iteration 0 batch 220 training_loss 0.6916632528527511
iteration 0 batch 230 training_loss 0.6901793251455568
iteration 0 batch 240 training_loss 0.6827596866095857
iteration 0 batch 250 training_loss 0.6901793251455568
iteration 0 batch 260 training_loss 0.6901793251455568
iteration 0 batch 270 training_loss 0.6842436143167799
iteration 0 batch 280 training_loss 0.6901793251455568
iteration 0 batch 290 training_loss 0.6916632528527511
iteration 0 batch 300 training_loss 0.6931471805599453
iteration 0 batch 310 training_loss 0.6931471805599453
iteration 0 batch 320 training_loss 0.6872114697311684
iteration 0 batch 330 training_loss 0.6886953974383626
iteration 0 batch 340 training_loss 0.6886953974383626
iteration 0 batch 350 training_loss 0.6857275420239741
iteration 0 batch 360 training_loss 0.6886953974383626
iteration 0 batch 370 training_loss 0.6901793251455568
iteration 0 batch 380 training_loss 0.6901793251455568
iteration 0 batch 390 training_loss 0.6901793251455568
iteration 0 batch 400 training_loss 0.6812757589023914
iteration 0 batch 410 training_loss 0.6931471805599453
iteration 0 batch 420 training_loss 0.6872114697311684
iteration 0 batch 430 training_loss 0.6901793251455568
iteration 0 batch 440 training_loss 0.6931471805599453
iteration 0 batch 450 training_loss 0.6901793251455568
iteration 0 batch 460 training_loss 0.6872114697311684
iteration 0 batch 470 training_loss 0.6901793251455568
iteration 0 batch 480 training_loss 0.6886953974383626
iteration 0 batch 490 training_loss 0.6886953974383626
iteration 0 batch 500 training_loss 0.6931471805599453
iteration 0 batch 510 training_loss 0.6916632528527511
iteration 0 batch 520 training_loss 0.6901793251455568
iteration 0 batch 530 training_loss 0.6901793251455568
iteration 0 batch 540 training_loss 0.6886953974383626
iteration 0 batch 550 training_loss 0.6916632528527511
iteration 0 batch 560 training_loss 0.6886953974383626
iteration 0 batch 570 training_loss 0.6886953974383626
iteration 0 batch 580 training_loss 0.6931471805599453
iteration 0 batch 590 training_loss 0.6931471805599453
iteration 0 batch 600 training_loss 0.6872114697311684
iteration 0 batch 610 training_loss 0.6931471805599453
iteration 0 batch 620 training_loss 0.6901793251455568
iteration 0 batch 630 training_loss 0.6916632528527511
iteration 0 batch 640 training_loss 0.6872114697311684
iteration 0 batch 650 training_loss 0.6886953974383626
iteration 0 batch 660 training_loss 0.6886953974383626
iteration 0 batch 670 training_loss 0.6931471805599453
iteration 0 batch 680 training_loss 0.6857275420239741
iteration 0 batch 690 training_loss 0.6886953974383626
iteration 0 batch 700 training_loss 0.6872114697311684
iteration 0 batch 710 training_loss 0.6886953974383626
iteration 0 batch 720 training_loss 0.6886953974383626
iteration 0 batch 730 training_loss 0.6872114697311684
iteration 0 batch 740 training_loss 0.6901793251455568
iteration 0 batch 750 training_loss 0.6886953974383626
iteration 0 batch 760 training_loss 0.6916632528527511
iteration 0 batch 770 training_loss 0.6886953974383626
iteration 0 batch 780 training_loss 0.6901793251455568
iteration 0 batch 790 training_loss 0.6886953974383626
iteration 0 batch 800 training_loss 0.6886953974383626
iteration 0 batch 810 training_loss 0.6901793251455568
iteration 0 batch 820 training_loss 0.6901793251455568
iteration 0 batch 830 training_loss 0.6886953974383626
iteration 0 batch 840 training_loss 0.6916632528527511
iteration 0 batch 850 training_loss 0.6931471805599453
iteration 0 batch 860 training_loss 0.6872114697311684
iteration 0 batch 870 training_loss 0.6886953974383626
iteration 0 batch 880 training_loss 0.6931471805599453
iteration 0 batch 890 training_loss 0.6931471805599453
iteration 0 batch 900 training_loss 0.6872114697311684
iteration 0 batch 910 training_loss 0.6931471805599453
iteration 0 batch 920 training_loss 0.6916632528527511
iteration 0 batch 930 training_loss 0.6931471805599453
iteration 0 batch 940 training_loss 0.6901793251455568
iteration 0 batch 950 training_loss 0.6931471805599453
iteration 0 batch 960 training_loss 0.6916632528527511
iteration 0 batch 970 training_loss 0.6931471805599453
iteration 0 batch 980 training_loss 0.6901793251455568
iteration 0 batch 990 training_loss 0.6931471805599453
iteration 0 batch 1000 training_loss 0.6901793251455568
iteration 0 batch 1010 training_loss 0.6901793251455568
iteration 0 batch 1020 training_loss 0.6872114697311684
iteration 0 batch 1030 training_loss 0.6872114697311684
iteration 0 batch 1040 training_loss 0.6916632528527511
iteration 0 batch 1050 training_loss 0.6916632528527511
iteration 0 batch 1060 training_loss 0.6931471805599453
iteration 0 batch 1070 training_loss 0.6872114697311683
iteration 0 batch 1080 training_loss 0.6931471805599453
iteration 0 batch 1090 training_loss 0.6842436143167799
iteration 0 batch 1100 training_loss 0.6886953974383626
iteration 0 batch 1110 training_loss 0.6931471805599453
iteration 0 batch 1120 training_loss 0.6901793251455568
iteration 0 batch 1130 training_loss 0.6916632528527511
iteration 0 batch 1140 training_loss 0.6901793251455568
iteration 0 batch 1150 training_loss 0.6857275420239741
iteration 0 batch 1160 training_loss 0.6886953974383626
iteration 0 batch 1170 training_loss 0.6916632528527511
iteration 0 batch 1180 training_loss 0.6886953974383625
iteration 0 batch 1190 training_loss 0.6931471805599453
iteration 0 batch 1200 training_loss 0.6886953974383626
iteration 0 batch 1210 training_loss 0.6916632528527511
iteration 0 batch 1220 training_loss 0.6916632528527511
iteration 0 batch 1230 training_loss 0.6916632528527511
iteration 0 batch 1240 training_loss 0.6916632528527511
iteration 0 batch 1250 training_loss 0.6916632528527511
iteration 0 batch 1260 training_loss 0.6901793251455568
iteration 0 batch 1270 training_loss 0.6901793251455568
iteration 0 batch 1280 training_loss 0.6931471805599453
iteration 0 batch 1290 training_loss 0.6857275420239741
iteration 0 batch 1300 training_loss 0.6872114697311684
iteration 0 batch 1310 training_loss 0.6857275420239741
iteration 0 batch 1320 training_loss 0.6931471805599453
iteration 0 batch 1330 training_loss 0.6901793251455568
iteration 0 batch 1340 training_loss 0.6916632528527511
iteration 0 batch 1350 training_loss 0.6857275420239741
iteration 0 batch 1360 training_loss 0.6931471805599453
iteration 0 batch 1370 training_loss 0.6901793251455568
iteration 0 batch 1380 training_loss 0.6916632528527511
iteration 0 batch 1390 training_loss 0.6916632528527511
iteration 0 batch 1400 training_loss 0.6886953974383626
iteration 0 batch 1410 training_loss 0.6916632528527511
iteration 0 batch 1420 training_loss 0.6916632528527511
iteration 0 batch 1430 training_loss 0.6931471805599453
iteration 0 batch 1440 training_loss 0.6872114697311684
iteration 0 batch 1450 training_loss 0.6931471805599453
iteration 0 batch 1460 training_loss 0.6901793251455568
iteration 0 batch 1470 training_loss 0.6931471805599453
iteration 0 batch 1480 training_loss 0.6857275420239741
iteration 0 batch 1490 training_loss 0.6916632528527511
iteration 0 batch 1500 training_loss 0.6931471805599453
iteration 0 batch 1510 training_loss 0.6916632528527511
iteration 0 batch 1520 training_loss 0.6931471805599453
iteration 0 batch 1530 training_loss 0.6901793251455568
iteration 0 batch 1540 training_loss 0.6872114697311684
iteration 0 batch 1550 training_loss 0.6842436143167799
iteration 0 batch 1560 training_loss 0.6931471805599453
iteration 0 batch 1570 training_loss 0.6901793251455568
iteration 0 batch 1580 training_loss 0.6901793251455568
iteration 0 batch 1590 training_loss 0.6916632528527511
iteration 0 batch 1600 training_loss 0.6916632528527511
iteration 0 batch 1610 training_loss 0.6901793251455568
iteration 0 batch 1620 training_loss 0.6901793251455568
iteration 0 batch 1630 training_loss 0.6886953974383626
iteration 0 batch 1640 training_loss 0.6901793251455568
iteration 0 batch 1650 training_loss 0.6931471805599453
iteration 0 batch 1660 training_loss 0.6886953974383626
iteration 0 batch 1670 training_loss 0.6901793251455568
iteration 0 batch 1680 training_loss 0.6872114697311684
iteration 0 batch 1690 training_loss 0.6931471805599453
iteration 0 batch 1700 training_loss 0.6931471805599453
iteration 0 batch 1710 training_loss 0.6916632528527511
iteration 0 batch 1720 training_loss 0.6886953974383626
iteration 0 batch 1730 training_loss 0.6872114697311684
iteration 0 batch 1740 training_loss 0.6931471805599453
iteration 0 batch 1750 training_loss 0.6916632528527511
iteration 0 batch 1760 training_loss 0.6886953974383626
iteration 0 batch 1770 training_loss 0.6886953974383625
iteration 0 batch 1780 training_loss 0.6901793251455568
iteration 0 batch 1790 training_loss 0.6872114697311684
iteration 0 batch 1800 training_loss 0.6901793251455568
iteration 0 batch 1810 training_loss 0.6931471805599453
iteration 0 batch 1820 training_loss 0.6916632528527511
iteration 0 batch 1830 training_loss 0.6901793251455568
iteration 0 batch 1840 training_loss 0.6886953974383626
iteration 0 batch 1850 training_loss 0.6901793251455568
iteration 0 batch 1860 training_loss 0.6916632528527511
iteration 0 batch 1870 training_loss 0.6901793251455568
iteration 0 batch 1880 training_loss 0.6872114697311684
iteration 0 batch 1890 training_loss 0.6886953974383626
iteration 0 batch 1900 training_loss 0.6916632528527511
iteration 0 batch 1910 training_loss 0.6916632528527511
iteration 0 batch 1920 training_loss 0.6931471805599453
iteration 0 batch 1930 training_loss 0.6901793251455568
iteration 0 batch 1940 training_loss 0.6901793251455568
iteration 0 batch 1950 training_loss 0.6931471805599453
iteration 0 batch 1960 training_loss 0.6901793251455568
iteration 0 batch 1970 training_loss 0.6916632528527511
iteration 0 batch 1980 training_loss 0.6886953974383626
iteration 0 batch 1990 training_loss 0.6886953974383626
iteration 0 batch 2000 training_loss 0.6931471805599453
iteration 0 batch 2010 training_loss 0.6872114697311684
iteration 0 batch 2020 training_loss 0.6916632528527511
iteration 0 batch 2030 training_loss 0.6886953974383626
iteration 0 batch 2040 training_loss 0.6886953974383626
iteration 0 batch 2050 training_loss 0.6931471805599453
iteration 0 batch 2060 training_loss 0.6886953974383626
iteration 0 batch 2070 training_loss 0.6901793251455568
iteration 0 batch 2080 training_loss 0.6916632528527511
iteration 0 batch 2090 training_loss 0.6931471805599453
iteration 0 batch 2100 training_loss 0.6901793251455568
iteration 0 batch 2110 training_loss 0.6931471805599453
iteration 0 batch 2120 training_loss 0.6901793251455568
iteration 0 batch 2130 training_loss 0.6916632528527511
iteration 0 batch 2140 training_loss 0.6931471805599453
iteration 0 batch 2150 training_loss 0.6886953974383626
iteration 0 batch 2160 training_loss 0.6931471805599453
iteration 0 batch 2170 training_loss 0.6886953974383626
iteration 0 batch 2180 training_loss 0.6916632528527511
iteration 0 batch 2190 training_loss 0.6916632528527511
iteration 0 batch 2200 training_loss 0.6872114697311684
iteration 0 batch 2210 training_loss 0.6916632528527511
iteration 0 batch 2220 training_loss 0.6916632528527511
iteration 0 batch 2230 training_loss 0.6931471805599453
iteration 0 batch 2240 training_loss 0.6886953974383626
iteration 0 batch 2250 training_loss 0.6916632528527511
iteration 0 batch 2260 training_loss 0.6901793251455568
iteration 0 batch 2270 training_loss 0.6901793251455568
iteration 0 batch 2280 training_loss 0.6916632528527511
iteration 0 batch 2290 training_loss 0.6916632528527511
iteration 0 batch 2300 training_loss 0.6886953974383626
iteration 0 batch 2310 training_loss 0.6901793251455568
iteration 0 batch 2320 training_loss 0.6931471805599453
iteration 0 batch 2330 training_loss 0.6931471805599453
iteration 0 batch 2340 training_loss 0.6872114697311684
iteration 0 batch 2350 training_loss 0.6931471805599453
iteration 0 batch 2360 training_loss 0.6886953974383626
iteration 0 batch 2370 training_loss 0.6872114697311684
iteration 0 batch 2380 training_loss 0.6931471805599453
iteration 0 batch 2390 training_loss 0.6916632528527511
iteration 0 batch 2400 training_loss 0.6931471805599453
iteration 0 batch 2410 training_loss 0.6916632528527511
iteration 0 batch 2420 training_loss 0.6931471805599453
iteration 0 batch 2430 training_loss 0.6916632528527511
iteration 0 batch 2440 training_loss 0.6931471805599453
iteration 0 batch 2450 training_loss 0.6916632528527511
iteration 0 batch 2460 training_loss 0.6931471805599453
iteration 0 batch 2470 training_loss 0.6931471805599453
iteration 0 batch 2480 training_loss 0.6916632528527511
iteration 0 batch 2490 training_loss 0.6901793251455568
iteration 0 batch 2500 training_loss 0.6931471805599453
iteration 0 batch 2510 training_loss 0.6916632528527511
iteration 0 batch 2520 training_loss 0.6916632528527511
iteration 0 batch 2530 training_loss 0.6931471805599453
iteration 0 batch 2540 training_loss 0.6931471805599453
iteration 0 batch 2550 training_loss 0.6901793251455568
iteration 0 batch 2560 training_loss 0.6931471805599453
iteration 0 batch 2570 training_loss 0.6886953974383626
iteration 0 batch 2580 training_loss 0.6916632528527511
iteration 0 batch 2590 training_loss 0.6916632528527511
iteration 0 batch 2600 training_loss 0.6901793251455568
iteration 0 batch 2610 training_loss 0.6886953974383626
iteration 0 batch 2620 training_loss 0.6886953974383625
iteration 0 batch 2630 training_loss 0.6901793251455568
iteration 0 batch 2640 training_loss 0.6901793251455568
iteration 0 batch 2650 training_loss 0.6931471805599453
iteration 0 batch 2660 training_loss 0.6916632528527511
iteration 0 batch 2670 training_loss 0.6931471805599453
iteration 0 batch 2680 training_loss 0.6916632528527511
iteration 0 batch 2690 training_loss 0.6916632528527511
iteration 0 batch 2700 training_loss 0.6916632528527511
iteration 0 batch 2710 training_loss 0.6931471805599453
iteration 0 batch 2720 training_loss 0.6886953974383626
iteration 0 batch 2730 training_loss 0.6872114697311684
iteration 0 batch 2740 training_loss 0.6901793251455568
iteration 0 batch 2750 training_loss 0.6872114697311684
iteration 0 batch 2760 training_loss 0.6931471805599453
iteration 0 batch 2770 training_loss 0.6931471805599453
iteration 0 batch 2780 training_loss 0.6931471805599453
iteration 0 batch 2790 training_loss 0.6931471805599453
iteration 0 batch 2800 training_loss 0.6901793251455568
iteration 0 batch 2810 training_loss 0.6931471805599453
iteration 0 batch 2820 training_loss 0.6931471805599453
iteration 0 batch 2830 training_loss 0.6916632528527511
iteration 0 batch 2840 training_loss 0.6901793251455568
iteration 0 batch 2850 training_loss 0.6931471805599453
iteration 0 batch 2860 training_loss 0.6931471805599453
iteration 0 batch 2870 training_loss 0.6886953974383626
iteration 0 batch 2880 training_loss 0.6916632528527511
iteration 0 batch 2890 training_loss 0.6916632528527511
iteration 0 batch 2900 training_loss 0.6886953974383626
iteration 0 batch 2910 training_loss 0.6931471805599453
iteration 0 batch 2920 training_loss 0.6916632528527511
iteration 0 batch 2930 training_loss 0.6872114697311684
iteration 0 batch 2940 training_loss 0.6886953974383626
iteration 0 batch 2950 training_loss 0.6901793251455568
iteration 0 batch 2960 training_loss 0.6901793251455568
iteration 0 batch 2970 training_loss 0.6916632528527511
iteration 0 batch 2980 training_loss 0.6916632528527511
iteration 0 batch 2990 training_loss 0.6886953974383626
iteration 0 batch 3000 training_loss 0.6916632528527511
iteration 0 batch 3010 training_loss 0.6872114697311684
iteration 0 batch 3020 training_loss 0.6901793251455568
iteration 0 batch 3030 training_loss 0.6886953974383626
iteration 0 batch 3040 training_loss 0.6931471805599453
iteration 0 batch 3050 training_loss 0.6916632528527511
iteration 0 batch 3060 training_loss 0.6916632528527511
iteration 0 batch 3070 training_loss 0.6886953974383626
iteration 0 batch 3080 training_loss 0.6931471805599453
iteration 0 batch 3090 training_loss 0.6886953974383626
iteration 0 batch 3100 training_loss 0.6886953974383626
iteration 0 batch 3110 training_loss 0.6916632528527511
iteration 0 batch 3120 training_loss 0.6931471805599453
iteration 0 batch 3130 training_loss 0.6916632528527511
iteration 0 batch 3140 training_loss 0.6931471805599453
iteration 0 batch 3150 training_loss 0.6916632528527511
iteration 0 batch 3160 training_loss 0.6916632528527511
iteration 0 batch 3170 training_loss 0.6901793251455568
iteration 0 batch 3180 training_loss 0.6916632528527511
iteration 0 batch 3190 training_loss 0.6872114697311684
iteration 0 batch 3200 training_loss 0.6901793251455568
iteration 0 batch 3210 training_loss 0.6916632528527511
iteration 0 batch 3220 training_loss 0.6886953974383626
iteration 0 batch 3230 training_loss 0.6916632528527511
iteration 0 batch 3240 training_loss 0.6916632528527511
iteration 0 batch 3250 training_loss 0.6916632528527511
iteration 0 batch 3260 training_loss 0.6931471805599453
iteration 0 batch 3270 training_loss 0.6931471805599453
iteration 0 batch 3280 training_loss 0.6931471805599453
iteration 0 batch 3290 training_loss 0.6931471805599453
iteration 0 batch 3300 training_loss 0.6916632528527511
iteration 0 batch 3310 training_loss 0.6931471805599453
iteration 0 batch 3320 training_loss 0.6931471805599453
iteration 0 batch 3330 training_loss 0.6931471805599453
iteration 0 batch 3340 training_loss 0.6931471805599453
iteration 0 batch 3350 training_loss 0.6931471805599453
iteration 0 batch 3360 training_loss 0.6916632528527511
iteration 0 batch 3370 training_loss 0.6901793251455568
iteration 0 batch 3380 training_loss 0.6916632528527511
iteration 0 batch 3390 training_loss 0.6901793251455568
iteration 0 batch 3400 training_loss 0.6901793251455568
iteration 0 batch 3410 training_loss 0.6931471805599453
iteration 0 batch 3420 training_loss 0.6886953974383626
iteration 0 batch 3430 training_loss 0.6916632528527511
iteration 0 batch 3440 training_loss 0.6931471805599453
iteration 0 batch 3450 training_loss 0.6901793251455568
iteration 0 batch 3460 training_loss 0.6916632528527511
iteration 0 batch 3470 training_loss 0.6857275420239741
iteration 0 batch 3480 training_loss 0.6901793251455568
iteration 0 batch 3490 training_loss 0.6931471805599453
iteration 0 batch 3500 training_loss 0.6931471805599453
iteration 0 batch 3510 training_loss 0.6931471805599453
iteration 0 batch 3520 training_loss 0.6916632528527511
iteration 0 batch 3530 training_loss 0.6916632528527511
iteration 0 batch 3540 training_loss 0.6916632528527511
iteration 0 batch 3550 training_loss 0.6901793251455568
iteration 0 batch 3560 training_loss 0.6901793251455568
iteration 0 batch 3570 training_loss 0.6931471805599453
iteration 0 batch 3580 training_loss 0.6931471805599453
iteration 0 batch 3590 training_loss 0.6916632528527511
iteration 0 batch 3600 training_loss 0.6916632528527511
iteration 0 batch 3610 training_loss 0.6931471805599453
iteration 0 batch 3620 training_loss 0.6886953974383626
iteration 0 batch 3630 training_loss 0.6916632528527511
iteration 0 batch 3640 training_loss 0.6916632528527511
iteration 0 batch 3650 training_loss 0.6886953974383626
iteration 0 batch 3660 training_loss 0.6901793251455568
iteration 0 batch 3670 training_loss 0.6901793251455568
iteration 0 batch 3680 training_loss 0.6931471805599453
iteration 0 batch 3690 training_loss 0.6916632528527511
iteration 0 batch 3700 training_loss 0.6931471805599453
iteration 0 batch 3710 training_loss 0.6931471805599453
iteration 0 batch 3720 training_loss 0.6916632528527511
iteration 0 batch 3730 training_loss 0.6931471805599453
iteration 0 batch 3740 training_loss 0.6916632528527511
iteration 0 batch 3750 training_loss 0.6901793251455568
iteration 0 batch 3760 training_loss 0.6916632528527511
iteration 0 batch 3770 training_loss 0.6931471805599453
iteration 0 batch 3780 training_loss 0.6931471805599453
iteration 0 batch 3790 training_loss 0.6901793251455568
iteration 0 batch 3800 training_loss 0.6916632528527511
iteration 0 batch 3810 training_loss 0.6916632528527511
iteration 0 batch 3820 training_loss 0.6916632528527511
iteration 0 batch 3830 training_loss 0.6931471805599453
iteration 0 batch 3840 training_loss 0.6901793251455568
iteration 0 batch 3850 training_loss 0.6901793251455568
iteration 0 batch 3860 training_loss 0.6916632528527511
iteration 0 batch 3870 training_loss 0.6931471805599453
iteration 0 batch 3880 training_loss 0.6931471805599453
iteration 0 batch 3890 training_loss 0.6916632528527511
iteration 0 batch 3900 training_loss 0.6916632528527511
iteration 0 batch 3910 training_loss 0.6931471805599453
iteration 0 batch 3920 training_loss 0.6872114697311684
iteration 0 batch 3930 training_loss 0.6901793251455568
iteration 0 batch 3940 training_loss 0.6901793251455568
iteration 0 batch 3950 training_loss 0.6916632528527511
iteration 0 batch 3960 training_loss 0.6916632528527511
iteration 0 batch 3970 training_loss 0.6916632528527511
iteration 0 batch 3980 training_loss 0.6916632528527511
iteration 0 batch 3990 training_loss 0.6916632528527511
iteration 0 batch 4000 training_loss 0.6916632528527511
iteration 0 batch 4010 training_loss 0.6931471805599453
iteration 0 batch 4020 training_loss 0.6916632528527511
iteration 0 batch 4030 training_loss 0.6916632528527511
iteration 0 batch 4040 training_loss 0.6901793251455568
iteration 0 batch 4050 training_loss 0.6931471805599453
iteration 0 batch 4060 training_loss 0.6916632528527511
iteration 0 batch 4070 training_loss 0.6931471805599453
iteration 0 batch 4080 training_loss 0.6901793251455568
iteration 0 batch 4090 training_loss 0.6872114697311684
iteration 0 batch 4100 training_loss 0.6901793251455568
iteration 0 batch 4110 training_loss 0.6916632528527511
iteration 0 batch 4120 training_loss 0.6916632528527511
iteration 0 batch 4130 training_loss 0.6916632528527511
iteration 0 batch 4140 training_loss 0.6916632528527511
iteration 0 batch 4150 training_loss 0.6886953974383626
iteration 0 batch 4160 training_loss 0.6916632528527511
iteration 0 batch 4170 training_loss 0.6931471805599453
iteration 0 batch 4180 training_loss 0.6916632528527511
iteration 0 batch 4190 training_loss 0.6916632528527511
iteration 0 batch 4200 training_loss 0.6886953974383626
iteration 0 batch 4210 training_loss 0.6901793251455568
iteration 0 batch 4220 training_loss 0.6931471805599453
iteration 0 batch 4230 training_loss 0.6901793251455568
iteration 0 batch 4240 training_loss 0.6931471805599453
iteration 0 batch 4250 training_loss 0.6872114697311684
iteration 0 batch 4260 training_loss 0.6916632528527511
iteration 0 batch 4270 training_loss 0.6901793251455568
iteration 0 batch 4280 training_loss 0.6916632528527511
iteration 0 batch 4290 training_loss 0.6931471805599453
iteration 0 batch 4300 training_loss 0.6916632528527511
iteration 0 batch 4310 training_loss 0.6901793251455568
iteration 0 batch 4320 training_loss 0.6931471805599453
iteration 0 batch 4330 training_loss 0.6931471805599453
iteration 0 batch 4340 training_loss 0.6916632528527511
iteration 0 batch 4350 training_loss 0.6916632528527511
iteration 0 batch 4360 training_loss 0.6886953974383626
iteration 0 batch 4370 training_loss 0.6916632528527511
iteration 0 batch 4380 training_loss 0.6931471805599453
iteration 0 batch 4390 training_loss 0.6916632528527511
iteration 0 batch 4400 training_loss 0.6931471805599453
iteration 0 batch 4410 training_loss 0.6931471805599453
iteration 0 batch 4420 training_loss 0.6886953974383626
iteration 0 batch 4430 training_loss 0.6886953974383626
iteration 0 batch 4440 training_loss 0.6931471805599453
iteration 0 batch 4450 training_loss 0.6916632528527511
iteration 0 batch 4460 training_loss 0.6886953974383626
iteration 0 batch 4470 training_loss 0.6931471805599453
iteration 0 batch 4480 training_loss 0.6916632528527511
iteration 0 batch 4490 training_loss 0.6916632528527511
iteration 0 batch 4500 training_loss 0.6872114697311684
iteration 0 batch 4510 training_loss 0.6916632528527511
iteration 0 batch 4520 training_loss 0.6931471805599453
iteration 0 batch 4530 training_loss 0.6931471805599453
iteration 0 batch 4540 training_loss 0.6916632528527511
iteration 0 batch 4550 training_loss 0.6916632528527511
iteration 0 batch 4560 training_loss 0.6931471805599453
iteration 0 batch 4570 training_loss 0.6842436143167799
iteration 0 batch 4580 training_loss 0.6916632528527511
iteration 0 batch 4590 training_loss 0.6916632528527511
iteration 0 batch 4600 training_loss 0.6857275420239741
iteration 0 batch 4610 training_loss 0.6931471805599453
iteration 0 batch 4620 training_loss 0.6901793251455568
iteration 0 batch 4630 training_loss 0.6931471805599453
iteration 0 batch 4640 training_loss 0.6916632528527511
iteration 0 batch 4650 training_loss 0.6901793251455568
iteration 0 batch 4660 training_loss 0.6916632528527511
iteration 0 batch 4670 training_loss 0.6931471805599453
iteration 0 batch 4680 training_loss 0.6901793251455568
iteration 0 batch 4690 training_loss 0.6931471805599453
iteration 0 batch 4700 training_loss 0.6901793251455568
iteration 0 batch 4710 training_loss 0.6931471805599453
iteration 0 batch 4720 training_loss 0.6916632528527511
iteration 0 batch 4730 training_loss 0.6916632528527511
iteration 0 batch 4740 training_loss 0.6886953974383626
iteration 0 batch 4750 training_loss 0.6931471805599453
iteration 0 batch 4760 training_loss 0.6931471805599453
iteration 0 batch 4770 training_loss 0.6916632528527511
iteration 0 batch 4780 training_loss 0.6916632528527511
iteration 0 batch 4790 training_loss 0.6916632528527511
iteration 0 batch 4800 training_loss 0.6916632528527511
iteration 0 batch 4810 training_loss 0.6916632528527511
iteration 0 batch 4820 training_loss 0.6901793251455568
iteration 0 batch 4830 training_loss 0.6931471805599453
iteration 0 batch 4840 training_loss 0.6931471805599453
iteration 0 batch 4850 training_loss 0.6931471805599453
iteration 0 batch 4860 training_loss 0.6931471805599453
iteration 0 batch 4870 training_loss 0.6916632528527511
iteration 0 batch 4880 training_loss 0.6931471805599453
iteration 0 batch 4890 training_loss 0.6901793251455568
iteration 0 batch 4900 training_loss 0.6931471805599453
iteration 0 batch 4910 training_loss 0.6931471805599453
iteration 0 batch 4920 training_loss 0.6916632528527511
iteration 0 batch 4930 training_loss 0.6901793251455568
iteration 0 batch 4940 training_loss 0.6916632528527511
iteration 0 batch 4950 training_loss 0.6872114697311684
iteration 0 batch 4960 training_loss 0.6901793251455568
iteration 0 batch 4970 training_loss 0.6931471805599453
iteration 0 batch 4980 training_loss 0.6916632528527511
iteration 0 batch 4990 training_loss 0.6901793251455568
iteration 0 batch 5000 training_loss 0.6916632528527511
iteration 0 batch 5010 training_loss 0.6886953974383626
iteration 0 batch 5020 training_loss 0.6931471805599453
iteration 0 batch 5030 training_loss 0.6931471805599453
iteration 0 batch 5040 training_loss 0.6931471805599453
iteration 0 batch 5050 training_loss 0.6916632528527511
iteration 0 batch 5060 training_loss 0.6916632528527511
iteration 0 batch 5070 training_loss 0.6901793251455568
iteration 0 batch 5080 training_loss 0.6916632528527511
iteration 0 batch 5090 training_loss 0.6916632528527511
iteration 0 batch 5100 training_loss 0.6916632528527511
iteration 0 batch 5110 training_loss 0.6931471805599453
iteration 0 batch 5120 training_loss 0.6916632528527511
iteration 0 batch 5130 training_loss 0.6931471805599453
iteration 0 batch 5140 training_loss 0.6901793251455568
iteration 0 batch 5150 training_loss 0.6931471805599453
iteration 0 batch 5160 training_loss 0.6931471805599453
iteration 0 batch 5170 training_loss 0.6916632528527511
iteration 0 batch 5180 training_loss 0.6931471805599453
iteration 0 batch 5190 training_loss 0.6931471805599453
iteration 0 batch 5200 training_loss 0.6916632528527511
iteration 0 batch 5210 training_loss 0.6916632528527511
iteration 0 batch 5220 training_loss 0.6931471805599453
iteration 0 batch 5230 training_loss 0.6931471805599453
iteration 0 batch 5240 training_loss 0.6916632528527511
iteration 0 batch 5250 training_loss 0.6916632528527511
iteration 0 batch 5260 training_loss 0.6931471805599453
iteration 0 batch 5270 training_loss 0.6916632528527511
iteration 0 batch 5280 training_loss 0.6931471805599453
iteration 0 batch 5290 training_loss 0.6901793251455568
iteration 0 batch 5300 training_loss 0.6916632528527511
iteration 0 batch 5310 training_loss 0.6886953974383626
iteration 0 batch 5320 training_loss 0.6901793251455568
iteration 0 batch 5330 training_loss 0.6916632528527511
iteration 0 batch 5340 training_loss 0.6916632528527511
iteration 0 batch 5350 training_loss 0.6916632528527511
iteration 0 batch 5360 training_loss 0.6916632528527511
iteration 0 batch 5370 training_loss 0.6931471805599453
iteration 0 batch 5380 training_loss 0.6916632528527511
iteration 0 batch 5390 training_loss 0.6916632528527511
iteration 0 batch 5400 training_loss 0.6886953974383626
iteration 0 batch 5410 training_loss 0.6931471805599453
iteration 0 batch 5420 training_loss 0.6916632528527511
iteration 0 batch 5430 training_loss 0.6931471805599453
iteration 0 batch 5440 training_loss 0.6916632528527511
iteration 0 batch 5450 training_loss 0.6931471805599453
iteration 0 batch 5460 training_loss 0.6931471805599453
iteration 0 batch 5470 training_loss 0.6931471805599453
iteration 0 batch 5480 training_loss 0.6916632528527511
iteration 0 batch 5490 training_loss 0.6901793251455568
iteration 0 batch 5500 training_loss 0.6931471805599453
iteration 0 batch 5510 training_loss 0.6931471805599453
iteration 0 batch 5520 training_loss 0.6916632528527511
iteration 0 batch 5530 training_loss 0.6842436143167799
iteration 0 batch 5540 training_loss 0.6901793251455568
iteration 0 batch 5550 training_loss 0.6931471805599453
iteration 0 batch 5560 training_loss 0.6931471805599453
iteration 0 batch 5570 training_loss 0.6901793251455568
iteration 0 batch 5580 training_loss 0.6931471805599453
iteration 0 batch 5590 training_loss 0.6931471805599453
iteration 0 batch 5600 training_loss 0.6931471805599453
iteration 0 batch 5610 training_loss 0.6931471805599453
iteration 0 batch 5620 training_loss 0.6901793251455568
iteration 0 batch 5630 training_loss 0.6901793251455568
iteration 0 batch 5640 training_loss 0.6886953974383626
iteration 0 batch 5650 training_loss 0.6931471805599453
iteration 0 batch 5660 training_loss 0.6931471805599453
iteration 0 batch 5670 training_loss 0.6916632528527511
iteration 0 batch 5680 training_loss 0.6901793251455568
iteration 0 batch 5690 training_loss 0.6916632528527511
iteration 0 batch 5700 training_loss 0.6916632528527511
iteration 0 batch 5710 training_loss 0.6916632528527511
iteration 0 batch 5720 training_loss 0.6916632528527511
iteration 0 batch 5730 training_loss 0.6916632528527511
iteration 0 batch 5740 training_loss 0.6931471805599453
iteration 0 batch 5750 training_loss 0.6916632528527511
iteration 0 batch 5760 training_loss 0.6931471805599453
iteration 0 batch 5770 training_loss 0.6931471805599453
iteration 0 batch 5780 training_loss 0.6931471805599453
iteration 0 batch 5790 training_loss 0.6916632528527511
iteration 0 batch 5800 training_loss 0.6931471805599453
iteration 0 batch 5810 training_loss 0.6931471805599453
iteration 0 batch 5820 training_loss 0.6916632528527511
iteration 0 batch 5830 training_loss 0.6901793251455568
iteration 0 batch 5840 training_loss 0.6916632528527511
iteration 0 batch 5850 training_loss 0.6901793251455568
iteration 0 batch 5860 training_loss 0.6931471805599453
iteration 0 batch 5870 training_loss 0.6916632528527511
iteration 0 batch 5880 training_loss 0.6916632528527511
iteration 0 batch 5890 training_loss 0.6886953974383626
iteration 0 batch 5900 training_loss 0.6916632528527511
iteration 0 batch 5910 training_loss 0.6901793251455568
iteration 0 batch 5920 training_loss 0.6916632528527511
iteration 0 batch 5930 training_loss 0.6916632528527511
iteration 0 batch 5940 training_loss 0.6931471805599453
iteration 0 batch 5950 training_loss 0.6931471805599453
iteration 0 batch 5960 training_loss 0.6916632528527511
iteration 0 batch 5970 training_loss 0.6931471805599453
iteration 0 batch 5980 training_loss 0.6931471805599453
iteration 0 batch 5990 training_loss 0.6931471805599453
iteration 0 batch 6000 training_loss 0.6916632528527511
iteration 0 batch 6010 training_loss 0.6916632528527511
iteration 0 batch 6020 training_loss 0.6901793251455568
iteration 0 batch 6030 training_loss 0.6916632528527511
iteration 0 batch 6040 training_loss 0.6916632528527511
iteration 0 batch 6050 training_loss 0.6931471805599453
iteration 0 batch 6060 training_loss 0.6931471805599453
iteration 0 batch 6070 training_loss 0.6886953974383626
iteration 0 batch 6080 training_loss 0.6931471805599453
iteration 0 batch 6090 training_loss 0.6901793251455568
iteration 0 batch 6100 training_loss 0.6901793251455568
iteration 0 batch 6110 training_loss 0.6931471805599453
iteration 0 batch 6120 training_loss 0.6916632528527511
iteration 0 batch 6130 training_loss 0.6901793251455568
iteration 0 batch 6140 training_loss 0.6916632528527511
iteration 0 batch 6150 training_loss 0.6916632528527511
iteration 0 batch 6160 training_loss 0.6931471805599453
iteration 0 batch 6170 training_loss 0.6916632528527511
iteration 0 batch 6180 training_loss 0.6916632528527511
iteration 0 batch 6190 training_loss 0.6931471805599453
iteration 0 batch 6200 training_loss 0.6931471805599453
iteration 0 batch 6210 training_loss 0.6916632528527511
iteration 0 batch 6220 training_loss 0.6916632528527511
iteration 0 batch 6230 training_loss 0.6916632528527511
iteration 0 batch 6240 training_loss 0.6931471805599453
iteration 0 batch 6250 training_loss 0.6901793251455568
iteration 0 batch 6260 training_loss 0.6931471805599453
iteration 0 batch 6270 training_loss 0.6931471805599453
iteration 0 batch 6280 training_loss 0.6931471805599453
iteration 0 batch 6290 training_loss 0.6901793251455568
iteration 0 batch 6300 training_loss 0.6931471805599453
iteration 0 batch 6310 training_loss 0.6931471805599453
iteration 0 batch 6320 training_loss 0.6916632528527511
iteration 0 batch 6330 training_loss 0.6931471805599453
iteration 0 batch 6340 training_loss 0.6916632528527511
iteration 0 batch 6350 training_loss 0.6916632528527511
iteration 0 batch 6360 training_loss 0.6916632528527511
iteration 0 batch 6370 training_loss 0.6931471805599453
iteration 0 batch 6380 training_loss 0.6916632528527511
iteration 0 batch 6390 training_loss 0.6901793251455568
iteration 0 batch 6400 training_loss 0.6931471805599453
iteration 0 batch 6410 training_loss 0.6931471805599453
iteration 0 batch 6420 training_loss 0.6916632528527511
iteration 0 batch 6430 training_loss 0.6916632528527511
iteration 0 batch 6440 training_loss 0.6931471805599453
iteration 0 batch 6450 training_loss 0.6931471805599453
iteration 0 batch 6460 training_loss 0.6931471805599453
iteration 0 batch 6470 training_loss 0.6931471805599453
iteration 0 batch 6480 training_loss 0.6901793251455568
iteration 0 batch 6490 training_loss 0.6901793251455568
iteration 0 batch 6500 training_loss 0.6886953974383626
iteration 0 batch 6510 training_loss 0.6931471805599453
iteration 0 batch 6520 training_loss 0.6916632528527511
iteration 0 batch 6530 training_loss 0.6931471805599453
iteration 0 batch 6540 training_loss 0.6931471805599453
iteration 0 batch 6550 training_loss 0.6931471805599453
iteration 0 batch 6560 training_loss 0.6931471805599453
iteration 0 batch 6570 training_loss 0.6916632528527511
iteration 0 batch 6580 training_loss 0.6916632528527511
iteration 0 batch 6590 training_loss 0.6931471805599453
iteration 0 batch 6600 training_loss 0.6931471805599453
iteration 0 batch 6610 training_loss 0.6931471805599453
iteration 0 batch 6620 training_loss 0.6872114697311684
iteration 0 batch 6630 training_loss 0.6916632528527511
iteration 0 batch 6640 training_loss 0.6916632528527511
iteration 0 batch 6650 training_loss 0.6916632528527511
iteration 0 batch 6660 training_loss 0.6931471805599453
iteration 0 batch 6670 training_loss 0.6901793251455568
iteration 0 batch 6680 training_loss 0.6916632528527511
iteration 0 batch 6690 training_loss 0.6931471805599453
iteration 0 batch 6700 training_loss 0.6916632528527511
iteration 0 batch 6710 training_loss 0.6931471805599453
iteration 0 batch 6720 training_loss 0.6916632528527511
iteration 0 batch 6730 training_loss 0.6931471805599453
iteration 0 batch 6740 training_loss 0.6916632528527511
iteration 0 batch 6750 training_loss 0.6916632528527511
iteration 0 batch 6760 training_loss 0.6901793251455568
iteration 0 batch 6770 training_loss 0.6901793251455568
iteration 0 batch 6780 training_loss 0.6931471805599453
iteration 0 batch 6790 training_loss 0.6931471805599453
iteration 0 batch 6800 training_loss 0.6916632528527511
iteration 0 batch 6810 training_loss 0.6916632528527511
iteration 0 batch 6820 training_loss 0.6886953974383626
iteration 0 batch 6830 training_loss 0.6916632528527511
iteration 0 batch 6840 training_loss 0.6931471805599453
iteration 0 batch 6850 training_loss 0.6931471805599453
iteration 0 batch 6860 training_loss 0.6916632528527511
iteration 0 batch 6870 training_loss 0.6872114697311684
iteration 0 batch 6880 training_loss 0.6931471805599453
iteration 0 batch 6890 training_loss 0.6827596866095857
iteration 0 batch 6900 training_loss 0.6901793251455568
iteration 0 batch 6910 training_loss 0.6931471805599453
iteration 0 batch 6920 training_loss 0.6916632528527511
iteration 0 batch 6930 training_loss 0.6931471805599453
iteration 0 batch 6940 training_loss 0.6901793251455568
iteration 0 batch 6950 training_loss 0.6901793251455568
iteration 0 batch 6960 training_loss 0.6931471805599453
iteration 0 batch 6970 training_loss 0.6916632528527511
iteration 0 batch 6980 training_loss 0.6931471805599453
iteration 0 batch 6990 training_loss 0.6916632528527511
iteration 0 batch 7000 training_loss 0.6931471805599453
iteration 0 batch 7010 training_loss 0.6931471805599453
iteration 0 batch 7020 training_loss 0.6916632528527511
iteration 0 batch 7030 training_loss 0.6916632528527511
iteration 0 batch 7040 training_loss 0.6916632528527511
iteration 0 batch 7050 training_loss 0.6916632528527511
iteration 0 batch 7060 training_loss 0.6931471805599453
iteration 0 batch 7070 training_loss 0.6931471805599453
iteration 0 batch 7080 training_loss 0.6931471805599453
iteration 0 batch 7090 training_loss 0.6916632528527511
iteration 0 batch 7100 training_loss 0.6886953974383626
iteration 0 batch 7110 training_loss 0.6916632528527511
iteration 0 batch 7120 training_loss 0.6916632528527511
iteration 0 batch 7130 training_loss 0.6931471805599453
iteration 0 batch 7140 training_loss 0.6931471805599453
iteration 0 batch 7150 training_loss 0.6931471805599453
iteration 0 batch 7160 training_loss 0.6931471805599453
iteration 0 batch 7170 training_loss 0.6931471805599453
iteration 0 batch 7180 training_loss 0.6901793251455568
iteration 0 batch 7190 training_loss 0.6931471805599453
iteration 0 batch 7200 training_loss 0.6931471805599453
iteration 0 batch 7210 training_loss 0.6931471805599453
iteration 0 batch 7220 training_loss 0.6931471805599453
iteration 0 batch 7230 training_loss 0.6916632528527511
iteration 0 batch 7240 training_loss 0.6916632528527511
iteration 0 batch 7250 training_loss 0.6931471805599453
iteration 0 batch 7260 training_loss 0.6931471805599453
iteration 0 batch 7270 training_loss 0.6931471805599453
iteration 0 batch 7280 training_loss 0.6931471805599453
iteration 0 batch 7290 training_loss 0.6886953974383626
iteration 0 batch 7300 training_loss 0.6931471805599453
iteration 0 batch 7310 training_loss 0.6916632528527511
iteration 0 batch 7320 training_loss 0.6901793251455568
iteration 0 batch 7330 training_loss 0.6931471805599453
iteration 0 batch 7340 training_loss 0.6901793251455568
iteration 0 batch 7350 training_loss 0.6931471805599453
iteration 0 batch 7360 training_loss 0.6931471805599453
iteration 0 batch 7370 training_loss 0.6916632528527511
iteration 0 batch 7380 training_loss 0.6931471805599453
iteration 0 batch 7390 training_loss 0.6916632528527511
iteration 0 batch 7400 training_loss 0.6931471805599453
iteration 0 batch 7410 training_loss 0.6931471805599453
iteration 0 batch 7420 training_loss 0.6931471805599453
iteration 0 batch 7430 training_loss 0.6931471805599453
iteration 0 batch 7440 training_loss 0.6916632528527511
iteration 0 batch 7450 training_loss 0.6916632528527511
iteration 0 batch 7460 training_loss 0.6916632528527511
iteration 0 batch 7470 training_loss 0.6931471805599453
iteration 0 batch 7480 training_loss 0.6931471805599453
iteration 0 batch 7490 training_loss 0.6916632528527511
iteration 0 batch 7500 training_loss 0.6931471805599453
iteration 0 batch 7510 training_loss 0.6931471805599453
iteration 0 batch 7520 training_loss 0.6916632528527511
iteration 0 batch 7530 training_loss 0.6916632528527511
iteration 0 batch 7540 training_loss 0.6916632528527511
iteration 0 batch 7550 training_loss 0.6901793251455568
iteration 0 batch 7560 training_loss 0.6901793251455568
iteration 0 batch 7570 training_loss 0.6901793251455568
iteration 0 batch 7580 training_loss 0.6931471805599453
iteration 0 batch 7590 training_loss 0.6901793251455568
iteration 0 batch 7600 training_loss 0.6931471805599453
iteration 0 batch 7610 training_loss 0.6901793251455568
iteration 0 batch 7620 training_loss 0.6931471805599453
iteration 0 batch 7630 training_loss 0.6901793251455568
iteration 0 batch 7640 training_loss 0.6916632528527511
iteration 0 batch 7650 training_loss 0.6931471805599453
iteration 0 batch 7660 training_loss 0.6931471805599453
iteration 0 batch 7670 training_loss 0.6931471805599453
iteration 0 batch 7680 training_loss 0.6916632528527511
iteration 0 batch 7690 training_loss 0.6931471805599453
iteration 0 batch 7700 training_loss 0.6931471805599453
iteration 0 batch 7710 training_loss 0.6931471805599453
iteration 0 batch 7720 training_loss 0.6916632528527511
iteration 0 batch 7730 training_loss 0.6931471805599453
iteration 0 batch 7740 training_loss 0.6886953974383626
iteration 0 batch 7750 training_loss 0.6916632528527511
iteration 0 batch 7760 training_loss 0.6901793251455568
iteration 0 batch 7770 training_loss 0.6886953974383626
iteration 0 batch 7780 training_loss 0.6916632528527511
iteration 0 batch 7790 training_loss 0.6931471805599453
iteration 0 batch 7800 training_loss 0.6916632528527511
iteration 0 batch 7810 training_loss 0.6931471805599453
iteration 0 batch 7820 training_loss 0.6931471805599453
iteration 0 batch 7830 training_loss 0.6916632528527511
iteration 0 batch 7840 training_loss 0.6916632528527511
iteration 0 batch 7850 training_loss 0.6931471805599453
iteration 0 batch 7860 training_loss 0.6931471805599453
iteration 0 batch 7870 training_loss 0.6916632528527511
iteration 0 batch 7880 training_loss 0.6916632528527511
iteration 0 batch 7890 training_loss 0.6916632528527511
iteration 0 batch 7900 training_loss 0.6886953974383626
iteration 0 batch 7910 training_loss 0.6916632528527511
iteration 0 batch 7920 training_loss 0.6916632528527511
iteration 0 batch 7930 training_loss 0.6916632528527511
iteration 0 batch 7940 training_loss 0.6931471805599453
iteration 0 batch 7950 training_loss 0.6931471805599453
iteration 0 batch 7960 training_loss 0.6931471805599453
iteration 0 batch 7970 training_loss 0.6901793251455568
iteration 0 batch 7980 training_loss 0.6916632528527511
iteration 0 batch 7990 training_loss 0.6931471805599453
iteration 0 batch 8000 training_loss 0.6931471805599453
iteration 0 batch 8010 training_loss 0.6901793251455568
iteration 0 batch 8020 training_loss 0.6931471805599453
iteration 0 batch 8030 training_loss 0.6916632528527511
iteration 0 batch 8040 training_loss 0.6931471805599453
iteration 0 batch 8050 training_loss 0.6916632528527511
iteration 0 batch 8060 training_loss 0.6931471805599453
iteration 0 batch 8070 training_loss 0.6916632528527511
iteration 0 batch 8080 training_loss 0.6931471805599453
iteration 0 batch 8090 training_loss 0.6931471805599453
iteration 0 batch 8100 training_loss 0.6931471805599453
iteration 0 batch 8110 training_loss 0.6886953974383626
iteration 0 batch 8120 training_loss 0.6931471805599453
iteration 0 batch 8130 training_loss 0.6886953974383625
iteration 0 batch 8140 training_loss 0.6931471805599453
iteration 0 batch 8150 training_loss 0.6931471805599453
iteration 0 batch 8160 training_loss 0.6931471805599453
iteration 0 batch 8170 training_loss 0.6931471805599453
iteration 0 batch 8180 training_loss 0.6886953974383626
iteration 0 batch 8190 training_loss 0.6931471805599453
iteration 0 batch 8200 training_loss 0.6901793251455568
iteration 0 batch 8210 training_loss 0.6931471805599453
iteration 0 batch 8220 training_loss 0.6872114697311684
iteration 0 batch 8230 training_loss 0.6916632528527511
iteration 0 batch 8240 training_loss 0.6916632528527511
iteration 0 batch 8250 training_loss 0.6916632528527511
iteration 0 batch 8260 training_loss 0.6931471805599453
iteration 0 batch 8270 training_loss 0.6931471805599453
iteration 0 batch 8280 training_loss 0.6916632528527511
iteration 0 batch 8290 training_loss 0.6916632528527511
iteration 0 batch 8300 training_loss 0.6931471805599453
iteration 0 batch 8310 training_loss 0.6916632528527511
iteration 0 batch 8320 training_loss 0.6931471805599453
iteration 0 batch 8330 training_loss 0.6931471805599453
iteration 0 batch 8340 training_loss 0.6901793251455568
iteration 0 batch 8350 training_loss 0.6931471805599453
iteration 0 batch 8360 training_loss 0.6901793251455568
iteration 0 batch 8370 training_loss 0.6931471805599453
iteration 0 batch 8380 training_loss 0.6916632528527511
iteration 0 batch 8390 training_loss 0.6916632528527511
iteration 0 batch 8400 training_loss 0.6931471805599453
iteration 0 batch 8410 training_loss 0.6901793251455568
iteration 0 batch 8420 training_loss 0.6901793251455568
iteration 0 batch 8430 training_loss 0.6916632528527511
iteration 0 batch 8440 training_loss 0.6901793251455568
iteration 0 batch 8450 training_loss 0.6931471805599453
iteration 0 batch 8460 training_loss 0.6931471805599453
iteration 0 batch 8470 training_loss 0.6916632528527511
iteration 0 batch 8480 training_loss 0.6901793251455568
iteration 0 batch 8490 training_loss 0.6931471805599453
iteration 0 batch 8500 training_loss 0.6931471805599453
iteration 0 batch 8510 training_loss 0.6901793251455568
iteration 0 batch 8520 training_loss 0.6931471805599453
iteration 0 batch 8530 training_loss 0.6916632528527511
iteration 0 batch 8540 training_loss 0.6916632528527511
iteration 0 batch 8550 training_loss 0.6931471805599453
iteration 0 batch 8560 training_loss 0.6916632528527511
iteration 0 batch 8570 training_loss 0.6931471805599453
iteration 0 batch 8580 training_loss 0.6931471805599453
iteration 0 batch 8590 training_loss 0.6916632528527511
iteration 0 batch 8600 training_loss 0.6931471805599453
iteration 0 batch 8610 training_loss 0.6916632528527511
iteration 0 batch 8620 training_loss 0.6931471805599453
iteration 0 batch 8630 training_loss 0.6916632528527511
iteration 0 batch 8640 training_loss 0.6931471805599453
iteration 0 batch 8650 training_loss 0.6931471805599453
iteration 0 batch 8660 training_loss 0.6931471805599453
iteration 0 batch 8670 training_loss 0.6916632528527511
iteration 0 batch 8680 training_loss 0.6931471805599453
iteration 0 batch 8690 training_loss 0.6916632528527511
iteration 0 batch 8700 training_loss 0.6916632528527511
iteration 0 batch 8710 training_loss 0.6931471805599453
iteration 0 batch 8720 training_loss 0.6916632528527511
iteration 0 batch 8730 training_loss 0.6931471805599453
iteration 0 batch 8740 training_loss 0.6916632528527511
iteration 0 batch 8750 training_loss 0.6916632528527511
iteration 0 batch 8760 training_loss 0.6916632528527511
iteration 0 batch 8770 training_loss 0.6916632528527511
iteration 0 batch 8780 training_loss 0.6931471805599453
iteration 0 batch 8790 training_loss 0.6931471805599453
iteration 0 batch 8800 training_loss 0.6916632528527511
iteration 0 batch 8810 training_loss 0.6931471805599453
iteration 0 batch 8820 training_loss 0.6916632528527511
iteration 0 batch 8830 training_loss 0.6901793251455568
iteration 0 batch 8840 training_loss 0.6931471805599453
iteration 0 batch 8850 training_loss 0.6931471805599453
iteration 0 batch 8860 training_loss 0.6916632528527511
iteration 0 batch 8870 training_loss 0.6931471805599453
iteration 0 batch 8880 training_loss 0.6931471805599453
iteration 0 batch 8890 training_loss 0.6901793251455568
iteration 0 batch 8900 training_loss 0.6931471805599453
iteration 0 batch 8910 training_loss 0.6931471805599453
iteration 0 batch 8920 training_loss 0.6916632528527511
iteration 0 batch 8930 training_loss 0.6931471805599453
iteration 0 batch 8940 training_loss 0.6931471805599453
iteration 0 batch 8950 training_loss 0.6931471805599453
iteration 0 batch 8960 training_loss 0.6931471805599453
iteration 0 batch 8970 training_loss 0.6931471805599453
iteration 0 batch 8980 training_loss 0.6931471805599453
iteration 0 batch 8990 training_loss 0.6931471805599453
iteration 0 batch 9000 training_loss 0.6931471805599453
iteration 0 batch 9010 training_loss 0.6931471805599453
iteration 0 batch 9020 training_loss 0.6931471805599453
iteration 0 batch 9030 training_loss 0.6916632528527511
iteration 0 batch 9040 training_loss 0.6916632528527511
iteration 0 batch 9050 training_loss 0.6931471805599453
iteration 0 batch 9060 training_loss 0.6931471805599453
iteration 0 batch 9070 training_loss 0.6916632528527511
iteration 0 batch 9080 training_loss 0.6901793251455568
iteration 0 batch 9090 training_loss 0.6931471805599453
iteration 0 batch 9100 training_loss 0.6931471805599453
iteration 0 batch 9110 training_loss 0.6916632528527511
iteration 0 batch 9120 training_loss 0.6931471805599453
iteration 0 batch 9130 training_loss 0.6916632528527511
iteration 0 batch 9140 training_loss 0.6916632528527511
iteration 0 batch 9150 training_loss 0.6916632528527511
iteration 0 batch 9160 training_loss 0.6931471805599453
iteration 0 batch 9170 training_loss 0.6931471805599453
iteration 0 batch 9180 training_loss 0.6901793251455568
iteration 0 batch 9190 training_loss 0.6931471805599453
iteration 0 batch 9200 training_loss 0.6931471805599453
iteration 0 batch 9210 training_loss 0.6916632528527511
iteration 0 batch 9220 training_loss 0.6931471805599453
iteration 0 batch 9230 training_loss 0.6931471805599453
iteration 0 batch 9240 training_loss 0.6931471805599453
iteration 0 batch 9250 training_loss 0.6931471805599453
iteration 0 batch 9260 training_loss 0.6931471805599453
iteration 0 batch 9270 training_loss 0.6931471805599453
iteration 0 batch 9280 training_loss 0.6872114697311684
iteration 0 batch 9290 training_loss 0.6931471805599453
iteration 0 batch 9300 training_loss 0.6931471805599453
iteration 0 batch 9310 training_loss 0.6916632528527511
iteration 0 batch 9320 training_loss 0.6931471805599453
iteration 0 batch 9330 training_loss 0.6916632528527511
iteration 0 batch 9340 training_loss 0.6931471805599453
iteration 0 batch 9350 training_loss 0.6916632528527511
iteration 0 batch 9360 training_loss 0.6931471805599453
iteration 0 batch 9370 training_loss 0.6916632528527511
iteration 0 batch 9380 training_loss 0.6931471805599453
iteration 0 batch 9390 training_loss 0.6916632528527511
iteration 0 batch 9400 training_loss 0.6931471805599453
iteration 0 batch 9410 training_loss 0.6931471805599453
iteration 0 batch 9420 training_loss 0.6931471805599453
iteration 0 batch 9430 training_loss 0.6916632528527511
iteration 0 batch 9440 training_loss 0.6916632528527511
iteration 0 batch 9450 training_loss 0.6916632528527511
iteration 0 batch 9460 training_loss 0.6916632528527511
iteration 0 batch 9470 training_loss 0.6931471805599453
iteration 0 batch 9480 training_loss 0.6931471805599453
iteration 0 batch 9490 training_loss 0.6931471805599453
iteration 0 batch 9500 training_loss 0.6931471805599453
iteration 0 batch 9510 training_loss 0.6916632528527511
iteration 0 batch 9520 training_loss 0.6931471805599453
iteration 0 batch 9530 training_loss 0.6931471805599453
iteration 0 batch 9540 training_loss 0.6916632528527511
iteration 0 batch 9550 training_loss 0.6931471805599453
iteration 0 batch 9560 training_loss 0.6931471805599453
iteration 0 batch 9570 training_loss 0.6931471805599453
iteration 0 batch 9580 training_loss 0.6901793251455568
iteration 0 batch 9590 training_loss 0.6931471805599453
iteration 0 batch 9600 training_loss 0.6916632528527511
iteration 0 batch 9610 training_loss 0.6931471805599453
iteration 0 batch 9620 training_loss 0.6931471805599453
iteration 0 batch 9630 training_loss 0.6931471805599453
iteration 0 batch 9640 training_loss 0.6931471805599453
iteration 0 batch 9650 training_loss 0.6931471805599453
iteration 0 batch 9660 training_loss 0.6916632528527511
iteration 0 batch 9670 training_loss 0.6916632528527511
iteration 0 batch 9680 training_loss 0.6916632528527511
iteration 0 batch 9690 training_loss 0.6916632528527511
iteration 0 batch 9700 training_loss 0.6901793251455568
iteration 0 batch 9710 training_loss 0.6931471805599453
iteration 0 batch 9720 training_loss 0.6931471805599453
iteration 0 batch 9730 training_loss 0.6931471805599453
iteration 0 batch 9740 training_loss 0.6916632528527511
iteration 0 batch 9750 training_loss 0.6931471805599453
iteration 0 batch 9760 training_loss 0.6931471805599453
iteration 0 batch 9770 training_loss 0.6916632528527511
iteration 0 batch 9780 training_loss 0.6931471805599453
iteration 0 batch 9790 training_loss 0.6931471805599453
iteration 0 batch 9800 training_loss 0.6931471805599453
iteration 0 batch 9810 training_loss 0.6901793251455568
iteration 0 batch 9820 training_loss 0.6931471805599453
iteration 0 batch 9830 training_loss 0.6886953974383625
iteration 0 batch 9840 training_loss 0.6931471805599453
iteration 0 batch 9850 training_loss 0.6931471805599453
iteration 0 batch 9860 training_loss 0.6931471805599453
iteration 0 batch 9870 training_loss 0.6872114697311684
iteration 0 batch 9880 training_loss 0.6931471805599453
iteration 0 batch 9890 training_loss 0.6931471805599453
iteration 0 batch 9900 training_loss 0.6916632528527511
iteration 0 batch 9910 training_loss 0.6916632528527511
iteration 0 batch 9920 training_loss 0.6901793251455568
iteration 0 batch 9930 training_loss 0.6916632528527511
iteration 0 batch 9940 training_loss 0.6931471805599453
iteration 0 batch 9950 training_loss 0.6886953974383626
iteration 0 batch 9960 training_loss 0.6916632528527511
iteration 0 batch 9970 training_loss 0.6931471805599453
iteration 0 batch 9980 training_loss 0.6931471805599453
iteration 0 batch 9990 training_loss 0.6931471805599453
iteration 0 batch 10000 training_loss 0.6931471805599453
iteration 0 batch 10010 training_loss 0.6931471805599453
iteration 0 batch 10020 training_loss 0.6916632528527511
iteration 0 batch 10030 training_loss 0.6931471805599453
iteration 0 batch 10040 training_loss 0.6931471805599453
iteration 0 batch 10050 training_loss 0.6901793251455568
iteration 0 batch 10060 training_loss 0.6931471805599453
iteration 0 batch 10070 training_loss 0.6916632528527511
iteration 0 batch 10080 training_loss 0.6931471805599453
iteration 0 batch 10090 training_loss 0.6916632528527511
iteration 0 batch 10100 training_loss 0.6931471805599453
iteration 0 batch 10110 training_loss 0.6916632528527511
iteration 0 batch 10120 training_loss 0.6931471805599453
iteration 0 batch 10130 training_loss 0.6931471805599453
iteration 0 batch 10140 training_loss 0.6931471805599453
iteration 0 batch 10150 training_loss 0.6916632528527511
iteration 0 batch 10160 training_loss 0.6931471805599453
iteration 0 batch 10170 training_loss 0.6916632528527511
iteration 0 batch 10180 training_loss 0.6916632528527511
iteration 0 batch 10190 training_loss 0.6916632528527511
iteration 0 batch 10200 training_loss 0.6931471805599453
iteration 0 batch 10210 training_loss 0.6931471805599453
iteration 0 batch 10220 training_loss 0.6931471805599453
iteration 0 batch 10230 training_loss 0.6931471805599453
iteration 0 batch 10240 training_loss 0.6931471805599453
iteration 0 batch 10250 training_loss 0.6931471805599453
iteration 0 batch 10260 training_loss 0.6931471805599453
iteration 0 batch 10270 training_loss 0.6931471805599453
iteration 0 batch 10280 training_loss 0.6931471805599453
iteration 0 batch 10290 training_loss 0.6931471805599453
iteration 0 batch 10300 training_loss 0.6931471805599453
iteration 0 batch 10310 training_loss 0.6916632528527511
iteration 0 batch 10320 training_loss 0.6916632528527511
iteration 0 batch 10330 training_loss 0.6931471805599453
iteration 0 batch 10340 training_loss 0.6916632528527511
iteration 0 batch 10350 training_loss 0.6901793251455568
iteration 0 batch 10360 training_loss 0.6931471805599453
iteration 0 batch 10370 training_loss 0.6931471805599453
iteration 0 batch 10380 training_loss 0.6931471805599453
iteration 0 batch 10390 training_loss 0.6931471805599453
iteration 0 batch 10400 training_loss 0.6931471805599453
iteration 0 batch 10410 training_loss 0.6931471805599453
iteration 0 batch 10420 training_loss 0.6901793251455568
iteration 0 batch 10430 training_loss 0.6886953974383626
iteration 0 batch 10440 training_loss 0.6916632528527511
iteration 0 batch 10450 training_loss 0.6931471805599453
iteration 0 batch 10460 training_loss 0.6916632528527511
iteration 0 batch 10470 training_loss 0.6931471805599453
iteration 0 batch 10480 training_loss 0.6916632528527511
iteration 0 batch 10490 training_loss 0.6931471805599453
iteration 0 batch 10500 training_loss 0.6931471805599453
iteration 0 batch 10510 training_loss 0.6916632528527511
iteration 0 batch 10520 training_loss 0.6916632528527511
iteration 0 batch 10530 training_loss 0.6931471805599453
iteration 0 batch 10540 training_loss 0.6931471805599453
iteration 0 batch 10550 training_loss 0.6916632528527511
iteration 0 batch 10560 training_loss 0.6931471805599453
iteration 0 batch 10570 training_loss 0.6931471805599453
iteration 0 batch 10580 training_loss 0.6931471805599453
iteration 0 batch 10590 training_loss 0.6931471805599453
iteration 0 batch 10600 training_loss 0.6931471805599453
iteration 0 batch 10610 training_loss 0.6916632528527511
iteration 0 batch 10620 training_loss 0.6916632528527511
iteration 0 batch 10630 training_loss 0.6931471805599453
iteration 0 batch 10640 training_loss 0.6916632528527511
iteration 0 batch 10650 training_loss 0.6931471805599453
iteration 0 batch 10660 training_loss 0.6916632528527511
iteration 0 batch 10670 training_loss 0.6931471805599453
iteration 0 batch 10680 training_loss 0.6931471805599453
iteration 0 batch 10690 training_loss 0.6901793251455568
iteration 0 batch 10700 training_loss 0.6931471805599453
iteration 0 batch 10710 training_loss 0.6931471805599453
iteration 0 batch 10720 training_loss 0.6931471805599453
iteration 0 batch 10730 training_loss 0.6931471805599453
iteration 0 batch 10740 training_loss 0.6931471805599453
iteration 0 batch 10750 training_loss 0.6916632528527511
iteration 0 batch 10760 training_loss 0.6931471805599453
iteration 0 batch 10770 training_loss 0.6916632528527511
iteration 0 batch 10780 training_loss 0.6931471805599453
iteration 0 batch 10790 training_loss 0.6931471805599453
iteration 0 batch 10800 training_loss 0.6931471805599453
iteration 0 batch 10810 training_loss 0.6931471805599453
iteration 0 batch 10820 training_loss 0.6931471805599453
iteration 0 batch 10830 training_loss 0.6931471805599453
iteration 0 batch 10840 training_loss 0.6931471805599453
iteration 0 batch 10850 training_loss 0.6931471805599453
iteration 0 batch 10860 training_loss 0.6901793251455568
iteration 0 batch 10870 training_loss 0.6916632528527511
iteration 0 batch 10880 training_loss 0.6931471805599453
iteration 0 batch 10890 training_loss 0.6931471805599453
iteration 0 batch 10900 training_loss 0.6931471805599453
iteration 0 batch 10910 training_loss 0.6931471805599453
iteration 0 batch 10920 training_loss 0.6916632528527511
iteration 0 batch 10930 training_loss 0.6931471805599453
iteration 0 batch 10940 training_loss 0.6931471805599453
iteration 0 batch 10950 training_loss 0.6916632528527511
iteration 0 batch 10960 training_loss 0.6931471805599453
iteration 0 batch 10970 training_loss 0.6931471805599453
iteration 0 batch 10980 training_loss 0.6931471805599453
iteration 0 batch 10990 training_loss 0.6916632528527511
iteration 0 batch 11000 training_loss 0.6931471805599453
iteration 0 batch 11010 training_loss 0.6931471805599453
iteration 0 batch 11020 training_loss 0.6931471805599453
iteration 0 batch 11030 training_loss 0.6916632528527511
iteration 0 batch 11040 training_loss 0.6916632528527511
iteration 0 batch 11050 training_loss 0.6931471805599453
iteration 0 batch 11060 training_loss 0.6931471805599453
iteration 0 batch 11070 training_loss 0.6901793251455568
iteration 0 batch 11080 training_loss 0.6931471805599453
iteration 0 batch 11090 training_loss 0.6931471805599453
iteration 0 batch 11100 training_loss 0.6931471805599453
iteration 0 batch 11110 training_loss 0.6931471805599453
iteration 0 batch 11120 training_loss 0.6931471805599453
iteration 0 batch 11130 training_loss 0.6916632528527511
iteration 0 batch 11140 training_loss 0.6901793251455568
iteration 0 batch 11150 training_loss 0.6916632528527511
iteration 0 batch 11160 training_loss 0.6931471805599453
iteration 0 batch 11170 training_loss 0.6931471805599453
iteration 0 batch 11180 training_loss 0.6931471805599453
iteration 0 batch 11190 training_loss 0.6931471805599453
iteration 0 batch 11200 training_loss 0.6916632528527511
iteration 0 batch 11210 training_loss 0.6931471805599453
iteration 0 batch 11220 training_loss 0.6916632528527511
iteration 0 batch 11230 training_loss 0.6931471805599453
iteration 0 batch 11240 training_loss 0.6901793251455568
iteration 0 batch 11250 training_loss 0.6916632528527511
iteration 0 batch 11260 training_loss 0.6931471805599453
iteration 0 batch 11270 training_loss 0.6931471805599453
iteration 0 batch 11280 training_loss 0.6886953974383626
iteration 0 batch 11290 training_loss 0.6931471805599453
iteration 0 batch 11300 training_loss 0.6931471805599453
iteration 0 batch 11310 training_loss 0.6916632528527511
iteration 0 batch 11320 training_loss 0.6916632528527511
iteration 0 batch 11330 training_loss 0.6931471805599453
iteration 0 batch 11340 training_loss 0.6931471805599453
iteration 0 batch 11350 training_loss 0.6916632528527511
iteration 0 batch 11360 training_loss 0.6931471805599453
iteration 0 batch 11370 training_loss 0.6931471805599453
iteration 0 batch 11380 training_loss 0.6901793251455568
iteration 0 batch 11390 training_loss 0.6931471805599453
iteration 0 batch 11400 training_loss 0.6931471805599453
iteration 0 batch 11410 training_loss 0.6931471805599453
iteration 0 batch 11420 training_loss 0.6916632528527511
iteration 0 batch 11430 training_loss 0.6916632528527511
iteration 0 batch 11440 training_loss 0.6916632528527511
iteration 0 batch 11450 training_loss 0.6901793251455568
iteration 0 batch 11460 training_loss 0.6931471805599453
iteration 0 batch 11470 training_loss 0.6916632528527511
iteration 0 batch 11480 training_loss 0.6931471805599453
iteration 0 batch 11490 training_loss 0.6916632528527511
iteration 0 batch 11500 training_loss 0.6916632528527511
iteration 0 batch 11510 training_loss 0.6916632528527511
iteration 0 batch 11520 training_loss 0.6931471805599453
iteration 0 batch 11530 training_loss 0.6931471805599453
iteration 0 batch 11540 training_loss 0.6916632528527511
iteration 0 batch 11550 training_loss 0.6901793251455568
iteration 0 batch 11560 training_loss 0.6916632528527511
iteration 0 batch 11570 training_loss 0.6931471805599453
iteration 0 batch 11580 training_loss 0.6931471805599453
iteration 0 batch 11590 training_loss 0.6931471805599453
iteration 0 batch 11600 training_loss 0.6931471805599453
iteration 0 batch 11610 training_loss 0.6931471805599453
iteration 0 batch 11620 training_loss 0.6931471805599453
iteration 0 batch 11630 training_loss 0.6931471805599453
iteration 0 batch 11640 training_loss 0.6916632528527511
iteration 0 batch 11650 training_loss 0.6916632528527511
iteration 0 batch 11660 training_loss 0.6916632528527511
iteration 0 batch 11670 training_loss 0.6931471805599453
iteration 0 batch 11680 training_loss 0.6931471805599453
iteration 0 batch 11690 training_loss 0.6931471805599453
iteration 0 batch 11700 training_loss 0.6931471805599453
iteration 0 batch 11710 training_loss 0.6931471805599453
iteration 0 batch 11720 training_loss 0.6931471805599453
iteration 0 batch 11730 training_loss 0.6931471805599453
iteration 0 batch 11740 training_loss 0.6931471805599453
iteration 0 batch 11750 training_loss 0.6916632528527511
iteration 0 batch 11760 training_loss 0.6931471805599453
iteration 0 batch 11770 training_loss 0.6931471805599453
iteration 0 batch 11780 training_loss 0.6931471805599453
iteration 0 batch 11790 training_loss 0.6916632528527511
iteration 0 batch 11800 training_loss 0.6931471805599453
iteration 0 batch 11810 training_loss 0.6931471805599453
iteration 0 batch 11820 training_loss 0.6916632528527511
iteration 0 batch 11830 training_loss 0.6931471805599453
iteration 0 batch 11840 training_loss 0.6931471805599453
iteration 0 batch 11850 training_loss 0.6916632528527511
iteration 0 batch 11860 training_loss 0.6931471805599453
iteration 0 batch 11870 training_loss 0.6931471805599453
iteration 0 batch 11880 training_loss 0.6931471805599453
iteration 0 batch 11890 training_loss 0.6916632528527511
iteration 0 batch 11900 training_loss 0.6931471805599453
iteration 0 batch 11910 training_loss 0.6916632528527511
iteration 0 batch 11920 training_loss 0.6931471805599453
iteration 0 batch 11930 training_loss 0.6931471805599453
iteration 0 batch 11940 training_loss 0.6901793251455568
iteration 0 batch 11950 training_loss 0.6916632528527511
iteration 0 batch 11960 training_loss 0.6931471805599453
iteration 0 batch 11970 training_loss 0.6931471805599453
iteration 0 batch 11980 training_loss 0.6931471805599453
iteration 0 batch 11990 training_loss 0.6931471805599453
iteration 0 batch 12000 training_loss 0.6916632528527511
iteration 0 batch 12010 training_loss 0.6931471805599453
iteration 0 batch 12020 training_loss 0.6931471805599453
iteration 0 batch 12030 training_loss 0.6931471805599453
iteration 0 batch 12040 training_loss 0.6931471805599453
iteration 0 batch 12050 training_loss 0.6931471805599453
iteration 0 batch 12060 training_loss 0.6916632528527511
iteration 0 batch 12070 training_loss 0.6931471805599453
iteration 0 batch 12080 training_loss 0.6916632528527511
iteration 0 batch 12090 training_loss 0.6931471805599453
iteration 0 batch 12100 training_loss 0.6931471805599453
iteration 0 batch 12110 training_loss 0.6916632528527511
iteration 0 batch 12120 training_loss 0.6901793251455568
iteration 0 batch 12130 training_loss 0.6916632528527511
iteration 0 batch 12140 training_loss 0.6931471805599453
iteration 0 batch 12150 training_loss 0.6931471805599453
iteration 0 batch 12160 training_loss 0.6931471805599453
iteration 0 batch 12170 training_loss 0.6931471805599453
iteration 0 batch 12180 training_loss 0.6931471805599453
iteration 0 batch 12190 training_loss 0.6931471805599453
iteration 0 batch 12200 training_loss 0.6931471805599453
iteration 0 batch 12210 training_loss 0.6886953974383626
iteration 0 batch 12220 training_loss 0.6931471805599453
iteration 0 batch 12230 training_loss 0.6916632528527511
iteration 0 batch 12240 training_loss 0.6931471805599453
iteration 0 batch 12250 training_loss 0.6901793251455568
iteration 0 batch 12260 training_loss 0.6916632528527511
iteration 0 batch 12270 training_loss 0.6931471805599453
iteration 0 batch 12280 training_loss 0.6916632528527511
iteration 0 batch 12290 training_loss 0.6931471805599453
iteration 0 batch 12300 training_loss 0.6931471805599453
iteration 0 batch 12310 training_loss 0.6931471805599453
iteration 0 batch 12320 training_loss 0.6931471805599453
iteration 0 batch 12330 training_loss 0.6916632528527511
iteration 0 batch 12340 training_loss 0.6916632528527511
iteration 0 batch 12350 training_loss 0.6916632528527511
iteration 0 batch 12360 training_loss 0.6916632528527511
iteration 0 batch 12370 training_loss 0.6931471805599453
iteration 0 batch 12380 training_loss 0.6931471805599453
iteration 0 batch 12390 training_loss 0.6931471805599453
iteration 0 batch 12400 training_loss 0.6931471805599453
iteration 0 batch 12410 training_loss 0.6901793251455568
iteration 0 batch 12420 training_loss 0.6916632528527511
iteration 0 batch 12430 training_loss 0.6931471805599453
iteration 0 batch 12440 training_loss 0.6901793251455568
iteration 0 batch 12450 training_loss 0.6931471805599453
iteration 0 batch 12460 training_loss 0.6916632528527511
iteration 0 batch 12470 training_loss 0.6931471805599453
iteration 0 batch 12480 training_loss 0.6931471805599453
iteration 0 batch 12490 training_loss 0.6931471805599453
iteration 0 batch 12500 training_loss 0.6931471805599453
iteration 0 batch 12510 training_loss 0.6916632528527511
iteration 0 batch 12520 training_loss 0.6931471805599453
iteration 0 batch 12530 training_loss 0.6916632528527511
iteration 0 batch 12540 training_loss 0.6931471805599453
iteration 0 batch 12550 training_loss 0.6931471805599453
iteration 0 batch 12560 training_loss 0.6931471805599453
iteration 0 batch 12570 training_loss 0.6931471805599453
iteration 0 batch 12580 training_loss 0.6931471805599453
iteration 0 batch 12590 training_loss 0.6886953974383626
iteration 0 batch 12600 training_loss 0.6931471805599453
iteration 0 batch 12610 training_loss 0.6916632528527511
iteration 0 batch 12620 training_loss 0.6931471805599453
iteration 0 batch 12630 training_loss 0.6916632528527511
iteration 0 batch 12640 training_loss 0.6931471805599453
iteration 0 batch 12650 training_loss 0.6916632528527511
iteration 0 batch 12660 training_loss 0.6916632528527511
iteration 0 batch 12670 training_loss 0.6916632528527511
iteration 0 batch 12680 training_loss 0.6931471805599453
iteration 0 batch 12690 training_loss 0.6931471805599453
iteration 0 batch 12700 training_loss 0.6931471805599453
iteration 0 batch 12710 training_loss 0.6931471805599453
iteration 0 batch 12720 training_loss 0.6931471805599453
iteration 0 batch 12730 training_loss 0.6916632528527511
iteration 0 batch 12740 training_loss 0.6931471805599453
iteration 0 batch 12750 training_loss 0.6931471805599453
iteration 0 batch 12760 training_loss 0.6931471805599453
iteration 0 batch 12770 training_loss 0.6931471805599453
iteration 0 batch 12780 training_loss 0.6931471805599453
iteration 0 batch 12790 training_loss 0.6916632528527511
iteration 0 batch 12800 training_loss 0.6916632528527511
iteration 0 batch 12810 training_loss 0.6931471805599453
iteration 0 batch 12820 training_loss 0.6931471805599453
iteration 0 batch 12830 training_loss 0.6931471805599453
iteration 0 batch 12840 training_loss 0.6931471805599453
iteration 0 batch 12850 training_loss 0.6916632528527511
iteration 0 batch 12860 training_loss 0.6931471805599453
iteration 0 batch 12870 training_loss 0.6931471805599453
iteration 0 batch 12880 training_loss 0.6901793251455568
iteration 0 batch 12890 training_loss 0.6931471805599453
iteration 0 batch 12900 training_loss 0.6931471805599453
iteration 0 batch 12910 training_loss 0.6931471805599453
iteration 0 batch 12920 training_loss 0.6931471805599453
iteration 0 batch 12930 training_loss 0.6916632528527511
iteration 0 batch 12940 training_loss 0.6916632528527511
iteration 0 batch 12950 training_loss 0.6931471805599453
iteration 0 batch 12960 training_loss 0.6931471805599453
iteration 0 batch 12970 training_loss 0.6916632528527511
iteration 0 batch 12980 training_loss 0.6931471805599453
iteration 0 batch 12990 training_loss 0.6931471805599453
iteration 0 batch 13000 training_loss 0.6931471805599453
iteration 0 batch 13010 training_loss 0.6931471805599453
iteration 0 batch 13020 training_loss 0.6916632528527511
iteration 0 batch 13030 training_loss 0.6916632528527511
iteration 0 batch 13040 training_loss 0.6916632528527511
iteration 0 batch 13050 training_loss 0.6931471805599453
iteration 0 batch 13060 training_loss 0.6931471805599453
iteration 0 batch 13070 training_loss 0.6916632528527511
iteration 0 batch 13080 training_loss 0.6916632528527511
iteration 0 batch 13090 training_loss 0.6931471805599453
iteration 0 batch 13100 training_loss 0.6931471805599453
iteration 0 batch 13110 training_loss 0.6901793251455568
iteration 0 batch 13120 training_loss 0.6931471805599453
iteration 0 batch 13130 training_loss 0.6916632528527511
iteration 0 batch 13140 training_loss 0.6931471805599453
iteration 0 batch 13150 training_loss 0.6916632528527511
iteration 0 batch 13160 training_loss 0.6901793251455568
iteration 0 batch 13170 training_loss 0.6901793251455568
iteration 0 batch 13180 training_loss 0.6931471805599453
iteration 0 batch 13190 training_loss 0.6931471805599453
iteration 0 batch 13200 training_loss 0.6931471805599453
iteration 0 batch 13210 training_loss 0.6931471805599453
iteration 0 batch 13220 training_loss 0.6931471805599453
iteration 0 batch 13230 training_loss 0.6916632528527511
iteration 0 batch 13240 training_loss 0.6931471805599453
iteration 0 batch 13250 training_loss 0.6916632528527511
iteration 0 batch 13260 training_loss 0.6931471805599453
iteration 0 batch 13270 training_loss 0.6916632528527511
iteration 0 batch 13280 training_loss 0.6931471805599453
iteration 0 batch 13290 training_loss 0.6931471805599453
iteration 0 batch 13300 training_loss 0.6931471805599453
iteration 0 batch 13310 training_loss 0.6931471805599453
iteration 0 batch 13320 training_loss 0.6931471805599453
iteration 0 batch 13330 training_loss 0.6931471805599453
iteration 0 batch 13340 training_loss 0.6916632528527511
iteration 0 batch 13350 training_loss 0.6931471805599453
iteration 0 batch 13360 training_loss 0.6931471805599453
iteration 0 batch 13370 training_loss 0.6931471805599453
iteration 0 batch 13380 training_loss 0.6931471805599453
iteration 0 batch 13390 training_loss 0.6916632528527511
iteration 0 batch 13400 training_loss 0.6931471805599453
iteration 0 batch 13410 training_loss 0.6916632528527511
iteration 0 batch 13420 training_loss 0.6931471805599453
iteration 0 batch 13430 training_loss 0.6931471805599453
iteration 0 batch 13440 training_loss 0.6931471805599453
iteration 0 batch 13450 training_loss 0.6931471805599453
iteration 0 batch 13460 training_loss 0.6931471805599453
iteration 0 batch 13470 training_loss 0.6916632528527511
iteration 0 batch 13480 training_loss 0.6916632528527511
iteration 0 batch 13490 training_loss 0.6931471805599453
iteration 0 batch 13500 training_loss 0.6931471805599453
iteration 0 batch 13510 training_loss 0.6931471805599453
iteration 0 batch 13520 training_loss 0.6931471805599453
iteration 0 batch 13530 training_loss 0.6931471805599453
iteration 0 batch 13540 training_loss 0.6916632528527511
iteration 0 batch 13550 training_loss 0.6931471805599453
iteration 0 batch 13560 training_loss 0.6931471805599453
iteration 0 batch 13570 training_loss 0.6931471805599453
iteration 0 batch 13580 training_loss 0.6901793251455568
iteration 0 batch 13590 training_loss 0.6901793251455568
iteration 0 batch 13600 training_loss 0.6931471805599453
iteration 0 batch 13610 training_loss 0.6931471805599453
iteration 0 batch 13620 training_loss 0.6931471805599453
iteration 0 batch 13630 training_loss 0.6931471805599453
iteration 0 batch 13640 training_loss 0.6916632528527511
iteration 0 batch 13650 training_loss 0.6931471805599453
iteration 0 batch 13660 training_loss 0.6916632528527511
iteration 0 batch 13670 training_loss 0.6931471805599453
iteration 0 batch 13680 training_loss 0.6931471805599453
iteration 0 batch 13690 training_loss 0.6931471805599453
iteration 0 batch 13700 training_loss 0.6931471805599453
iteration 0 batch 13710 training_loss 0.6931471805599453
iteration 0 batch 13720 training_loss 0.6931471805599453
iteration 0 batch 13730 training_loss 0.6931471805599453
iteration 0 batch 13740 training_loss 0.6931471805599453
iteration 0 batch 13750 training_loss 0.6931471805599453
iteration 0 batch 13760 training_loss 0.6931471805599453
iteration 0 batch 13770 training_loss 0.6931471805599453
iteration 0 batch 13780 training_loss 0.6931471805599453
iteration 0 batch 13790 training_loss 0.6931471805599453
iteration 0 batch 13800 training_loss 0.6916632528527511
iteration 0 batch 13810 training_loss 0.6916632528527511
iteration 0 batch 13820 training_loss 0.6916632528527511
iteration 0 batch 13830 training_loss 0.6931471805599453
iteration 0 batch 13840 training_loss 0.6916632528527511
iteration 0 batch 13850 training_loss 0.6931471805599453
iteration 0 batch 13860 training_loss 0.6916632528527511
iteration 0 batch 13870 training_loss 0.6931471805599453
iteration 0 batch 13880 training_loss 0.6931471805599453
iteration 0 batch 13890 training_loss 0.6916632528527511
iteration 0 batch 13900 training_loss 0.6916632528527511
iteration 0 batch 13910 training_loss 0.6931471805599453
iteration 0 batch 13920 training_loss 0.6931471805599453
iteration 0 batch 13930 training_loss 0.6916632528527511
iteration 0 batch 13940 training_loss 0.6931471805599453
iteration 0 batch 13950 training_loss 0.6916632528527511
iteration 0 batch 13960 training_loss 0.6886953974383626
iteration 0 batch 13970 training_loss 0.6931471805599453
iteration 0 batch 13980 training_loss 0.6931471805599453
iteration 0 batch 13990 training_loss 0.6916632528527511
iteration 0 batch 14000 training_loss 0.6931471805599453
iteration 0 batch 14010 training_loss 0.6931471805599453
iteration 0 batch 14020 training_loss 0.6916632528527511
iteration 0 batch 14030 training_loss 0.6901793251455568
iteration 0 batch 14040 training_loss 0.6931471805599453
iteration 0 batch 14050 training_loss 0.6931471805599453
iteration 0 batch 14060 training_loss 0.6916632528527511
iteration 0 batch 14070 training_loss 0.6916632528527511
iteration 0 batch 14080 training_loss 0.6916632528527511
iteration 0 batch 14090 training_loss 0.6931471805599453
iteration 0 batch 14100 training_loss 0.6931471805599453
iteration 0 batch 14110 training_loss 0.6916632528527511
iteration 0 batch 14120 training_loss 0.6931471805599453
iteration 0 batch 14130 training_loss 0.6931471805599453
iteration 0 batch 14140 training_loss 0.6916632528527511
iteration 0 batch 14150 training_loss 0.6931471805599453
iteration 0 batch 14160 training_loss 0.6931471805599453
iteration 0 batch 14170 training_loss 0.6931471805599453
iteration 0 batch 14180 training_loss 0.6931471805599453
iteration 0 batch 14190 training_loss 0.6931471805599453
iteration 0 batch 14200 training_loss 0.6916632528527511
iteration 0 batch 14210 training_loss 0.6931471805599453
iteration 0 batch 14220 training_loss 0.6931471805599453
iteration 0 batch 14230 training_loss 0.6931471805599453
iteration 0 batch 14240 training_loss 0.6901793251455568
iteration 0 batch 14250 training_loss 0.6901793251455568
iteration 0 batch 14260 training_loss 0.6931471805599453
iteration 0 batch 14270 training_loss 0.6931471805599453
iteration 0 batch 14280 training_loss 0.6931471805599453
iteration 0 batch 14290 training_loss 0.6931471805599453
iteration 0 batch 14300 training_loss 0.6916632528527511
iteration 0 batch 14310 training_loss 0.6916632528527511
iteration 0 batch 14320 training_loss 0.6931471805599453
iteration 0 batch 14330 training_loss 0.6931471805599453
iteration 0 batch 14340 training_loss 0.6931471805599453
iteration 0 batch 14350 training_loss 0.6931471805599453
iteration 0 batch 14360 training_loss 0.6931471805599453
iteration 0 batch 14370 training_loss 0.6931471805599453
iteration 0 batch 14380 training_loss 0.6931471805599453
iteration 0 batch 14390 training_loss 0.6916632528527511
iteration 0 batch 14400 training_loss 0.6931471805599453
iteration 0 batch 14410 training_loss 0.6931471805599453
iteration 0 batch 14420 training_loss 0.6916632528527511
iteration 0 batch 14430 training_loss 0.6931471805599453
iteration 0 batch 14440 training_loss 0.6931471805599453
iteration 0 batch 14450 training_loss 0.6931471805599453
iteration 0 batch 14460 training_loss 0.6916632528527511
iteration 0 batch 14470 training_loss 0.6931471805599453
iteration 0 batch 14480 training_loss 0.6916632528527511
iteration 0 batch 14490 training_loss 0.6931471805599453
iteration 0 batch 14500 training_loss 0.6931471805599453
iteration 0 batch 14510 training_loss 0.6931471805599453
iteration 0 batch 14520 training_loss 0.6916632528527511
iteration 0 batch 14530 training_loss 0.6916632528527511
iteration 0 batch 14540 training_loss 0.6931471805599453
iteration 0 batch 14550 training_loss 0.6916632528527511
iteration 0 batch 14560 training_loss 0.6931471805599453
iteration 0 batch 14570 training_loss 0.6931471805599453
iteration 0 batch 14580 training_loss 0.6916632528527511
iteration 0 batch 14590 training_loss 0.6931471805599453
iteration 0 batch 14600 training_loss 0.6872114697311684
iteration 0 batch 14610 training_loss 0.6931471805599453
iteration 0 batch 14620 training_loss 0.6916632528527511
iteration 0 batch 14630 training_loss 0.6931471805599453
iteration 0 batch 14640 training_loss 0.6931471805599453
iteration 0 batch 14650 training_loss 0.6916632528527511
iteration 0 batch 14660 training_loss 0.6916632528527511
iteration 0 batch 14670 training_loss 0.6931471805599453
iteration 0 batch 14680 training_loss 0.6931471805599453
iteration 0 batch 14690 training_loss 0.6931471805599453
iteration 0 batch 14700 training_loss 0.6931471805599453
iteration 0 batch 14710 training_loss 0.6916632528527511
iteration 0 batch 14720 training_loss 0.6916632528527511
iteration 0 batch 14730 training_loss 0.6916632528527511
iteration 0 batch 14740 training_loss 0.6931471805599453
iteration 0 batch 14750 training_loss 0.6931471805599453
iteration 0 batch 14760 training_loss 0.6916632528527511
iteration 0 batch 14770 training_loss 0.6931471805599453
iteration 0 batch 14780 training_loss 0.6931471805599453
iteration 0 batch 14790 training_loss 0.6931471805599453
iteration 0 batch 14800 training_loss 0.6886953974383626
iteration 0 batch 14810 training_loss 0.6916632528527511
iteration 0 batch 14820 training_loss 0.6916632528527511
iteration 0 batch 14830 training_loss 0.6931471805599453
iteration 0 batch 14840 training_loss 0.6931471805599453
iteration 0 batch 14850 training_loss 0.6901793251455568
iteration 0 batch 14860 training_loss 0.6931471805599453
iteration 0 batch 14870 training_loss 0.6916632528527511
iteration 0 batch 14880 training_loss 0.6901793251455568
iteration 0 batch 14890 training_loss 0.6916632528527511
iteration 0 batch 14900 training_loss 0.6931471805599453
iteration 0 batch 14910 training_loss 0.6931471805599453
iteration 0 batch 14920 training_loss 0.6916632528527511
iteration 0 batch 14930 training_loss 0.6916632528527511
iteration 0 batch 14940 training_loss 0.6931471805599453
iteration 0 batch 14950 training_loss 0.6916632528527511
iteration 0 batch 14960 training_loss 0.6931471805599453
iteration 0 batch 14970 training_loss 0.6931471805599453
iteration 0 batch 14980 training_loss 0.6931471805599453
iteration 0 batch 14990 training_loss 0.6916632528527511
iteration 0 batch 15000 training_loss 0.6931471805599453
iteration 0 batch 15010 training_loss 0.6931471805599453
iteration 0 batch 15020 training_loss 0.6931471805599453
iteration 0 batch 15030 training_loss 0.6916632528527511
iteration 0 batch 15040 training_loss 0.6931471805599453
iteration 0 batch 15050 training_loss 0.6916632528527511
iteration 0 batch 15060 training_loss 0.6931471805599453
iteration 0 batch 15070 training_loss 0.6931471805599453
iteration 0 batch 15080 training_loss 0.6901793251455568
iteration 0 batch 15090 training_loss 0.6916632528527511
iteration 0 batch 15100 training_loss 0.6931471805599453
iteration 0 batch 15110 training_loss 0.6931471805599453
iteration 0 batch 15120 training_loss 0.6886953974383626
iteration 0 batch 15130 training_loss 0.6931471805599453
iteration 0 batch 15140 training_loss 0.6931471805599453
iteration 0 batch 15150 training_loss 0.6886953974383626
iteration 0 batch 15160 training_loss 0.6931471805599453
iteration 0 batch 15170 training_loss 0.6916632528527511
iteration 0 batch 15180 training_loss 0.6931471805599453
iteration 0 batch 15190 training_loss 0.6931471805599453
iteration 0 batch 15200 training_loss 0.6916632528527511
iteration 0 batch 15210 training_loss 0.6931471805599453
iteration 0 batch 15220 training_loss 0.6931471805599453
iteration 0 batch 15230 training_loss 0.6931471805599453
iteration 0 batch 15240 training_loss 0.6931471805599453
iteration 0 batch 15250 training_loss 0.6931471805599453
iteration 0 batch 15260 training_loss 0.6931471805599453
iteration 0 batch 15270 training_loss 0.6931471805599453
iteration 0 batch 15280 training_loss 0.6931471805599453
iteration 0 batch 15290 training_loss 0.6931471805599453
iteration 0 batch 15300 training_loss 0.6931471805599453
iteration 0 batch 15310 training_loss 0.6916632528527511
iteration 0 batch 15320 training_loss 0.6916632528527511
iteration 0 batch 15330 training_loss 0.6931471805599453
iteration 0 batch 15340 training_loss 0.6931471805599453
iteration 0 batch 15350 training_loss 0.6931471805599453
iteration 0 batch 15360 training_loss 0.6916632528527511
iteration 0 batch 15370 training_loss 0.6931471805599453
iteration 0 batch 15380 training_loss 0.6916632528527511
iteration 0 batch 15390 training_loss 0.6901793251455568
iteration 0 batch 15400 training_loss 0.6931471805599453
iteration 0 batch 15410 training_loss 0.6931471805599453
iteration 0 batch 15420 training_loss 0.6916632528527511
iteration 0 batch 15430 training_loss 0.6931471805599453
iteration 0 batch 15440 training_loss 0.6916632528527511
iteration 0 batch 15450 training_loss 0.6931471805599453
iteration 0 batch 15460 training_loss 0.6931471805599453
iteration 0 batch 15470 training_loss 0.6931471805599453
iteration 0 batch 15480 training_loss 0.6931471805599453
iteration 0 batch 15490 training_loss 0.6931471805599453
iteration 0 batch 15500 training_loss 0.6931471805599453
iteration 0 batch 15510 training_loss 0.6916632528527511
iteration 0 batch 15520 training_loss 0.6901793251455568
iteration 0 batch 15530 training_loss 0.6901793251455568
iteration 0 batch 15540 training_loss 0.6916632528527511
iteration 0 batch 15550 training_loss 0.6931471805599453
iteration 0 batch 15560 training_loss 0.6931471805599453
iteration 0 batch 15570 training_loss 0.6931471805599453
iteration 0 batch 15580 training_loss 0.6931471805599453
iteration 0 batch 15590 training_loss 0.6931471805599453
iteration 0 batch 15600 training_loss 0.6931471805599453
iteration 0 batch 15610 training_loss 0.6931471805599453
iteration 0 batch 15620 training_loss 0.6931471805599453
iteration 0 batch 15630 training_loss 0.6916632528527511
iteration 0 batch 15640 training_loss 0.6916632528527511
iteration 0 batch 15650 training_loss 0.6916632528527511
iteration 0 batch 15660 training_loss 0.6931471805599453
iteration 0 batch 15670 training_loss 0.6931471805599453
iteration 0 batch 15680 training_loss 0.6931471805599453
iteration 0 batch 15690 training_loss 0.6931471805599453
iteration 0 batch 15700 training_loss 0.6931471805599453
iteration 0 batch 15710 training_loss 0.6931471805599453
iteration 0 batch 15720 training_loss 0.6931471805599453
iteration 0 batch 15730 training_loss 0.6931471805599453
iteration 0 batch 15740 training_loss 0.6931471805599453
iteration 0 batch 15750 training_loss 0.6916632528527511
iteration 0 batch 15760 training_loss 0.6916632528527511
iteration 0 batch 15770 training_loss 0.6916632528527511
iteration 0 batch 15780 training_loss 0.6916632528527511
iteration 0 batch 15790 training_loss 0.6916632528527511
iteration 0 batch 15800 training_loss 0.6931471805599453
iteration 0 batch 15810 training_loss 0.6931471805599453
iteration 0 batch 15820 training_loss 0.6931471805599453
iteration 0 batch 15830 training_loss 0.6916632528527511
iteration 0 batch 15840 training_loss 0.6931471805599453
iteration 0 batch 15850 training_loss 0.6931471805599453
iteration 0 batch 15860 training_loss 0.6931471805599453
iteration 0 batch 15870 training_loss 0.6931471805599453
iteration 0 batch 15880 training_loss 0.6931471805599453
iteration 0 batch 15890 training_loss 0.6931471805599453
iteration 0 batch 15900 training_loss 0.6931471805599453
iteration 0 batch 15910 training_loss 0.6931471805599453
iteration 0 batch 15920 training_loss 0.6916632528527511
iteration 0 batch 15930 training_loss 0.6916632528527511
iteration 0 batch 15940 training_loss 0.6931471805599453
iteration 0 batch 15950 training_loss 0.6931471805599453
iteration 0 batch 15960 training_loss 0.6916632528527511
iteration 0 batch 15970 training_loss 0.6916632528527511
iteration 0 batch 15980 training_loss 0.6931471805599453
iteration 0 batch 15990 training_loss 0.6901793251455568
iteration 0 batch 16000 training_loss 0.6931471805599453
iteration 0 batch 16010 training_loss 0.6931471805599453
iteration 0 batch 16020 training_loss 0.6931471805599453
iteration 0 batch 16030 training_loss 0.6931471805599453
iteration 0 batch 16040 training_loss 0.6931471805599453
iteration 0 batch 16050 training_loss 0.6916632528527511
iteration 0 batch 16060 training_loss 0.6931471805599453
iteration 0 batch 16070 training_loss 0.6931471805599453
iteration 0 batch 16080 training_loss 0.6916632528527511
iteration 0 batch 16090 training_loss 0.6931471805599453
iteration 0 batch 16100 training_loss 0.6931471805599453
iteration 0 batch 16110 training_loss 0.6931471805599453
iteration 0 batch 16120 training_loss 0.6931471805599453
iteration 0 batch 16130 training_loss 0.6931471805599453
iteration 0 batch 16140 training_loss 0.6931471805599453
iteration 0 batch 16150 training_loss 0.6931471805599453
iteration 0 batch 16160 training_loss 0.6916632528527511
iteration 0 batch 16170 training_loss 0.6916632528527511
iteration 0 batch 16180 training_loss 0.6916632528527511
iteration 0 batch 16190 training_loss 0.6931471805599453
iteration 0 batch 16200 training_loss 0.6916632528527511
iteration 0 batch 16210 training_loss 0.6931471805599453
iteration 0 batch 16220 training_loss 0.6931471805599453
iteration 0 batch 16230 training_loss 0.6931471805599453
iteration 0 batch 16240 training_loss 0.6931471805599453
iteration 0 batch 16250 training_loss 0.6931471805599453
iteration 0 batch 16260 training_loss 0.6931471805599453
iteration 0 batch 16270 training_loss 0.6916632528527511
iteration 0 batch 16280 training_loss 0.6931471805599453
iteration 0 batch 16290 training_loss 0.6931471805599453
iteration 0 batch 16300 training_loss 0.6931471805599453
iteration 0 batch 16310 training_loss 0.6931471805599453
iteration 0 batch 16320 training_loss 0.6916632528527511
iteration 0 batch 16330 training_loss 0.6931471805599453
iteration 0 batch 16340 training_loss 0.6931471805599453
iteration 0 batch 16350 training_loss 0.6931471805599453
iteration 0 batch 16360 training_loss 0.6916632528527511
iteration 0 batch 16370 training_loss 0.6916632528527511
iteration 0 batch 16380 training_loss 0.6916632528527511
iteration 0 batch 16390 training_loss 0.6886953974383626
iteration 0 batch 16400 training_loss 0.6931471805599453
iteration 0 batch 16410 training_loss 0.6931471805599453
iteration 0 batch 16420 training_loss 0.6931471805599453
iteration 0 batch 16430 training_loss 0.6931471805599453
iteration 0 batch 16440 training_loss 0.6931471805599453
iteration 0 batch 16450 training_loss 0.6931471805599453
iteration 0 batch 16460 training_loss 0.6931471805599453
iteration 0 batch 16470 training_loss 0.6931471805599453
iteration 0 batch 16480 training_loss 0.6931471805599453
iteration 0 batch 16490 training_loss 0.6931471805599453
iteration 0 batch 16500 training_loss 0.6931471805599453
iteration 0 batch 16510 training_loss 0.6916632528527511
iteration 0 batch 16520 training_loss 0.6916632528527511
iteration 0 batch 16530 training_loss 0.6931471805599453
iteration 0 batch 16540 training_loss 0.6931471805599453
iteration 0 batch 16550 training_loss 0.6931471805599453
iteration 0 batch 16560 training_loss 0.6916632528527511
iteration 0 batch 16570 training_loss 0.6916632528527511
iteration 0 batch 16580 training_loss 0.6916632528527511
iteration 0 batch 16590 training_loss 0.6931471805599453
iteration 0 batch 16600 training_loss 0.6916632528527511
iteration 0 batch 16610 training_loss 0.6916632528527511
iteration 0 batch 16620 training_loss 0.6931471805599453
iteration 0 batch 16630 training_loss 0.6916632528527511
iteration 0 batch 16640 training_loss 0.6931471805599453
iteration 0 batch 16650 training_loss 0.6931471805599453
iteration 0 batch 16660 training_loss 0.6931471805599453
iteration 0 batch 16670 training_loss 0.6916632528527511
iteration 0 batch 16680 training_loss 0.6916632528527511
iteration 0 batch 16690 training_loss 0.6916632528527511
iteration 0 batch 16700 training_loss 0.6916632528527511
iteration 0 batch 16710 training_loss 0.6931471805599453
iteration 0 batch 16720 training_loss 0.6931471805599453
iteration 0 batch 16730 training_loss 0.6931471805599453
iteration 0 batch 16740 training_loss 0.6931471805599453
iteration 0 batch 16750 training_loss 0.6931471805599453
iteration 0 batch 16760 training_loss 0.6931471805599453
iteration 0 batch 16770 training_loss 0.6931471805599453
iteration 0 batch 16780 training_loss 0.6931471805599453
iteration 0 batch 16790 training_loss 0.6916632528527511
iteration 0 batch 16800 training_loss 0.6931471805599453
iteration 0 batch 16810 training_loss 0.6916632528527511
iteration 0 batch 16820 training_loss 0.6916632528527511
iteration 0 batch 16830 training_loss 0.6931471805599453
iteration 0 batch 16840 training_loss 0.6916632528527511
iteration 0 batch 16850 training_loss 0.6931471805599453
iteration 0 batch 16860 training_loss 0.6931471805599453
iteration 0 batch 16870 training_loss 0.6931471805599453
iteration 0 batch 16880 training_loss 0.6931471805599453
iteration 0 batch 16890 training_loss 0.6916632528527511
iteration 0 batch 16900 training_loss 0.6931471805599453
iteration 0 batch 16910 training_loss 0.6931471805599453
iteration 0 batch 16920 training_loss 0.6916632528527511
iteration 0 batch 16930 training_loss 0.6931471805599453
iteration 0 batch 16940 training_loss 0.6931471805599453
iteration 0 batch 16950 training_loss 0.6931471805599453
iteration 0 batch 16960 training_loss 0.6931471805599453
iteration 0 batch 16970 training_loss 0.6931471805599453
iteration 0 batch 16980 training_loss 0.6916632528527511
iteration 0 batch 16990 training_loss 0.6931471805599453
iteration 0 batch 17000 training_loss 0.6931471805599453
iteration 0 batch 17010 training_loss 0.6931471805599453
iteration 0 batch 17020 training_loss 0.6931471805599453
iteration 0 batch 17030 training_loss 0.6931471805599453
iteration 0 batch 17040 training_loss 0.6901793251455568
iteration 0 batch 17050 training_loss 0.6916632528527511
iteration 0 batch 17060 training_loss 0.6931471805599453
iteration 0 batch 17070 training_loss 0.6931471805599453
iteration 0 batch 17080 training_loss 0.6931471805599453
iteration 0 batch 17090 training_loss 0.6931471805599453
iteration 0 batch 17100 training_loss 0.6931471805599453
iteration 0 batch 17110 training_loss 0.6916632528527511
iteration 0 batch 17120 training_loss 0.6931471805599453
iteration 0 batch 17130 training_loss 0.6931471805599453
iteration 0 batch 17140 training_loss 0.6931471805599453
iteration 0 batch 17150 training_loss 0.6916632528527511
iteration 0 batch 17160 training_loss 0.6931471805599453
iteration 0 batch 17170 training_loss 0.6931471805599453
iteration 0 batch 17180 training_loss 0.6916632528527511
iteration 0 batch 17190 training_loss 0.6931471805599453
iteration 0 batch 17200 training_loss 0.6931471805599453
iteration 0 batch 17210 training_loss 0.6931471805599453
iteration 0 batch 17220 training_loss 0.6931471805599453
iteration 0 batch 17230 training_loss 0.6916632528527511
iteration 0 batch 17240 training_loss 0.6916632528527511
iteration 0 batch 17250 training_loss 0.6931471805599453
iteration 0 batch 17260 training_loss 0.6931471805599453
iteration 0 batch 17270 training_loss 0.6916632528527511
iteration 0 batch 17280 training_loss 0.6916632528527511
iteration 0 batch 17290 training_loss 0.6916632528527511
iteration 0 batch 17300 training_loss 0.6931471805599453
iteration 0 batch 17310 training_loss 0.6931471805599453
iteration 0 batch 17320 training_loss 0.6931471805599453
iteration 0 batch 17330 training_loss 0.6931471805599453
iteration 0 batch 17340 training_loss 0.6931471805599453
iteration 0 batch 17350 training_loss 0.6931471805599453
iteration 0 batch 17360 training_loss 0.6931471805599453
iteration 0 batch 17370 training_loss 0.6916632528527511
iteration 0 batch 17380 training_loss 0.6916632528527511
iteration 0 batch 17390 training_loss 0.6931471805599453
iteration 0 batch 17400 training_loss 0.6931471805599453
iteration 0 batch 17410 training_loss 0.6916632528527511
iteration 0 batch 17420 training_loss 0.6931471805599453
iteration 0 batch 17430 training_loss 0.6901793251455568
iteration 0 batch 17440 training_loss 0.6931471805599453
iteration 0 batch 17450 training_loss 0.6931471805599453
iteration 0 batch 17460 training_loss 0.6931471805599453
iteration 0 batch 17470 training_loss 0.6931471805599453
iteration 0 batch 17480 training_loss 0.6916632528527511
iteration 0 batch 17490 training_loss 0.6916632528527511
iteration 0 batch 17500 training_loss 0.6931471805599453
iteration 0 batch 17510 training_loss 0.6916632528527511
iteration 0 batch 17520 training_loss 0.6931471805599453
iteration 0 batch 17530 training_loss 0.6916632528527511
iteration 0 batch 17540 training_loss 0.6931471805599453
iteration 0 batch 17550 training_loss 0.6931471805599453
iteration 0 batch 17560 training_loss 0.6916632528527511
iteration 0 batch 17570 training_loss 0.6931471805599453
iteration 0 batch 17580 training_loss 0.6931471805599453
iteration 0 batch 17590 training_loss 0.6931471805599453
iteration 0 batch 17600 training_loss 0.6916632528527511
iteration 0 batch 17610 training_loss 0.6916632528527511
iteration 0 batch 17620 training_loss 0.6931471805599453
iteration 0 batch 17630 training_loss 0.6931471805599453
iteration 0 batch 17640 training_loss 0.6931471805599453
iteration 0 batch 17650 training_loss 0.6931471805599453
iteration 0 batch 17660 training_loss 0.6931471805599453
iteration 0 batch 17670 training_loss 0.6916632528527511
iteration 0 batch 17680 training_loss 0.6916632528527511
iteration 0 batch 17690 training_loss 0.6916632528527511
iteration 0 batch 17700 training_loss 0.6931471805599453
iteration 0 batch 17710 training_loss 0.6931471805599453
iteration 0 batch 17720 training_loss 0.6931471805599453
iteration 0 batch 17730 training_loss 0.6931471805599453
iteration 0 batch 17740 training_loss 0.6931471805599453
iteration 0 batch 17750 training_loss 0.6931471805599453
iteration 0 batch 17760 training_loss 0.6931471805599453
iteration 0 batch 17770 training_loss 0.6931471805599453
iteration 0 batch 17780 training_loss 0.6916632528527511
iteration 0 batch 17790 training_loss 0.6931471805599453
iteration 0 batch 17800 training_loss 0.6931471805599453
iteration 0 batch 17810 training_loss 0.6916632528527511
iteration 0 batch 17820 training_loss 0.6931471805599453
iteration 0 batch 17830 training_loss 0.6931471805599453
iteration 0 batch 17840 training_loss 0.6931471805599453
iteration 0 batch 17850 training_loss 0.6916632528527511
iteration 0 batch 17860 training_loss 0.6916632528527511
iteration 0 batch 17870 training_loss 0.6901793251455568
iteration 0 batch 17880 training_loss 0.6916632528527511
iteration 0 batch 17890 training_loss 0.6931471805599453
iteration 0 batch 17900 training_loss 0.6931471805599453
iteration 0 batch 17910 training_loss 0.6931471805599453
iteration 0 batch 17920 training_loss 0.6916632528527511
iteration 0 batch 17930 training_loss 0.6901793251455568
iteration 0 batch 17940 training_loss 0.6931471805599453
iteration 0 batch 17950 training_loss 0.6916632528527511
iteration 0 batch 17960 training_loss 0.6916632528527511
iteration 0 batch 17970 training_loss 0.6931471805599453
iteration 0 batch 17980 training_loss 0.6931471805599453
iteration 0 batch 17990 training_loss 0.6931471805599453
iteration 0 batch 18000 training_loss 0.6916632528527511
iteration 0 batch 18010 training_loss 0.6931471805599453
iteration 0 batch 18020 training_loss 0.6931471805599453
iteration 0 batch 18030 training_loss 0.6931471805599453
iteration 0 batch 18040 training_loss 0.6931471805599453
iteration 0 batch 18050 training_loss 0.6931471805599453
iteration 0 batch 18060 training_loss 0.6931471805599453
iteration 0 batch 18070 training_loss 0.6931471805599453
iteration 0 batch 18080 training_loss 0.6916632528527511
iteration 0 batch 18090 training_loss 0.6931471805599453
iteration 0 batch 18100 training_loss 0.6931471805599453
iteration 0 batch 18110 training_loss 0.6931471805599453
iteration 0 batch 18120 training_loss 0.6931471805599453
iteration 0 batch 18130 training_loss 0.6931471805599453
iteration 0 batch 18140 training_loss 0.6931471805599453
iteration 0 batch 18150 training_loss 0.6931471805599453
iteration 0 batch 18160 training_loss 0.6931471805599453
iteration 0 batch 18170 training_loss 0.6931471805599453
iteration 0 batch 18180 training_loss 0.6931471805599453
iteration 0 batch 18190 training_loss 0.6916632528527511
iteration 0 batch 18200 training_loss 0.6931471805599453
iteration 0 batch 18210 training_loss 0.6931471805599453
iteration 0 batch 18220 training_loss 0.6931471805599453
iteration 0 batch 18230 training_loss 0.6916632528527511
iteration 0 batch 18240 training_loss 0.6916632528527511
iteration 0 batch 18250 training_loss 0.6931471805599453
iteration 0 batch 18260 training_loss 0.6916632528527511
iteration 0 batch 18270 training_loss 0.6931471805599453
iteration 0 batch 18280 training_loss 0.6931471805599453
iteration 0 batch 18290 training_loss 0.6916632528527511
iteration 0 batch 18300 training_loss 0.6931471805599453
iteration 0 batch 18310 training_loss 0.6931471805599453
iteration 0 batch 18320 training_loss 0.6931471805599453
iteration 0 batch 18330 training_loss 0.6931471805599453
iteration 0 batch 18340 training_loss 0.6931471805599453
iteration 0 batch 18350 training_loss 0.6931471805599453
iteration 0 batch 18360 training_loss 0.6931471805599453
iteration 0 batch 18370 training_loss 0.6931471805599453
iteration 0 batch 18380 training_loss 0.6931471805599453
iteration 0 batch 18390 training_loss 0.6931471805599453
iteration 0 batch 18400 training_loss 0.6931471805599453
iteration 0 batch 18410 training_loss 0.6916632528527511
iteration 0 batch 18420 training_loss 0.6931471805599453
iteration 0 batch 18430 training_loss 0.6931471805599453
iteration 0 batch 18440 training_loss 0.6931471805599453
iteration 0 batch 18450 training_loss 0.6931471805599453
iteration 0 batch 18460 training_loss 0.6931471805599453
iteration 0 batch 18470 training_loss 0.6931471805599453
iteration 0 batch 18480 training_loss 0.6931471805599453
iteration 0 batch 18490 training_loss 0.6931471805599453
iteration 0 batch 18500 training_loss 0.6931471805599453
iteration 0 batch 18510 training_loss 0.6931471805599453
iteration 0 batch 18520 training_loss 0.6931471805599453
iteration 0 batch 18530 training_loss 0.6901793251455568
iteration 0 batch 18540 training_loss 0.6916632528527511
iteration 0 batch 18550 training_loss 0.6931471805599453
iteration 0 batch 18560 training_loss 0.6931471805599453
iteration 0 batch 18570 training_loss 0.6916632528527511
iteration 0 batch 18580 training_loss 0.6931471805599453
iteration 0 batch 18590 training_loss 0.6931471805599453
iteration 0 batch 18600 training_loss 0.6916632528527511
iteration 0 batch 18610 training_loss 0.6916632528527511
iteration 1 batch 0 training_loss 0.6931471805599453
iteration 1 batch 10 training_loss 0.6916632528527511
iteration 1 batch 20 training_loss 0.6916632528527511
iteration 1 batch 30 training_loss 0.6931471805599453
iteration 1 batch 40 training_loss 0.6931471805599453
iteration 1 batch 50 training_loss 0.6931471805599453
iteration 1 batch 60 training_loss 0.6916632528527511
iteration 1 batch 70 training_loss 0.6931471805599453
iteration 1 batch 80 training_loss 0.6931471805599453
iteration 1 batch 90 training_loss 0.6901793251455568
iteration 1 batch 100 training_loss 0.6931471805599453
iteration 1 batch 110 training_loss 0.6916632528527511
iteration 1 batch 120 training_loss 0.6931471805599453
iteration 1 batch 130 training_loss 0.6916632528527511
iteration 1 batch 140 training_loss 0.6931471805599453
iteration 1 batch 150 training_loss 0.6931471805599453
iteration 1 batch 160 training_loss 0.6931471805599453
iteration 1 batch 170 training_loss 0.6931471805599453
iteration 1 batch 180 training_loss 0.6931471805599453
iteration 1 batch 190 training_loss 0.6931471805599453
iteration 1 batch 200 training_loss 0.6931471805599453
iteration 1 batch 210 training_loss 0.6901793251455568
iteration 1 batch 220 training_loss 0.6931471805599453
iteration 1 batch 230 training_loss 0.6901793251455568
iteration 1 batch 240 training_loss 0.6931471805599453
iteration 1 batch 250 training_loss 0.6901793251455568
iteration 1 batch 260 training_loss 0.6931471805599453
iteration 1 batch 270 training_loss 0.6931471805599453
iteration 1 batch 280 training_loss 0.6931471805599453
iteration 1 batch 290 training_loss 0.6931471805599453
iteration 1 batch 300 training_loss 0.6931471805599453
iteration 1 batch 310 training_loss 0.6916632528527511
iteration 1 batch 320 training_loss 0.6931471805599453
iteration 1 batch 330 training_loss 0.6901793251455568
iteration 1 batch 340 training_loss 0.6931471805599453
iteration 1 batch 350 training_loss 0.6931471805599453
iteration 1 batch 360 training_loss 0.6916632528527511
iteration 1 batch 370 training_loss 0.6931471805599453
iteration 1 batch 380 training_loss 0.6916632528527511
iteration 1 batch 390 training_loss 0.6916632528527511
iteration 1 batch 400 training_loss 0.6931471805599453
iteration 1 batch 410 training_loss 0.6886953974383626
iteration 1 batch 420 training_loss 0.6931471805599453
iteration 1 batch 430 training_loss 0.6916632528527511
iteration 1 batch 440 training_loss 0.6931471805599453
iteration 1 batch 450 training_loss 0.6916632528527511
iteration 1 batch 460 training_loss 0.6931471805599453
iteration 1 batch 470 training_loss 0.6916632528527511
iteration 1 batch 480 training_loss 0.6916632528527511
iteration 1 batch 490 training_loss 0.6931471805599453
iteration 1 batch 500 training_loss 0.6931471805599453
iteration 1 batch 510 training_loss 0.6931471805599453
iteration 1 batch 520 training_loss 0.6931471805599453
iteration 1 batch 530 training_loss 0.6931471805599453
iteration 1 batch 540 training_loss 0.6931471805599453
iteration 1 batch 550 training_loss 0.6916632528527511
iteration 1 batch 560 training_loss 0.6916632528527511
iteration 1 batch 570 training_loss 0.6901793251455568
iteration 1 batch 580 training_loss 0.6901793251455568
iteration 1 batch 590 training_loss 0.6916632528527511
iteration 1 batch 600 training_loss 0.6931471805599453
iteration 1 batch 610 training_loss 0.6916632528527511
iteration 1 batch 620 training_loss 0.6931471805599453
iteration 1 batch 630 training_loss 0.6931471805599453
iteration 1 batch 640 training_loss 0.6931471805599453
iteration 1 batch 650 training_loss 0.6931471805599453
iteration 1 batch 660 training_loss 0.6931471805599453
iteration 1 batch 670 training_loss 0.6931471805599453
iteration 1 batch 680 training_loss 0.6916632528527511
iteration 1 batch 690 training_loss 0.6931471805599453
iteration 1 batch 700 training_loss 0.6931471805599453
iteration 1 batch 710 training_loss 0.6931471805599453
iteration 1 batch 720 training_loss 0.6931471805599453
iteration 1 batch 730 training_loss 0.6931471805599453
iteration 1 batch 740 training_loss 0.6931471805599453
iteration 1 batch 750 training_loss 0.6931471805599453
iteration 1 batch 760 training_loss 0.6931471805599453
iteration 1 batch 770 training_loss 0.6931471805599453
iteration 1 batch 780 training_loss 0.6931471805599453
iteration 1 batch 790 training_loss 0.6931471805599453
iteration 1 batch 800 training_loss 0.6931471805599453
iteration 1 batch 810 training_loss 0.6916632528527511
iteration 1 batch 820 training_loss 0.6916632528527511
iteration 1 batch 830 training_loss 0.6916632528527511
iteration 1 batch 840 training_loss 0.6931471805599453
iteration 1 batch 850 training_loss 0.6916632528527511
iteration 1 batch 860 training_loss 0.6916632528527511
iteration 1 batch 870 training_loss 0.6931471805599453
iteration 1 batch 880 training_loss 0.6931471805599453
iteration 1 batch 890 training_loss 0.6931471805599453
iteration 1 batch 900 training_loss 0.6931471805599453
iteration 1 batch 910 training_loss 0.6931471805599453
iteration 1 batch 920 training_loss 0.6931471805599453
iteration 1 batch 930 training_loss 0.6901793251455568
iteration 1 batch 940 training_loss 0.6916632528527511
iteration 1 batch 950 training_loss 0.6931471805599453
iteration 1 batch 960 training_loss 0.6931471805599453
iteration 1 batch 970 training_loss 0.6931471805599453
iteration 1 batch 980 training_loss 0.6931471805599453
iteration 1 batch 990 training_loss 0.6916632528527511
iteration 1 batch 1000 training_loss 0.6931471805599453
iteration 1 batch 1010 training_loss 0.6931471805599453
iteration 1 batch 1020 training_loss 0.6931471805599453
iteration 1 batch 1030 training_loss 0.6916632528527511
iteration 1 batch 1040 training_loss 0.6931471805599453
iteration 1 batch 1050 training_loss 0.6931471805599453
iteration 1 batch 1060 training_loss 0.6901793251455568
iteration 1 batch 1070 training_loss 0.6886953974383626
iteration 1 batch 1080 training_loss 0.6931471805599453
iteration 1 batch 1090 training_loss 0.6931471805599453
iteration 1 batch 1100 training_loss 0.6931471805599453
iteration 1 batch 1110 training_loss 0.6931471805599453
iteration 1 batch 1120 training_loss 0.6931471805599453
iteration 1 batch 1130 training_loss 0.6931471805599453
iteration 1 batch 1140 training_loss 0.6931471805599453
iteration 1 batch 1150 training_loss 0.6931471805599453
iteration 1 batch 1160 training_loss 0.6916632528527511
iteration 1 batch 1170 training_loss 0.6931471805599453
iteration 1 batch 1180 training_loss 0.6931471805599453
iteration 1 batch 1190 training_loss 0.6931471805599453
iteration 1 batch 1200 training_loss 0.6931471805599453
iteration 1 batch 1210 training_loss 0.6916632528527511
iteration 1 batch 1220 training_loss 0.6916632528527511
iteration 1 batch 1230 training_loss 0.6931471805599453
iteration 1 batch 1240 training_loss 0.6931471805599453
iteration 1 batch 1250 training_loss 0.6931471805599453
iteration 1 batch 1260 training_loss 0.6931471805599453
iteration 1 batch 1270 training_loss 0.6916632528527511
iteration 1 batch 1280 training_loss 0.6931471805599453
iteration 1 batch 1290 training_loss 0.6931471805599453
iteration 1 batch 1300 training_loss 0.6931471805599453
iteration 1 batch 1310 training_loss 0.6916632528527511
iteration 1 batch 1320 training_loss 0.6931471805599453
iteration 1 batch 1330 training_loss 0.6931471805599453
iteration 1 batch 1340 training_loss 0.6931471805599453
iteration 1 batch 1350 training_loss 0.6931471805599453
iteration 1 batch 1360 training_loss 0.6931471805599453
iteration 1 batch 1370 training_loss 0.6931471805599453
iteration 1 batch 1380 training_loss 0.6916632528527511
iteration 1 batch 1390 training_loss 0.6931471805599453
iteration 1 batch 1400 training_loss 0.6931471805599453
iteration 1 batch 1410 training_loss 0.6931471805599453
iteration 1 batch 1420 training_loss 0.6931471805599453
iteration 1 batch 1430 training_loss 0.6931471805599453
iteration 1 batch 1440 training_loss 0.6931471805599453
iteration 1 batch 1450 training_loss 0.6931471805599453
iteration 1 batch 1460 training_loss 0.6931471805599453
iteration 1 batch 1470 training_loss 0.6931471805599453
iteration 1 batch 1480 training_loss 0.6931471805599453
iteration 1 batch 1490 training_loss 0.6931471805599453
iteration 1 batch 1500 training_loss 0.6916632528527511
iteration 1 batch 1510 training_loss 0.6916632528527511
iteration 1 batch 1520 training_loss 0.6931471805599453
iteration 1 batch 1530 training_loss 0.6931471805599453
iteration 1 batch 1540 training_loss 0.6931471805599453
iteration 1 batch 1550 training_loss 0.6931471805599453
iteration 1 batch 1560 training_loss 0.6931471805599453
iteration 1 batch 1570 training_loss 0.6931471805599453
iteration 1 batch 1580 training_loss 0.6931471805599453
iteration 1 batch 1590 training_loss 0.6931471805599453
iteration 1 batch 1600 training_loss 0.6931471805599453
iteration 1 batch 1610 training_loss 0.6931471805599453
iteration 1 batch 1620 training_loss 0.6916632528527511
iteration 1 batch 1630 training_loss 0.6931471805599453
iteration 1 batch 1640 training_loss 0.6931471805599453
iteration 1 batch 1650 training_loss 0.6916632528527511
iteration 1 batch 1660 training_loss 0.6916632528527511
iteration 1 batch 1670 training_loss 0.6931471805599453
iteration 1 batch 1680 training_loss 0.6931471805599453
iteration 1 batch 1690 training_loss 0.6931471805599453
iteration 1 batch 1700 training_loss 0.6931471805599453
iteration 1 batch 1710 training_loss 0.6916632528527511
iteration 1 batch 1720 training_loss 0.6931471805599453
iteration 1 batch 1730 training_loss 0.6931471805599453
iteration 1 batch 1740 training_loss 0.6931471805599453
iteration 1 batch 1750 training_loss 0.6931471805599453
iteration 1 batch 1760 training_loss 0.6916632528527511
iteration 1 batch 1770 training_loss 0.6931471805599453
iteration 1 batch 1780 training_loss 0.6916632528527511
iteration 1 batch 1790 training_loss 0.6931471805599453
iteration 1 batch 1800 training_loss 0.6931471805599453
iteration 1 batch 1810 training_loss 0.6931471805599453
iteration 1 batch 1820 training_loss 0.6931471805599453
iteration 1 batch 1830 training_loss 0.6931471805599453
iteration 1 batch 1840 training_loss 0.6931471805599453
iteration 1 batch 1850 training_loss 0.6916632528527511
iteration 1 batch 1860 training_loss 0.6931471805599453
iteration 1 batch 1870 training_loss 0.6931471805599453
iteration 1 batch 1880 training_loss 0.6931471805599453
iteration 1 batch 1890 training_loss 0.6916632528527511
iteration 1 batch 1900 training_loss 0.6931471805599453
iteration 1 batch 1910 training_loss 0.6931471805599453
iteration 1 batch 1920 training_loss 0.6916632528527511
iteration 1 batch 1930 training_loss 0.6931471805599453
iteration 1 batch 1940 training_loss 0.6901793251455568
iteration 1 batch 1950 training_loss 0.6931471805599453
iteration 1 batch 1960 training_loss 0.6931471805599453
iteration 1 batch 1970 training_loss 0.6901793251455568
iteration 1 batch 1980 training_loss 0.6931471805599453
iteration 1 batch 1990 training_loss 0.6931471805599453
iteration 1 batch 2000 training_loss 0.6916632528527511
iteration 1 batch 2010 training_loss 0.6916632528527511
iteration 1 batch 2020 training_loss 0.6931471805599453
iteration 1 batch 2030 training_loss 0.6916632528527511
iteration 1 batch 2040 training_loss 0.6931471805599453
iteration 1 batch 2050 training_loss 0.6931471805599453
iteration 1 batch 2060 training_loss 0.6916632528527511
iteration 1 batch 2070 training_loss 0.6931471805599453
iteration 1 batch 2080 training_loss 0.6931471805599453
iteration 1 batch 2090 training_loss 0.6931471805599453
iteration 1 batch 2100 training_loss 0.6916632528527511
iteration 1 batch 2110 training_loss 0.6901793251455568
iteration 1 batch 2120 training_loss 0.6931471805599453
iteration 1 batch 2130 training_loss 0.6931471805599453
iteration 1 batch 2140 training_loss 0.6931471805599453
iteration 1 batch 2150 training_loss 0.6916632528527511
iteration 1 batch 2160 training_loss 0.6931471805599453
iteration 1 batch 2170 training_loss 0.6931471805599453
iteration 1 batch 2180 training_loss 0.6931471805599453
iteration 1 batch 2190 training_loss 0.6931471805599453
iteration 1 batch 2200 training_loss 0.6916632528527511
iteration 1 batch 2210 training_loss 0.6916632528527511
iteration 1 batch 2220 training_loss 0.6931471805599453
iteration 1 batch 2230 training_loss 0.6931471805599453
iteration 1 batch 2240 training_loss 0.6916632528527511
iteration 1 batch 2250 training_loss 0.6931471805599453
iteration 1 batch 2260 training_loss 0.6931471805599453
iteration 1 batch 2270 training_loss 0.6931471805599453
iteration 1 batch 2280 training_loss 0.6931471805599453
iteration 1 batch 2290 training_loss 0.6931471805599453
iteration 1 batch 2300 training_loss 0.6916632528527511
iteration 1 batch 2310 training_loss 0.6931471805599453
iteration 1 batch 2320 training_loss 0.6931471805599453
iteration 1 batch 2330 training_loss 0.6916632528527511
iteration 1 batch 2340 training_loss 0.6931471805599453
iteration 1 batch 2350 training_loss 0.6916632528527511
iteration 1 batch 2360 training_loss 0.6916632528527511
iteration 1 batch 2370 training_loss 0.6901793251455568
iteration 1 batch 2380 training_loss 0.6916632528527511
iteration 1 batch 2390 training_loss 0.6931471805599453
iteration 1 batch 2400 training_loss 0.6931471805599453
iteration 1 batch 2410 training_loss 0.6916632528527511
iteration 1 batch 2420 training_loss 0.6931471805599453
iteration 1 batch 2430 training_loss 0.6931471805599453
iteration 1 batch 2440 training_loss 0.6931471805599453
iteration 1 batch 2450 training_loss 0.6901793251455568
iteration 1 batch 2460 training_loss 0.6931471805599453
iteration 1 batch 2470 training_loss 0.6931471805599453
iteration 1 batch 2480 training_loss 0.6931471805599453
iteration 1 batch 2490 training_loss 0.6931471805599453
iteration 1 batch 2500 training_loss 0.6931471805599453
iteration 1 batch 2510 training_loss 0.6931471805599453
iteration 1 batch 2520 training_loss 0.6931471805599453
iteration 1 batch 2530 training_loss 0.6931471805599453
iteration 1 batch 2540 training_loss 0.6916632528527511
iteration 1 batch 2550 training_loss 0.6931471805599453
iteration 1 batch 2560 training_loss 0.6931471805599453
iteration 1 batch 2570 training_loss 0.6916632528527511
iteration 1 batch 2580 training_loss 0.6931471805599453
iteration 1 batch 2590 training_loss 0.6901793251455568
iteration 1 batch 2600 training_loss 0.6901793251455568
iteration 1 batch 2610 training_loss 0.6931471805599453
iteration 1 batch 2620 training_loss 0.6931471805599453
iteration 1 batch 2630 training_loss 0.6931471805599453
iteration 1 batch 2640 training_loss 0.6901793251455568
iteration 1 batch 2650 training_loss 0.6916632528527511
iteration 1 batch 2660 training_loss 0.6931471805599453
iteration 1 batch 2670 training_loss 0.6931471805599453
iteration 1 batch 2680 training_loss 0.6931471805599453
iteration 1 batch 2690 training_loss 0.6931471805599453
iteration 1 batch 2700 training_loss 0.6931471805599453
iteration 1 batch 2710 training_loss 0.6931471805599453
iteration 1 batch 2720 training_loss 0.6931471805599453
iteration 1 batch 2730 training_loss 0.6916632528527511
iteration 1 batch 2740 training_loss 0.6931471805599453
iteration 1 batch 2750 training_loss 0.6901793251455568
iteration 1 batch 2760 training_loss 0.6931471805599453
iteration 1 batch 2770 training_loss 0.6931471805599453
iteration 1 batch 2780 training_loss 0.6931471805599453
iteration 1 batch 2790 training_loss 0.6931471805599453
iteration 1 batch 2800 training_loss 0.6916632528527511
iteration 1 batch 2810 training_loss 0.6931471805599453
iteration 1 batch 2820 training_loss 0.6931471805599453
iteration 1 batch 2830 training_loss 0.6916632528527511
iteration 1 batch 2840 training_loss 0.6916632528527511
iteration 1 batch 2850 training_loss 0.6931471805599453
iteration 1 batch 2860 training_loss 0.6931471805599453
iteration 1 batch 2870 training_loss 0.6931471805599453
iteration 1 batch 2880 training_loss 0.6931471805599453
iteration 1 batch 2890 training_loss 0.6931471805599453
iteration 1 batch 2900 training_loss 0.6916632528527511
iteration 1 batch 2910 training_loss 0.6931471805599453
iteration 1 batch 2920 training_loss 0.6931471805599453
iteration 1 batch 2930 training_loss 0.6931471805599453
iteration 1 batch 2940 training_loss 0.6901793251455568
iteration 1 batch 2950 training_loss 0.6931471805599453
iteration 1 batch 2960 training_loss 0.6931471805599453
iteration 1 batch 2970 training_loss 0.6931471805599453
iteration 1 batch 2980 training_loss 0.6931471805599453
iteration 1 batch 2990 training_loss 0.6931471805599453
iteration 1 batch 3000 training_loss 0.6931471805599453
iteration 1 batch 3010 training_loss 0.6931471805599453
iteration 1 batch 3020 training_loss 0.6931471805599453
iteration 1 batch 3030 training_loss 0.6931471805599453
iteration 1 batch 3040 training_loss 0.6931471805599453
iteration 1 batch 3050 training_loss 0.6916632528527511
iteration 1 batch 3060 training_loss 0.6916632528527511
iteration 1 batch 3070 training_loss 0.6931471805599453
iteration 1 batch 3080 training_loss 0.6916632528527511
iteration 1 batch 3090 training_loss 0.6931471805599453
iteration 1 batch 3100 training_loss 0.6931471805599453
iteration 1 batch 3110 training_loss 0.6901793251455568
iteration 1 batch 3120 training_loss 0.6916632528527511
iteration 1 batch 3130 training_loss 0.6931471805599453
iteration 1 batch 3140 training_loss 0.6931471805599453
iteration 1 batch 3150 training_loss 0.6931471805599453
iteration 1 batch 3160 training_loss 0.6916632528527511
iteration 1 batch 3170 training_loss 0.6931471805599453
iteration 1 batch 3180 training_loss 0.6931471805599453
iteration 1 batch 3190 training_loss 0.6901793251455568
iteration 1 batch 3200 training_loss 0.6916632528527511
iteration 1 batch 3210 training_loss 0.6931471805599453
iteration 1 batch 3220 training_loss 0.6931471805599453
iteration 1 batch 3230 training_loss 0.6916632528527511
iteration 1 batch 3240 training_loss 0.6931471805599453
iteration 1 batch 3250 training_loss 0.6916632528527511
iteration 1 batch 3260 training_loss 0.6931471805599453
iteration 1 batch 3270 training_loss 0.6931471805599453
iteration 1 batch 3280 training_loss 0.6931471805599453
iteration 1 batch 3290 training_loss 0.6916632528527511
iteration 1 batch 3300 training_loss 0.6931471805599453
iteration 1 batch 3310 training_loss 0.6931471805599453
iteration 1 batch 3320 training_loss 0.6931471805599453
iteration 1 batch 3330 training_loss 0.6931471805599453
iteration 1 batch 3340 training_loss 0.6931471805599453
iteration 1 batch 3350 training_loss 0.6931471805599453
iteration 1 batch 3360 training_loss 0.6931471805599453
iteration 1 batch 3370 training_loss 0.6931471805599453
iteration 1 batch 3380 training_loss 0.6931471805599453
iteration 1 batch 3390 training_loss 0.6931471805599453
iteration 1 batch 3400 training_loss 0.6931471805599453
iteration 1 batch 3410 training_loss 0.6916632528527511
iteration 1 batch 3420 training_loss 0.6931471805599453
iteration 1 batch 3430 training_loss 0.6931471805599453
iteration 1 batch 3440 training_loss 0.6931471805599453
iteration 1 batch 3450 training_loss 0.6931471805599453
iteration 1 batch 3460 training_loss 0.6931471805599453
iteration 1 batch 3470 training_loss 0.6931471805599453
iteration 1 batch 3480 training_loss 0.6931471805599453
iteration 1 batch 3490 training_loss 0.6931471805599453
iteration 1 batch 3500 training_loss 0.6931471805599453
iteration 1 batch 3510 training_loss 0.6931471805599453
iteration 1 batch 3520 training_loss 0.6931471805599453
iteration 1 batch 3530 training_loss 0.6916632528527511
iteration 1 batch 3540 training_loss 0.6931471805599453
iteration 1 batch 3550 training_loss 0.6931471805599453
iteration 1 batch 3560 training_loss 0.6931471805599453
iteration 1 batch 3570 training_loss 0.6931471805599453
iteration 1 batch 3580 training_loss 0.6916632528527511
iteration 1 batch 3590 training_loss 0.6931471805599453
iteration 1 batch 3600 training_loss 0.6931471805599453
iteration 1 batch 3610 training_loss 0.6916632528527511
iteration 1 batch 3620 training_loss 0.6916632528527511
iteration 1 batch 3630 training_loss 0.6916632528527511
iteration 1 batch 3640 training_loss 0.6931471805599453
iteration 1 batch 3650 training_loss 0.6931471805599453
iteration 1 batch 3660 training_loss 0.6931471805599453
iteration 1 batch 3670 training_loss 0.6916632528527511
iteration 1 batch 3680 training_loss 0.6916632528527511
iteration 1 batch 3690 training_loss 0.6931471805599453
iteration 1 batch 3700 training_loss 0.6901793251455568
iteration 1 batch 3710 training_loss 0.6931471805599453
iteration 1 batch 3720 training_loss 0.6901793251455568
iteration 1 batch 3730 training_loss 0.6901793251455568
iteration 1 batch 3740 training_loss 0.6916632528527511
iteration 1 batch 3750 training_loss 0.6931471805599453
iteration 1 batch 3760 training_loss 0.6931471805599453
iteration 1 batch 3770 training_loss 0.6931471805599453
iteration 1 batch 3780 training_loss 0.6931471805599453
iteration 1 batch 3790 training_loss 0.6916632528527511
iteration 1 batch 3800 training_loss 0.6931471805599453
iteration 1 batch 3810 training_loss 0.6916632528527511
iteration 1 batch 3820 training_loss 0.6931471805599453
iteration 1 batch 3830 training_loss 0.6931471805599453
iteration 1 batch 3840 training_loss 0.6931471805599453
iteration 1 batch 3850 training_loss 0.6931471805599453
iteration 1 batch 3860 training_loss 0.6931471805599453
iteration 1 batch 3870 training_loss 0.6931471805599453
iteration 1 batch 3880 training_loss 0.6931471805599453
iteration 1 batch 3890 training_loss 0.6931471805599453
iteration 1 batch 3900 training_loss 0.6931471805599453
iteration 1 batch 3910 training_loss 0.6931471805599453
iteration 1 batch 3920 training_loss 0.6916632528527511
iteration 1 batch 3930 training_loss 0.6916632528527511
iteration 1 batch 3940 training_loss 0.6931471805599453
iteration 1 batch 3950 training_loss 0.6916632528527511
iteration 1 batch 3960 training_loss 0.6886953974383626
iteration 1 batch 3970 training_loss 0.6931471805599453
iteration 1 batch 3980 training_loss 0.6931471805599453
iteration 1 batch 3990 training_loss 0.6931471805599453
iteration 1 batch 4000 training_loss 0.6931471805599453
iteration 1 batch 4010 training_loss 0.6931471805599453
iteration 1 batch 4020 training_loss 0.6931471805599453
iteration 1 batch 4030 training_loss 0.6931471805599453
iteration 1 batch 4040 training_loss 0.6916632528527511
iteration 1 batch 4050 training_loss 0.6931471805599453
iteration 1 batch 4060 training_loss 0.6916632528527511
iteration 1 batch 4070 training_loss 0.6931471805599453
iteration 1 batch 4080 training_loss 0.6931471805599453
iteration 1 batch 4090 training_loss 0.6931471805599453
iteration 1 batch 4100 training_loss 0.6931471805599453
iteration 1 batch 4110 training_loss 0.6931471805599453
iteration 1 batch 4120 training_loss 0.6931471805599453
iteration 1 batch 4130 training_loss 0.6931471805599453
iteration 1 batch 4140 training_loss 0.6916632528527511
iteration 1 batch 4150 training_loss 0.6901793251455568
iteration 1 batch 4160 training_loss 0.6916632528527511
iteration 1 batch 4170 training_loss 0.6931471805599453
iteration 1 batch 4180 training_loss 0.6931471805599453
iteration 1 batch 4190 training_loss 0.6931471805599453
iteration 1 batch 4200 training_loss 0.6931471805599453
iteration 1 batch 4210 training_loss 0.6931471805599453
iteration 1 batch 4220 training_loss 0.6931471805599453
iteration 1 batch 4230 training_loss 0.6916632528527511
iteration 1 batch 4240 training_loss 0.6916632528527511
iteration 1 batch 4250 training_loss 0.6916632528527511
iteration 1 batch 4260 training_loss 0.6931471805599453
iteration 1 batch 4270 training_loss 0.6916632528527511
iteration 1 batch 4280 training_loss 0.6931471805599453
iteration 1 batch 4290 training_loss 0.6916632528527511
iteration 1 batch 4300 training_loss 0.6931471805599453
iteration 1 batch 4310 training_loss 0.6931471805599453
iteration 1 batch 4320 training_loss 0.6931471805599453
iteration 1 batch 4330 training_loss 0.6916632528527511
iteration 1 batch 4340 training_loss 0.6931471805599453
iteration 1 batch 4350 training_loss 0.6931471805599453
iteration 1 batch 4360 training_loss 0.6931471805599453
iteration 1 batch 4370 training_loss 0.6931471805599453
iteration 1 batch 4380 training_loss 0.6931471805599453
iteration 1 batch 4390 training_loss 0.6931471805599453
iteration 1 batch 4400 training_loss 0.6916632528527511
iteration 1 batch 4410 training_loss 0.6931471805599453
iteration 1 batch 4420 training_loss 0.6931471805599453
iteration 1 batch 4430 training_loss 0.6931471805599453
iteration 1 batch 4440 training_loss 0.6931471805599453
iteration 1 batch 4450 training_loss 0.6931471805599453
iteration 1 batch 4460 training_loss 0.6916632528527511
iteration 1 batch 4470 training_loss 0.6931471805599453
iteration 1 batch 4480 training_loss 0.6931471805599453
iteration 1 batch 4490 training_loss 0.6931471805599453
iteration 1 batch 4500 training_loss 0.6931471805599453
iteration 1 batch 4510 training_loss 0.6916632528527511
iteration 1 batch 4520 training_loss 0.6901793251455568
iteration 1 batch 4530 training_loss 0.6931471805599453
iteration 1 batch 4540 training_loss 0.6931471805599453
iteration 1 batch 4550 training_loss 0.6916632528527511
iteration 1 batch 4560 training_loss 0.6931471805599453
iteration 1 batch 4570 training_loss 0.6931471805599453
iteration 1 batch 4580 training_loss 0.6916632528527511
iteration 1 batch 4590 training_loss 0.6931471805599453
iteration 1 batch 4600 training_loss 0.6931471805599453
iteration 1 batch 4610 training_loss 0.6931471805599453
iteration 1 batch 4620 training_loss 0.6931471805599453
iteration 1 batch 4630 training_loss 0.6931471805599453
iteration 1 batch 4640 training_loss 0.6931471805599453
iteration 1 batch 4650 training_loss 0.6931471805599453
iteration 1 batch 4660 training_loss 0.6931471805599453
iteration 1 batch 4670 training_loss 0.6916632528527511
iteration 1 batch 4680 training_loss 0.6931471805599453
iteration 1 batch 4690 training_loss 0.6931471805599453
iteration 1 batch 4700 training_loss 0.6931471805599453
iteration 1 batch 4710 training_loss 0.6931471805599453
iteration 1 batch 4720 training_loss 0.6931471805599453
iteration 1 batch 4730 training_loss 0.6916632528527511
iteration 1 batch 4740 training_loss 0.6916632528527511
iteration 1 batch 4750 training_loss 0.6931471805599453
iteration 1 batch 4760 training_loss 0.6916632528527511
iteration 1 batch 4770 training_loss 0.6901793251455568
iteration 1 batch 4780 training_loss 0.6931471805599453
iteration 1 batch 4790 training_loss 0.6901793251455568
iteration 1 batch 4800 training_loss 0.6931471805599453
iteration 1 batch 4810 training_loss 0.6916632528527511
iteration 1 batch 4820 training_loss 0.6931471805599453
iteration 1 batch 4830 training_loss 0.6931471805599453
iteration 1 batch 4840 training_loss 0.6931471805599453
iteration 1 batch 4850 training_loss 0.6931471805599453
iteration 1 batch 4860 training_loss 0.6931471805599453
iteration 1 batch 4870 training_loss 0.6901793251455568
iteration 1 batch 4880 training_loss 0.6931471805599453
iteration 1 batch 4890 training_loss 0.6931471805599453
iteration 1 batch 4900 training_loss 0.6916632528527511
iteration 1 batch 4910 training_loss 0.6916632528527511
iteration 1 batch 4920 training_loss 0.6931471805599453
iteration 1 batch 4930 training_loss 0.6931471805599453
iteration 1 batch 4940 training_loss 0.6931471805599453
iteration 1 batch 4950 training_loss 0.6916632528527511
iteration 1 batch 4960 training_loss 0.6931471805599453
iteration 1 batch 4970 training_loss 0.6931471805599453
iteration 1 batch 4980 training_loss 0.6931471805599453
iteration 1 batch 4990 training_loss 0.6916632528527511
iteration 1 batch 5000 training_loss 0.6931471805599453
iteration 1 batch 5010 training_loss 0.6931471805599453
iteration 1 batch 5020 training_loss 0.6931471805599453
iteration 1 batch 5030 training_loss 0.6931471805599453
iteration 1 batch 5040 training_loss 0.6931471805599453
iteration 1 batch 5050 training_loss 0.6931471805599453
iteration 1 batch 5060 training_loss 0.6931471805599453
iteration 1 batch 5070 training_loss 0.6916632528527511
iteration 1 batch 5080 training_loss 0.6931471805599453
iteration 1 batch 5090 training_loss 0.6916632528527511
iteration 1 batch 5100 training_loss 0.6916632528527511
iteration 1 batch 5110 training_loss 0.6931471805599453
iteration 1 batch 5120 training_loss 0.6931471805599453
iteration 1 batch 5130 training_loss 0.6931471805599453
iteration 1 batch 5140 training_loss 0.6931471805599453
iteration 1 batch 5150 training_loss 0.6931471805599453
iteration 1 batch 5160 training_loss 0.6916632528527511
iteration 1 batch 5170 training_loss 0.6931471805599453
iteration 1 batch 5180 training_loss 0.6931471805599453
iteration 1 batch 5190 training_loss 0.6916632528527511
iteration 1 batch 5200 training_loss 0.6901793251455568
iteration 1 batch 5210 training_loss 0.6916632528527511
iteration 1 batch 5220 training_loss 0.6931471805599453
iteration 1 batch 5230 training_loss 0.6931471805599453
iteration 1 batch 5240 training_loss 0.6931471805599453
iteration 1 batch 5250 training_loss 0.6916632528527511
iteration 1 batch 5260 training_loss 0.6916632528527511
iteration 1 batch 5270 training_loss 0.6931471805599453
iteration 1 batch 5280 training_loss 0.6931471805599453
iteration 1 batch 5290 training_loss 0.6931471805599453
iteration 1 batch 5300 training_loss 0.6931471805599453
iteration 1 batch 5310 training_loss 0.6931471805599453
iteration 1 batch 5320 training_loss 0.6931471805599453
iteration 1 batch 5330 training_loss 0.6931471805599453
iteration 1 batch 5340 training_loss 0.6916632528527511
iteration 1 batch 5350 training_loss 0.6931471805599453
iteration 1 batch 5360 training_loss 0.6931471805599453
iteration 1 batch 5370 training_loss 0.6931471805599453
iteration 1 batch 5380 training_loss 0.6931471805599453
iteration 1 batch 5390 training_loss 0.6931471805599453
iteration 1 batch 5400 training_loss 0.6916632528527511
iteration 1 batch 5410 training_loss 0.6931471805599453
iteration 1 batch 5420 training_loss 0.6931471805599453
iteration 1 batch 5430 training_loss 0.6931471805599453
iteration 1 batch 5440 training_loss 0.6916632528527511
iteration 1 batch 5450 training_loss 0.6931471805599453
iteration 1 batch 5460 training_loss 0.6931471805599453
iteration 1 batch 5470 training_loss 0.6931471805599453
iteration 1 batch 5480 training_loss 0.6931471805599453
iteration 1 batch 5490 training_loss 0.6916632528527511
iteration 1 batch 5500 training_loss 0.6931471805599453
iteration 1 batch 5510 training_loss 0.6931471805599453
iteration 1 batch 5520 training_loss 0.6931471805599453
iteration 1 batch 5530 training_loss 0.6931471805599453
iteration 1 batch 5540 training_loss 0.6931471805599453
iteration 1 batch 5550 training_loss 0.6931471805599453
iteration 1 batch 5560 training_loss 0.6901793251455568
iteration 1 batch 5570 training_loss 0.6931471805599453
iteration 1 batch 5580 training_loss 0.6916632528527511
iteration 1 batch 5590 training_loss 0.6916632528527511
iteration 1 batch 5600 training_loss 0.6931471805599453
iteration 1 batch 5610 training_loss 0.6916632528527511
iteration 1 batch 5620 training_loss 0.6916632528527511
iteration 1 batch 5630 training_loss 0.6931471805599453
iteration 1 batch 5640 training_loss 0.6916632528527511
iteration 1 batch 5650 training_loss 0.6931471805599453
iteration 1 batch 5660 training_loss 0.6931471805599453
iteration 1 batch 5670 training_loss 0.6931471805599453
iteration 1 batch 5680 training_loss 0.6931471805599453
iteration 1 batch 5690 training_loss 0.6931471805599453
iteration 1 batch 5700 training_loss 0.6931471805599453
iteration 1 batch 5710 training_loss 0.6931471805599453
iteration 1 batch 5720 training_loss 0.6931471805599453
iteration 1 batch 5730 training_loss 0.6931471805599453
iteration 1 batch 5740 training_loss 0.6931471805599453
iteration 1 batch 5750 training_loss 0.6931471805599453
iteration 1 batch 5760 training_loss 0.6931471805599453
iteration 1 batch 5770 training_loss 0.6931471805599453
iteration 1 batch 5780 training_loss 0.6931471805599453
iteration 1 batch 5790 training_loss 0.6931471805599453
iteration 1 batch 5800 training_loss 0.6931471805599453
iteration 1 batch 5810 training_loss 0.6931471805599453
iteration 1 batch 5820 training_loss 0.6931471805599453
iteration 1 batch 5830 training_loss 0.6931471805599453
iteration 1 batch 5840 training_loss 0.6931471805599453
iteration 1 batch 5850 training_loss 0.6916632528527511
iteration 1 batch 5860 training_loss 0.6916632528527511
iteration 1 batch 5870 training_loss 0.6931471805599453
iteration 1 batch 5880 training_loss 0.6931471805599453
iteration 1 batch 5890 training_loss 0.6931471805599453
iteration 1 batch 5900 training_loss 0.6931471805599453
iteration 1 batch 5910 training_loss 0.6931471805599453
iteration 1 batch 5920 training_loss 0.6931471805599453
iteration 1 batch 5930 training_loss 0.6931471805599453
iteration 1 batch 5940 training_loss 0.6916632528527511
iteration 1 batch 5950 training_loss 0.6931471805599453
iteration 1 batch 5960 training_loss 0.6931471805599453
iteration 1 batch 5970 training_loss 0.6931471805599453
iteration 1 batch 5980 training_loss 0.6931471805599453
iteration 1 batch 5990 training_loss 0.6931471805599453
iteration 1 batch 6000 training_loss 0.6931471805599453
iteration 1 batch 6010 training_loss 0.6916632528527511
iteration 1 batch 6020 training_loss 0.6931471805599453
iteration 1 batch 6030 training_loss 0.6931471805599453
iteration 1 batch 6040 training_loss 0.6931471805599453
iteration 1 batch 6050 training_loss 0.6916632528527511
iteration 1 batch 6060 training_loss 0.6931471805599453
iteration 1 batch 6070 training_loss 0.6931471805599453
iteration 1 batch 6080 training_loss 0.6931471805599453
iteration 1 batch 6090 training_loss 0.6931471805599453
iteration 1 batch 6100 training_loss 0.6931471805599453
iteration 1 batch 6110 training_loss 0.6931471805599453
iteration 1 batch 6120 training_loss 0.6931471805599453
iteration 1 batch 6130 training_loss 0.6931471805599453
iteration 1 batch 6140 training_loss 0.6931471805599453
iteration 1 batch 6150 training_loss 0.6931471805599453
iteration 1 batch 6160 training_loss 0.6931471805599453
iteration 1 batch 6170 training_loss 0.6916632528527511
iteration 1 batch 6180 training_loss 0.6931471805599453
iteration 1 batch 6190 training_loss 0.6931471805599453
iteration 1 batch 6200 training_loss 0.6931471805599453
iteration 1 batch 6210 training_loss 0.6931471805599453
iteration 1 batch 6220 training_loss 0.6901793251455568
iteration 1 batch 6230 training_loss 0.6931471805599453
iteration 1 batch 6240 training_loss 0.6916632528527511
iteration 1 batch 6250 training_loss 0.6931471805599453
iteration 1 batch 6260 training_loss 0.6931471805599453
iteration 1 batch 6270 training_loss 0.6931471805599453
iteration 1 batch 6280 training_loss 0.6931471805599453
iteration 1 batch 6290 training_loss 0.6916632528527511
iteration 1 batch 6300 training_loss 0.6931471805599453
iteration 1 batch 6310 training_loss 0.6916632528527511
iteration 1 batch 6320 training_loss 0.6931471805599453
iteration 1 batch 6330 training_loss 0.6931471805599453
iteration 1 batch 6340 training_loss 0.6931471805599453
iteration 1 batch 6350 training_loss 0.6931471805599453
iteration 1 batch 6360 training_loss 0.6931471805599453
iteration 1 batch 6370 training_loss 0.6931471805599453
iteration 1 batch 6380 training_loss 0.6931471805599453
iteration 1 batch 6390 training_loss 0.6931471805599453
iteration 1 batch 6400 training_loss 0.6916632528527511
iteration 1 batch 6410 training_loss 0.6916632528527511
iteration 1 batch 6420 training_loss 0.6931471805599453
iteration 1 batch 6430 training_loss 0.6931471805599453
iteration 1 batch 6440 training_loss 0.6931471805599453
iteration 1 batch 6450 training_loss 0.6901793251455568
iteration 1 batch 6460 training_loss 0.6931471805599453
iteration 1 batch 6470 training_loss 0.6931471805599453
iteration 1 batch 6480 training_loss 0.6931471805599453
iteration 1 batch 6490 training_loss 0.6901793251455568
iteration 1 batch 6500 training_loss 0.6916632528527511
iteration 1 batch 6510 training_loss 0.6931471805599453
iteration 1 batch 6520 training_loss 0.6916632528527511
iteration 1 batch 6530 training_loss 0.6931471805599453
iteration 1 batch 6540 training_loss 0.6916632528527511
iteration 1 batch 6550 training_loss 0.6931471805599453
iteration 1 batch 6560 training_loss 0.6931471805599453
iteration 1 batch 6570 training_loss 0.6916632528527511
iteration 1 batch 6580 training_loss 0.6931471805599453
iteration 1 batch 6590 training_loss 0.6931471805599453
iteration 1 batch 6600 training_loss 0.6931471805599453
iteration 1 batch 6610 training_loss 0.6931471805599453
iteration 1 batch 6620 training_loss 0.6931471805599453
iteration 1 batch 6630 training_loss 0.6931471805599453
iteration 1 batch 6640 training_loss 0.6931471805599453
iteration 1 batch 6650 training_loss 0.6931471805599453
iteration 1 batch 6660 training_loss 0.6901793251455568
iteration 1 batch 6670 training_loss 0.6931471805599453
iteration 1 batch 6680 training_loss 0.6931471805599453
iteration 1 batch 6690 training_loss 0.6931471805599453
iteration 1 batch 6700 training_loss 0.6931471805599453
iteration 1 batch 6710 training_loss 0.6931471805599453
iteration 1 batch 6720 training_loss 0.6931471805599453
iteration 1 batch 6730 training_loss 0.6916632528527511
iteration 1 batch 6740 training_loss 0.6931471805599453
iteration 1 batch 6750 training_loss 0.6931471805599453
iteration 1 batch 6760 training_loss 0.6931471805599453
iteration 1 batch 6770 training_loss 0.6931471805599453
iteration 1 batch 6780 training_loss 0.6931471805599453
iteration 1 batch 6790 training_loss 0.6931471805599453
iteration 1 batch 6800 training_loss 0.6931471805599453
iteration 1 batch 6810 training_loss 0.6931471805599453
iteration 1 batch 6820 training_loss 0.6931471805599453
iteration 1 batch 6830 training_loss 0.6931471805599453
iteration 1 batch 6840 training_loss 0.6931471805599453
iteration 1 batch 6850 training_loss 0.6916632528527511
iteration 1 batch 6860 training_loss 0.6931471805599453
iteration 1 batch 6870 training_loss 0.6931471805599453
iteration 1 batch 6880 training_loss 0.6931471805599453
iteration 1 batch 6890 training_loss 0.6931471805599453
iteration 1 batch 6900 training_loss 0.6931471805599453
iteration 1 batch 6910 training_loss 0.6931471805599453
iteration 1 batch 6920 training_loss 0.6931471805599453
iteration 1 batch 6930 training_loss 0.6931471805599453
iteration 1 batch 6940 training_loss 0.6931471805599453
iteration 1 batch 6950 training_loss 0.6931471805599453
iteration 1 batch 6960 training_loss 0.6931471805599453
iteration 1 batch 6970 training_loss 0.6931471805599453
iteration 1 batch 6980 training_loss 0.6931471805599453
iteration 1 batch 6990 training_loss 0.6931471805599453
iteration 1 batch 7000 training_loss 0.6931471805599453
iteration 1 batch 7010 training_loss 0.6916632528527511
iteration 1 batch 7020 training_loss 0.6931471805599453
iteration 1 batch 7030 training_loss 0.6916632528527511
iteration 1 batch 7040 training_loss 0.6916632528527511
iteration 1 batch 7050 training_loss 0.6931471805599453
iteration 1 batch 7060 training_loss 0.6931471805599453
iteration 1 batch 7070 training_loss 0.6931471805599453
iteration 1 batch 7080 training_loss 0.6931471805599453
iteration 1 batch 7090 training_loss 0.6931471805599453
iteration 1 batch 7100 training_loss 0.6931471805599453
iteration 1 batch 7110 training_loss 0.6931471805599453
iteration 1 batch 7120 training_loss 0.6901793251455568
iteration 1 batch 7130 training_loss 0.6931471805599453
iteration 1 batch 7140 training_loss 0.6931471805599453
iteration 1 batch 7150 training_loss 0.6931471805599453
iteration 1 batch 7160 training_loss 0.6931471805599453
iteration 1 batch 7170 training_loss 0.6931471805599453
iteration 1 batch 7180 training_loss 0.6916632528527511
iteration 1 batch 7190 training_loss 0.6931471805599453
iteration 1 batch 7200 training_loss 0.6916632528527511
iteration 1 batch 7210 training_loss 0.6931471805599453
iteration 1 batch 7220 training_loss 0.6931471805599453
iteration 1 batch 7230 training_loss 0.6916632528527511
iteration 1 batch 7240 training_loss 0.6931471805599453
iteration 1 batch 7250 training_loss 0.6901793251455568
iteration 1 batch 7260 training_loss 0.6931471805599453
iteration 1 batch 7270 training_loss 0.6916632528527511
iteration 1 batch 7280 training_loss 0.6931471805599453
iteration 1 batch 7290 training_loss 0.6931471805599453
iteration 1 batch 7300 training_loss 0.6931471805599453
iteration 1 batch 7310 training_loss 0.6931471805599453
iteration 1 batch 7320 training_loss 0.6931471805599453
iteration 1 batch 7330 training_loss 0.6931471805599453
iteration 1 batch 7340 training_loss 0.6931471805599453
iteration 1 batch 7350 training_loss 0.6916632528527511
iteration 1 batch 7360 training_loss 0.6931471805599453
iteration 1 batch 7370 training_loss 0.6931471805599453
iteration 1 batch 7380 training_loss 0.6916632528527511
iteration 1 batch 7390 training_loss 0.6931471805599453
iteration 1 batch 7400 training_loss 0.6931471805599453
iteration 1 batch 7410 training_loss 0.6931471805599453
iteration 1 batch 7420 training_loss 0.6931471805599453
iteration 1 batch 7430 training_loss 0.6916632528527511
iteration 1 batch 7440 training_loss 0.6931471805599453
iteration 1 batch 7450 training_loss 0.6931471805599453
iteration 1 batch 7460 training_loss 0.6931471805599453
iteration 1 batch 7470 training_loss 0.6916632528527511
iteration 1 batch 7480 training_loss 0.6931471805599453
iteration 1 batch 7490 training_loss 0.6931471805599453
iteration 1 batch 7500 training_loss 0.6931471805599453
iteration 1 batch 7510 training_loss 0.6931471805599453
iteration 1 batch 7520 training_loss 0.6916632528527511
iteration 1 batch 7530 training_loss 0.6901793251455568
iteration 1 batch 7540 training_loss 0.6931471805599453
iteration 1 batch 7550 training_loss 0.6916632528527511
iteration 1 batch 7560 training_loss 0.6931471805599453
iteration 1 batch 7570 training_loss 0.6931471805599453
iteration 1 batch 7580 training_loss 0.6931471805599453
iteration 1 batch 7590 training_loss 0.6931471805599453
iteration 1 batch 7600 training_loss 0.6931471805599453
iteration 1 batch 7610 training_loss 0.6931471805599453
iteration 1 batch 7620 training_loss 0.6931471805599453
iteration 1 batch 7630 training_loss 0.6931471805599453
iteration 1 batch 7640 training_loss 0.6931471805599453
iteration 1 batch 7650 training_loss 0.6931471805599453
iteration 1 batch 7660 training_loss 0.6931471805599453
iteration 1 batch 7670 training_loss 0.6931471805599453
iteration 1 batch 7680 training_loss 0.6931471805599453
iteration 1 batch 7690 training_loss 0.6931471805599453
iteration 1 batch 7700 training_loss 0.6916632528527511
iteration 1 batch 7710 training_loss 0.6931471805599453
iteration 1 batch 7720 training_loss 0.6931471805599453
iteration 1 batch 7730 training_loss 0.6931471805599453
iteration 1 batch 7740 training_loss 0.6931471805599453
iteration 1 batch 7750 training_loss 0.6931471805599453
iteration 1 batch 7760 training_loss 0.6901793251455568
iteration 1 batch 7770 training_loss 0.6931471805599453
iteration 1 batch 7780 training_loss 0.6931471805599453
iteration 1 batch 7790 training_loss 0.6931471805599453
iteration 1 batch 7800 training_loss 0.6901793251455568
iteration 1 batch 7810 training_loss 0.6916632528527511
iteration 1 batch 7820 training_loss 0.6931471805599453
iteration 1 batch 7830 training_loss 0.6931471805599453
iteration 1 batch 7840 training_loss 0.6931471805599453
iteration 1 batch 7850 training_loss 0.6931471805599453
iteration 1 batch 7860 training_loss 0.6931471805599453
iteration 1 batch 7870 training_loss 0.6901793251455568
iteration 1 batch 7880 training_loss 0.6931471805599453
iteration 1 batch 7890 training_loss 0.6931471805599453
iteration 1 batch 7900 training_loss 0.6931471805599453
iteration 1 batch 7910 training_loss 0.6931471805599453
iteration 1 batch 7920 training_loss 0.6916632528527511
iteration 1 batch 7930 training_loss 0.6916632528527511
iteration 1 batch 7940 training_loss 0.6931471805599453
iteration 1 batch 7950 training_loss 0.6931471805599453
iteration 1 batch 7960 training_loss 0.6931471805599453
iteration 1 batch 7970 training_loss 0.6931471805599453
iteration 1 batch 7980 training_loss 0.6931471805599453
iteration 1 batch 7990 training_loss 0.6931471805599453
iteration 1 batch 8000 training_loss 0.6916632528527511
iteration 1 batch 8010 training_loss 0.6886953974383626
iteration 1 batch 8020 training_loss 0.6931471805599453
iteration 1 batch 8030 training_loss 0.6931471805599453
iteration 1 batch 8040 training_loss 0.6931471805599453
iteration 1 batch 8050 training_loss 0.6931471805599453
iteration 1 batch 8060 training_loss 0.6901793251455568
iteration 1 batch 8070 training_loss 0.6931471805599453
iteration 1 batch 8080 training_loss 0.6916632528527511
iteration 1 batch 8090 training_loss 0.6916632528527511
iteration 1 batch 8100 training_loss 0.6931471805599453
iteration 1 batch 8110 training_loss 0.6931471805599453
iteration 1 batch 8120 training_loss 0.6931471805599453
iteration 1 batch 8130 training_loss 0.6931471805599453
iteration 1 batch 8140 training_loss 0.6931471805599453
iteration 1 batch 8150 training_loss 0.6916632528527511
iteration 1 batch 8160 training_loss 0.6931471805599453
iteration 1 batch 8170 training_loss 0.6931471805599453
iteration 1 batch 8180 training_loss 0.6931471805599453
iteration 1 batch 8190 training_loss 0.6931471805599453
iteration 1 batch 8200 training_loss 0.6931471805599453
iteration 1 batch 8210 training_loss 0.6931471805599453
iteration 1 batch 8220 training_loss 0.6931471805599453
iteration 1 batch 8230 training_loss 0.6931471805599453
iteration 1 batch 8240 training_loss 0.6931471805599453
iteration 1 batch 8250 training_loss 0.6886953974383626
iteration 1 batch 8260 training_loss 0.6931471805599453
iteration 1 batch 8270 training_loss 0.6931471805599453
iteration 1 batch 8280 training_loss 0.6931471805599453
iteration 1 batch 8290 training_loss 0.6916632528527511
iteration 1 batch 8300 training_loss 0.6916632528527511
iteration 1 batch 8310 training_loss 0.6931471805599453
iteration 1 batch 8320 training_loss 0.6916632528527511
iteration 1 batch 8330 training_loss 0.6901793251455568
iteration 1 batch 8340 training_loss 0.6931471805599453
iteration 1 batch 8350 training_loss 0.6931471805599453
iteration 1 batch 8360 training_loss 0.6931471805599453
iteration 1 batch 8370 training_loss 0.6931471805599453
iteration 1 batch 8380 training_loss 0.6916632528527511
iteration 1 batch 8390 training_loss 0.6931471805599453
iteration 1 batch 8400 training_loss 0.6931471805599453
iteration 1 batch 8410 training_loss 0.6931471805599453
iteration 1 batch 8420 training_loss 0.6901793251455568
iteration 1 batch 8430 training_loss 0.6916632528527511
iteration 1 batch 8440 training_loss 0.6931471805599453
iteration 1 batch 8450 training_loss 0.6931471805599453
iteration 1 batch 8460 training_loss 0.6931471805599453
iteration 1 batch 8470 training_loss 0.6931471805599453
iteration 1 batch 8480 training_loss 0.6931471805599453
iteration 1 batch 8490 training_loss 0.6916632528527511
iteration 1 batch 8500 training_loss 0.6916632528527511
iteration 1 batch 8510 training_loss 0.6916632528527511
iteration 1 batch 8520 training_loss 0.6931471805599453
iteration 1 batch 8530 training_loss 0.6931471805599453
iteration 1 batch 8540 training_loss 0.6931471805599453
iteration 1 batch 8550 training_loss 0.6931471805599453
iteration 1 batch 8560 training_loss 0.6916632528527511
iteration 1 batch 8570 training_loss 0.6931471805599453
iteration 1 batch 8580 training_loss 0.6931471805599453
iteration 1 batch 8590 training_loss 0.6931471805599453
iteration 1 batch 8600 training_loss 0.6916632528527511
iteration 1 batch 8610 training_loss 0.6931471805599453
iteration 1 batch 8620 training_loss 0.6931471805599453
iteration 1 batch 8630 training_loss 0.6916632528527511
iteration 1 batch 8640 training_loss 0.6931471805599453
iteration 1 batch 8650 training_loss 0.6931471805599453
iteration 1 batch 8660 training_loss 0.6931471805599453
iteration 1 batch 8670 training_loss 0.6931471805599453
iteration 1 batch 8680 training_loss 0.6931471805599453
iteration 1 batch 8690 training_loss 0.6931471805599453
iteration 1 batch 8700 training_loss 0.6931471805599453
iteration 1 batch 8710 training_loss 0.6931471805599453
iteration 1 batch 8720 training_loss 0.6931471805599453
iteration 1 batch 8730 training_loss 0.6916632528527511
iteration 1 batch 8740 training_loss 0.6916632528527511
iteration 1 batch 8750 training_loss 0.6916632528527511
iteration 1 batch 8760 training_loss 0.6931471805599453
iteration 1 batch 8770 training_loss 0.6931471805599453
iteration 1 batch 8780 training_loss 0.6916632528527511
iteration 1 batch 8790 training_loss 0.6931471805599453
iteration 1 batch 8800 training_loss 0.6931471805599453
iteration 1 batch 8810 training_loss 0.6931471805599453
iteration 1 batch 8820 training_loss 0.6916632528527511
iteration 1 batch 8830 training_loss 0.6931471805599453
iteration 1 batch 8840 training_loss 0.6931471805599453
iteration 1 batch 8850 training_loss 0.6886953974383626
iteration 1 batch 8860 training_loss 0.6931471805599453
iteration 1 batch 8870 training_loss 0.6931471805599453
iteration 1 batch 8880 training_loss 0.6931471805599453
iteration 1 batch 8890 training_loss 0.6931471805599453
iteration 1 batch 8900 training_loss 0.6931471805599453
iteration 1 batch 8910 training_loss 0.6931471805599453
iteration 1 batch 8920 training_loss 0.6931471805599453
iteration 1 batch 8930 training_loss 0.6931471805599453
iteration 1 batch 8940 training_loss 0.6931471805599453
iteration 1 batch 8950 training_loss 0.6931471805599453
iteration 1 batch 8960 training_loss 0.6931471805599453
iteration 1 batch 8970 training_loss 0.6931471805599453
iteration 1 batch 8980 training_loss 0.6931471805599453
iteration 1 batch 8990 training_loss 0.6931471805599453
iteration 1 batch 9000 training_loss 0.6931471805599453
iteration 1 batch 9010 training_loss 0.6931471805599453
iteration 1 batch 9020 training_loss 0.6931471805599453
iteration 1 batch 9030 training_loss 0.6931471805599453
iteration 1 batch 9040 training_loss 0.6931471805599453
iteration 1 batch 9050 training_loss 0.6931471805599453
iteration 1 batch 9060 training_loss 0.6916632528527511
iteration 1 batch 9070 training_loss 0.6931471805599453
iteration 1 batch 9080 training_loss 0.6916632528527511
iteration 1 batch 9090 training_loss 0.6931471805599453
iteration 1 batch 9100 training_loss 0.6931471805599453
iteration 1 batch 9110 training_loss 0.6916632528527511
iteration 1 batch 9120 training_loss 0.6931471805599453
iteration 1 batch 9130 training_loss 0.6931471805599453
iteration 1 batch 9140 training_loss 0.6916632528527511
iteration 1 batch 9150 training_loss 0.6931471805599453
iteration 1 batch 9160 training_loss 0.6931471805599453
iteration 1 batch 9170 training_loss 0.6931471805599453
iteration 1 batch 9180 training_loss 0.6931471805599453
iteration 1 batch 9190 training_loss 0.6901793251455568
iteration 1 batch 9200 training_loss 0.6931471805599453
iteration 1 batch 9210 training_loss 0.6931471805599453
iteration 1 batch 9220 training_loss 0.6931471805599453
iteration 1 batch 9230 training_loss 0.6931471805599453
iteration 1 batch 9240 training_loss 0.6931471805599453
iteration 1 batch 9250 training_loss 0.6931471805599453
iteration 1 batch 9260 training_loss 0.6916632528527511
iteration 1 batch 9270 training_loss 0.6931471805599453
iteration 1 batch 9280 training_loss 0.6931471805599453
iteration 1 batch 9290 training_loss 0.6931471805599453
iteration 1 batch 9300 training_loss 0.6931471805599453
iteration 1 batch 9310 training_loss 0.6931471805599453
iteration 1 batch 9320 training_loss 0.6931471805599453
iteration 1 batch 9330 training_loss 0.6931471805599453
iteration 1 batch 9340 training_loss 0.6931471805599453
iteration 1 batch 9350 training_loss 0.6931471805599453
iteration 1 batch 9360 training_loss 0.6916632528527511
iteration 1 batch 9370 training_loss 0.6916632528527511
iteration 1 batch 9380 training_loss 0.6931471805599453
iteration 1 batch 9390 training_loss 0.6931471805599453
iteration 1 batch 9400 training_loss 0.6931471805599453
iteration 1 batch 9410 training_loss 0.6931471805599453
iteration 1 batch 9420 training_loss 0.6931471805599453
iteration 1 batch 9430 training_loss 0.6931471805599453
iteration 1 batch 9440 training_loss 0.6931471805599453
iteration 1 batch 9450 training_loss 0.6931471805599453
iteration 1 batch 9460 training_loss 0.6931471805599453
iteration 1 batch 9470 training_loss 0.6931471805599453
iteration 1 batch 9480 training_loss 0.6931471805599453
iteration 1 batch 9490 training_loss 0.6916632528527511
iteration 1 batch 9500 training_loss 0.6931471805599453
iteration 1 batch 9510 training_loss 0.6916632528527511
iteration 1 batch 9520 training_loss 0.6931471805599453
iteration 1 batch 9530 training_loss 0.6931471805599453
iteration 1 batch 9540 training_loss 0.6931471805599453
iteration 1 batch 9550 training_loss 0.6916632528527511
iteration 1 batch 9560 training_loss 0.6931471805599453
iteration 1 batch 9570 training_loss 0.6931471805599453
iteration 1 batch 9580 training_loss 0.6931471805599453
iteration 1 batch 9590 training_loss 0.6931471805599453
iteration 1 batch 9600 training_loss 0.6931471805599453
iteration 1 batch 9610 training_loss 0.6931471805599453
iteration 1 batch 9620 training_loss 0.6916632528527511
iteration 1 batch 9630 training_loss 0.6931471805599453
iteration 1 batch 9640 training_loss 0.6931471805599453
iteration 1 batch 9650 training_loss 0.6931471805599453
iteration 1 batch 9660 training_loss 0.6931471805599453
iteration 1 batch 9670 training_loss 0.6931471805599453
iteration 1 batch 9680 training_loss 0.6931471805599453
iteration 1 batch 9690 training_loss 0.6931471805599453
iteration 1 batch 9700 training_loss 0.6931471805599453
iteration 1 batch 9710 training_loss 0.6931471805599453
iteration 1 batch 9720 training_loss 0.6931471805599453
iteration 1 batch 9730 training_loss 0.6916632528527511
iteration 1 batch 9740 training_loss 0.6931471805599453
iteration 1 batch 9750 training_loss 0.6916632528527511
iteration 1 batch 9760 training_loss 0.6931471805599453
iteration 1 batch 9770 training_loss 0.6931471805599453
iteration 1 batch 9780 training_loss 0.6916632528527511
iteration 1 batch 9790 training_loss 0.6931471805599453
iteration 1 batch 9800 training_loss 0.6931471805599453
iteration 1 batch 9810 training_loss 0.6931471805599453
iteration 1 batch 9820 training_loss 0.6931471805599453
iteration 1 batch 9830 training_loss 0.6916632528527511
iteration 1 batch 9840 training_loss 0.6931471805599453
iteration 1 batch 9850 training_loss 0.6931471805599453
iteration 1 batch 9860 training_loss 0.6931471805599453
iteration 1 batch 9870 training_loss 0.6931471805599453
iteration 1 batch 9880 training_loss 0.6931471805599453
iteration 1 batch 9890 training_loss 0.6916632528527511
iteration 1 batch 9900 training_loss 0.6931471805599453
iteration 1 batch 9910 training_loss 0.6931471805599453
iteration 1 batch 9920 training_loss 0.6931471805599453
iteration 1 batch 9930 training_loss 0.6931471805599453
iteration 1 batch 9940 training_loss 0.6916632528527511
iteration 1 batch 9950 training_loss 0.6931471805599453
iteration 1 batch 9960 training_loss 0.6931471805599453
iteration 1 batch 9970 training_loss 0.6931471805599453
iteration 1 batch 9980 training_loss 0.6916632528527511
iteration 1 batch 9990 training_loss 0.6931471805599453
iteration 1 batch 10000 training_loss 0.6931471805599453
iteration 1 batch 10010 training_loss 0.6916632528527511
iteration 1 batch 10020 training_loss 0.6916632528527511
iteration 1 batch 10030 training_loss 0.6931471805599453
iteration 1 batch 10040 training_loss 0.6931471805599453
iteration 1 batch 10050 training_loss 0.6931471805599453
iteration 1 batch 10060 training_loss 0.6931471805599453
iteration 1 batch 10070 training_loss 0.6916632528527511
iteration 1 batch 10080 training_loss 0.6931471805599453
iteration 1 batch 10090 training_loss 0.6931471805599453
iteration 1 batch 10100 training_loss 0.6931471805599453
iteration 1 batch 10110 training_loss 0.6931471805599453
iteration 1 batch 10120 training_loss 0.6931471805599453
iteration 1 batch 10130 training_loss 0.6931471805599453
iteration 1 batch 10140 training_loss 0.6931471805599453
iteration 1 batch 10150 training_loss 0.6931471805599453
iteration 1 batch 10160 training_loss 0.6931471805599453
iteration 1 batch 10170 training_loss 0.6931471805599453
iteration 1 batch 10180 training_loss 0.6916632528527511
iteration 1 batch 10190 training_loss 0.6931471805599453
iteration 1 batch 10200 training_loss 0.6931471805599453
iteration 1 batch 10210 training_loss 0.6931471805599453
iteration 1 batch 10220 training_loss 0.6931471805599453
iteration 1 batch 10230 training_loss 0.6931471805599453
iteration 1 batch 10240 training_loss 0.6931471805599453
iteration 1 batch 10250 training_loss 0.6931471805599453
iteration 1 batch 10260 training_loss 0.6931471805599453
iteration 1 batch 10270 training_loss 0.6931471805599453
iteration 1 batch 10280 training_loss 0.6931471805599453
iteration 1 batch 10290 training_loss 0.6931471805599453
iteration 1 batch 10300 training_loss 0.6931471805599453
iteration 1 batch 10310 training_loss 0.6931471805599453
iteration 1 batch 10320 training_loss 0.6931471805599453
iteration 1 batch 10330 training_loss 0.6916632528527511
iteration 1 batch 10340 training_loss 0.6931471805599453
iteration 1 batch 10350 training_loss 0.6931471805599453
iteration 1 batch 10360 training_loss 0.6931471805599453
iteration 1 batch 10370 training_loss 0.6931471805599453
iteration 1 batch 10380 training_loss 0.6931471805599453
iteration 1 batch 10390 training_loss 0.6931471805599453
iteration 1 batch 10400 training_loss 0.6931471805599453
iteration 1 batch 10410 training_loss 0.6931471805599453
iteration 1 batch 10420 training_loss 0.6931471805599453
iteration 1 batch 10430 training_loss 0.6916632528527511
iteration 1 batch 10440 training_loss 0.6931471805599453
iteration 1 batch 10450 training_loss 0.6931471805599453
iteration 1 batch 10460 training_loss 0.6931471805599453
iteration 1 batch 10470 training_loss 0.6931471805599453
iteration 1 batch 10480 training_loss 0.6872114697311684
iteration 1 batch 10490 training_loss 0.6931471805599453
iteration 1 batch 10500 training_loss 0.6931471805599453
iteration 1 batch 10510 training_loss 0.6931471805599453
iteration 1 batch 10520 training_loss 0.6916632528527511
iteration 1 batch 10530 training_loss 0.6931471805599453
iteration 1 batch 10540 training_loss 0.6931471805599453
iteration 1 batch 10550 training_loss 0.6931471805599453
iteration 1 batch 10560 training_loss 0.6931471805599453
iteration 1 batch 10570 training_loss 0.6931471805599453
iteration 1 batch 10580 training_loss 0.6931471805599453
iteration 1 batch 10590 training_loss 0.6931471805599453
iteration 1 batch 10600 training_loss 0.6931471805599453
iteration 1 batch 10610 training_loss 0.6931471805599453
iteration 1 batch 10620 training_loss 0.6931471805599453
iteration 1 batch 10630 training_loss 0.6931471805599453
iteration 1 batch 10640 training_loss 0.6931471805599453
iteration 1 batch 10650 training_loss 0.6931471805599453
iteration 1 batch 10660 training_loss 0.6931471805599453
iteration 1 batch 10670 training_loss 0.6931471805599453
iteration 1 batch 10680 training_loss 0.6931471805599453
iteration 1 batch 10690 training_loss 0.6931471805599453
iteration 1 batch 10700 training_loss 0.6931471805599453
iteration 1 batch 10710 training_loss 0.6931471805599453
iteration 1 batch 10720 training_loss 0.6931471805599453
iteration 1 batch 10730 training_loss 0.6916632528527511
iteration 1 batch 10740 training_loss 0.6931471805599453
iteration 1 batch 10750 training_loss 0.6931471805599453
iteration 1 batch 10760 training_loss 0.6931471805599453
iteration 1 batch 10770 training_loss 0.6916632528527511
iteration 1 batch 10780 training_loss 0.6931471805599453
iteration 1 batch 10790 training_loss 0.6931471805599453
iteration 1 batch 10800 training_loss 0.6931471805599453
iteration 1 batch 10810 training_loss 0.6931471805599453
iteration 1 batch 10820 training_loss 0.6931471805599453
iteration 1 batch 10830 training_loss 0.6931471805599453
iteration 1 batch 10840 training_loss 0.6916632528527511
iteration 1 batch 10850 training_loss 0.6931471805599453
iteration 1 batch 10860 training_loss 0.6931471805599453
iteration 1 batch 10870 training_loss 0.6916632528527511
iteration 1 batch 10880 training_loss 0.6931471805599453
iteration 1 batch 10890 training_loss 0.6931471805599453
iteration 1 batch 10900 training_loss 0.6916632528527511
iteration 1 batch 10910 training_loss 0.6916632528527511
iteration 1 batch 10920 training_loss 0.6916632528527511
iteration 1 batch 10930 training_loss 0.6931471805599453
iteration 1 batch 10940 training_loss 0.6931471805599453
iteration 1 batch 10950 training_loss 0.6931471805599453
iteration 1 batch 10960 training_loss 0.6931471805599453
iteration 1 batch 10970 training_loss 0.6916632528527511
iteration 1 batch 10980 training_loss 0.6931471805599453
iteration 1 batch 10990 training_loss 0.6931471805599453
iteration 1 batch 11000 training_loss 0.6916632528527511
iteration 1 batch 11010 training_loss 0.6931471805599453
iteration 1 batch 11020 training_loss 0.6916632528527511
iteration 1 batch 11030 training_loss 0.6916632528527511
iteration 1 batch 11040 training_loss 0.6931471805599453
iteration 1 batch 11050 training_loss 0.6931471805599453
iteration 1 batch 11060 training_loss 0.6931471805599453
iteration 1 batch 11070 training_loss 0.6931471805599453
iteration 1 batch 11080 training_loss 0.6931471805599453
iteration 1 batch 11090 training_loss 0.6931471805599453
iteration 1 batch 11100 training_loss 0.6916632528527511
iteration 1 batch 11110 training_loss 0.6931471805599453
iteration 1 batch 11120 training_loss 0.6931471805599453
iteration 1 batch 11130 training_loss 0.6916632528527511
iteration 1 batch 11140 training_loss 0.6931471805599453
iteration 1 batch 11150 training_loss 0.6931471805599453
iteration 1 batch 11160 training_loss 0.6931471805599453
iteration 1 batch 11170 training_loss 0.6916632528527511
iteration 1 batch 11180 training_loss 0.6931471805599453
iteration 1 batch 11190 training_loss 0.6901793251455568
iteration 1 batch 11200 training_loss 0.6931471805599453
iteration 1 batch 11210 training_loss 0.6931471805599453
iteration 1 batch 11220 training_loss 0.6931471805599453
iteration 1 batch 11230 training_loss 0.6931471805599453
iteration 1 batch 11240 training_loss 0.6931471805599453
iteration 1 batch 11250 training_loss 0.6916632528527511
iteration 1 batch 11260 training_loss 0.6931471805599453
iteration 1 batch 11270 training_loss 0.6931471805599453
iteration 1 batch 11280 training_loss 0.6931471805599453
iteration 1 batch 11290 training_loss 0.6931471805599453
iteration 1 batch 11300 training_loss 0.6931471805599453
iteration 1 batch 11310 training_loss 0.6931471805599453
iteration 1 batch 11320 training_loss 0.6931471805599453
iteration 1 batch 11330 training_loss 0.6901793251455568
iteration 1 batch 11340 training_loss 0.6931471805599453
iteration 1 batch 11350 training_loss 0.6931471805599453
iteration 1 batch 11360 training_loss 0.6931471805599453
iteration 1 batch 11370 training_loss 0.6931471805599453
iteration 1 batch 11380 training_loss 0.6931471805599453
iteration 1 batch 11390 training_loss 0.6916632528527511
iteration 1 batch 11400 training_loss 0.6931471805599453
iteration 1 batch 11410 training_loss 0.6931471805599453
iteration 1 batch 11420 training_loss 0.6931471805599453
iteration 1 batch 11430 training_loss 0.6931471805599453
iteration 1 batch 11440 training_loss 0.6916632528527511
iteration 1 batch 11450 training_loss 0.6931471805599453
iteration 1 batch 11460 training_loss 0.6931471805599453
iteration 1 batch 11470 training_loss 0.6931471805599453
iteration 1 batch 11480 training_loss 0.6931471805599453
iteration 1 batch 11490 training_loss 0.6931471805599453
iteration 1 batch 11500 training_loss 0.6931471805599453
iteration 1 batch 11510 training_loss 0.6931471805599453
iteration 1 batch 11520 training_loss 0.6931471805599453
iteration 1 batch 11530 training_loss 0.6931471805599453
iteration 1 batch 11540 training_loss 0.6931471805599453
iteration 1 batch 11550 training_loss 0.6931471805599453
iteration 1 batch 11560 training_loss 0.6931471805599453
iteration 1 batch 11570 training_loss 0.6931471805599453
iteration 1 batch 11580 training_loss 0.6916632528527511
iteration 1 batch 11590 training_loss 0.6931471805599453
iteration 1 batch 11600 training_loss 0.6916632528527511
iteration 1 batch 11610 training_loss 0.6931471805599453
iteration 1 batch 11620 training_loss 0.6931471805599453
iteration 1 batch 11630 training_loss 0.6931471805599453
iteration 1 batch 11640 training_loss 0.6931471805599453
iteration 1 batch 11650 training_loss 0.6931471805599453
iteration 1 batch 11660 training_loss 0.6901793251455568
iteration 1 batch 11670 training_loss 0.6931471805599453
iteration 1 batch 11680 training_loss 0.6931471805599453
iteration 1 batch 11690 training_loss 0.6931471805599453
iteration 1 batch 11700 training_loss 0.6931471805599453
iteration 1 batch 11710 training_loss 0.6931471805599453
iteration 1 batch 11720 training_loss 0.6931471805599453
iteration 1 batch 11730 training_loss 0.6931471805599453
iteration 1 batch 11740 training_loss 0.6931471805599453
iteration 1 batch 11750 training_loss 0.6931471805599453
iteration 1 batch 11760 training_loss 0.6931471805599453
iteration 1 batch 11770 training_loss 0.6916632528527511
iteration 1 batch 11780 training_loss 0.6931471805599453
iteration 1 batch 11790 training_loss 0.6931471805599453
iteration 1 batch 11800 training_loss 0.6931471805599453
iteration 1 batch 11810 training_loss 0.6931471805599453
iteration 1 batch 11820 training_loss 0.6931471805599453
iteration 1 batch 11830 training_loss 0.6916632528527511
iteration 1 batch 11840 training_loss 0.6931471805599453
iteration 1 batch 11850 training_loss 0.6931471805599453
iteration 1 batch 11860 training_loss 0.6931471805599453
iteration 1 batch 11870 training_loss 0.6931471805599453
iteration 1 batch 11880 training_loss 0.6931471805599453
iteration 1 batch 11890 training_loss 0.6931471805599453
iteration 1 batch 11900 training_loss 0.6931471805599453
iteration 1 batch 11910 training_loss 0.6931471805599453
iteration 1 batch 11920 training_loss 0.6931471805599453
iteration 1 batch 11930 training_loss 0.6931471805599453
iteration 1 batch 11940 training_loss 0.6931471805599453
iteration 1 batch 11950 training_loss 0.6931471805599453
iteration 1 batch 11960 training_loss 0.6931471805599453
iteration 1 batch 11970 training_loss 0.6931471805599453
iteration 1 batch 11980 training_loss 0.6931471805599453
iteration 1 batch 11990 training_loss 0.6931471805599453
iteration 1 batch 12000 training_loss 0.6931471805599453
iteration 1 batch 12010 training_loss 0.6931471805599453
iteration 1 batch 12020 training_loss 0.6916632528527511
iteration 1 batch 12030 training_loss 0.6931471805599453
iteration 1 batch 12040 training_loss 0.6931471805599453
iteration 1 batch 12050 training_loss 0.6931471805599453
iteration 1 batch 12060 training_loss 0.6931471805599453
iteration 1 batch 12070 training_loss 0.6931471805599453
iteration 1 batch 12080 training_loss 0.6931471805599453
iteration 1 batch 12090 training_loss 0.6931471805599453
iteration 1 batch 12100 training_loss 0.6931471805599453
iteration 1 batch 12110 training_loss 0.6931471805599453
iteration 1 batch 12120 training_loss 0.6931471805599453
iteration 1 batch 12130 training_loss 0.6931471805599453
iteration 1 batch 12140 training_loss 0.6931471805599453
iteration 1 batch 12150 training_loss 0.6931471805599453
iteration 1 batch 12160 training_loss 0.6901793251455568
iteration 1 batch 12170 training_loss 0.6931471805599453
iteration 1 batch 12180 training_loss 0.6931471805599453
iteration 1 batch 12190 training_loss 0.6931471805599453
iteration 1 batch 12200 training_loss 0.6931471805599453
iteration 1 batch 12210 training_loss 0.6931471805599453
iteration 1 batch 12220 training_loss 0.6931471805599453
iteration 1 batch 12230 training_loss 0.6916632528527511
iteration 1 batch 12240 training_loss 0.6931471805599453
iteration 1 batch 12250 training_loss 0.6931471805599453
iteration 1 batch 12260 training_loss 0.6931471805599453
iteration 1 batch 12270 training_loss 0.6931471805599453
iteration 1 batch 12280 training_loss 0.6931471805599453
iteration 1 batch 12290 training_loss 0.6931471805599453
iteration 1 batch 12300 training_loss 0.6931471805599453
iteration 1 batch 12310 training_loss 0.6931471805599453
iteration 1 batch 12320 training_loss 0.6916632528527511
iteration 1 batch 12330 training_loss 0.6916632528527511
iteration 1 batch 12340 training_loss 0.6931471805599453
iteration 1 batch 12350 training_loss 0.6916632528527511
iteration 1 batch 12360 training_loss 0.6916632528527511
iteration 1 batch 12370 training_loss 0.6931471805599453
iteration 1 batch 12380 training_loss 0.6931471805599453
iteration 1 batch 12390 training_loss 0.6916632528527511
iteration 1 batch 12400 training_loss 0.6931471805599453
iteration 1 batch 12410 training_loss 0.6931471805599453
iteration 1 batch 12420 training_loss 0.6931471805599453
iteration 1 batch 12430 training_loss 0.6931471805599453
iteration 1 batch 12440 training_loss 0.6931471805599453
iteration 1 batch 12450 training_loss 0.6931471805599453
iteration 1 batch 12460 training_loss 0.6931471805599453
iteration 1 batch 12470 training_loss 0.6931471805599453
iteration 1 batch 12480 training_loss 0.6931471805599453
iteration 1 batch 12490 training_loss 0.6931471805599453
iteration 1 batch 12500 training_loss 0.6916632528527511
iteration 1 batch 12510 training_loss 0.6916632528527511
iteration 1 batch 12520 training_loss 0.6931471805599453
iteration 1 batch 12530 training_loss 0.6931471805599453
iteration 1 batch 12540 training_loss 0.6931471805599453
iteration 1 batch 12550 training_loss 0.6931471805599453
iteration 1 batch 12560 training_loss 0.6916632528527511
iteration 1 batch 12570 training_loss 0.6931471805599453
iteration 1 batch 12580 training_loss 0.6931471805599453
iteration 1 batch 12590 training_loss 0.6916632528527511
iteration 1 batch 12600 training_loss 0.6931471805599453
iteration 1 batch 12610 training_loss 0.6931471805599453
iteration 1 batch 12620 training_loss 0.6931471805599453
iteration 1 batch 12630 training_loss 0.6931471805599453
iteration 1 batch 12640 training_loss 0.6916632528527511
iteration 1 batch 12650 training_loss 0.6916632528527511
iteration 1 batch 12660 training_loss 0.6931471805599453
iteration 1 batch 12670 training_loss 0.6931471805599453
iteration 1 batch 12680 training_loss 0.6931471805599453
iteration 1 batch 12690 training_loss 0.6916632528527511
iteration 1 batch 12700 training_loss 0.6931471805599453
iteration 1 batch 12710 training_loss 0.6931471805599453
iteration 1 batch 12720 training_loss 0.6931471805599453
iteration 1 batch 12730 training_loss 0.6916632528527511
iteration 1 batch 12740 training_loss 0.6916632528527511
iteration 1 batch 12750 training_loss 0.6916632528527511
iteration 1 batch 12760 training_loss 0.6931471805599453
iteration 1 batch 12770 training_loss 0.6931471805599453
iteration 1 batch 12780 training_loss 0.6916632528527511
iteration 1 batch 12790 training_loss 0.6931471805599453
iteration 1 batch 12800 training_loss 0.6931471805599453
iteration 1 batch 12810 training_loss 0.6931471805599453
iteration 1 batch 12820 training_loss 0.6931471805599453
iteration 1 batch 12830 training_loss 0.6931471805599453
iteration 1 batch 12840 training_loss 0.6916632528527511
iteration 1 batch 12850 training_loss 0.6931471805599453
iteration 1 batch 12860 training_loss 0.6931471805599453
iteration 1 batch 12870 training_loss 0.6931471805599453
iteration 1 batch 12880 training_loss 0.6931471805599453
iteration 1 batch 12890 training_loss 0.6931471805599453
iteration 1 batch 12900 training_loss 0.6916632528527511
iteration 1 batch 12910 training_loss 0.6916632528527511
iteration 1 batch 12920 training_loss 0.6931471805599453
iteration 1 batch 12930 training_loss 0.6931471805599453
iteration 1 batch 12940 training_loss 0.6931471805599453
iteration 1 batch 12950 training_loss 0.6931471805599453
iteration 1 batch 12960 training_loss 0.6931471805599453
iteration 1 batch 12970 training_loss 0.6931471805599453
iteration 1 batch 12980 training_loss 0.6916632528527511
iteration 1 batch 12990 training_loss 0.6931471805599453
iteration 1 batch 13000 training_loss 0.6931471805599453
iteration 1 batch 13010 training_loss 0.6931471805599453
iteration 1 batch 13020 training_loss 0.6931471805599453
iteration 1 batch 13030 training_loss 0.6916632528527511
iteration 1 batch 13040 training_loss 0.6916632528527511
iteration 1 batch 13050 training_loss 0.6931471805599453
iteration 1 batch 13060 training_loss 0.6916632528527511
iteration 1 batch 13070 training_loss 0.6931471805599453
iteration 1 batch 13080 training_loss 0.6931471805599453
iteration 1 batch 13090 training_loss 0.6931471805599453
iteration 1 batch 13100 training_loss 0.6931471805599453
iteration 1 batch 13110 training_loss 0.6931471805599453
iteration 1 batch 13120 training_loss 0.6916632528527511
iteration 1 batch 13130 training_loss 0.6931471805599453
iteration 1 batch 13140 training_loss 0.6931471805599453
iteration 1 batch 13150 training_loss 0.6931471805599453
iteration 1 batch 13160 training_loss 0.6916632528527511
iteration 1 batch 13170 training_loss 0.6931471805599453
iteration 1 batch 13180 training_loss 0.6916632528527511
iteration 1 batch 13190 training_loss 0.6931471805599453
iteration 1 batch 13200 training_loss 0.6916632528527511
iteration 1 batch 13210 training_loss 0.6931471805599453
iteration 1 batch 13220 training_loss 0.6931471805599453
iteration 1 batch 13230 training_loss 0.6931471805599453
iteration 1 batch 13240 training_loss 0.6931471805599453
iteration 1 batch 13250 training_loss 0.6931471805599453
iteration 1 batch 13260 training_loss 0.6931471805599453
iteration 1 batch 13270 training_loss 0.6931471805599453
iteration 1 batch 13280 training_loss 0.6931471805599453
iteration 1 batch 13290 training_loss 0.6931471805599453
iteration 1 batch 13300 training_loss 0.6931471805599453
iteration 1 batch 13310 training_loss 0.6931471805599453
iteration 1 batch 13320 training_loss 0.6931471805599453
iteration 1 batch 13330 training_loss 0.6931471805599453
iteration 1 batch 13340 training_loss 0.6931471805599453
iteration 1 batch 13350 training_loss 0.6931471805599453
iteration 1 batch 13360 training_loss 0.6931471805599453
iteration 1 batch 13370 training_loss 0.6931471805599453
iteration 1 batch 13380 training_loss 0.6931471805599453
iteration 1 batch 13390 training_loss 0.6931471805599453
iteration 1 batch 13400 training_loss 0.6931471805599453
iteration 1 batch 13410 training_loss 0.6931471805599453
iteration 1 batch 13420 training_loss 0.6931471805599453
iteration 1 batch 13430 training_loss 0.6931471805599453
iteration 1 batch 13440 training_loss 0.6931471805599453
iteration 1 batch 13450 training_loss 0.6931471805599453
iteration 1 batch 13460 training_loss 0.6931471805599453
iteration 1 batch 13470 training_loss 0.6931471805599453
iteration 1 batch 13480 training_loss 0.6931471805599453
iteration 1 batch 13490 training_loss 0.6916632528527511
iteration 1 batch 13500 training_loss 0.6931471805599453
iteration 1 batch 13510 training_loss 0.6931471805599453
iteration 1 batch 13520 training_loss 0.6931471805599453
iteration 1 batch 13530 training_loss 0.6931471805599453
iteration 1 batch 13540 training_loss 0.6931471805599453
iteration 1 batch 13550 training_loss 0.6916632528527511
iteration 1 batch 13560 training_loss 0.6916632528527511
iteration 1 batch 13570 training_loss 0.6916632528527511
iteration 1 batch 13580 training_loss 0.6931471805599453
iteration 1 batch 13590 training_loss 0.6931471805599453
iteration 1 batch 13600 training_loss 0.6931471805599453
iteration 1 batch 13610 training_loss 0.6931471805599453
iteration 1 batch 13620 training_loss 0.6931471805599453
iteration 1 batch 13630 training_loss 0.6931471805599453
iteration 1 batch 13640 training_loss 0.6931471805599453
iteration 1 batch 13650 training_loss 0.6931471805599453
iteration 1 batch 13660 training_loss 0.6931471805599453
iteration 1 batch 13670 training_loss 0.6931471805599453
iteration 1 batch 13680 training_loss 0.6931471805599453
iteration 1 batch 13690 training_loss 0.6931471805599453
iteration 1 batch 13700 training_loss 0.6931471805599453
iteration 1 batch 13710 training_loss 0.6931471805599453
iteration 1 batch 13720 training_loss 0.6931471805599453
iteration 1 batch 13730 training_loss 0.6931471805599453
iteration 1 batch 13740 training_loss 0.6931471805599453
iteration 1 batch 13750 training_loss 0.6931471805599453
iteration 1 batch 13760 training_loss 0.6931471805599453
iteration 1 batch 13770 training_loss 0.6916632528527511
iteration 1 batch 13780 training_loss 0.6931471805599453
iteration 1 batch 13790 training_loss 0.6931471805599453
iteration 1 batch 13800 training_loss 0.6916632528527511
iteration 1 batch 13810 training_loss 0.6931471805599453
iteration 1 batch 13820 training_loss 0.6916632528527511
iteration 1 batch 13830 training_loss 0.6931471805599453
iteration 1 batch 13840 training_loss 0.6916632528527511
iteration 1 batch 13850 training_loss 0.6931471805599453
iteration 1 batch 13860 training_loss 0.6931471805599453
iteration 1 batch 13870 training_loss 0.6931471805599453
iteration 1 batch 13880 training_loss 0.6916632528527511
iteration 1 batch 13890 training_loss 0.6931471805599453
iteration 1 batch 13900 training_loss 0.6931471805599453
iteration 1 batch 13910 training_loss 0.6931471805599453
iteration 1 batch 13920 training_loss 0.6931471805599453
iteration 1 batch 13930 training_loss 0.6931471805599453
iteration 1 batch 13940 training_loss 0.6931471805599453
iteration 1 batch 13950 training_loss 0.6931471805599453
iteration 1 batch 13960 training_loss 0.6931471805599453
iteration 1 batch 13970 training_loss 0.6931471805599453
iteration 1 batch 13980 training_loss 0.6931471805599453
iteration 1 batch 13990 training_loss 0.6931471805599453
iteration 1 batch 14000 training_loss 0.6931471805599453
iteration 1 batch 14010 training_loss 0.6916632528527511
iteration 1 batch 14020 training_loss 0.6931471805599453
iteration 1 batch 14030 training_loss 0.6931471805599453
iteration 1 batch 14040 training_loss 0.6931471805599453
iteration 1 batch 14050 training_loss 0.6901793251455568
iteration 1 batch 14060 training_loss 0.6916632528527511
iteration 1 batch 14070 training_loss 0.6931471805599453
iteration 1 batch 14080 training_loss 0.6931471805599453
iteration 1 batch 14090 training_loss 0.6916632528527511
iteration 1 batch 14100 training_loss 0.6931471805599453
iteration 1 batch 14110 training_loss 0.6931471805599453
iteration 1 batch 14120 training_loss 0.6931471805599453
iteration 1 batch 14130 training_loss 0.6931471805599453
iteration 1 batch 14140 training_loss 0.6931471805599453
iteration 1 batch 14150 training_loss 0.6931471805599453
iteration 1 batch 14160 training_loss 0.6931471805599453
iteration 1 batch 14170 training_loss 0.6931471805599453
iteration 1 batch 14180 training_loss 0.6931471805599453
iteration 1 batch 14190 training_loss 0.6931471805599453
iteration 1 batch 14200 training_loss 0.6931471805599453
iteration 1 batch 14210 training_loss 0.6931471805599453
iteration 1 batch 14220 training_loss 0.6931471805599453
iteration 1 batch 14230 training_loss 0.6931471805599453
iteration 1 batch 14240 training_loss 0.6931471805599453
iteration 1 batch 14250 training_loss 0.6931471805599453
iteration 1 batch 14260 training_loss 0.6931471805599453
iteration 1 batch 14270 training_loss 0.6916632528527511
iteration 1 batch 14280 training_loss 0.6931471805599453
iteration 1 batch 14290 training_loss 0.6916632528527511
iteration 1 batch 14300 training_loss 0.6931471805599453
iteration 1 batch 14310 training_loss 0.6931471805599453
iteration 1 batch 14320 training_loss 0.6916632528527511
iteration 1 batch 14330 training_loss 0.6931471805599453
iteration 1 batch 14340 training_loss 0.6916632528527511
iteration 1 batch 14350 training_loss 0.6931471805599453
iteration 1 batch 14360 training_loss 0.6931471805599453
iteration 1 batch 14370 training_loss 0.6916632528527511
iteration 1 batch 14380 training_loss 0.6931471805599453
iteration 1 batch 14390 training_loss 0.6916632528527511
iteration 1 batch 14400 training_loss 0.6931471805599453
iteration 1 batch 14410 training_loss 0.6916632528527511
iteration 1 batch 14420 training_loss 0.6931471805599453
iteration 1 batch 14430 training_loss 0.6931471805599453
iteration 1 batch 14440 training_loss 0.6931471805599453
iteration 1 batch 14450 training_loss 0.6916632528527511
iteration 1 batch 14460 training_loss 0.6931471805599453
iteration 1 batch 14470 training_loss 0.6931471805599453
iteration 1 batch 14480 training_loss 0.6931471805599453
iteration 1 batch 14490 training_loss 0.6916632528527511
iteration 1 batch 14500 training_loss 0.6931471805599453
iteration 1 batch 14510 training_loss 0.6931471805599453
iteration 1 batch 14520 training_loss 0.6916632528527511
iteration 1 batch 14530 training_loss 0.6931471805599453
iteration 1 batch 14540 training_loss 0.6931471805599453
iteration 1 batch 14550 training_loss 0.6916632528527511
iteration 1 batch 14560 training_loss 0.6931471805599453
iteration 1 batch 14570 training_loss 0.6931471805599453
iteration 1 batch 14580 training_loss 0.6916632528527511
iteration 1 batch 14590 training_loss 0.6931471805599453
iteration 1 batch 14600 training_loss 0.6931471805599453
iteration 1 batch 14610 training_loss 0.6931471805599453
iteration 1 batch 14620 training_loss 0.6931471805599453
iteration 1 batch 14630 training_loss 0.6916632528527511
iteration 1 batch 14640 training_loss 0.6931471805599453
iteration 1 batch 14650 training_loss 0.6931471805599453
iteration 1 batch 14660 training_loss 0.6931471805599453
iteration 1 batch 14670 training_loss 0.6931471805599453
iteration 1 batch 14680 training_loss 0.6931471805599453
iteration 1 batch 14690 training_loss 0.6931471805599453
iteration 1 batch 14700 training_loss 0.6931471805599453
iteration 1 batch 14710 training_loss 0.6916632528527511
iteration 1 batch 14720 training_loss 0.6931471805599453
iteration 1 batch 14730 training_loss 0.6931471805599453
iteration 1 batch 14740 training_loss 0.6931471805599453
iteration 1 batch 14750 training_loss 0.6931471805599453
iteration 1 batch 14760 training_loss 0.6931471805599453
iteration 1 batch 14770 training_loss 0.6931471805599453
iteration 1 batch 14780 training_loss 0.6916632528527511
iteration 1 batch 14790 training_loss 0.6931471805599453
iteration 1 batch 14800 training_loss 0.6931471805599453
iteration 1 batch 14810 training_loss 0.6931471805599453
iteration 1 batch 14820 training_loss 0.6931471805599453
iteration 1 batch 14830 training_loss 0.6931471805599453
iteration 1 batch 14840 training_loss 0.6931471805599453
iteration 1 batch 14850 training_loss 0.6931471805599453
iteration 1 batch 14860 training_loss 0.6931471805599453
iteration 1 batch 14870 training_loss 0.6931471805599453
iteration 1 batch 14880 training_loss 0.6931471805599453
iteration 1 batch 14890 training_loss 0.6931471805599453
iteration 1 batch 14900 training_loss 0.6931471805599453
iteration 1 batch 14910 training_loss 0.6931471805599453
iteration 1 batch 14920 training_loss 0.6931471805599453
iteration 1 batch 14930 training_loss 0.6916632528527511
iteration 1 batch 14940 training_loss 0.6931471805599453
iteration 1 batch 14950 training_loss 0.6931471805599453
iteration 1 batch 14960 training_loss 0.6931471805599453
iteration 1 batch 14970 training_loss 0.6931471805599453
iteration 1 batch 14980 training_loss 0.6931471805599453
iteration 1 batch 14990 training_loss 0.6931471805599453
iteration 1 batch 15000 training_loss 0.6931471805599453
iteration 1 batch 15010 training_loss 0.6931471805599453
iteration 1 batch 15020 training_loss 0.6931471805599453
iteration 1 batch 15030 training_loss 0.6931471805599453
iteration 1 batch 15040 training_loss 0.6931471805599453
iteration 1 batch 15050 training_loss 0.6931471805599453
iteration 1 batch 15060 training_loss 0.6931471805599453
iteration 1 batch 15070 training_loss 0.6931471805599453
iteration 1 batch 15080 training_loss 0.6931471805599453
iteration 1 batch 15090 training_loss 0.6931471805599453
iteration 1 batch 15100 training_loss 0.6931471805599453
iteration 1 batch 15110 training_loss 0.6931471805599453
iteration 1 batch 15120 training_loss 0.6931471805599453
iteration 1 batch 15130 training_loss 0.6931471805599453
iteration 1 batch 15140 training_loss 0.6931471805599453
iteration 1 batch 15150 training_loss 0.6931471805599453
iteration 1 batch 15160 training_loss 0.6931471805599453
iteration 1 batch 15170 training_loss 0.6931471805599453
iteration 1 batch 15180 training_loss 0.6931471805599453
iteration 1 batch 15190 training_loss 0.6916632528527511
iteration 1 batch 15200 training_loss 0.6916632528527511
iteration 1 batch 15210 training_loss 0.6931471805599453
iteration 1 batch 15220 training_loss 0.6931471805599453
iteration 1 batch 15230 training_loss 0.6931471805599453
iteration 1 batch 15240 training_loss 0.6931471805599453
iteration 1 batch 15250 training_loss 0.6916632528527511
iteration 1 batch 15260 training_loss 0.6931471805599453
iteration 1 batch 15270 training_loss 0.6931471805599453
iteration 1 batch 15280 training_loss 0.6931471805599453
iteration 1 batch 15290 training_loss 0.6931471805599453
iteration 1 batch 15300 training_loss 0.6916632528527511
iteration 1 batch 15310 training_loss 0.6931471805599453
iteration 1 batch 15320 training_loss 0.6931471805599453
iteration 1 batch 15330 training_loss 0.6916632528527511
iteration 1 batch 15340 training_loss 0.6931471805599453
iteration 1 batch 15350 training_loss 0.6931471805599453
iteration 1 batch 15360 training_loss 0.6931471805599453
iteration 1 batch 15370 training_loss 0.6931471805599453
iteration 1 batch 15380 training_loss 0.6931471805599453
iteration 1 batch 15390 training_loss 0.6931471805599453
iteration 1 batch 15400 training_loss 0.6931471805599453
iteration 1 batch 15410 training_loss 0.6931471805599453
iteration 1 batch 15420 training_loss 0.6931471805599453
iteration 1 batch 15430 training_loss 0.6931471805599453
iteration 1 batch 15440 training_loss 0.6916632528527511
iteration 1 batch 15450 training_loss 0.6901793251455568
iteration 1 batch 15460 training_loss 0.6931471805599453
iteration 1 batch 15470 training_loss 0.6931471805599453
iteration 1 batch 15480 training_loss 0.6901793251455568
iteration 1 batch 15490 training_loss 0.6931471805599453
iteration 1 batch 15500 training_loss 0.6931471805599453
iteration 1 batch 15510 training_loss 0.6931471805599453
iteration 1 batch 15520 training_loss 0.6931471805599453
iteration 1 batch 15530 training_loss 0.6916632528527511
iteration 1 batch 15540 training_loss 0.6916632528527511
iteration 1 batch 15550 training_loss 0.6931471805599453
iteration 1 batch 15560 training_loss 0.6916632528527511
iteration 1 batch 15570 training_loss 0.6931471805599453
iteration 1 batch 15580 training_loss 0.6931471805599453
iteration 1 batch 15590 training_loss 0.6931471805599453
iteration 1 batch 15600 training_loss 0.6916632528527511
iteration 1 batch 15610 training_loss 0.6931471805599453
iteration 1 batch 15620 training_loss 0.6916632528527511
iteration 1 batch 15630 training_loss 0.6931471805599453
iteration 1 batch 15640 training_loss 0.6931471805599453
iteration 1 batch 15650 training_loss 0.6931471805599453
iteration 1 batch 15660 training_loss 0.6931471805599453
iteration 1 batch 15670 training_loss 0.6931471805599453
iteration 1 batch 15680 training_loss 0.6901793251455568
iteration 1 batch 15690 training_loss 0.6931471805599453
iteration 1 batch 15700 training_loss 0.6931471805599453
iteration 1 batch 15710 training_loss 0.6931471805599453
iteration 1 batch 15720 training_loss 0.6931471805599453
iteration 1 batch 15730 training_loss 0.6931471805599453
iteration 1 batch 15740 training_loss 0.6931471805599453
iteration 1 batch 15750 training_loss 0.6931471805599453
iteration 1 batch 15760 training_loss 0.6901793251455568
iteration 1 batch 15770 training_loss 0.6931471805599453
iteration 1 batch 15780 training_loss 0.6931471805599453
iteration 1 batch 15790 training_loss 0.6916632528527511
iteration 1 batch 15800 training_loss 0.6931471805599453
iteration 1 batch 15810 training_loss 0.6931471805599453
iteration 1 batch 15820 training_loss 0.6931471805599453
iteration 1 batch 15830 training_loss 0.6931471805599453
iteration 1 batch 15840 training_loss 0.6931471805599453
iteration 1 batch 15850 training_loss 0.6931471805599453
iteration 1 batch 15860 training_loss 0.6931471805599453
iteration 1 batch 15870 training_loss 0.6931471805599453
iteration 1 batch 15880 training_loss 0.6931471805599453
iteration 1 batch 15890 training_loss 0.6931471805599453
iteration 1 batch 15900 training_loss 0.6931471805599453
iteration 1 batch 15910 training_loss 0.6931471805599453
iteration 1 batch 15920 training_loss 0.6931471805599453
iteration 1 batch 15930 training_loss 0.6931471805599453
iteration 1 batch 15940 training_loss 0.6931471805599453
iteration 1 batch 15950 training_loss 0.6916632528527511
iteration 1 batch 15960 training_loss 0.6931471805599453
iteration 1 batch 15970 training_loss 0.6931471805599453
iteration 1 batch 15980 training_loss 0.6931471805599453
iteration 1 batch 15990 training_loss 0.6931471805599453
iteration 1 batch 16000 training_loss 0.6931471805599453
iteration 1 batch 16010 training_loss 0.6931471805599453
iteration 1 batch 16020 training_loss 0.6931471805599453
iteration 1 batch 16030 training_loss 0.6931471805599453
iteration 1 batch 16040 training_loss 0.6931471805599453
iteration 1 batch 16050 training_loss 0.6931471805599453
iteration 1 batch 16060 training_loss 0.6931471805599453
iteration 1 batch 16070 training_loss 0.6931471805599453
iteration 1 batch 16080 training_loss 0.6931471805599453
iteration 1 batch 16090 training_loss 0.6931471805599453
iteration 1 batch 16100 training_loss 0.6931471805599453
iteration 1 batch 16110 training_loss 0.6931471805599453
iteration 1 batch 16120 training_loss 0.6931471805599453
iteration 1 batch 16130 training_loss 0.6931471805599453
iteration 1 batch 16140 training_loss 0.6931471805599453
iteration 1 batch 16150 training_loss 0.6931471805599453
iteration 1 batch 16160 training_loss 0.6931471805599453
iteration 1 batch 16170 training_loss 0.6916632528527511
iteration 1 batch 16180 training_loss 0.6931471805599453
iteration 1 batch 16190 training_loss 0.6931471805599453
iteration 1 batch 16200 training_loss 0.6916632528527511
iteration 1 batch 16210 training_loss 0.6916632528527511
iteration 1 batch 16220 training_loss 0.6931471805599453
iteration 1 batch 16230 training_loss 0.6931471805599453
iteration 1 batch 16240 training_loss 0.6931471805599453
iteration 1 batch 16250 training_loss 0.6916632528527511
iteration 1 batch 16260 training_loss 0.6916632528527511
iteration 1 batch 16270 training_loss 0.6931471805599453
iteration 1 batch 16280 training_loss 0.6931471805599453
iteration 1 batch 16290 training_loss 0.6931471805599453
iteration 1 batch 16300 training_loss 0.6931471805599453
iteration 1 batch 16310 training_loss 0.6931471805599453
iteration 1 batch 16320 training_loss 0.6931471805599453
iteration 1 batch 16330 training_loss 0.6916632528527511
iteration 1 batch 16340 training_loss 0.6931471805599453
iteration 1 batch 16350 training_loss 0.6931471805599453
iteration 1 batch 16360 training_loss 0.6916632528527511
iteration 1 batch 16370 training_loss 0.6916632528527511
iteration 1 batch 16380 training_loss 0.6916632528527511
iteration 1 batch 16390 training_loss 0.6931471805599453
iteration 1 batch 16400 training_loss 0.6931471805599453
iteration 1 batch 16410 training_loss 0.6931471805599453
iteration 1 batch 16420 training_loss 0.6931471805599453
iteration 1 batch 16430 training_loss 0.6931471805599453
iteration 1 batch 16440 training_loss 0.6931471805599453
iteration 1 batch 16450 training_loss 0.6931471805599453
iteration 1 batch 16460 training_loss 0.6916632528527511
iteration 1 batch 16470 training_loss 0.6931471805599453
iteration 1 batch 16480 training_loss 0.6901793251455568
iteration 1 batch 16490 training_loss 0.6931471805599453
iteration 1 batch 16500 training_loss 0.6916632528527511
iteration 1 batch 16510 training_loss 0.6931471805599453
iteration 1 batch 16520 training_loss 0.6931471805599453
iteration 1 batch 16530 training_loss 0.6931471805599453
iteration 1 batch 16540 training_loss 0.6931471805599453
iteration 1 batch 16550 training_loss 0.6931471805599453
iteration 1 batch 16560 training_loss 0.6931471805599453
iteration 1 batch 16570 training_loss 0.6931471805599453
iteration 1 batch 16580 training_loss 0.6931471805599453
iteration 1 batch 16590 training_loss 0.6931471805599453
iteration 1 batch 16600 training_loss 0.6931471805599453
iteration 1 batch 16610 training_loss 0.6931471805599453
iteration 1 batch 16620 training_loss 0.6931471805599453
iteration 1 batch 16630 training_loss 0.6931471805599453
iteration 1 batch 16640 training_loss 0.6916632528527511
iteration 1 batch 16650 training_loss 0.6931471805599453
iteration 1 batch 16660 training_loss 0.6931471805599453
iteration 1 batch 16670 training_loss 0.6931471805599453
iteration 1 batch 16680 training_loss 0.6931471805599453
iteration 1 batch 16690 training_loss 0.6931471805599453
iteration 1 batch 16700 training_loss 0.6931471805599453
iteration 1 batch 16710 training_loss 0.6931471805599453
iteration 1 batch 16720 training_loss 0.6931471805599453
iteration 1 batch 16730 training_loss 0.6931471805599453
iteration 1 batch 16740 training_loss 0.6916632528527511
iteration 1 batch 16750 training_loss 0.6931471805599453
iteration 1 batch 16760 training_loss 0.6931471805599453
iteration 1 batch 16770 training_loss 0.6931471805599453
iteration 1 batch 16780 training_loss 0.6931471805599453
iteration 1 batch 16790 training_loss 0.6931471805599453
iteration 1 batch 16800 training_loss 0.6931471805599453
iteration 1 batch 16810 training_loss 0.6931471805599453
iteration 1 batch 16820 training_loss 0.6931471805599453
iteration 1 batch 16830 training_loss 0.6916632528527511
iteration 1 batch 16840 training_loss 0.6916632528527511
iteration 1 batch 16850 training_loss 0.6931471805599453
iteration 1 batch 16860 training_loss 0.6931471805599453
iteration 1 batch 16870 training_loss 0.6916632528527511
iteration 1 batch 16880 training_loss 0.6931471805599453
iteration 1 batch 16890 training_loss 0.6931471805599453
iteration 1 batch 16900 training_loss 0.6931471805599453
iteration 1 batch 16910 training_loss 0.6931471805599453
iteration 1 batch 16920 training_loss 0.6916632528527511
iteration 1 batch 16930 training_loss 0.6931471805599453
iteration 1 batch 16940 training_loss 0.6931471805599453
iteration 1 batch 16950 training_loss 0.6931471805599453
iteration 1 batch 16960 training_loss 0.6931471805599453
iteration 1 batch 16970 training_loss 0.6931471805599453
iteration 1 batch 16980 training_loss 0.6931471805599453
iteration 1 batch 16990 training_loss 0.6916632528527511
iteration 1 batch 17000 training_loss 0.6931471805599453
iteration 1 batch 17010 training_loss 0.6916632528527511
iteration 1 batch 17020 training_loss 0.6916632528527511
iteration 1 batch 17030 training_loss 0.6931471805599453
iteration 1 batch 17040 training_loss 0.6931471805599453
iteration 1 batch 17050 training_loss 0.6931471805599453
iteration 1 batch 17060 training_loss 0.6931471805599453
iteration 1 batch 17070 training_loss 0.6916632528527511
iteration 1 batch 17080 training_loss 0.6931471805599453
iteration 1 batch 17090 training_loss 0.6931471805599453
iteration 1 batch 17100 training_loss 0.6931471805599453
iteration 1 batch 17110 training_loss 0.6931471805599453
iteration 1 batch 17120 training_loss 0.6931471805599453
iteration 1 batch 17130 training_loss 0.6931471805599453
iteration 1 batch 17140 training_loss 0.6931471805599453
iteration 1 batch 17150 training_loss 0.6931471805599453
iteration 1 batch 17160 training_loss 0.6931471805599453
iteration 1 batch 17170 training_loss 0.6931471805599453
iteration 1 batch 17180 training_loss 0.6916632528527511
iteration 1 batch 17190 training_loss 0.6916632528527511
iteration 1 batch 17200 training_loss 0.6931471805599453
iteration 1 batch 17210 training_loss 0.6931471805599453
iteration 1 batch 17220 training_loss 0.6931471805599453
iteration 1 batch 17230 training_loss 0.6901793251455568
iteration 1 batch 17240 training_loss 0.6931471805599453
iteration 1 batch 17250 training_loss 0.6931471805599453
iteration 1 batch 17260 training_loss 0.6931471805599453
iteration 1 batch 17270 training_loss 0.6931471805599453
iteration 1 batch 17280 training_loss 0.6931471805599453
iteration 1 batch 17290 training_loss 0.6931471805599453
iteration 1 batch 17300 training_loss 0.6916632528527511
iteration 1 batch 17310 training_loss 0.6931471805599453
iteration 1 batch 17320 training_loss 0.6931471805599453
iteration 1 batch 17330 training_loss 0.6931471805599453
iteration 1 batch 17340 training_loss 0.6931471805599453
iteration 1 batch 17350 training_loss 0.6931471805599453
iteration 1 batch 17360 training_loss 0.6931471805599453
iteration 1 batch 17370 training_loss 0.6931471805599453
iteration 1 batch 17380 training_loss 0.6931471805599453
iteration 1 batch 17390 training_loss 0.6931471805599453
iteration 1 batch 17400 training_loss 0.6931471805599453
iteration 1 batch 17410 training_loss 0.6931471805599453
iteration 1 batch 17420 training_loss 0.6931471805599453
iteration 1 batch 17430 training_loss 0.6931471805599453
iteration 1 batch 17440 training_loss 0.6931471805599453
iteration 1 batch 17450 training_loss 0.6931471805599453
iteration 1 batch 17460 training_loss 0.6931471805599453
iteration 1 batch 17470 training_loss 0.6931471805599453
iteration 1 batch 17480 training_loss 0.6931471805599453
iteration 1 batch 17490 training_loss 0.6931471805599453
iteration 1 batch 17500 training_loss 0.6931471805599453
iteration 1 batch 17510 training_loss 0.6931471805599453
iteration 1 batch 17520 training_loss 0.6931471805599453
iteration 1 batch 17530 training_loss 0.6931471805599453
iteration 1 batch 17540 training_loss 0.6931471805599453
iteration 1 batch 17550 training_loss 0.6931471805599453
iteration 1 batch 17560 training_loss 0.6931471805599453
iteration 1 batch 17570 training_loss 0.6931471805599453
iteration 1 batch 17580 training_loss 0.6931471805599453
iteration 1 batch 17590 training_loss 0.6931471805599453
iteration 1 batch 17600 training_loss 0.6931471805599453
iteration 1 batch 17610 training_loss 0.6931471805599453
iteration 1 batch 17620 training_loss 0.6931471805599453
iteration 1 batch 17630 training_loss 0.6931471805599453
iteration 1 batch 17640 training_loss 0.6916632528527511
iteration 1 batch 17650 training_loss 0.6916632528527511
iteration 1 batch 17660 training_loss 0.6931471805599453
iteration 1 batch 17670 training_loss 0.6931471805599453
iteration 1 batch 17680 training_loss 0.6931471805599453
iteration 1 batch 17690 training_loss 0.6931471805599453
iteration 1 batch 17700 training_loss 0.6931471805599453
iteration 1 batch 17710 training_loss 0.6931471805599453
iteration 1 batch 17720 training_loss 0.6931471805599453
iteration 1 batch 17730 training_loss 0.6931471805599453
iteration 1 batch 17740 training_loss 0.6931471805599453
iteration 1 batch 17750 training_loss 0.6931471805599453
iteration 1 batch 17760 training_loss 0.6931471805599453
iteration 1 batch 17770 training_loss 0.6931471805599453
iteration 1 batch 17780 training_loss 0.6931471805599453
iteration 1 batch 17790 training_loss 0.6931471805599453
iteration 1 batch 17800 training_loss 0.6916632528527511
iteration 1 batch 17810 training_loss 0.6931471805599453
iteration 1 batch 17820 training_loss 0.6931471805599453
iteration 1 batch 17830 training_loss 0.6931471805599453
iteration 1 batch 17840 training_loss 0.6931471805599453
iteration 1 batch 17850 training_loss 0.6931471805599453
iteration 1 batch 17860 training_loss 0.6931471805599453
iteration 1 batch 17870 training_loss 0.6931471805599453
iteration 1 batch 17880 training_loss 0.6916632528527511
iteration 1 batch 17890 training_loss 0.6931471805599453
iteration 1 batch 17900 training_loss 0.6931471805599453
iteration 1 batch 17910 training_loss 0.6931471805599453
iteration 1 batch 17920 training_loss 0.6931471805599453
iteration 1 batch 17930 training_loss 0.6916632528527511
iteration 1 batch 17940 training_loss 0.6931471805599453
iteration 1 batch 17950 training_loss 0.6931471805599453
iteration 1 batch 17960 training_loss 0.6931471805599453
iteration 1 batch 17970 training_loss 0.6931471805599453
iteration 1 batch 17980 training_loss 0.6931471805599453
iteration 1 batch 17990 training_loss 0.6901793251455568
iteration 1 batch 18000 training_loss 0.6931471805599453
iteration 1 batch 18010 training_loss 0.6931471805599453
iteration 1 batch 18020 training_loss 0.6931471805599453
iteration 1 batch 18030 training_loss 0.6931471805599453
iteration 1 batch 18040 training_loss 0.6931471805599453
iteration 1 batch 18050 training_loss 0.6931471805599453
iteration 1 batch 18060 training_loss 0.6931471805599453
iteration 1 batch 18070 training_loss 0.6931471805599453
iteration 1 batch 18080 training_loss 0.6931471805599453
iteration 1 batch 18090 training_loss 0.6931471805599453
iteration 1 batch 18100 training_loss 0.6931471805599453
iteration 1 batch 18110 training_loss 0.6931471805599453
iteration 1 batch 18120 training_loss 0.6916632528527511
iteration 1 batch 18130 training_loss 0.6931471805599453
iteration 1 batch 18140 training_loss 0.6931471805599453
iteration 1 batch 18150 training_loss 0.6931471805599453
iteration 1 batch 18160 training_loss 0.6931471805599453
iteration 1 batch 18170 training_loss 0.6931471805599453
iteration 1 batch 18180 training_loss 0.6931471805599453
iteration 1 batch 18190 training_loss 0.6931471805599453
iteration 1 batch 18200 training_loss 0.6931471805599453
iteration 1 batch 18210 training_loss 0.6931471805599453
iteration 1 batch 18220 training_loss 0.6931471805599453
iteration 1 batch 18230 training_loss 0.6931471805599453
iteration 1 batch 18240 training_loss 0.6931471805599453
iteration 1 batch 18250 training_loss 0.6931471805599453
iteration 1 batch 18260 training_loss 0.6916632528527511
iteration 1 batch 18270 training_loss 0.6931471805599453
iteration 1 batch 18280 training_loss 0.6931471805599453
iteration 1 batch 18290 training_loss 0.6931471805599453
iteration 1 batch 18300 training_loss 0.6916632528527511
iteration 1 batch 18310 training_loss 0.6931471805599453
iteration 1 batch 18320 training_loss 0.6931471805599453
iteration 1 batch 18330 training_loss 0.6931471805599453
iteration 1 batch 18340 training_loss 0.6931471805599453
iteration 1 batch 18350 training_loss 0.6931471805599453
iteration 1 batch 18360 training_loss 0.6931471805599453
iteration 1 batch 18370 training_loss 0.6931471805599453
iteration 1 batch 18380 training_loss 0.6931471805599453
iteration 1 batch 18390 training_loss 0.6931471805599453
iteration 1 batch 18400 training_loss 0.6916632528527511
iteration 1 batch 18410 training_loss 0.6931471805599453
iteration 1 batch 18420 training_loss 0.6931471805599453
iteration 1 batch 18430 training_loss 0.6931471805599453
iteration 1 batch 18440 training_loss 0.6931471805599453
iteration 1 batch 18450 training_loss 0.6931471805599453
iteration 1 batch 18460 training_loss 0.6931471805599453
iteration 1 batch 18470 training_loss 0.6916632528527511
iteration 1 batch 18480 training_loss 0.6931471805599453
iteration 1 batch 18490 training_loss 0.6931471805599453
iteration 1 batch 18500 training_loss 0.6931471805599453
iteration 1 batch 18510 training_loss 0.6916632528527511
iteration 1 batch 18520 training_loss 0.6931471805599453
iteration 1 batch 18530 training_loss 0.6931471805599453
iteration 1 batch 18540 training_loss 0.6931471805599453
iteration 1 batch 18550 training_loss 0.6931471805599453
iteration 1 batch 18560 training_loss 0.6931471805599453
iteration 1 batch 18570 training_loss 0.6931471805599453
iteration 1 batch 18580 training_loss 0.6931471805599453
iteration 1 batch 18590 training_loss 0.6931471805599453
iteration 1 batch 18600 training_loss 0.6931471805599453
iteration 1 batch 18610 training_loss 0.6931471805599453
iteration 2 batch 0 training_loss 0.6931471805599453
iteration 2 batch 10 training_loss 0.6931471805599453
iteration 2 batch 20 training_loss 0.6916632528527511
iteration 2 batch 30 training_loss 0.6931471805599453
iteration 2 batch 40 training_loss 0.6931471805599453
iteration 2 batch 50 training_loss 0.6931471805599453
iteration 2 batch 60 training_loss 0.6916632528527511
iteration 2 batch 70 training_loss 0.6931471805599453
iteration 2 batch 80 training_loss 0.6931471805599453
iteration 2 batch 90 training_loss 0.6931471805599453
iteration 2 batch 100 training_loss 0.6931471805599453
iteration 2 batch 110 training_loss 0.6931471805599453
iteration 2 batch 120 training_loss 0.6931471805599453
iteration 2 batch 130 training_loss 0.6931471805599453
iteration 2 batch 140 training_loss 0.6931471805599453
iteration 2 batch 150 training_loss 0.6931471805599453
iteration 2 batch 160 training_loss 0.6931471805599453
iteration 2 batch 170 training_loss 0.6916632528527511
iteration 2 batch 180 training_loss 0.6931471805599453
iteration 2 batch 190 training_loss 0.6931471805599453
iteration 2 batch 200 training_loss 0.6931471805599453
iteration 2 batch 210 training_loss 0.6931471805599453
iteration 2 batch 220 training_loss 0.6931471805599453
iteration 2 batch 230 training_loss 0.6916632528527511
iteration 2 batch 240 training_loss 0.6931471805599453
iteration 2 batch 250 training_loss 0.6931471805599453
iteration 2 batch 260 training_loss 0.6931471805599453
iteration 2 batch 270 training_loss 0.6931471805599453
iteration 2 batch 280 training_loss 0.6931471805599453
iteration 2 batch 290 training_loss 0.6931471805599453
iteration 2 batch 300 training_loss 0.6931471805599453
iteration 2 batch 310 training_loss 0.6916632528527511
iteration 2 batch 320 training_loss 0.6916632528527511
iteration 2 batch 330 training_loss 0.6931471805599453
iteration 2 batch 340 training_loss 0.6931471805599453
iteration 2 batch 350 training_loss 0.6931471805599453
iteration 2 batch 360 training_loss 0.6931471805599453
iteration 2 batch 370 training_loss 0.6931471805599453
iteration 2 batch 380 training_loss 0.6931471805599453
iteration 2 batch 390 training_loss 0.6931471805599453
iteration 2 batch 400 training_loss 0.6931471805599453
iteration 2 batch 410 training_loss 0.6916632528527511
iteration 2 batch 420 training_loss 0.6931471805599453
iteration 2 batch 430 training_loss 0.6931471805599453
iteration 2 batch 440 training_loss 0.6916632528527511
iteration 2 batch 450 training_loss 0.6931471805599453
iteration 2 batch 460 training_loss 0.6931471805599453
iteration 2 batch 470 training_loss 0.6931471805599453
iteration 2 batch 480 training_loss 0.6931471805599453
iteration 2 batch 490 training_loss 0.6931471805599453
iteration 2 batch 500 training_loss 0.6931471805599453
iteration 2 batch 510 training_loss 0.6931471805599453
iteration 2 batch 520 training_loss 0.6931471805599453
iteration 2 batch 530 training_loss 0.6916632528527511
iteration 2 batch 540 training_loss 0.6931471805599453
iteration 2 batch 550 training_loss 0.6931471805599453
iteration 2 batch 560 training_loss 0.6916632528527511
iteration 2 batch 570 training_loss 0.6931471805599453
iteration 2 batch 580 training_loss 0.6916632528527511
iteration 2 batch 590 training_loss 0.6931471805599453
iteration 2 batch 600 training_loss 0.6931471805599453
iteration 2 batch 610 training_loss 0.6931471805599453
iteration 2 batch 620 training_loss 0.6916632528527511
iteration 2 batch 630 training_loss 0.6916632528527511
iteration 2 batch 640 training_loss 0.6931471805599453
iteration 2 batch 650 training_loss 0.6931471805599453
iteration 2 batch 660 training_loss 0.6931471805599453
iteration 2 batch 670 training_loss 0.6931471805599453
iteration 2 batch 680 training_loss 0.6931471805599453
iteration 2 batch 690 training_loss 0.6931471805599453
iteration 2 batch 700 training_loss 0.6931471805599453
iteration 2 batch 710 training_loss 0.6916632528527511
iteration 2 batch 720 training_loss 0.6931471805599453
iteration 2 batch 730 training_loss 0.6931471805599453
iteration 2 batch 740 training_loss 0.6931471805599453
iteration 2 batch 750 training_loss 0.6931471805599453
iteration 2 batch 760 training_loss 0.6901793251455568
iteration 2 batch 770 training_loss 0.6931471805599453
iteration 2 batch 780 training_loss 0.6931471805599453
iteration 2 batch 790 training_loss 0.6931471805599453
iteration 2 batch 800 training_loss 0.6931471805599453
iteration 2 batch 810 training_loss 0.6931471805599453
iteration 2 batch 820 training_loss 0.6916632528527511
iteration 2 batch 830 training_loss 0.6931471805599453
iteration 2 batch 840 training_loss 0.6931471805599453
iteration 2 batch 850 training_loss 0.6931471805599453
iteration 2 batch 860 training_loss 0.6931471805599453
iteration 2 batch 870 training_loss 0.6916632528527511
iteration 2 batch 880 training_loss 0.6931471805599453
iteration 2 batch 890 training_loss 0.6931471805599453
iteration 2 batch 900 training_loss 0.6931471805599453
iteration 2 batch 910 training_loss 0.6931471805599453
iteration 2 batch 920 training_loss 0.6931471805599453
iteration 2 batch 930 training_loss 0.6931471805599453
iteration 2 batch 940 training_loss 0.6931471805599453
iteration 2 batch 950 training_loss 0.6931471805599453
iteration 2 batch 960 training_loss 0.6931471805599453
iteration 2 batch 970 training_loss 0.6931471805599453
iteration 2 batch 980 training_loss 0.6931471805599453
iteration 2 batch 990 training_loss 0.6931471805599453
iteration 2 batch 1000 training_loss 0.6931471805599453
iteration 2 batch 1010 training_loss 0.6931471805599453
iteration 2 batch 1020 training_loss 0.6931471805599453
iteration 2 batch 1030 training_loss 0.6931471805599453
iteration 2 batch 1040 training_loss 0.6931471805599453
iteration 2 batch 1050 training_loss 0.6931471805599453
iteration 2 batch 1060 training_loss 0.6931471805599453
iteration 2 batch 1070 training_loss 0.6916632528527511
iteration 2 batch 1080 training_loss 0.6931471805599453
iteration 2 batch 1090 training_loss 0.6931471805599453
iteration 2 batch 1100 training_loss 0.6931471805599453
iteration 2 batch 1110 training_loss 0.6931471805599453
iteration 2 batch 1120 training_loss 0.6931471805599453
iteration 2 batch 1130 training_loss 0.6931471805599453
iteration 2 batch 1140 training_loss 0.6931471805599453
iteration 2 batch 1150 training_loss 0.6931471805599453
iteration 2 batch 1160 training_loss 0.6931471805599453
iteration 2 batch 1170 training_loss 0.6931471805599453
iteration 2 batch 1180 training_loss 0.6931471805599453
iteration 2 batch 1190 training_loss 0.6931471805599453
iteration 2 batch 1200 training_loss 0.6931471805599453
iteration 2 batch 1210 training_loss 0.6916632528527511
iteration 2 batch 1220 training_loss 0.6916632528527511
iteration 2 batch 1230 training_loss 0.6931471805599453
iteration 2 batch 1240 training_loss 0.6916632528527511
iteration 2 batch 1250 training_loss 0.6931471805599453
iteration 2 batch 1260 training_loss 0.6916632528527511
iteration 2 batch 1270 training_loss 0.6931471805599453
iteration 2 batch 1280 training_loss 0.6931471805599453
iteration 2 batch 1290 training_loss 0.6931471805599453
iteration 2 batch 1300 training_loss 0.6931471805599453
iteration 2 batch 1310 training_loss 0.6931471805599453
iteration 2 batch 1320 training_loss 0.6931471805599453
iteration 2 batch 1330 training_loss 0.6931471805599453
iteration 2 batch 1340 training_loss 0.6931471805599453
iteration 2 batch 1350 training_loss 0.6931471805599453
iteration 2 batch 1360 training_loss 0.6931471805599453
iteration 2 batch 1370 training_loss 0.6901793251455568
iteration 2 batch 1380 training_loss 0.6931471805599453
iteration 2 batch 1390 training_loss 0.6916632528527511
iteration 2 batch 1400 training_loss 0.6931471805599453
iteration 2 batch 1410 training_loss 0.6916632528527511
iteration 2 batch 1420 training_loss 0.6931471805599453
iteration 2 batch 1430 training_loss 0.6931471805599453
iteration 2 batch 1440 training_loss 0.6916632528527511
iteration 2 batch 1450 training_loss 0.6916632528527511
iteration 2 batch 1460 training_loss 0.6916632528527511
iteration 2 batch 1470 training_loss 0.6931471805599453
iteration 2 batch 1480 training_loss 0.6931471805599453
iteration 2 batch 1490 training_loss 0.6931471805599453
iteration 2 batch 1500 training_loss 0.6931471805599453
iteration 2 batch 1510 training_loss 0.6916632528527511
iteration 2 batch 1520 training_loss 0.6931471805599453
iteration 2 batch 1530 training_loss 0.6931471805599453
iteration 2 batch 1540 training_loss 0.6931471805599453
iteration 2 batch 1550 training_loss 0.6931471805599453
iteration 2 batch 1560 training_loss 0.6916632528527511
iteration 2 batch 1570 training_loss 0.6931471805599453
iteration 2 batch 1580 training_loss 0.6931471805599453
iteration 2 batch 1590 training_loss 0.6931471805599453
iteration 2 batch 1600 training_loss 0.6931471805599453
iteration 2 batch 1610 training_loss 0.6931471805599453
iteration 2 batch 1620 training_loss 0.6931471805599453
iteration 2 batch 1630 training_loss 0.6916632528527511
iteration 2 batch 1640 training_loss 0.6931471805599453
iteration 2 batch 1650 training_loss 0.6931471805599453
iteration 2 batch 1660 training_loss 0.6931471805599453
iteration 2 batch 1670 training_loss 0.6931471805599453
iteration 2 batch 1680 training_loss 0.6931471805599453
iteration 2 batch 1690 training_loss 0.6931471805599453
iteration 2 batch 1700 training_loss 0.6931471805599453
iteration 2 batch 1710 training_loss 0.6931471805599453
iteration 2 batch 1720 training_loss 0.6916632528527511
iteration 2 batch 1730 training_loss 0.6931471805599453
iteration 2 batch 1740 training_loss 0.6931471805599453
iteration 2 batch 1750 training_loss 0.6916632528527511
iteration 2 batch 1760 training_loss 0.6931471805599453
iteration 2 batch 1770 training_loss 0.6931471805599453
iteration 2 batch 1780 training_loss 0.6931471805599453
iteration 2 batch 1790 training_loss 0.6931471805599453
iteration 2 batch 1800 training_loss 0.6931471805599453
iteration 2 batch 1810 training_loss 0.6916632528527511
iteration 2 batch 1820 training_loss 0.6931471805599453
iteration 2 batch 1830 training_loss 0.6931471805599453
iteration 2 batch 1840 training_loss 0.6931471805599453
iteration 2 batch 1850 training_loss 0.6931471805599453
iteration 2 batch 1860 training_loss 0.6931471805599453
iteration 2 batch 1870 training_loss 0.6916632528527511
iteration 2 batch 1880 training_loss 0.6916632528527511
iteration 2 batch 1890 training_loss 0.6931471805599453
iteration 2 batch 1900 training_loss 0.6931471805599453
iteration 2 batch 1910 training_loss 0.6931471805599453
iteration 2 batch 1920 training_loss 0.6931471805599453
iteration 2 batch 1930 training_loss 0.6931471805599453
iteration 2 batch 1940 training_loss 0.6931471805599453
iteration 2 batch 1950 training_loss 0.6931471805599453
iteration 2 batch 1960 training_loss 0.6931471805599453
iteration 2 batch 1970 training_loss 0.6931471805599453
iteration 2 batch 1980 training_loss 0.6931471805599453
iteration 2 batch 1990 training_loss 0.6931471805599453
iteration 2 batch 2000 training_loss 0.6931471805599453
iteration 2 batch 2010 training_loss 0.6931471805599453
iteration 2 batch 2020 training_loss 0.6931471805599453
iteration 2 batch 2030 training_loss 0.6931471805599453
iteration 2 batch 2040 training_loss 0.6931471805599453
iteration 2 batch 2050 training_loss 0.6931471805599453
iteration 2 batch 2060 training_loss 0.6931471805599453
iteration 2 batch 2070 training_loss 0.6916632528527511
iteration 2 batch 2080 training_loss 0.6916632528527511
iteration 2 batch 2090 training_loss 0.6916632528527511
iteration 2 batch 2100 training_loss 0.6931471805599453
iteration 2 batch 2110 training_loss 0.6931471805599453
iteration 2 batch 2120 training_loss 0.6931471805599453
iteration 2 batch 2130 training_loss 0.6931471805599453
iteration 2 batch 2140 training_loss 0.6931471805599453
iteration 2 batch 2150 training_loss 0.6916632528527511
iteration 2 batch 2160 training_loss 0.6931471805599453
iteration 2 batch 2170 training_loss 0.6916632528527511
iteration 2 batch 2180 training_loss 0.6931471805599453
iteration 2 batch 2190 training_loss 0.6931471805599453
iteration 2 batch 2200 training_loss 0.6931471805599453
iteration 2 batch 2210 training_loss 0.6931471805599453
iteration 2 batch 2220 training_loss 0.6931471805599453
iteration 2 batch 2230 training_loss 0.6931471805599453
iteration 2 batch 2240 training_loss 0.6916632528527511
iteration 2 batch 2250 training_loss 0.6931471805599453
iteration 2 batch 2260 training_loss 0.6931471805599453
iteration 2 batch 2270 training_loss 0.6931471805599453
iteration 2 batch 2280 training_loss 0.6931471805599453
iteration 2 batch 2290 training_loss 0.6916632528527511
iteration 2 batch 2300 training_loss 0.6916632528527511
iteration 2 batch 2310 training_loss 0.6931471805599453
iteration 2 batch 2320 training_loss 0.6931471805599453
iteration 2 batch 2330 training_loss 0.6931471805599453
iteration 2 batch 2340 training_loss 0.6931471805599453
iteration 2 batch 2350 training_loss 0.6931471805599453
iteration 2 batch 2360 training_loss 0.6931471805599453
iteration 2 batch 2370 training_loss 0.6931471805599453
iteration 2 batch 2380 training_loss 0.6931471805599453
iteration 2 batch 2390 training_loss 0.6931471805599453
iteration 2 batch 2400 training_loss 0.6931471805599453
iteration 2 batch 2410 training_loss 0.6886953974383626
iteration 2 batch 2420 training_loss 0.6931471805599453
iteration 2 batch 2430 training_loss 0.6931471805599453
iteration 2 batch 2440 training_loss 0.6931471805599453
iteration 2 batch 2450 training_loss 0.6931471805599453
iteration 2 batch 2460 training_loss 0.6931471805599453
iteration 2 batch 2470 training_loss 0.6916632528527511
iteration 2 batch 2480 training_loss 0.6931471805599453
iteration 2 batch 2490 training_loss 0.6931471805599453
iteration 2 batch 2500 training_loss 0.6931471805599453
iteration 2 batch 2510 training_loss 0.6931471805599453
iteration 2 batch 2520 training_loss 0.6931471805599453
iteration 2 batch 2530 training_loss 0.6931471805599453
iteration 2 batch 2540 training_loss 0.6931471805599453
iteration 2 batch 2550 training_loss 0.6931471805599453
iteration 2 batch 2560 training_loss 0.6931471805599453
iteration 2 batch 2570 training_loss 0.6916632528527511
iteration 2 batch 2580 training_loss 0.6931471805599453
iteration 2 batch 2590 training_loss 0.6931471805599453
iteration 2 batch 2600 training_loss 0.6931471805599453
iteration 2 batch 2610 training_loss 0.6931471805599453
iteration 2 batch 2620 training_loss 0.6931471805599453
iteration 2 batch 2630 training_loss 0.6931471805599453
iteration 2 batch 2640 training_loss 0.6931471805599453
iteration 2 batch 2650 training_loss 0.6931471805599453
iteration 2 batch 2660 training_loss 0.6916632528527511
iteration 2 batch 2670 training_loss 0.6931471805599453
iteration 2 batch 2680 training_loss 0.6931471805599453
iteration 2 batch 2690 training_loss 0.6931471805599453
iteration 2 batch 2700 training_loss 0.6931471805599453
iteration 2 batch 2710 training_loss 0.6931471805599453
iteration 2 batch 2720 training_loss 0.6916632528527511
iteration 2 batch 2730 training_loss 0.6931471805599453
iteration 2 batch 2740 training_loss 0.6931471805599453
iteration 2 batch 2750 training_loss 0.6931471805599453
iteration 2 batch 2760 training_loss 0.6931471805599453
iteration 2 batch 2770 training_loss 0.6931471805599453
iteration 2 batch 2780 training_loss 0.6916632528527511
iteration 2 batch 2790 training_loss 0.6916632528527511
iteration 2 batch 2800 training_loss 0.6931471805599453
iteration 2 batch 2810 training_loss 0.6931471805599453
iteration 2 batch 2820 training_loss 0.6916632528527511
iteration 2 batch 2830 training_loss 0.6931471805599453
iteration 2 batch 2840 training_loss 0.6931471805599453
iteration 2 batch 2850 training_loss 0.6916632528527511
iteration 2 batch 2860 training_loss 0.6931471805599453
iteration 2 batch 2870 training_loss 0.6931471805599453
iteration 2 batch 2880 training_loss 0.6916632528527511
iteration 2 batch 2890 training_loss 0.6931471805599453
iteration 2 batch 2900 training_loss 0.6916632528527511
iteration 2 batch 2910 training_loss 0.6916632528527511
iteration 2 batch 2920 training_loss 0.6916632528527511
iteration 2 batch 2930 training_loss 0.6931471805599453
iteration 2 batch 2940 training_loss 0.6931471805599453
iteration 2 batch 2950 training_loss 0.6886953974383626
iteration 2 batch 2960 training_loss 0.6931471805599453
iteration 2 batch 2970 training_loss 0.6931471805599453
iteration 2 batch 2980 training_loss 0.6931471805599453
iteration 2 batch 2990 training_loss 0.6931471805599453
iteration 2 batch 3000 training_loss 0.6931471805599453
iteration 2 batch 3010 training_loss 0.6931471805599453
iteration 2 batch 3020 training_loss 0.6931471805599453
iteration 2 batch 3030 training_loss 0.6931471805599453
iteration 2 batch 3040 training_loss 0.6931471805599453
iteration 2 batch 3050 training_loss 0.6931471805599453
iteration 2 batch 3060 training_loss 0.6931471805599453
iteration 2 batch 3070 training_loss 0.6931471805599453
iteration 2 batch 3080 training_loss 0.6931471805599453
iteration 2 batch 3090 training_loss 0.6931471805599453
iteration 2 batch 3100 training_loss 0.6931471805599453
iteration 2 batch 3110 training_loss 0.6916632528527511
iteration 2 batch 3120 training_loss 0.6916632528527511
iteration 2 batch 3130 training_loss 0.6931471805599453
iteration 2 batch 3140 training_loss 0.6931471805599453
iteration 2 batch 3150 training_loss 0.6931471805599453
iteration 2 batch 3160 training_loss 0.6931471805599453
iteration 2 batch 3170 training_loss 0.6931471805599453
iteration 2 batch 3180 training_loss 0.6931471805599453
iteration 2 batch 3190 training_loss 0.6931471805599453
iteration 2 batch 3200 training_loss 0.6931471805599453
iteration 2 batch 3210 training_loss 0.6931471805599453
iteration 2 batch 3220 training_loss 0.6931471805599453
iteration 2 batch 3230 training_loss 0.6916632528527511
iteration 2 batch 3240 training_loss 0.6916632528527511
iteration 2 batch 3250 training_loss 0.6931471805599453
iteration 2 batch 3260 training_loss 0.6931471805599453
iteration 2 batch 3270 training_loss 0.6931471805599453
iteration 2 batch 3280 training_loss 0.6931471805599453
iteration 2 batch 3290 training_loss 0.6931471805599453
iteration 2 batch 3300 training_loss 0.6901793251455568
iteration 2 batch 3310 training_loss 0.6916632528527511
iteration 2 batch 3320 training_loss 0.6931471805599453
iteration 2 batch 3330 training_loss 0.6931471805599453
iteration 2 batch 3340 training_loss 0.6916632528527511
iteration 2 batch 3350 training_loss 0.6931471805599453
iteration 2 batch 3360 training_loss 0.6931471805599453
iteration 2 batch 3370 training_loss 0.6931471805599453
iteration 2 batch 3380 training_loss 0.6931471805599453
iteration 2 batch 3390 training_loss 0.6931471805599453
iteration 2 batch 3400 training_loss 0.6931471805599453
iteration 2 batch 3410 training_loss 0.6931471805599453
iteration 2 batch 3420 training_loss 0.6931471805599453
iteration 2 batch 3430 training_loss 0.6931471805599453
iteration 2 batch 3440 training_loss 0.6931471805599453
iteration 2 batch 3450 training_loss 0.6931471805599453
iteration 2 batch 3460 training_loss 0.6931471805599453
iteration 2 batch 3470 training_loss 0.6931471805599453
iteration 2 batch 3480 training_loss 0.6931471805599453
iteration 2 batch 3490 training_loss 0.6931471805599453
iteration 2 batch 3500 training_loss 0.6931471805599453
iteration 2 batch 3510 training_loss 0.6931471805599453
iteration 2 batch 3520 training_loss 0.6931471805599453
iteration 2 batch 3530 training_loss 0.6931471805599453
iteration 2 batch 3540 training_loss 0.6931471805599453
iteration 2 batch 3550 training_loss 0.6931471805599453
iteration 2 batch 3560 training_loss 0.6931471805599453
iteration 2 batch 3570 training_loss 0.6916632528527511
iteration 2 batch 3580 training_loss 0.6931471805599453
iteration 2 batch 3590 training_loss 0.6931471805599453
iteration 2 batch 3600 training_loss 0.6931471805599453
iteration 2 batch 3610 training_loss 0.6931471805599453
iteration 2 batch 3620 training_loss 0.6931471805599453
iteration 2 batch 3630 training_loss 0.6931471805599453
iteration 2 batch 3640 training_loss 0.6931471805599453
iteration 2 batch 3650 training_loss 0.6931471805599453
iteration 2 batch 3660 training_loss 0.6931471805599453
iteration 2 batch 3670 training_loss 0.6916632528527511
iteration 2 batch 3680 training_loss 0.6931471805599453
iteration 2 batch 3690 training_loss 0.6931471805599453
iteration 2 batch 3700 training_loss 0.6931471805599453
iteration 2 batch 3710 training_loss 0.6931471805599453
iteration 2 batch 3720 training_loss 0.6931471805599453
iteration 2 batch 3730 training_loss 0.6931471805599453
iteration 2 batch 3740 training_loss 0.6931471805599453
iteration 2 batch 3750 training_loss 0.6931471805599453
iteration 2 batch 3760 training_loss 0.6931471805599453
iteration 2 batch 3770 training_loss 0.6931471805599453
iteration 2 batch 3780 training_loss 0.6931471805599453
iteration 2 batch 3790 training_loss 0.6931471805599453
iteration 2 batch 3800 training_loss 0.6916632528527511
iteration 2 batch 3810 training_loss 0.6931471805599453
iteration 2 batch 3820 training_loss 0.6931471805599453
iteration 2 batch 3830 training_loss 0.6931471805599453
iteration 2 batch 3840 training_loss 0.6916632528527511
iteration 2 batch 3850 training_loss 0.6931471805599453
iteration 2 batch 3860 training_loss 0.6931471805599453
iteration 2 batch 3870 training_loss 0.6931471805599453
iteration 2 batch 3880 training_loss 0.6931471805599453
iteration 2 batch 3890 training_loss 0.6931471805599453
iteration 2 batch 3900 training_loss 0.6931471805599453
iteration 2 batch 3910 training_loss 0.6931471805599453
iteration 2 batch 3920 training_loss 0.6916632528527511
iteration 2 batch 3930 training_loss 0.6931471805599453
iteration 2 batch 3940 training_loss 0.6931471805599453
iteration 2 batch 3950 training_loss 0.6916632528527511
iteration 2 batch 3960 training_loss 0.6931471805599453
iteration 2 batch 3970 training_loss 0.6931471805599453
iteration 2 batch 3980 training_loss 0.6916632528527511
iteration 2 batch 3990 training_loss 0.6931471805599453
iteration 2 batch 4000 training_loss 0.6931471805599453
iteration 2 batch 4010 training_loss 0.6931471805599453
iteration 2 batch 4020 training_loss 0.6916632528527511
iteration 2 batch 4030 training_loss 0.6931471805599453
iteration 2 batch 4040 training_loss 0.6931471805599453
iteration 2 batch 4050 training_loss 0.6931471805599453
iteration 2 batch 4060 training_loss 0.6931471805599453
iteration 2 batch 4070 training_loss 0.6931471805599453
iteration 2 batch 4080 training_loss 0.6931471805599453
iteration 2 batch 4090 training_loss 0.6931471805599453
iteration 2 batch 4100 training_loss 0.6931471805599453
iteration 2 batch 4110 training_loss 0.6931471805599453
iteration 2 batch 4120 training_loss 0.6931471805599453
iteration 2 batch 4130 training_loss 0.6931471805599453
iteration 2 batch 4140 training_loss 0.6901793251455568
iteration 2 batch 4150 training_loss 0.6931471805599453
iteration 2 batch 4160 training_loss 0.6916632528527511
iteration 2 batch 4170 training_loss 0.6931471805599453
iteration 2 batch 4180 training_loss 0.6931471805599453
iteration 2 batch 4190 training_loss 0.6931471805599453
iteration 2 batch 4200 training_loss 0.6931471805599453
iteration 2 batch 4210 training_loss 0.6916632528527511
iteration 2 batch 4220 training_loss 0.6931471805599453
iteration 2 batch 4230 training_loss 0.6931471805599453
iteration 2 batch 4240 training_loss 0.6931471805599453
iteration 2 batch 4250 training_loss 0.6931471805599453
iteration 2 batch 4260 training_loss 0.6931471805599453
iteration 2 batch 4270 training_loss 0.6931471805599453
iteration 2 batch 4280 training_loss 0.6916632528527511
iteration 2 batch 4290 training_loss 0.6931471805599453
iteration 2 batch 4300 training_loss 0.6931471805599453
iteration 2 batch 4310 training_loss 0.6931471805599453
iteration 2 batch 4320 training_loss 0.6931471805599453
iteration 2 batch 4330 training_loss 0.6931471805599453
iteration 2 batch 4340 training_loss 0.6931471805599453
iteration 2 batch 4350 training_loss 0.6931471805599453
iteration 2 batch 4360 training_loss 0.6931471805599453
iteration 2 batch 4370 training_loss 0.6931471805599453
iteration 2 batch 4380 training_loss 0.6931471805599453
iteration 2 batch 4390 training_loss 0.6931471805599453
iteration 2 batch 4400 training_loss 0.6931471805599453
iteration 2 batch 4410 training_loss 0.6931471805599453
iteration 2 batch 4420 training_loss 0.6931471805599453
iteration 2 batch 4430 training_loss 0.6931471805599453
iteration 2 batch 4440 training_loss 0.6931471805599453
iteration 2 batch 4450 training_loss 0.6931471805599453
iteration 2 batch 4460 training_loss 0.6931471805599453
iteration 2 batch 4470 training_loss 0.6931471805599453
iteration 2 batch 4480 training_loss 0.6931471805599453
iteration 2 batch 4490 training_loss 0.6931471805599453
iteration 2 batch 4500 training_loss 0.6931471805599453
iteration 2 batch 4510 training_loss 0.6931471805599453
iteration 2 batch 4520 training_loss 0.6931471805599453
iteration 2 batch 4530 training_loss 0.6931471805599453
iteration 2 batch 4540 training_loss 0.6916632528527511
iteration 2 batch 4550 training_loss 0.6931471805599453
iteration 2 batch 4560 training_loss 0.6931471805599453
iteration 2 batch 4570 training_loss 0.6931471805599453
iteration 2 batch 4580 training_loss 0.6931471805599453
iteration 2 batch 4590 training_loss 0.6931471805599453
iteration 2 batch 4600 training_loss 0.6931471805599453
iteration 2 batch 4610 training_loss 0.6931471805599453
iteration 2 batch 4620 training_loss 0.6931471805599453
iteration 2 batch 4630 training_loss 0.6931471805599453
iteration 2 batch 4640 training_loss 0.6931471805599453
iteration 2 batch 4650 training_loss 0.6931471805599453
iteration 2 batch 4660 training_loss 0.6931471805599453
iteration 2 batch 4670 training_loss 0.6931471805599453
iteration 2 batch 4680 training_loss 0.6931471805599453
iteration 2 batch 4690 training_loss 0.6931471805599453
iteration 2 batch 4700 training_loss 0.6931471805599453
iteration 2 batch 4710 training_loss 0.6931471805599453
iteration 2 batch 4720 training_loss 0.6916632528527511
iteration 2 batch 4730 training_loss 0.6931471805599453
iteration 2 batch 4740 training_loss 0.6931471805599453
iteration 2 batch 4750 training_loss 0.6931471805599453
iteration 2 batch 4760 training_loss 0.6931471805599453
iteration 2 batch 4770 training_loss 0.6931471805599453
iteration 2 batch 4780 training_loss 0.6916632528527511
iteration 2 batch 4790 training_loss 0.6931471805599453
iteration 2 batch 4800 training_loss 0.6916632528527511
iteration 2 batch 4810 training_loss 0.6931471805599453
iteration 2 batch 4820 training_loss 0.6931471805599453
iteration 2 batch 4830 training_loss 0.6931471805599453
iteration 2 batch 4840 training_loss 0.6931471805599453
iteration 2 batch 4850 training_loss 0.6931471805599453
iteration 2 batch 4860 training_loss 0.6931471805599453
iteration 2 batch 4870 training_loss 0.6931471805599453
iteration 2 batch 4880 training_loss 0.6931471805599453
iteration 2 batch 4890 training_loss 0.6931471805599453
iteration 2 batch 4900 training_loss 0.6931471805599453
iteration 2 batch 4910 training_loss 0.6931471805599453
iteration 2 batch 4920 training_loss 0.6931471805599453
iteration 2 batch 4930 training_loss 0.6931471805599453
iteration 2 batch 4940 training_loss 0.6916632528527511
iteration 2 batch 4950 training_loss 0.6931471805599453
iteration 2 batch 4960 training_loss 0.6931471805599453
iteration 2 batch 4970 training_loss 0.6931471805599453
iteration 2 batch 4980 training_loss 0.6931471805599453
iteration 2 batch 4990 training_loss 0.6931471805599453
iteration 2 batch 5000 training_loss 0.6931471805599453
iteration 2 batch 5010 training_loss 0.6916632528527511
iteration 2 batch 5020 training_loss 0.6931471805599453
iteration 2 batch 5030 training_loss 0.6931471805599453
iteration 2 batch 5040 training_loss 0.6931471805599453
iteration 2 batch 5050 training_loss 0.6901793251455568
iteration 2 batch 5060 training_loss 0.6931471805599453
iteration 2 batch 5070 training_loss 0.6931471805599453
iteration 2 batch 5080 training_loss 0.6931471805599453
iteration 2 batch 5090 training_loss 0.6931471805599453
iteration 2 batch 5100 training_loss 0.6931471805599453
iteration 2 batch 5110 training_loss 0.6931471805599453
iteration 2 batch 5120 training_loss 0.6931471805599453
iteration 2 batch 5130 training_loss 0.6931471805599453
iteration 2 batch 5140 training_loss 0.6931471805599453
iteration 2 batch 5150 training_loss 0.6931471805599453
iteration 2 batch 5160 training_loss 0.6931471805599453
iteration 2 batch 5170 training_loss 0.6931471805599453
iteration 2 batch 5180 training_loss 0.6916632528527511
iteration 2 batch 5190 training_loss 0.6916632528527511
iteration 2 batch 5200 training_loss 0.6931471805599453
iteration 2 batch 5210 training_loss 0.6931471805599453
iteration 2 batch 5220 training_loss 0.6931471805599453
iteration 2 batch 5230 training_loss 0.6931471805599453
iteration 2 batch 5240 training_loss 0.6916632528527511
iteration 2 batch 5250 training_loss 0.6931471805599453
iteration 2 batch 5260 training_loss 0.6916632528527511
iteration 2 batch 5270 training_loss 0.6931471805599453
iteration 2 batch 5280 training_loss 0.6931471805599453
iteration 2 batch 5290 training_loss 0.6916632528527511
iteration 2 batch 5300 training_loss 0.6931471805599453
iteration 2 batch 5310 training_loss 0.6931471805599453
iteration 2 batch 5320 training_loss 0.6916632528527511
iteration 2 batch 5330 training_loss 0.6931471805599453
iteration 2 batch 5340 training_loss 0.6931471805599453
iteration 2 batch 5350 training_loss 0.6931471805599453
iteration 2 batch 5360 training_loss 0.6931471805599453
iteration 2 batch 5370 training_loss 0.6931471805599453
iteration 2 batch 5380 training_loss 0.6931471805599453
iteration 2 batch 5390 training_loss 0.6931471805599453
iteration 2 batch 5400 training_loss 0.6931471805599453
iteration 2 batch 5410 training_loss 0.6931471805599453
iteration 2 batch 5420 training_loss 0.6931471805599453
iteration 2 batch 5430 training_loss 0.6931471805599453
iteration 2 batch 5440 training_loss 0.6931471805599453
iteration 2 batch 5450 training_loss 0.6931471805599453
iteration 2 batch 5460 training_loss 0.6931471805599453
iteration 2 batch 5470 training_loss 0.6931471805599453
iteration 2 batch 5480 training_loss 0.6931471805599453
iteration 2 batch 5490 training_loss 0.6931471805599453
iteration 2 batch 5500 training_loss 0.6931471805599453
iteration 2 batch 5510 training_loss 0.6931471805599453
iteration 2 batch 5520 training_loss 0.6931471805599453
iteration 2 batch 5530 training_loss 0.6931471805599453
iteration 2 batch 5540 training_loss 0.6931471805599453
iteration 2 batch 5550 training_loss 0.6931471805599453
iteration 2 batch 5560 training_loss 0.6931471805599453
iteration 2 batch 5570 training_loss 0.6931471805599453
iteration 2 batch 5580 training_loss 0.6931471805599453
iteration 2 batch 5590 training_loss 0.6901793251455568
iteration 2 batch 5600 training_loss 0.6931471805599453
iteration 2 batch 5610 training_loss 0.6931471805599453
iteration 2 batch 5620 training_loss 0.6931471805599453
iteration 2 batch 5630 training_loss 0.6931471805599453
iteration 2 batch 5640 training_loss 0.6916632528527511
iteration 2 batch 5650 training_loss 0.6931471805599453
iteration 2 batch 5660 training_loss 0.6931471805599453
iteration 2 batch 5670 training_loss 0.6931471805599453
iteration 2 batch 5680 training_loss 0.6931471805599453
iteration 2 batch 5690 training_loss 0.6931471805599453
iteration 2 batch 5700 training_loss 0.6931471805599453
iteration 2 batch 5710 training_loss 0.6931471805599453
iteration 2 batch 5720 training_loss 0.6931471805599453
iteration 2 batch 5730 training_loss 0.6931471805599453
iteration 2 batch 5740 training_loss 0.6931471805599453
iteration 2 batch 5750 training_loss 0.6931471805599453
iteration 2 batch 5760 training_loss 0.6931471805599453
iteration 2 batch 5770 training_loss 0.6931471805599453
iteration 2 batch 5780 training_loss 0.6931471805599453
iteration 2 batch 5790 training_loss 0.6916632528527511
iteration 2 batch 5800 training_loss 0.6931471805599453
iteration 2 batch 5810 training_loss 0.6931471805599453
iteration 2 batch 5820 training_loss 0.6916632528527511
iteration 2 batch 5830 training_loss 0.6931471805599453
iteration 2 batch 5840 training_loss 0.6931471805599453
iteration 2 batch 5850 training_loss 0.6931471805599453
iteration 2 batch 5860 training_loss 0.6931471805599453
iteration 2 batch 5870 training_loss 0.6931471805599453
iteration 2 batch 5880 training_loss 0.6931471805599453
iteration 2 batch 5890 training_loss 0.6931471805599453
iteration 2 batch 5900 training_loss 0.6931471805599453
iteration 2 batch 5910 training_loss 0.6931471805599453
iteration 2 batch 5920 training_loss 0.6931471805599453
iteration 2 batch 5930 training_loss 0.6931471805599453
iteration 2 batch 5940 training_loss 0.6931471805599453
iteration 2 batch 5950 training_loss 0.6931471805599453
iteration 2 batch 5960 training_loss 0.6931471805599453
iteration 2 batch 5970 training_loss 0.6931471805599453
iteration 2 batch 5980 training_loss 0.6931471805599453
iteration 2 batch 5990 training_loss 0.6931471805599453
iteration 2 batch 6000 training_loss 0.6931471805599453
iteration 2 batch 6010 training_loss 0.6916632528527511
iteration 2 batch 6020 training_loss 0.6931471805599453
iteration 2 batch 6030 training_loss 0.6931471805599453
iteration 2 batch 6040 training_loss 0.6931471805599453
iteration 2 batch 6050 training_loss 0.6931471805599453
iteration 2 batch 6060 training_loss 0.6931471805599453
iteration 2 batch 6070 training_loss 0.6916632528527511
iteration 2 batch 6080 training_loss 0.6916632528527511
iteration 2 batch 6090 training_loss 0.6931471805599453
iteration 2 batch 6100 training_loss 0.6931471805599453
iteration 2 batch 6110 training_loss 0.6931471805599453
iteration 2 batch 6120 training_loss 0.6931471805599453
iteration 2 batch 6130 training_loss 0.6931471805599453
iteration 2 batch 6140 training_loss 0.6916632528527511
iteration 2 batch 6150 training_loss 0.6931471805599453
iteration 2 batch 6160 training_loss 0.6931471805599453
iteration 2 batch 6170 training_loss 0.6916632528527511
iteration 2 batch 6180 training_loss 0.6931471805599453
iteration 2 batch 6190 training_loss 0.6931471805599453
iteration 2 batch 6200 training_loss 0.6931471805599453
iteration 2 batch 6210 training_loss 0.6931471805599453
iteration 2 batch 6220 training_loss 0.6931471805599453
iteration 2 batch 6230 training_loss 0.6931471805599453
iteration 2 batch 6240 training_loss 0.6931471805599453
iteration 2 batch 6250 training_loss 0.6931471805599453
iteration 2 batch 6260 training_loss 0.6931471805599453
iteration 2 batch 6270 training_loss 0.6931471805599453
iteration 2 batch 6280 training_loss 0.6931471805599453
iteration 2 batch 6290 training_loss 0.6931471805599453
iteration 2 batch 6300 training_loss 0.6931471805599453
iteration 2 batch 6310 training_loss 0.6931471805599453
iteration 2 batch 6320 training_loss 0.6931471805599453
iteration 2 batch 6330 training_loss 0.6916632528527511
iteration 2 batch 6340 training_loss 0.6916632528527511
iteration 2 batch 6350 training_loss 0.6931471805599453
iteration 2 batch 6360 training_loss 0.6916632528527511
iteration 2 batch 6370 training_loss 0.6931471805599453
iteration 2 batch 6380 training_loss 0.6931471805599453
iteration 2 batch 6390 training_loss 0.6931471805599453
iteration 2 batch 6400 training_loss 0.6916632528527511
iteration 2 batch 6410 training_loss 0.6931471805599453
iteration 2 batch 6420 training_loss 0.6931471805599453
iteration 2 batch 6430 training_loss 0.6931471805599453
iteration 2 batch 6440 training_loss 0.6931471805599453
iteration 2 batch 6450 training_loss 0.6931471805599453
iteration 2 batch 6460 training_loss 0.6916632528527511
iteration 2 batch 6470 training_loss 0.6931471805599453
iteration 2 batch 6480 training_loss 0.6931471805599453
iteration 2 batch 6490 training_loss 0.6916632528527511
iteration 2 batch 6500 training_loss 0.6931471805599453
iteration 2 batch 6510 training_loss 0.6931471805599453
iteration 2 batch 6520 training_loss 0.6931471805599453
iteration 2 batch 6530 training_loss 0.6916632528527511
iteration 2 batch 6540 training_loss 0.6931471805599453
iteration 2 batch 6550 training_loss 0.6931471805599453
iteration 2 batch 6560 training_loss 0.6931471805599453
iteration 2 batch 6570 training_loss 0.6931471805599453
iteration 2 batch 6580 training_loss 0.6931471805599453
iteration 2 batch 6590 training_loss 0.6931471805599453
iteration 2 batch 6600 training_loss 0.6931471805599453
iteration 2 batch 6610 training_loss 0.6931471805599453
iteration 2 batch 6620 training_loss 0.6931471805599453
iteration 2 batch 6630 training_loss 0.6916632528527511
iteration 2 batch 6640 training_loss 0.6931471805599453
iteration 2 batch 6650 training_loss 0.6931471805599453
iteration 2 batch 6660 training_loss 0.6931471805599453
iteration 2 batch 6670 training_loss 0.6931471805599453
iteration 2 batch 6680 training_loss 0.6931471805599453
iteration 2 batch 6690 training_loss 0.6931471805599453
iteration 2 batch 6700 training_loss 0.6931471805599453
iteration 2 batch 6710 training_loss 0.6931471805599453
iteration 2 batch 6720 training_loss 0.6931471805599453
iteration 2 batch 6730 training_loss 0.6931471805599453
iteration 2 batch 6740 training_loss 0.6916632528527511
iteration 2 batch 6750 training_loss 0.6931471805599453
iteration 2 batch 6760 training_loss 0.6931471805599453
iteration 2 batch 6770 training_loss 0.6931471805599453
iteration 2 batch 6780 training_loss 0.6931471805599453
iteration 2 batch 6790 training_loss 0.6931471805599453
iteration 2 batch 6800 training_loss 0.6931471805599453
iteration 2 batch 6810 training_loss 0.6931471805599453
iteration 2 batch 6820 training_loss 0.6931471805599453
iteration 2 batch 6830 training_loss 0.6931471805599453
iteration 2 batch 6840 training_loss 0.6931471805599453
iteration 2 batch 6850 training_loss 0.6931471805599453
iteration 2 batch 6860 training_loss 0.6931471805599453
iteration 2 batch 6870 training_loss 0.6931471805599453
iteration 2 batch 6880 training_loss 0.6931471805599453
iteration 2 batch 6890 training_loss 0.6931471805599453
iteration 2 batch 6900 training_loss 0.6931471805599453
iteration 2 batch 6910 training_loss 0.6931471805599453
iteration 2 batch 6920 training_loss 0.6931471805599453
iteration 2 batch 6930 training_loss 0.6931471805599453
iteration 2 batch 6940 training_loss 0.6931471805599453
iteration 2 batch 6950 training_loss 0.6931471805599453
iteration 2 batch 6960 training_loss 0.6931471805599453
iteration 2 batch 6970 training_loss 0.6931471805599453
iteration 2 batch 6980 training_loss 0.6931471805599453
iteration 2 batch 6990 training_loss 0.6931471805599453
iteration 2 batch 7000 training_loss 0.6931471805599453
iteration 2 batch 7010 training_loss 0.6931471805599453
iteration 2 batch 7020 training_loss 0.6931471805599453
iteration 2 batch 7030 training_loss 0.6931471805599453
iteration 2 batch 7040 training_loss 0.6931471805599453
iteration 2 batch 7050 training_loss 0.6931471805599453
iteration 2 batch 7060 training_loss 0.6931471805599453
iteration 2 batch 7070 training_loss 0.6931471805599453
iteration 2 batch 7080 training_loss 0.6931471805599453
iteration 2 batch 7090 training_loss 0.6931471805599453
iteration 2 batch 7100 training_loss 0.6931471805599453
iteration 2 batch 7110 training_loss 0.6916632528527511
iteration 2 batch 7120 training_loss 0.6931471805599453
iteration 2 batch 7130 training_loss 0.6931471805599453
iteration 2 batch 7140 training_loss 0.6931471805599453
iteration 2 batch 7150 training_loss 0.6931471805599453
iteration 2 batch 7160 training_loss 0.6931471805599453
iteration 2 batch 7170 training_loss 0.6931471805599453
iteration 2 batch 7180 training_loss 0.6916632528527511
iteration 2 batch 7190 training_loss 0.6931471805599453
iteration 2 batch 7200 training_loss 0.6931471805599453
iteration 2 batch 7210 training_loss 0.6931471805599453
iteration 2 batch 7220 training_loss 0.6931471805599453
iteration 2 batch 7230 training_loss 0.6931471805599453
iteration 2 batch 7240 training_loss 0.6931471805599453
iteration 2 batch 7250 training_loss 0.6931471805599453
iteration 2 batch 7260 training_loss 0.6931471805599453
iteration 2 batch 7270 training_loss 0.6931471805599453
iteration 2 batch 7280 training_loss 0.6931471805599453
iteration 2 batch 7290 training_loss 0.6931471805599453
iteration 2 batch 7300 training_loss 0.6931471805599453
iteration 2 batch 7310 training_loss 0.6931471805599453
iteration 2 batch 7320 training_loss 0.6931471805599453
iteration 2 batch 7330 training_loss 0.6931471805599453
iteration 2 batch 7340 training_loss 0.6916632528527511
iteration 2 batch 7350 training_loss 0.6931471805599453
iteration 2 batch 7360 training_loss 0.6931471805599453
iteration 2 batch 7370 training_loss 0.6931471805599453
iteration 2 batch 7380 training_loss 0.6931471805599453
iteration 2 batch 7390 training_loss 0.6931471805599453
iteration 2 batch 7400 training_loss 0.6931471805599453
iteration 2 batch 7410 training_loss 0.6931471805599453
iteration 2 batch 7420 training_loss 0.6931471805599453
iteration 2 batch 7430 training_loss 0.6931471805599453
iteration 2 batch 7440 training_loss 0.6901793251455568
iteration 2 batch 7450 training_loss 0.6916632528527511
iteration 2 batch 7460 training_loss 0.6931471805599453
iteration 2 batch 7470 training_loss 0.6931471805599453
iteration 2 batch 7480 training_loss 0.6931471805599453
iteration 2 batch 7490 training_loss 0.6931471805599453
iteration 2 batch 7500 training_loss 0.6931471805599453
iteration 2 batch 7510 training_loss 0.6931471805599453
iteration 2 batch 7520 training_loss 0.6931471805599453
iteration 2 batch 7530 training_loss 0.6931471805599453
iteration 2 batch 7540 training_loss 0.6931471805599453
iteration 2 batch 7550 training_loss 0.6931471805599453
iteration 2 batch 7560 training_loss 0.6931471805599453
iteration 2 batch 7570 training_loss 0.6931471805599453
iteration 2 batch 7580 training_loss 0.6931471805599453
iteration 2 batch 7590 training_loss 0.6931471805599453
iteration 2 batch 7600 training_loss 0.6931471805599453
iteration 2 batch 7610 training_loss 0.6931471805599453
iteration 2 batch 7620 training_loss 0.6931471805599453
iteration 2 batch 7630 training_loss 0.6931471805599453
iteration 2 batch 7640 training_loss 0.6931471805599453
iteration 2 batch 7650 training_loss 0.6931471805599453
iteration 2 batch 7660 training_loss 0.6931471805599453
iteration 2 batch 7670 training_loss 0.6931471805599453
iteration 2 batch 7680 training_loss 0.6931471805599453
iteration 2 batch 7690 training_loss 0.6916632528527511
iteration 2 batch 7700 training_loss 0.6931471805599453
iteration 2 batch 7710 training_loss 0.6931471805599453
iteration 2 batch 7720 training_loss 0.6931471805599453
iteration 2 batch 7730 training_loss 0.6916632528527511
iteration 2 batch 7740 training_loss 0.6931471805599453
iteration 2 batch 7750 training_loss 0.6931471805599453
iteration 2 batch 7760 training_loss 0.6931471805599453
iteration 2 batch 7770 training_loss 0.6931471805599453
iteration 2 batch 7780 training_loss 0.6916632528527511
iteration 2 batch 7790 training_loss 0.6916632528527511
iteration 2 batch 7800 training_loss 0.6931471805599453
iteration 2 batch 7810 training_loss 0.6931471805599453
iteration 2 batch 7820 training_loss 0.6931471805599453
iteration 2 batch 7830 training_loss 0.6931471805599453
iteration 2 batch 7840 training_loss 0.6931471805599453
iteration 2 batch 7850 training_loss 0.6931471805599453
iteration 2 batch 7860 training_loss 0.6931471805599453
iteration 2 batch 7870 training_loss 0.6916632528527511
iteration 2 batch 7880 training_loss 0.6931471805599453
iteration 2 batch 7890 training_loss 0.6931471805599453
iteration 2 batch 7900 training_loss 0.6931471805599453
iteration 2 batch 7910 training_loss 0.6931471805599453
iteration 2 batch 7920 training_loss 0.6916632528527511
iteration 2 batch 7930 training_loss 0.6931471805599453
iteration 2 batch 7940 training_loss 0.6931471805599453
iteration 2 batch 7950 training_loss 0.6931471805599453
iteration 2 batch 7960 training_loss 0.6931471805599453
iteration 2 batch 7970 training_loss 0.6931471805599453
iteration 2 batch 7980 training_loss 0.6931471805599453
iteration 2 batch 7990 training_loss 0.6931471805599453
iteration 2 batch 8000 training_loss 0.6931471805599453
iteration 2 batch 8010 training_loss 0.6931471805599453
iteration 2 batch 8020 training_loss 0.6931471805599453
iteration 2 batch 8030 training_loss 0.6931471805599453
iteration 2 batch 8040 training_loss 0.6931471805599453
iteration 2 batch 8050 training_loss 0.6931471805599453
iteration 2 batch 8060 training_loss 0.6931471805599453
iteration 2 batch 8070 training_loss 0.6931471805599453
iteration 2 batch 8080 training_loss 0.6931471805599453
iteration 2 batch 8090 training_loss 0.6931471805599453
iteration 2 batch 8100 training_loss 0.6931471805599453
iteration 2 batch 8110 training_loss 0.6931471805599453
iteration 2 batch 8120 training_loss 0.6931471805599453
iteration 2 batch 8130 training_loss 0.6931471805599453
iteration 2 batch 8140 training_loss 0.6931471805599453
iteration 2 batch 8150 training_loss 0.6931471805599453
iteration 2 batch 8160 training_loss 0.6931471805599453
iteration 2 batch 8170 training_loss 0.6931471805599453
iteration 2 batch 8180 training_loss 0.6931471805599453
iteration 2 batch 8190 training_loss 0.6931471805599453
iteration 2 batch 8200 training_loss 0.6916632528527511
iteration 2 batch 8210 training_loss 0.6931471805599453
iteration 2 batch 8220 training_loss 0.6931471805599453
iteration 2 batch 8230 training_loss 0.6931471805599453
iteration 2 batch 8240 training_loss 0.6916632528527511
iteration 2 batch 8250 training_loss 0.6916632528527511
iteration 2 batch 8260 training_loss 0.6931471805599453
iteration 2 batch 8270 training_loss 0.6931471805599453
iteration 2 batch 8280 training_loss 0.6931471805599453
iteration 2 batch 8290 training_loss 0.6931471805599453
iteration 2 batch 8300 training_loss 0.6931471805599453
iteration 2 batch 8310 training_loss 0.6931471805599453
iteration 2 batch 8320 training_loss 0.6916632528527511
iteration 2 batch 8330 training_loss 0.6931471805599453
iteration 2 batch 8340 training_loss 0.6931471805599453
iteration 2 batch 8350 training_loss 0.6931471805599453
iteration 2 batch 8360 training_loss 0.6931471805599453
iteration 2 batch 8370 training_loss 0.6931471805599453
iteration 2 batch 8380 training_loss 0.6931471805599453
iteration 2 batch 8390 training_loss 0.6931471805599453
iteration 2 batch 8400 training_loss 0.6931471805599453
iteration 2 batch 8410 training_loss 0.6916632528527511
iteration 2 batch 8420 training_loss 0.6931471805599453
iteration 2 batch 8430 training_loss 0.6931471805599453
iteration 2 batch 8440 training_loss 0.6931471805599453
iteration 2 batch 8450 training_loss 0.6931471805599453
iteration 2 batch 8460 training_loss 0.6931471805599453
iteration 2 batch 8470 training_loss 0.6931471805599453
iteration 2 batch 8480 training_loss 0.6931471805599453
iteration 2 batch 8490 training_loss 0.6931471805599453
iteration 2 batch 8500 training_loss 0.6931471805599453
iteration 2 batch 8510 training_loss 0.6931471805599453
iteration 2 batch 8520 training_loss 0.6931471805599453
iteration 2 batch 8530 training_loss 0.6931471805599453
iteration 2 batch 8540 training_loss 0.6931471805599453
iteration 2 batch 8550 training_loss 0.6931471805599453
iteration 2 batch 8560 training_loss 0.6931471805599453
iteration 2 batch 8570 training_loss 0.6931471805599453
iteration 2 batch 8580 training_loss 0.6931471805599453
iteration 2 batch 8590 training_loss 0.6931471805599453
iteration 2 batch 8600 training_loss 0.6931471805599453
iteration 2 batch 8610 training_loss 0.6931471805599453
iteration 2 batch 8620 training_loss 0.6931471805599453
iteration 2 batch 8630 training_loss 0.6931471805599453
iteration 2 batch 8640 training_loss 0.6931471805599453
iteration 2 batch 8650 training_loss 0.6931471805599453
iteration 2 batch 8660 training_loss 0.6916632528527511
iteration 2 batch 8670 training_loss 0.6931471805599453
iteration 2 batch 8680 training_loss 0.6931471805599453
iteration 2 batch 8690 training_loss 0.6931471805599453
iteration 2 batch 8700 training_loss 0.6916632528527511
iteration 2 batch 8710 training_loss 0.6931471805599453
iteration 2 batch 8720 training_loss 0.6931471805599453
iteration 2 batch 8730 training_loss 0.6931471805599453
iteration 2 batch 8740 training_loss 0.6931471805599453
iteration 2 batch 8750 training_loss 0.6931471805599453
iteration 2 batch 8760 training_loss 0.6931471805599453
iteration 2 batch 8770 training_loss 0.6931471805599453
iteration 2 batch 8780 training_loss 0.6931471805599453
iteration 2 batch 8790 training_loss 0.6931471805599453
iteration 2 batch 8800 training_loss 0.6931471805599453
iteration 2 batch 8810 training_loss 0.6916632528527511
iteration 2 batch 8820 training_loss 0.6931471805599453
iteration 2 batch 8830 training_loss 0.6916632528527511
iteration 2 batch 8840 training_loss 0.6931471805599453
iteration 2 batch 8850 training_loss 0.6931471805599453
iteration 2 batch 8860 training_loss 0.6931471805599453
iteration 2 batch 8870 training_loss 0.6931471805599453
iteration 2 batch 8880 training_loss 0.6931471805599453
iteration 2 batch 8890 training_loss 0.6931471805599453
iteration 2 batch 8900 training_loss 0.6931471805599453
iteration 2 batch 8910 training_loss 0.6931471805599453
iteration 2 batch 8920 training_loss 0.6931471805599453
iteration 2 batch 8930 training_loss 0.6931471805599453
iteration 2 batch 8940 training_loss 0.6931471805599453
iteration 2 batch 8950 training_loss 0.6931471805599453
iteration 2 batch 8960 training_loss 0.6931471805599453
iteration 2 batch 8970 training_loss 0.6931471805599453
iteration 2 batch 8980 training_loss 0.6931471805599453
iteration 2 batch 8990 training_loss 0.6931471805599453
iteration 2 batch 9000 training_loss 0.6931471805599453
iteration 2 batch 9010 training_loss 0.6931471805599453
iteration 2 batch 9020 training_loss 0.6931471805599453
iteration 2 batch 9030 training_loss 0.6931471805599453
iteration 2 batch 9040 training_loss 0.6931471805599453
iteration 2 batch 9050 training_loss 0.6931471805599453
iteration 2 batch 9060 training_loss 0.6931471805599453
iteration 2 batch 9070 training_loss 0.6916632528527511
iteration 2 batch 9080 training_loss 0.6931471805599453
iteration 2 batch 9090 training_loss 0.6931471805599453
iteration 2 batch 9100 training_loss 0.6916632528527511
iteration 2 batch 9110 training_loss 0.6931471805599453
iteration 2 batch 9120 training_loss 0.6931471805599453
iteration 2 batch 9130 training_loss 0.6916632528527511
iteration 2 batch 9140 training_loss 0.6931471805599453
iteration 2 batch 9150 training_loss 0.6931471805599453
iteration 2 batch 9160 training_loss 0.6931471805599453
iteration 2 batch 9170 training_loss 0.6931471805599453
iteration 2 batch 9180 training_loss 0.6931471805599453
iteration 2 batch 9190 training_loss 0.6931471805599453
iteration 2 batch 9200 training_loss 0.6916632528527511
iteration 2 batch 9210 training_loss 0.6931471805599453
iteration 2 batch 9220 training_loss 0.6931471805599453
iteration 2 batch 9230 training_loss 0.6931471805599453
iteration 2 batch 9240 training_loss 0.6931471805599453
iteration 2 batch 9250 training_loss 0.6931471805599453
iteration 2 batch 9260 training_loss 0.6931471805599453
iteration 2 batch 9270 training_loss 0.6931471805599453
iteration 2 batch 9280 training_loss 0.6931471805599453
iteration 2 batch 9290 training_loss 0.6931471805599453
iteration 2 batch 9300 training_loss 0.6931471805599453
iteration 2 batch 9310 training_loss 0.6931471805599453
iteration 2 batch 9320 training_loss 0.6931471805599453
iteration 2 batch 9330 training_loss 0.6931471805599453
iteration 2 batch 9340 training_loss 0.6931471805599453
iteration 2 batch 9350 training_loss 0.6931471805599453
iteration 2 batch 9360 training_loss 0.6931471805599453
iteration 2 batch 9370 training_loss 0.6931471805599453
iteration 2 batch 9380 training_loss 0.6931471805599453
iteration 2 batch 9390 training_loss 0.6931471805599453
iteration 2 batch 9400 training_loss 0.6931471805599453
iteration 2 batch 9410 training_loss 0.6931471805599453
iteration 2 batch 9420 training_loss 0.6931471805599453
iteration 2 batch 9430 training_loss 0.6931471805599453
iteration 2 batch 9440 training_loss 0.6931471805599453
iteration 2 batch 9450 training_loss 0.6916632528527511
iteration 2 batch 9460 training_loss 0.6931471805599453
iteration 2 batch 9470 training_loss 0.6916632528527511
iteration 2 batch 9480 training_loss 0.6931471805599453
iteration 2 batch 9490 training_loss 0.6931471805599453
iteration 2 batch 9500 training_loss 0.6931471805599453
iteration 2 batch 9510 training_loss 0.6931471805599453
iteration 2 batch 9520 training_loss 0.6931471805599453
iteration 2 batch 9530 training_loss 0.6931471805599453
iteration 2 batch 9540 training_loss 0.6931471805599453
iteration 2 batch 9550 training_loss 0.6931471805599453
iteration 2 batch 9560 training_loss 0.6916632528527511
iteration 2 batch 9570 training_loss 0.6931471805599453
iteration 2 batch 9580 training_loss 0.6931471805599453
iteration 2 batch 9590 training_loss 0.6931471805599453
iteration 2 batch 9600 training_loss 0.6931471805599453
iteration 2 batch 9610 training_loss 0.6916632528527511
iteration 2 batch 9620 training_loss 0.6931471805599453
iteration 2 batch 9630 training_loss 0.6931471805599453
iteration 2 batch 9640 training_loss 0.6931471805599453
iteration 2 batch 9650 training_loss 0.6931471805599453
iteration 2 batch 9660 training_loss 0.6916632528527511
iteration 2 batch 9670 training_loss 0.6916632528527511
iteration 2 batch 9680 training_loss 0.6931471805599453
iteration 2 batch 9690 training_loss 0.6901793251455568
iteration 2 batch 9700 training_loss 0.6931471805599453
iteration 2 batch 9710 training_loss 0.6931471805599453
iteration 2 batch 9720 training_loss 0.6931471805599453
iteration 2 batch 9730 training_loss 0.6931471805599453
iteration 2 batch 9740 training_loss 0.6931471805599453
iteration 2 batch 9750 training_loss 0.6931471805599453
iteration 2 batch 9760 training_loss 0.6931471805599453
iteration 2 batch 9770 training_loss 0.6931471805599453
iteration 2 batch 9780 training_loss 0.6931471805599453
iteration 2 batch 9790 training_loss 0.6931471805599453
iteration 2 batch 9800 training_loss 0.6931471805599453
iteration 2 batch 9810 training_loss 0.6931471805599453
iteration 2 batch 9820 training_loss 0.6931471805599453
iteration 2 batch 9830 training_loss 0.6931471805599453
iteration 2 batch 9840 training_loss 0.6931471805599453
iteration 2 batch 9850 training_loss 0.6931471805599453
iteration 2 batch 9860 training_loss 0.6931471805599453
iteration 2 batch 9870 training_loss 0.6931471805599453
iteration 2 batch 9880 training_loss 0.6931471805599453
iteration 2 batch 9890 training_loss 0.6931471805599453
iteration 2 batch 9900 training_loss 0.6916632528527511
iteration 2 batch 9910 training_loss 0.6931471805599453
iteration 2 batch 9920 training_loss 0.6931471805599453
iteration 2 batch 9930 training_loss 0.6931471805599453
iteration 2 batch 9940 training_loss 0.6931471805599453
iteration 2 batch 9950 training_loss 0.6931471805599453
iteration 2 batch 9960 training_loss 0.6931471805599453
iteration 2 batch 9970 training_loss 0.6931471805599453
iteration 2 batch 9980 training_loss 0.6931471805599453
iteration 2 batch 9990 training_loss 0.6931471805599453
iteration 2 batch 10000 training_loss 0.6931471805599453
iteration 2 batch 10010 training_loss 0.6916632528527511
iteration 2 batch 10020 training_loss 0.6931471805599453
iteration 2 batch 10030 training_loss 0.6916632528527511
iteration 2 batch 10040 training_loss 0.6931471805599453
iteration 2 batch 10050 training_loss 0.6931471805599453
iteration 2 batch 10060 training_loss 0.6931471805599453
iteration 2 batch 10070 training_loss 0.6931471805599453
iteration 2 batch 10080 training_loss 0.6931471805599453
iteration 2 batch 10090 training_loss 0.6931471805599453
iteration 2 batch 10100 training_loss 0.6916632528527511
iteration 2 batch 10110 training_loss 0.6931471805599453
iteration 2 batch 10120 training_loss 0.6931471805599453
iteration 2 batch 10130 training_loss 0.6931471805599453
iteration 2 batch 10140 training_loss 0.6931471805599453
iteration 2 batch 10150 training_loss 0.6931471805599453
iteration 2 batch 10160 training_loss 0.6931471805599453
iteration 2 batch 10170 training_loss 0.6931471805599453
iteration 2 batch 10180 training_loss 0.6931471805599453
iteration 2 batch 10190 training_loss 0.6931471805599453
iteration 2 batch 10200 training_loss 0.6916632528527511
iteration 2 batch 10210 training_loss 0.6916632528527511
iteration 2 batch 10220 training_loss 0.6931471805599453
iteration 2 batch 10230 training_loss 0.6931471805599453
iteration 2 batch 10240 training_loss 0.6931471805599453
iteration 2 batch 10250 training_loss 0.6931471805599453
iteration 2 batch 10260 training_loss 0.6931471805599453
iteration 2 batch 10270 training_loss 0.6931471805599453
iteration 2 batch 10280 training_loss 0.6931471805599453
iteration 2 batch 10290 training_loss 0.6931471805599453
iteration 2 batch 10300 training_loss 0.6931471805599453
iteration 2 batch 10310 training_loss 0.6931471805599453
iteration 2 batch 10320 training_loss 0.6931471805599453
iteration 2 batch 10330 training_loss 0.6931471805599453
iteration 2 batch 10340 training_loss 0.6931471805599453
iteration 2 batch 10350 training_loss 0.6931471805599453
iteration 2 batch 10360 training_loss 0.6931471805599453
iteration 2 batch 10370 training_loss 0.6931471805599453
iteration 2 batch 10380 training_loss 0.6931471805599453
iteration 2 batch 10390 training_loss 0.6931471805599453
iteration 2 batch 10400 training_loss 0.6916632528527511
iteration 2 batch 10410 training_loss 0.6931471805599453
iteration 2 batch 10420 training_loss 0.6931471805599453
iteration 2 batch 10430 training_loss 0.6931471805599453
iteration 2 batch 10440 training_loss 0.6931471805599453
iteration 2 batch 10450 training_loss 0.6931471805599453
iteration 2 batch 10460 training_loss 0.6931471805599453
iteration 2 batch 10470 training_loss 0.6931471805599453
iteration 2 batch 10480 training_loss 0.6931471805599453
iteration 2 batch 10490 training_loss 0.6931471805599453
iteration 2 batch 10500 training_loss 0.6931471805599453
iteration 2 batch 10510 training_loss 0.6931471805599453
iteration 2 batch 10520 training_loss 0.6931471805599453
iteration 2 batch 10530 training_loss 0.6931471805599453
iteration 2 batch 10540 training_loss 0.6901793251455568
iteration 2 batch 10550 training_loss 0.6931471805599453
iteration 2 batch 10560 training_loss 0.6931471805599453
iteration 2 batch 10570 training_loss 0.6931471805599453
iteration 2 batch 10580 training_loss 0.6931471805599453
iteration 2 batch 10590 training_loss 0.6931471805599453
iteration 2 batch 10600 training_loss 0.6931471805599453
iteration 2 batch 10610 training_loss 0.6931471805599453
iteration 2 batch 10620 training_loss 0.6931471805599453
iteration 2 batch 10630 training_loss 0.6931471805599453
iteration 2 batch 10640 training_loss 0.6931471805599453
iteration 2 batch 10650 training_loss 0.6931471805599453
iteration 2 batch 10660 training_loss 0.6931471805599453
iteration 2 batch 10670 training_loss 0.6931471805599453
iteration 2 batch 10680 training_loss 0.6931471805599453
iteration 2 batch 10690 training_loss 0.6931471805599453
iteration 2 batch 10700 training_loss 0.6931471805599453
iteration 2 batch 10710 training_loss 0.6931471805599453
iteration 2 batch 10720 training_loss 0.6931471805599453
iteration 2 batch 10730 training_loss 0.6931471805599453
iteration 2 batch 10740 training_loss 0.6931471805599453
iteration 2 batch 10750 training_loss 0.6931471805599453
iteration 2 batch 10760 training_loss 0.6931471805599453
iteration 2 batch 10770 training_loss 0.6901793251455568
iteration 2 batch 10780 training_loss 0.6931471805599453
iteration 2 batch 10790 training_loss 0.6931471805599453
iteration 2 batch 10800 training_loss 0.6931471805599453
iteration 2 batch 10810 training_loss 0.6931471805599453
iteration 2 batch 10820 training_loss 0.6931471805599453
iteration 2 batch 10830 training_loss 0.6931471805599453
iteration 2 batch 10840 training_loss 0.6916632528527511
iteration 2 batch 10850 training_loss 0.6931471805599453
iteration 2 batch 10860 training_loss 0.6931471805599453
iteration 2 batch 10870 training_loss 0.6931471805599453
iteration 2 batch 10880 training_loss 0.6931471805599453
iteration 2 batch 10890 training_loss 0.6931471805599453
iteration 2 batch 10900 training_loss 0.6931471805599453
iteration 2 batch 10910 training_loss 0.6931471805599453
iteration 2 batch 10920 training_loss 0.6931471805599453
iteration 2 batch 10930 training_loss 0.6931471805599453
iteration 2 batch 10940 training_loss 0.6931471805599453
iteration 2 batch 10950 training_loss 0.6931471805599453
iteration 2 batch 10960 training_loss 0.6931471805599453
iteration 2 batch 10970 training_loss 0.6931471805599453
iteration 2 batch 10980 training_loss 0.6931471805599453
iteration 2 batch 10990 training_loss 0.6931471805599453
iteration 2 batch 11000 training_loss 0.6931471805599453
iteration 2 batch 11010 training_loss 0.6931471805599453
iteration 2 batch 11020 training_loss 0.6931471805599453
iteration 2 batch 11030 training_loss 0.6931471805599453
iteration 2 batch 11040 training_loss 0.6931471805599453
iteration 2 batch 11050 training_loss 0.6931471805599453
iteration 2 batch 11060 training_loss 0.6931471805599453
iteration 2 batch 11070 training_loss 0.6931471805599453
iteration 2 batch 11080 training_loss 0.6931471805599453
iteration 2 batch 11090 training_loss 0.6931471805599453
iteration 2 batch 11100 training_loss 0.6931471805599453
iteration 2 batch 11110 training_loss 0.6931471805599453
iteration 2 batch 11120 training_loss 0.6931471805599453
iteration 2 batch 11130 training_loss 0.6931471805599453
iteration 2 batch 11140 training_loss 0.6931471805599453
iteration 2 batch 11150 training_loss 0.6931471805599453
iteration 2 batch 11160 training_loss 0.6931471805599453
iteration 2 batch 11170 training_loss 0.6931471805599453
iteration 2 batch 11180 training_loss 0.6931471805599453
iteration 2 batch 11190 training_loss 0.6931471805599453
iteration 2 batch 11200 training_loss 0.6931471805599453
iteration 2 batch 11210 training_loss 0.6931471805599453
iteration 2 batch 11220 training_loss 0.6931471805599453
iteration 2 batch 11230 training_loss 0.6931471805599453
iteration 2 batch 11240 training_loss 0.6931471805599453
iteration 2 batch 11250 training_loss 0.6931471805599453
iteration 2 batch 11260 training_loss 0.6931471805599453
iteration 2 batch 11270 training_loss 0.6931471805599453
iteration 2 batch 11280 training_loss 0.6931471805599453
iteration 2 batch 11290 training_loss 0.6931471805599453
iteration 2 batch 11300 training_loss 0.6931471805599453
iteration 2 batch 11310 training_loss 0.6931471805599453
iteration 2 batch 11320 training_loss 0.6931471805599453
iteration 2 batch 11330 training_loss 0.6931471805599453
iteration 2 batch 11340 training_loss 0.6931471805599453
iteration 2 batch 11350 training_loss 0.6931471805599453
iteration 2 batch 11360 training_loss 0.6916632528527511
iteration 2 batch 11370 training_loss 0.6931471805599453
iteration 2 batch 11380 training_loss 0.6931471805599453
iteration 2 batch 11390 training_loss 0.6931471805599453
iteration 2 batch 11400 training_loss 0.6916632528527511
iteration 2 batch 11410 training_loss 0.6931471805599453
iteration 2 batch 11420 training_loss 0.6931471805599453
iteration 2 batch 11430 training_loss 0.6916632528527511
iteration 2 batch 11440 training_loss 0.6931471805599453
iteration 2 batch 11450 training_loss 0.6931471805599453
iteration 2 batch 11460 training_loss 0.6931471805599453
iteration 2 batch 11470 training_loss 0.6931471805599453
iteration 2 batch 11480 training_loss 0.6931471805599453
iteration 2 batch 11490 training_loss 0.6931471805599453
iteration 2 batch 11500 training_loss 0.6931471805599453
iteration 2 batch 11510 training_loss 0.6931471805599453
iteration 2 batch 11520 training_loss 0.6931471805599453
iteration 2 batch 11530 training_loss 0.6931471805599453
iteration 2 batch 11540 training_loss 0.6931471805599453
iteration 2 batch 11550 training_loss 0.6931471805599453
iteration 2 batch 11560 training_loss 0.6916632528527511
iteration 2 batch 11570 training_loss 0.6916632528527511
iteration 2 batch 11580 training_loss 0.6916632528527511
iteration 2 batch 11590 training_loss 0.6916632528527511
iteration 2 batch 11600 training_loss 0.6931471805599453
iteration 2 batch 11610 training_loss 0.6931471805599453
iteration 2 batch 11620 training_loss 0.6931471805599453
iteration 2 batch 11630 training_loss 0.6916632528527511
iteration 2 batch 11640 training_loss 0.6931471805599453
iteration 2 batch 11650 training_loss 0.6931471805599453
iteration 2 batch 11660 training_loss 0.6931471805599453
iteration 2 batch 11670 training_loss 0.6931471805599453
iteration 2 batch 11680 training_loss 0.6931471805599453
iteration 2 batch 11690 training_loss 0.6931471805599453
iteration 2 batch 11700 training_loss 0.6931471805599453
iteration 2 batch 11710 training_loss 0.6916632528527511
iteration 2 batch 11720 training_loss 0.6916632528527511
iteration 2 batch 11730 training_loss 0.6916632528527511
iteration 2 batch 11740 training_loss 0.6931471805599453
iteration 2 batch 11750 training_loss 0.6931471805599453
iteration 2 batch 11760 training_loss 0.6931471805599453
iteration 2 batch 11770 training_loss 0.6931471805599453
iteration 2 batch 11780 training_loss 0.6931471805599453
iteration 2 batch 11790 training_loss 0.6931471805599453
iteration 2 batch 11800 training_loss 0.6931471805599453
iteration 2 batch 11810 training_loss 0.6931471805599453
iteration 2 batch 11820 training_loss 0.6931471805599453
iteration 2 batch 11830 training_loss 0.6931471805599453
iteration 2 batch 11840 training_loss 0.6931471805599453
iteration 2 batch 11850 training_loss 0.6916632528527511
iteration 2 batch 11860 training_loss 0.6931471805599453
iteration 2 batch 11870 training_loss 0.6931471805599453
iteration 2 batch 11880 training_loss 0.6931471805599453
iteration 2 batch 11890 training_loss 0.6931471805599453
iteration 2 batch 11900 training_loss 0.6931471805599453
iteration 2 batch 11910 training_loss 0.6916632528527511
iteration 2 batch 11920 training_loss 0.6931471805599453
iteration 2 batch 11930 training_loss 0.6931471805599453
iteration 2 batch 11940 training_loss 0.6916632528527511
iteration 2 batch 11950 training_loss 0.6931471805599453
iteration 2 batch 11960 training_loss 0.6931471805599453
iteration 2 batch 11970 training_loss 0.6931471805599453
iteration 2 batch 11980 training_loss 0.6931471805599453
iteration 2 batch 11990 training_loss 0.6916632528527511
iteration 2 batch 12000 training_loss 0.6931471805599453
iteration 2 batch 12010 training_loss 0.6931471805599453
iteration 2 batch 12020 training_loss 0.6931471805599453
iteration 2 batch 12030 training_loss 0.6931471805599453
iteration 2 batch 12040 training_loss 0.6931471805599453
iteration 2 batch 12050 training_loss 0.6931471805599453
iteration 2 batch 12060 training_loss 0.6931471805599453
iteration 2 batch 12070 training_loss 0.6931471805599453
iteration 2 batch 12080 training_loss 0.6916632528527511
iteration 2 batch 12090 training_loss 0.6931471805599453
iteration 2 batch 12100 training_loss 0.6931471805599453
iteration 2 batch 12110 training_loss 0.6916632528527511
iteration 2 batch 12120 training_loss 0.6931471805599453
iteration 2 batch 12130 training_loss 0.6931471805599453
iteration 2 batch 12140 training_loss 0.6931471805599453
iteration 2 batch 12150 training_loss 0.6931471805599453
iteration 2 batch 12160 training_loss 0.6931471805599453
iteration 2 batch 12170 training_loss 0.6931471805599453
iteration 2 batch 12180 training_loss 0.6931471805599453
iteration 2 batch 12190 training_loss 0.6931471805599453
iteration 2 batch 12200 training_loss 0.6931471805599453
iteration 2 batch 12210 training_loss 0.6931471805599453
iteration 2 batch 12220 training_loss 0.6931471805599453
iteration 2 batch 12230 training_loss 0.6931471805599453
iteration 2 batch 12240 training_loss 0.6931471805599453
iteration 2 batch 12250 training_loss 0.6931471805599453
iteration 2 batch 12260 training_loss 0.6916632528527511
iteration 2 batch 12270 training_loss 0.6931471805599453
iteration 2 batch 12280 training_loss 0.6931471805599453
iteration 2 batch 12290 training_loss 0.6931471805599453
iteration 2 batch 12300 training_loss 0.6916632528527511
iteration 2 batch 12310 training_loss 0.6931471805599453
iteration 2 batch 12320 training_loss 0.6931471805599453
iteration 2 batch 12330 training_loss 0.6931471805599453
iteration 2 batch 12340 training_loss 0.6931471805599453
iteration 2 batch 12350 training_loss 0.6931471805599453
iteration 2 batch 12360 training_loss 0.6931471805599453
iteration 2 batch 12370 training_loss 0.6931471805599453
iteration 2 batch 12380 training_loss 0.6931471805599453
iteration 2 batch 12390 training_loss 0.6931471805599453
iteration 2 batch 12400 training_loss 0.6931471805599453
iteration 2 batch 12410 training_loss 0.6931471805599453
iteration 2 batch 12420 training_loss 0.6916632528527511
iteration 2 batch 12430 training_loss 0.6931471805599453
iteration 2 batch 12440 training_loss 0.6931471805599453
iteration 2 batch 12450 training_loss 0.6931471805599453
iteration 2 batch 12460 training_loss 0.6931471805599453
iteration 2 batch 12470 training_loss 0.6931471805599453
iteration 2 batch 12480 training_loss 0.6931471805599453
iteration 2 batch 12490 training_loss 0.6916632528527511
iteration 2 batch 12500 training_loss 0.6931471805599453
iteration 2 batch 12510 training_loss 0.6931471805599453
iteration 2 batch 12520 training_loss 0.6931471805599453
iteration 2 batch 12530 training_loss 0.6931471805599453
iteration 2 batch 12540 training_loss 0.6931471805599453
iteration 2 batch 12550 training_loss 0.6931471805599453
iteration 2 batch 12560 training_loss 0.6931471805599453
iteration 2 batch 12570 training_loss 0.6916632528527511
iteration 2 batch 12580 training_loss 0.6916632528527511
iteration 2 batch 12590 training_loss 0.6931471805599453
iteration 2 batch 12600 training_loss 0.6931471805599453
iteration 2 batch 12610 training_loss 0.6931471805599453
iteration 2 batch 12620 training_loss 0.6931471805599453
iteration 2 batch 12630 training_loss 0.6931471805599453
iteration 2 batch 12640 training_loss 0.6931471805599453
iteration 2 batch 12650 training_loss 0.6931471805599453
iteration 2 batch 12660 training_loss 0.6931471805599453
iteration 2 batch 12670 training_loss 0.6931471805599453
iteration 2 batch 12680 training_loss 0.6931471805599453
iteration 2 batch 12690 training_loss 0.6931471805599453
iteration 2 batch 12700 training_loss 0.6931471805599453
iteration 2 batch 12710 training_loss 0.6931471805599453
iteration 2 batch 12720 training_loss 0.6931471805599453
iteration 2 batch 12730 training_loss 0.6931471805599453
iteration 2 batch 12740 training_loss 0.6931471805599453
iteration 2 batch 12750 training_loss 0.6931471805599453
iteration 2 batch 12760 training_loss 0.6931471805599453
iteration 2 batch 12770 training_loss 0.6931471805599453
iteration 2 batch 12780 training_loss 0.6931471805599453
iteration 2 batch 12790 training_loss 0.6931471805599453
iteration 2 batch 12800 training_loss 0.6916632528527511
iteration 2 batch 12810 training_loss 0.6931471805599453
iteration 2 batch 12820 training_loss 0.6931471805599453
iteration 2 batch 12830 training_loss 0.6931471805599453
iteration 2 batch 12840 training_loss 0.6931471805599453
iteration 2 batch 12850 training_loss 0.6931471805599453
iteration 2 batch 12860 training_loss 0.6931471805599453
iteration 2 batch 12870 training_loss 0.6916632528527511
iteration 2 batch 12880 training_loss 0.6931471805599453
iteration 2 batch 12890 training_loss 0.6931471805599453
iteration 2 batch 12900 training_loss 0.6931471805599453
iteration 2 batch 12910 training_loss 0.6931471805599453
iteration 2 batch 12920 training_loss 0.6931471805599453
iteration 2 batch 12930 training_loss 0.6931471805599453
iteration 2 batch 12940 training_loss 0.6931471805599453
iteration 2 batch 12950 training_loss 0.6931471805599453
iteration 2 batch 12960 training_loss 0.6931471805599453
iteration 2 batch 12970 training_loss 0.6916632528527511
iteration 2 batch 12980 training_loss 0.6931471805599453
iteration 2 batch 12990 training_loss 0.6931471805599453
iteration 2 batch 13000 training_loss 0.6931471805599453
iteration 2 batch 13010 training_loss 0.6916632528527511
iteration 2 batch 13020 training_loss 0.6931471805599453
iteration 2 batch 13030 training_loss 0.6931471805599453
iteration 2 batch 13040 training_loss 0.6916632528527511
iteration 2 batch 13050 training_loss 0.6931471805599453
iteration 2 batch 13060 training_loss 0.6931471805599453
iteration 2 batch 13070 training_loss 0.6931471805599453
iteration 2 batch 13080 training_loss 0.6931471805599453
iteration 2 batch 13090 training_loss 0.6931471805599453
iteration 2 batch 13100 training_loss 0.6931471805599453
iteration 2 batch 13110 training_loss 0.6931471805599453
iteration 2 batch 13120 training_loss 0.6931471805599453
iteration 2 batch 13130 training_loss 0.6931471805599453
iteration 2 batch 13140 training_loss 0.6916632528527511
iteration 2 batch 13150 training_loss 0.6931471805599453
iteration 2 batch 13160 training_loss 0.6916632528527511
iteration 2 batch 13170 training_loss 0.6931471805599453
iteration 2 batch 13180 training_loss 0.6931471805599453
iteration 2 batch 13190 training_loss 0.6916632528527511
iteration 2 batch 13200 training_loss 0.6931471805599453
iteration 2 batch 13210 training_loss 0.6931471805599453
iteration 2 batch 13220 training_loss 0.6931471805599453
iteration 2 batch 13230 training_loss 0.6916632528527511
iteration 2 batch 13240 training_loss 0.6931471805599453
iteration 2 batch 13250 training_loss 0.6931471805599453
iteration 2 batch 13260 training_loss 0.6931471805599453
iteration 2 batch 13270 training_loss 0.6931471805599453
iteration 2 batch 13280 training_loss 0.6916632528527511
iteration 2 batch 13290 training_loss 0.6931471805599453
iteration 2 batch 13300 training_loss 0.6931471805599453
iteration 2 batch 13310 training_loss 0.6931471805599453
iteration 2 batch 13320 training_loss 0.6931471805599453
iteration 2 batch 13330 training_loss 0.6916632528527511
iteration 2 batch 13340 training_loss 0.6916632528527511
iteration 2 batch 13350 training_loss 0.6931471805599453
iteration 2 batch 13360 training_loss 0.6931471805599453
iteration 2 batch 13370 training_loss 0.6916632528527511
iteration 2 batch 13380 training_loss 0.6931471805599453
iteration 2 batch 13390 training_loss 0.6931471805599453
iteration 2 batch 13400 training_loss 0.6931471805599453
iteration 2 batch 13410 training_loss 0.6931471805599453
iteration 2 batch 13420 training_loss 0.6931471805599453
iteration 2 batch 13430 training_loss 0.6931471805599453
iteration 2 batch 13440 training_loss 0.6931471805599453
iteration 2 batch 13450 training_loss 0.6931471805599453
iteration 2 batch 13460 training_loss 0.6916632528527511
iteration 2 batch 13470 training_loss 0.6931471805599453
iteration 2 batch 13480 training_loss 0.6931471805599453
iteration 2 batch 13490 training_loss 0.6931471805599453
iteration 2 batch 13500 training_loss 0.6931471805599453
iteration 2 batch 13510 training_loss 0.6931471805599453
iteration 2 batch 13520 training_loss 0.6931471805599453
iteration 2 batch 13530 training_loss 0.6931471805599453
iteration 2 batch 13540 training_loss 0.6931471805599453
iteration 2 batch 13550 training_loss 0.6931471805599453
iteration 2 batch 13560 training_loss 0.6931471805599453
iteration 2 batch 13570 training_loss 0.6916632528527511
iteration 2 batch 13580 training_loss 0.6931471805599453
iteration 2 batch 13590 training_loss 0.6931471805599453
iteration 2 batch 13600 training_loss 0.6931471805599453
iteration 2 batch 13610 training_loss 0.6931471805599453
iteration 2 batch 13620 training_loss 0.6916632528527511
iteration 2 batch 13630 training_loss 0.6931471805599453
iteration 2 batch 13640 training_loss 0.6931471805599453
iteration 2 batch 13650 training_loss 0.6931471805599453
iteration 2 batch 13660 training_loss 0.6931471805599453
iteration 2 batch 13670 training_loss 0.6931471805599453
iteration 2 batch 13680 training_loss 0.6931471805599453
iteration 2 batch 13690 training_loss 0.6931471805599453
iteration 2 batch 13700 training_loss 0.6931471805599453
iteration 2 batch 13710 training_loss 0.6931471805599453
iteration 2 batch 13720 training_loss 0.6916632528527511
iteration 2 batch 13730 training_loss 0.6931471805599453
iteration 2 batch 13740 training_loss 0.6931471805599453
iteration 2 batch 13750 training_loss 0.6931471805599453
iteration 2 batch 13760 training_loss 0.6931471805599453
iteration 2 batch 13770 training_loss 0.6931471805599453
iteration 2 batch 13780 training_loss 0.6931471805599453
iteration 2 batch 13790 training_loss 0.6931471805599453
iteration 2 batch 13800 training_loss 0.6931471805599453
iteration 2 batch 13810 training_loss 0.6931471805599453
iteration 2 batch 13820 training_loss 0.6931471805599453
iteration 2 batch 13830 training_loss 0.6931471805599453
iteration 2 batch 13840 training_loss 0.6931471805599453
iteration 2 batch 13850 training_loss 0.6931471805599453
iteration 2 batch 13860 training_loss 0.6931471805599453
iteration 2 batch 13870 training_loss 0.6931471805599453
iteration 2 batch 13880 training_loss 0.6916632528527511
iteration 2 batch 13890 training_loss 0.6931471805599453
iteration 2 batch 13900 training_loss 0.6916632528527511
iteration 2 batch 13910 training_loss 0.6931471805599453
iteration 2 batch 13920 training_loss 0.6931471805599453
iteration 2 batch 13930 training_loss 0.6931471805599453
iteration 2 batch 13940 training_loss 0.6931471805599453
iteration 2 batch 13950 training_loss 0.6931471805599453
iteration 2 batch 13960 training_loss 0.6931471805599453
iteration 2 batch 13970 training_loss 0.6931471805599453
iteration 2 batch 13980 training_loss 0.6931471805599453
iteration 2 batch 13990 training_loss 0.6916632528527511
iteration 2 batch 14000 training_loss 0.6931471805599453
iteration 2 batch 14010 training_loss 0.6931471805599453
iteration 2 batch 14020 training_loss 0.6931471805599453
iteration 2 batch 14030 training_loss 0.6931471805599453
iteration 2 batch 14040 training_loss 0.6931471805599453
iteration 2 batch 14050 training_loss 0.6931471805599453
iteration 2 batch 14060 training_loss 0.6931471805599453
iteration 2 batch 14070 training_loss 0.6931471805599453
iteration 2 batch 14080 training_loss 0.6931471805599453
iteration 2 batch 14090 training_loss 0.6931471805599453
iteration 2 batch 14100 training_loss 0.6931471805599453
iteration 2 batch 14110 training_loss 0.6931471805599453
iteration 2 batch 14120 training_loss 0.6931471805599453
iteration 2 batch 14130 training_loss 0.6931471805599453
iteration 2 batch 14140 training_loss 0.6931471805599453
iteration 2 batch 14150 training_loss 0.6931471805599453
iteration 2 batch 14160 training_loss 0.6931471805599453
iteration 2 batch 14170 training_loss 0.6931471805599453
iteration 2 batch 14180 training_loss 0.6931471805599453
iteration 2 batch 14190 training_loss 0.6931471805599453
iteration 2 batch 14200 training_loss 0.6931471805599453
iteration 2 batch 14210 training_loss 0.6931471805599453
iteration 2 batch 14220 training_loss 0.6931471805599453
iteration 2 batch 14230 training_loss 0.6931471805599453
iteration 2 batch 14240 training_loss 0.6931471805599453
iteration 2 batch 14250 training_loss 0.6931471805599453
iteration 2 batch 14260 training_loss 0.6931471805599453
iteration 2 batch 14270 training_loss 0.6931471805599453
iteration 2 batch 14280 training_loss 0.6931471805599453
iteration 2 batch 14290 training_loss 0.6931471805599453
iteration 2 batch 14300 training_loss 0.6931471805599453
iteration 2 batch 14310 training_loss 0.6931471805599453
iteration 2 batch 14320 training_loss 0.6931471805599453
iteration 2 batch 14330 training_loss 0.6931471805599453
iteration 2 batch 14340 training_loss 0.6931471805599453
iteration 2 batch 14350 training_loss 0.6931471805599453
iteration 2 batch 14360 training_loss 0.6931471805599453
iteration 2 batch 14370 training_loss 0.6931471805599453
iteration 2 batch 14380 training_loss 0.6931471805599453
iteration 2 batch 14390 training_loss 0.6931471805599453
iteration 2 batch 14400 training_loss 0.6931471805599453
iteration 2 batch 14410 training_loss 0.6931471805599453
iteration 2 batch 14420 training_loss 0.6931471805599453
iteration 2 batch 14430 training_loss 0.6931471805599453
iteration 2 batch 14440 training_loss 0.6931471805599453
iteration 2 batch 14450 training_loss 0.6916632528527511
iteration 2 batch 14460 training_loss 0.6931471805599453
iteration 2 batch 14470 training_loss 0.6931471805599453
iteration 2 batch 14480 training_loss 0.6916632528527511
iteration 2 batch 14490 training_loss 0.6916632528527511
iteration 2 batch 14500 training_loss 0.6931471805599453
iteration 2 batch 14510 training_loss 0.6931471805599453
iteration 2 batch 14520 training_loss 0.6931471805599453
iteration 2 batch 14530 training_loss 0.6931471805599453
iteration 2 batch 14540 training_loss 0.6931471805599453
iteration 2 batch 14550 training_loss 0.6931471805599453
iteration 2 batch 14560 training_loss 0.6931471805599453
iteration 2 batch 14570 training_loss 0.6931471805599453
iteration 2 batch 14580 training_loss 0.6931471805599453
iteration 2 batch 14590 training_loss 0.6931471805599453
iteration 2 batch 14600 training_loss 0.6916632528527511
iteration 2 batch 14610 training_loss 0.6931471805599453
iteration 2 batch 14620 training_loss 0.6931471805599453
iteration 2 batch 14630 training_loss 0.6931471805599453
iteration 2 batch 14640 training_loss 0.6931471805599453
iteration 2 batch 14650 training_loss 0.6931471805599453
iteration 2 batch 14660 training_loss 0.6931471805599453
iteration 2 batch 14670 training_loss 0.6931471805599453
iteration 2 batch 14680 training_loss 0.6931471805599453
iteration 2 batch 14690 training_loss 0.6916632528527511
iteration 2 batch 14700 training_loss 0.6931471805599453
iteration 2 batch 14710 training_loss 0.6931471805599453
iteration 2 batch 14720 training_loss 0.6931471805599453
iteration 2 batch 14730 training_loss 0.6916632528527511
iteration 2 batch 14740 training_loss 0.6916632528527511
iteration 2 batch 14750 training_loss 0.6931471805599453
iteration 2 batch 14760 training_loss 0.6931471805599453
iteration 2 batch 14770 training_loss 0.6931471805599453
iteration 2 batch 14780 training_loss 0.6931471805599453
iteration 2 batch 14790 training_loss 0.6916632528527511
iteration 2 batch 14800 training_loss 0.6931471805599453
iteration 2 batch 14810 training_loss 0.6931471805599453
iteration 2 batch 14820 training_loss 0.6931471805599453
iteration 2 batch 14830 training_loss 0.6916632528527511
iteration 2 batch 14840 training_loss 0.6931471805599453
iteration 2 batch 14850 training_loss 0.6916632528527511
iteration 2 batch 14860 training_loss 0.6916632528527511
iteration 2 batch 14870 training_loss 0.6931471805599453
iteration 2 batch 14880 training_loss 0.6916632528527511
iteration 2 batch 14890 training_loss 0.6931471805599453
iteration 2 batch 14900 training_loss 0.6931471805599453
iteration 2 batch 14910 training_loss 0.6931471805599453
iteration 2 batch 14920 training_loss 0.6931471805599453
iteration 2 batch 14930 training_loss 0.6916632528527511
iteration 2 batch 14940 training_loss 0.6931471805599453
iteration 2 batch 14950 training_loss 0.6931471805599453
iteration 2 batch 14960 training_loss 0.6931471805599453
iteration 2 batch 14970 training_loss 0.6916632528527511
iteration 2 batch 14980 training_loss 0.6931471805599453
iteration 2 batch 14990 training_loss 0.6931471805599453
iteration 2 batch 15000 training_loss 0.6931471805599453
iteration 2 batch 15010 training_loss 0.6916632528527511
iteration 2 batch 15020 training_loss 0.6931471805599453
iteration 2 batch 15030 training_loss 0.6931471805599453
iteration 2 batch 15040 training_loss 0.6931471805599453
iteration 2 batch 15050 training_loss 0.6931471805599453
iteration 2 batch 15060 training_loss 0.6931471805599453
iteration 2 batch 15070 training_loss 0.6931471805599453
iteration 2 batch 15080 training_loss 0.6931471805599453
iteration 2 batch 15090 training_loss 0.6931471805599453
iteration 2 batch 15100 training_loss 0.6931471805599453
iteration 2 batch 15110 training_loss 0.6931471805599453
iteration 2 batch 15120 training_loss 0.6931471805599453
iteration 2 batch 15130 training_loss 0.6931471805599453
iteration 2 batch 15140 training_loss 0.6916632528527511
iteration 2 batch 15150 training_loss 0.6931471805599453
iteration 2 batch 15160 training_loss 0.6931471805599453
iteration 2 batch 15170 training_loss 0.6931471805599453
iteration 2 batch 15180 training_loss 0.6931471805599453
iteration 2 batch 15190 training_loss 0.6931471805599453
iteration 2 batch 15200 training_loss 0.6931471805599453
iteration 2 batch 15210 training_loss 0.6931471805599453
iteration 2 batch 15220 training_loss 0.6931471805599453
iteration 2 batch 15230 training_loss 0.6931471805599453
iteration 2 batch 15240 training_loss 0.6931471805599453
iteration 2 batch 15250 training_loss 0.6931471805599453
iteration 2 batch 15260 training_loss 0.6931471805599453
iteration 2 batch 15270 training_loss 0.6931471805599453
iteration 2 batch 15280 training_loss 0.6931471805599453
iteration 2 batch 15290 training_loss 0.6931471805599453
iteration 2 batch 15300 training_loss 0.6931471805599453
iteration 2 batch 15310 training_loss 0.6931471805599453
iteration 2 batch 15320 training_loss 0.6931471805599453
iteration 2 batch 15330 training_loss 0.6916632528527511
iteration 2 batch 15340 training_loss 0.6916632528527511
iteration 2 batch 15350 training_loss 0.6931471805599453
iteration 2 batch 15360 training_loss 0.6931471805599453
iteration 2 batch 15370 training_loss 0.6931471805599453
iteration 2 batch 15380 training_loss 0.6931471805599453
iteration 2 batch 15390 training_loss 0.6931471805599453
iteration 2 batch 15400 training_loss 0.6916632528527511
iteration 2 batch 15410 training_loss 0.6931471805599453
iteration 2 batch 15420 training_loss 0.6931471805599453
iteration 2 batch 15430 training_loss 0.6931471805599453
iteration 2 batch 15440 training_loss 0.6931471805599453
iteration 2 batch 15450 training_loss 0.6931471805599453
iteration 2 batch 15460 training_loss 0.6931471805599453
iteration 2 batch 15470 training_loss 0.6931471805599453
iteration 2 batch 15480 training_loss 0.6931471805599453
iteration 2 batch 15490 training_loss 0.6931471805599453
iteration 2 batch 15500 training_loss 0.6931471805599453
iteration 2 batch 15510 training_loss 0.6916632528527511
iteration 2 batch 15520 training_loss 0.6931471805599453
iteration 2 batch 15530 training_loss 0.6931471805599453
iteration 2 batch 15540 training_loss 0.6931471805599453
iteration 2 batch 15550 training_loss 0.6931471805599453
iteration 2 batch 15560 training_loss 0.6931471805599453
iteration 2 batch 15570 training_loss 0.6931471805599453
iteration 2 batch 15580 training_loss 0.6931471805599453
iteration 2 batch 15590 training_loss 0.6916632528527511
iteration 2 batch 15600 training_loss 0.6931471805599453
iteration 2 batch 15610 training_loss 0.6931471805599453
iteration 2 batch 15620 training_loss 0.6931471805599453
iteration 2 batch 15630 training_loss 0.6931471805599453
iteration 2 batch 15640 training_loss 0.6931471805599453
iteration 2 batch 15650 training_loss 0.6931471805599453
iteration 2 batch 15660 training_loss 0.6931471805599453
iteration 2 batch 15670 training_loss 0.6931471805599453
iteration 2 batch 15680 training_loss 0.6931471805599453
iteration 2 batch 15690 training_loss 0.6916632528527511
iteration 2 batch 15700 training_loss 0.6931471805599453
iteration 2 batch 15710 training_loss 0.6931471805599453
iteration 2 batch 15720 training_loss 0.6931471805599453
iteration 2 batch 15730 training_loss 0.6931471805599453
iteration 2 batch 15740 training_loss 0.6931471805599453
iteration 2 batch 15750 training_loss 0.6931471805599453
iteration 2 batch 15760 training_loss 0.6931471805599453
iteration 2 batch 15770 training_loss 0.6931471805599453
iteration 2 batch 15780 training_loss 0.6931471805599453
iteration 2 batch 15790 training_loss 0.6931471805599453
iteration 2 batch 15800 training_loss 0.6931471805599453
iteration 2 batch 15810 training_loss 0.6931471805599453
iteration 2 batch 15820 training_loss 0.6931471805599453
iteration 2 batch 15830 training_loss 0.6931471805599453
iteration 2 batch 15840 training_loss 0.6916632528527511
iteration 2 batch 15850 training_loss 0.6931471805599453
iteration 2 batch 15860 training_loss 0.6931471805599453
iteration 2 batch 15870 training_loss 0.6931471805599453
iteration 2 batch 15880 training_loss 0.6931471805599453
iteration 2 batch 15890 training_loss 0.6931471805599453
iteration 2 batch 15900 training_loss 0.6931471805599453
iteration 2 batch 15910 training_loss 0.6931471805599453
iteration 2 batch 15920 training_loss 0.6931471805599453
iteration 2 batch 15930 training_loss 0.6931471805599453
iteration 2 batch 15940 training_loss 0.6931471805599453
iteration 2 batch 15950 training_loss 0.6916632528527511
iteration 2 batch 15960 training_loss 0.6916632528527511
iteration 2 batch 15970 training_loss 0.6931471805599453
iteration 2 batch 15980 training_loss 0.6931471805599453
iteration 2 batch 15990 training_loss 0.6916632528527511
iteration 2 batch 16000 training_loss 0.6931471805599453
iteration 2 batch 16010 training_loss 0.6931471805599453
iteration 2 batch 16020 training_loss 0.6931471805599453
iteration 2 batch 16030 training_loss 0.6931471805599453
iteration 2 batch 16040 training_loss 0.6931471805599453
iteration 2 batch 16050 training_loss 0.6931471805599453
iteration 2 batch 16060 training_loss 0.6931471805599453
iteration 2 batch 16070 training_loss 0.6931471805599453
iteration 2 batch 16080 training_loss 0.6931471805599453
iteration 2 batch 16090 training_loss 0.6916632528527511
iteration 2 batch 16100 training_loss 0.6931471805599453
iteration 2 batch 16110 training_loss 0.6931471805599453
iteration 2 batch 16120 training_loss 0.6931471805599453
iteration 2 batch 16130 training_loss 0.6931471805599453
iteration 2 batch 16140 training_loss 0.6916632528527511
iteration 2 batch 16150 training_loss 0.6931471805599453
iteration 2 batch 16160 training_loss 0.6931471805599453
iteration 2 batch 16170 training_loss 0.6931471805599453
iteration 2 batch 16180 training_loss 0.6916632528527511
iteration 2 batch 16190 training_loss 0.6931471805599453
iteration 2 batch 16200 training_loss 0.6931471805599453
iteration 2 batch 16210 training_loss 0.6931471805599453
iteration 2 batch 16220 training_loss 0.6931471805599453
iteration 2 batch 16230 training_loss 0.6916632528527511
iteration 2 batch 16240 training_loss 0.6931471805599453
iteration 2 batch 16250 training_loss 0.6931471805599453
iteration 2 batch 16260 training_loss 0.6931471805599453
iteration 2 batch 16270 training_loss 0.6931471805599453
iteration 2 batch 16280 training_loss 0.6916632528527511
iteration 2 batch 16290 training_loss 0.6931471805599453
iteration 2 batch 16300 training_loss 0.6901793251455568
iteration 2 batch 16310 training_loss 0.6916632528527511
iteration 2 batch 16320 training_loss 0.6931471805599453
iteration 2 batch 16330 training_loss 0.6931471805599453
iteration 2 batch 16340 training_loss 0.6931471805599453
iteration 2 batch 16350 training_loss 0.6931471805599453
iteration 2 batch 16360 training_loss 0.6931471805599453
iteration 2 batch 16370 training_loss 0.6931471805599453
iteration 2 batch 16380 training_loss 0.6931471805599453
iteration 2 batch 16390 training_loss 0.6931471805599453
iteration 2 batch 16400 training_loss 0.6931471805599453
iteration 2 batch 16410 training_loss 0.6931471805599453
iteration 2 batch 16420 training_loss 0.6931471805599453
iteration 2 batch 16430 training_loss 0.6931471805599453
iteration 2 batch 16440 training_loss 0.6931471805599453
iteration 2 batch 16450 training_loss 0.6931471805599453
iteration 2 batch 16460 training_loss 0.6931471805599453
iteration 2 batch 16470 training_loss 0.6931471805599453
iteration 2 batch 16480 training_loss 0.6931471805599453
iteration 2 batch 16490 training_loss 0.6931471805599453
iteration 2 batch 16500 training_loss 0.6931471805599453
iteration 2 batch 16510 training_loss 0.6931471805599453
iteration 2 batch 16520 training_loss 0.6931471805599453
iteration 2 batch 16530 training_loss 0.6931471805599453
iteration 2 batch 16540 training_loss 0.6931471805599453
iteration 2 batch 16550 training_loss 0.6916632528527511
iteration 2 batch 16560 training_loss 0.6931471805599453
iteration 2 batch 16570 training_loss 0.6931471805599453
iteration 2 batch 16580 training_loss 0.6931471805599453
iteration 2 batch 16590 training_loss 0.6931471805599453
iteration 2 batch 16600 training_loss 0.6931471805599453
iteration 2 batch 16610 training_loss 0.6931471805599453
iteration 2 batch 16620 training_loss 0.6931471805599453
iteration 2 batch 16630 training_loss 0.6931471805599453
iteration 2 batch 16640 training_loss 0.6916632528527511
iteration 2 batch 16650 training_loss 0.6931471805599453
iteration 2 batch 16660 training_loss 0.6931471805599453
iteration 2 batch 16670 training_loss 0.6931471805599453
iteration 2 batch 16680 training_loss 0.6931471805599453
iteration 2 batch 16690 training_loss 0.6931471805599453
iteration 2 batch 16700 training_loss 0.6931471805599453
iteration 2 batch 16710 training_loss 0.6931471805599453
iteration 2 batch 16720 training_loss 0.6931471805599453
iteration 2 batch 16730 training_loss 0.6931471805599453
iteration 2 batch 16740 training_loss 0.6931471805599453
iteration 2 batch 16750 training_loss 0.6931471805599453
iteration 2 batch 16760 training_loss 0.6931471805599453
iteration 2 batch 16770 training_loss 0.6931471805599453
iteration 2 batch 16780 training_loss 0.6931471805599453
iteration 2 batch 16790 training_loss 0.6916632528527511
iteration 2 batch 16800 training_loss 0.6931471805599453
iteration 2 batch 16810 training_loss 0.6931471805599453
iteration 2 batch 16820 training_loss 0.6931471805599453
iteration 2 batch 16830 training_loss 0.6931471805599453
iteration 2 batch 16840 training_loss 0.6931471805599453
iteration 2 batch 16850 training_loss 0.6931471805599453
iteration 2 batch 16860 training_loss 0.6931471805599453
iteration 2 batch 16870 training_loss 0.6931471805599453
iteration 2 batch 16880 training_loss 0.6931471805599453
iteration 2 batch 16890 training_loss 0.6931471805599453
iteration 2 batch 16900 training_loss 0.6931471805599453
iteration 2 batch 16910 training_loss 0.6931471805599453
iteration 2 batch 16920 training_loss 0.6916632528527511
iteration 2 batch 16930 training_loss 0.6931471805599453
iteration 2 batch 16940 training_loss 0.6931471805599453
iteration 2 batch 16950 training_loss 0.6931471805599453
iteration 2 batch 16960 training_loss 0.6931471805599453
iteration 2 batch 16970 training_loss 0.6916632528527511
iteration 2 batch 16980 training_loss 0.6931471805599453
iteration 2 batch 16990 training_loss 0.6931471805599453
iteration 2 batch 17000 training_loss 0.6931471805599453
iteration 2 batch 17010 training_loss 0.6931471805599453
iteration 2 batch 17020 training_loss 0.6931471805599453
iteration 2 batch 17030 training_loss 0.6931471805599453
iteration 2 batch 17040 training_loss 0.6931471805599453
iteration 2 batch 17050 training_loss 0.6931471805599453
iteration 2 batch 17060 training_loss 0.6931471805599453
iteration 2 batch 17070 training_loss 0.6931471805599453
iteration 2 batch 17080 training_loss 0.6931471805599453
iteration 2 batch 17090 training_loss 0.6931471805599453
iteration 2 batch 17100 training_loss 0.6931471805599453
iteration 2 batch 17110 training_loss 0.6901793251455568
iteration 2 batch 17120 training_loss 0.6931471805599453
iteration 2 batch 17130 training_loss 0.6931471805599453
iteration 2 batch 17140 training_loss 0.6931471805599453
iteration 2 batch 17150 training_loss 0.6931471805599453
iteration 2 batch 17160 training_loss 0.6931471805599453
iteration 2 batch 17170 training_loss 0.6931471805599453
iteration 2 batch 17180 training_loss 0.6931471805599453
iteration 2 batch 17190 training_loss 0.6916632528527511
iteration 2 batch 17200 training_loss 0.6931471805599453
iteration 2 batch 17210 training_loss 0.6931471805599453
iteration 2 batch 17220 training_loss 0.6931471805599453
iteration 2 batch 17230 training_loss 0.6931471805599453
iteration 2 batch 17240 training_loss 0.6931471805599453
iteration 2 batch 17250 training_loss 0.6931471805599453
iteration 2 batch 17260 training_loss 0.6931471805599453
iteration 2 batch 17270 training_loss 0.6931471805599453
iteration 2 batch 17280 training_loss 0.6931471805599453
iteration 2 batch 17290 training_loss 0.6916632528527511
iteration 2 batch 17300 training_loss 0.6931471805599453
iteration 2 batch 17310 training_loss 0.6931471805599453
iteration 2 batch 17320 training_loss 0.6931471805599453
iteration 2 batch 17330 training_loss 0.6931471805599453
iteration 2 batch 17340 training_loss 0.6931471805599453
iteration 2 batch 17350 training_loss 0.6931471805599453
iteration 2 batch 17360 training_loss 0.6931471805599453
iteration 2 batch 17370 training_loss 0.6931471805599453
iteration 2 batch 17380 training_loss 0.6931471805599453
iteration 2 batch 17390 training_loss 0.6931471805599453
iteration 2 batch 17400 training_loss 0.6931471805599453
iteration 2 batch 17410 training_loss 0.6931471805599453
iteration 2 batch 17420 training_loss 0.6931471805599453
iteration 2 batch 17430 training_loss 0.6931471805599453
iteration 2 batch 17440 training_loss 0.6931471805599453
iteration 2 batch 17450 training_loss 0.6931471805599453
iteration 2 batch 17460 training_loss 0.6931471805599453
iteration 2 batch 17470 training_loss 0.6931471805599453
iteration 2 batch 17480 training_loss 0.6931471805599453
iteration 2 batch 17490 training_loss 0.6931471805599453
iteration 2 batch 17500 training_loss 0.6931471805599453
iteration 2 batch 17510 training_loss 0.6931471805599453
iteration 2 batch 17520 training_loss 0.6931471805599453
iteration 2 batch 17530 training_loss 0.6931471805599453
iteration 2 batch 17540 training_loss 0.6931471805599453
iteration 2 batch 17550 training_loss 0.6931471805599453
iteration 2 batch 17560 training_loss 0.6931471805599453
iteration 2 batch 17570 training_loss 0.6931471805599453
iteration 2 batch 17580 training_loss 0.6931471805599453
iteration 2 batch 17590 training_loss 0.6931471805599453
iteration 2 batch 17600 training_loss 0.6931471805599453
iteration 2 batch 17610 training_loss 0.6931471805599453
iteration 2 batch 17620 training_loss 0.6931471805599453
iteration 2 batch 17630 training_loss 0.6931471805599453
iteration 2 batch 17640 training_loss 0.6931471805599453
iteration 2 batch 17650 training_loss 0.6931471805599453
iteration 2 batch 17660 training_loss 0.6931471805599453
iteration 2 batch 17670 training_loss 0.6916632528527511
iteration 2 batch 17680 training_loss 0.6931471805599453
iteration 2 batch 17690 training_loss 0.6931471805599453
iteration 2 batch 17700 training_loss 0.6931471805599453
iteration 2 batch 17710 training_loss 0.6916632528527511
iteration 2 batch 17720 training_loss 0.6931471805599453
iteration 2 batch 17730 training_loss 0.6931471805599453
iteration 2 batch 17740 training_loss 0.6931471805599453
iteration 2 batch 17750 training_loss 0.6931471805599453
iteration 2 batch 17760 training_loss 0.6931471805599453
iteration 2 batch 17770 training_loss 0.6916632528527511
iteration 2 batch 17780 training_loss 0.6931471805599453
iteration 2 batch 17790 training_loss 0.6931471805599453
iteration 2 batch 17800 training_loss 0.6931471805599453
iteration 2 batch 17810 training_loss 0.6931471805599453
iteration 2 batch 17820 training_loss 0.6931471805599453
iteration 2 batch 17830 training_loss 0.6931471805599453
iteration 2 batch 17840 training_loss 0.6931471805599453
iteration 2 batch 17850 training_loss 0.6931471805599453
iteration 2 batch 17860 training_loss 0.6931471805599453
iteration 2 batch 17870 training_loss 0.6916632528527511
iteration 2 batch 17880 training_loss 0.6931471805599453
iteration 2 batch 17890 training_loss 0.6931471805599453
iteration 2 batch 17900 training_loss 0.6931471805599453
iteration 2 batch 17910 training_loss 0.6931471805599453
iteration 2 batch 17920 training_loss 0.6916632528527511
iteration 2 batch 17930 training_loss 0.6931471805599453
iteration 2 batch 17940 training_loss 0.6931471805599453
iteration 2 batch 17950 training_loss 0.6916632528527511
iteration 2 batch 17960 training_loss 0.6916632528527511
iteration 2 batch 17970 training_loss 0.6931471805599453
iteration 2 batch 17980 training_loss 0.6931471805599453
iteration 2 batch 17990 training_loss 0.6931471805599453
iteration 2 batch 18000 training_loss 0.6931471805599453
iteration 2 batch 18010 training_loss 0.6931471805599453
iteration 2 batch 18020 training_loss 0.6931471805599453
iteration 2 batch 18030 training_loss 0.6931471805599453
iteration 2 batch 18040 training_loss 0.6931471805599453
iteration 2 batch 18050 training_loss 0.6931471805599453
iteration 2 batch 18060 training_loss 0.6931471805599453
iteration 2 batch 18070 training_loss 0.6931471805599453
iteration 2 batch 18080 training_loss 0.6931471805599453
iteration 2 batch 18090 training_loss 0.6931471805599453
iteration 2 batch 18100 training_loss 0.6931471805599453
iteration 2 batch 18110 training_loss 0.6931471805599453
iteration 2 batch 18120 training_loss 0.6931471805599453
iteration 2 batch 18130 training_loss 0.6931471805599453
iteration 2 batch 18140 training_loss 0.6931471805599453
iteration 2 batch 18150 training_loss 0.6916632528527511
iteration 2 batch 18160 training_loss 0.6931471805599453
iteration 2 batch 18170 training_loss 0.6931471805599453
iteration 2 batch 18180 training_loss 0.6931471805599453
iteration 2 batch 18190 training_loss 0.6931471805599453
iteration 2 batch 18200 training_loss 0.6916632528527511
iteration 2 batch 18210 training_loss 0.6916632528527511
iteration 2 batch 18220 training_loss 0.6931471805599453
iteration 2 batch 18230 training_loss 0.6931471805599453
iteration 2 batch 18240 training_loss 0.6931471805599453
iteration 2 batch 18250 training_loss 0.6931471805599453
iteration 2 batch 18260 training_loss 0.6931471805599453
iteration 2 batch 18270 training_loss 0.6931471805599453
iteration 2 batch 18280 training_loss 0.6931471805599453
iteration 2 batch 18290 training_loss 0.6931471805599453
iteration 2 batch 18300 training_loss 0.6931471805599453
iteration 2 batch 18310 training_loss 0.6931471805599453
iteration 2 batch 18320 training_loss 0.6931471805599453
iteration 2 batch 18330 training_loss 0.6931471805599453
iteration 2 batch 18340 training_loss 0.6931471805599453
iteration 2 batch 18350 training_loss 0.6931471805599453
iteration 2 batch 18360 training_loss 0.6931471805599453
iteration 2 batch 18370 training_loss 0.6931471805599453
iteration 2 batch 18380 training_loss 0.6931471805599453
iteration 2 batch 18390 training_loss 0.6916632528527511
iteration 2 batch 18400 training_loss 0.6931471805599453
iteration 2 batch 18410 training_loss 0.6931471805599453
iteration 2 batch 18420 training_loss 0.6931471805599453
iteration 2 batch 18430 training_loss 0.6931471805599453
iteration 2 batch 18440 training_loss 0.6931471805599453
iteration 2 batch 18450 training_loss 0.6931471805599453
iteration 2 batch 18460 training_loss 0.6916632528527511
iteration 2 batch 18470 training_loss 0.6931471805599453
iteration 2 batch 18480 training_loss 0.6931471805599453
iteration 2 batch 18490 training_loss 0.6931471805599453
iteration 2 batch 18500 training_loss 0.6931471805599453
iteration 2 batch 18510 training_loss 0.6916632528527511
iteration 2 batch 18520 training_loss 0.6931471805599453
iteration 2 batch 18530 training_loss 0.6916632528527511
iteration 2 batch 18540 training_loss 0.6931471805599453
iteration 2 batch 18550 training_loss 0.6931471805599453
iteration 2 batch 18560 training_loss 0.6931471805599453
iteration 2 batch 18570 training_loss 0.6931471805599453
iteration 2 batch 18580 training_loss 0.6931471805599453
iteration 2 batch 18590 training_loss 0.6931471805599453
iteration 2 batch 18600 training_loss 0.6916632528527511
iteration 2 batch 18610 training_loss 0.6931471805599453
iteration 3 batch 0 training_loss 0.6916632528527511
iteration 3 batch 10 training_loss 0.6931471805599453
iteration 3 batch 20 training_loss 0.6931471805599453
iteration 3 batch 30 training_loss 0.6931471805599453
iteration 3 batch 40 training_loss 0.6931471805599453
iteration 3 batch 50 training_loss 0.6931471805599453
iteration 3 batch 60 training_loss 0.6931471805599453
iteration 3 batch 70 training_loss 0.6931471805599453
iteration 3 batch 80 training_loss 0.6916632528527511
iteration 3 batch 90 training_loss 0.6931471805599453
iteration 3 batch 100 training_loss 0.6931471805599453
iteration 3 batch 110 training_loss 0.6931471805599453
iteration 3 batch 120 training_loss 0.6931471805599453
iteration 3 batch 130 training_loss 0.6931471805599453
iteration 3 batch 140 training_loss 0.6931471805599453
iteration 3 batch 150 training_loss 0.6931471805599453
iteration 3 batch 160 training_loss 0.6931471805599453
iteration 3 batch 170 training_loss 0.6931471805599453
iteration 3 batch 180 training_loss 0.6931471805599453
iteration 3 batch 190 training_loss 0.6931471805599453
iteration 3 batch 200 training_loss 0.6916632528527511
iteration 3 batch 210 training_loss 0.6931471805599453
iteration 3 batch 220 training_loss 0.6931471805599453
iteration 3 batch 230 training_loss 0.6931471805599453
iteration 3 batch 240 training_loss 0.6931471805599453
iteration 3 batch 250 training_loss 0.6931471805599453
iteration 3 batch 260 training_loss 0.6931471805599453
iteration 3 batch 270 training_loss 0.6931471805599453
iteration 3 batch 280 training_loss 0.6931471805599453
iteration 3 batch 290 training_loss 0.6931471805599453
iteration 3 batch 300 training_loss 0.6931471805599453
iteration 3 batch 310 training_loss 0.6931471805599453
iteration 3 batch 320 training_loss 0.6901793251455568
iteration 3 batch 330 training_loss 0.6931471805599453
iteration 3 batch 340 training_loss 0.6931471805599453
iteration 3 batch 350 training_loss 0.6931471805599453
iteration 3 batch 360 training_loss 0.6931471805599453
iteration 3 batch 370 training_loss 0.6916632528527511
iteration 3 batch 380 training_loss 0.6931471805599453
iteration 3 batch 390 training_loss 0.6931471805599453
iteration 3 batch 400 training_loss 0.6931471805599453
iteration 3 batch 410 training_loss 0.6931471805599453
iteration 3 batch 420 training_loss 0.6931471805599453
iteration 3 batch 430 training_loss 0.6916632528527511
iteration 3 batch 440 training_loss 0.6931471805599453
iteration 3 batch 450 training_loss 0.6931471805599453
iteration 3 batch 460 training_loss 0.6931471805599453
iteration 3 batch 470 training_loss 0.6931471805599453
iteration 3 batch 480 training_loss 0.6931471805599453
iteration 3 batch 490 training_loss 0.6931471805599453
iteration 3 batch 500 training_loss 0.6931471805599453
iteration 3 batch 510 training_loss 0.6916632528527511
iteration 3 batch 520 training_loss 0.6916632528527511
iteration 3 batch 530 training_loss 0.6931471805599453
iteration 3 batch 540 training_loss 0.6931471805599453
iteration 3 batch 550 training_loss 0.6931471805599453
iteration 3 batch 560 training_loss 0.6931471805599453
iteration 3 batch 570 training_loss 0.6931471805599453
iteration 3 batch 580 training_loss 0.6931471805599453
iteration 3 batch 590 training_loss 0.6931471805599453
iteration 3 batch 600 training_loss 0.6931471805599453
iteration 3 batch 610 training_loss 0.6916632528527511
iteration 3 batch 620 training_loss 0.6931471805599453
iteration 3 batch 630 training_loss 0.6931471805599453
iteration 3 batch 640 training_loss 0.6931471805599453
iteration 3 batch 650 training_loss 0.6931471805599453
iteration 3 batch 660 training_loss 0.6916632528527511
iteration 3 batch 670 training_loss 0.6931471805599453
iteration 3 batch 680 training_loss 0.6931471805599453
iteration 3 batch 690 training_loss 0.6931471805599453
iteration 3 batch 700 training_loss 0.6931471805599453
iteration 3 batch 710 training_loss 0.6931471805599453
iteration 3 batch 720 training_loss 0.6931471805599453
iteration 3 batch 730 training_loss 0.6931471805599453
iteration 3 batch 740 training_loss 0.6931471805599453
iteration 3 batch 750 training_loss 0.6931471805599453
iteration 3 batch 760 training_loss 0.6931471805599453
iteration 3 batch 770 training_loss 0.6931471805599453
iteration 3 batch 780 training_loss 0.6931471805599453
iteration 3 batch 790 training_loss 0.6931471805599453
iteration 3 batch 800 training_loss 0.6931471805599453
iteration 3 batch 810 training_loss 0.6931471805599453
iteration 3 batch 820 training_loss 0.6931471805599453
iteration 3 batch 830 training_loss 0.6931471805599453
iteration 3 batch 840 training_loss 0.6931471805599453
iteration 3 batch 850 training_loss 0.6931471805599453
iteration 3 batch 860 training_loss 0.6931471805599453
iteration 3 batch 870 training_loss 0.6931471805599453
iteration 3 batch 880 training_loss 0.6931471805599453
iteration 3 batch 890 training_loss 0.6931471805599453
iteration 3 batch 900 training_loss 0.6931471805599453
iteration 3 batch 910 training_loss 0.6916632528527511
iteration 3 batch 920 training_loss 0.6931471805599453
iteration 3 batch 930 training_loss 0.6931471805599453
iteration 3 batch 940 training_loss 0.6931471805599453
iteration 3 batch 950 training_loss 0.6931471805599453
iteration 3 batch 960 training_loss 0.6931471805599453
iteration 3 batch 970 training_loss 0.6931471805599453
iteration 3 batch 980 training_loss 0.6931471805599453
iteration 3 batch 990 training_loss 0.6931471805599453
iteration 3 batch 1000 training_loss 0.6931471805599453
iteration 3 batch 1010 training_loss 0.6931471805599453
iteration 3 batch 1020 training_loss 0.6931471805599453
iteration 3 batch 1030 training_loss 0.6931471805599453
iteration 3 batch 1040 training_loss 0.6916632528527511
iteration 3 batch 1050 training_loss 0.6931471805599453
iteration 3 batch 1060 training_loss 0.6931471805599453
iteration 3 batch 1070 training_loss 0.6931471805599453
iteration 3 batch 1080 training_loss 0.6931471805599453
iteration 3 batch 1090 training_loss 0.6916632528527511
iteration 3 batch 1100 training_loss 0.6931471805599453
iteration 3 batch 1110 training_loss 0.6931471805599453
iteration 3 batch 1120 training_loss 0.6931471805599453
iteration 3 batch 1130 training_loss 0.6931471805599453
iteration 3 batch 1140 training_loss 0.6931471805599453
iteration 3 batch 1150 training_loss 0.6931471805599453
iteration 3 batch 1160 training_loss 0.6931471805599453
iteration 3 batch 1170 training_loss 0.6931471805599453
iteration 3 batch 1180 training_loss 0.6931471805599453
iteration 3 batch 1190 training_loss 0.6931471805599453
iteration 3 batch 1200 training_loss 0.6931471805599453
iteration 3 batch 1210 training_loss 0.6901793251455568
iteration 3 batch 1220 training_loss 0.6931471805599453
iteration 3 batch 1230 training_loss 0.6916632528527511
iteration 3 batch 1240 training_loss 0.6931471805599453
iteration 3 batch 1250 training_loss 0.6931471805599453
iteration 3 batch 1260 training_loss 0.6931471805599453
iteration 3 batch 1270 training_loss 0.6931471805599453
iteration 3 batch 1280 training_loss 0.6916632528527511
iteration 3 batch 1290 training_loss 0.6931471805599453
iteration 3 batch 1300 training_loss 0.6931471805599453
iteration 3 batch 1310 training_loss 0.6931471805599453
iteration 3 batch 1320 training_loss 0.6931471805599453
iteration 3 batch 1330 training_loss 0.6931471805599453
iteration 3 batch 1340 training_loss 0.6931471805599453
iteration 3 batch 1350 training_loss 0.6931471805599453
iteration 3 batch 1360 training_loss 0.6931471805599453
iteration 3 batch 1370 training_loss 0.6916632528527511
iteration 3 batch 1380 training_loss 0.6931471805599453
iteration 3 batch 1390 training_loss 0.6916632528527511
iteration 3 batch 1400 training_loss 0.6931471805599453
iteration 3 batch 1410 training_loss 0.6931471805599453
iteration 3 batch 1420 training_loss 0.6931471805599453
iteration 3 batch 1430 training_loss 0.6931471805599453
iteration 3 batch 1440 training_loss 0.6931471805599453
iteration 3 batch 1450 training_loss 0.6931471805599453
iteration 3 batch 1460 training_loss 0.6931471805599453
iteration 3 batch 1470 training_loss 0.6916632528527511
iteration 3 batch 1480 training_loss 0.6931471805599453
iteration 3 batch 1490 training_loss 0.6931471805599453
iteration 3 batch 1500 training_loss 0.6931471805599453
iteration 3 batch 1510 training_loss 0.6931471805599453
iteration 3 batch 1520 training_loss 0.6931471805599453
iteration 3 batch 1530 training_loss 0.6931471805599453
iteration 3 batch 1540 training_loss 0.6916632528527511
iteration 3 batch 1550 training_loss 0.6931471805599453
iteration 3 batch 1560 training_loss 0.6931471805599453
iteration 3 batch 1570 training_loss 0.6931471805599453
iteration 3 batch 1580 training_loss 0.6916632528527511
iteration 3 batch 1590 training_loss 0.6931471805599453
iteration 3 batch 1600 training_loss 0.6931471805599453
iteration 3 batch 1610 training_loss 0.6931471805599453
iteration 3 batch 1620 training_loss 0.6931471805599453
iteration 3 batch 1630 training_loss 0.6931471805599453
iteration 3 batch 1640 training_loss 0.6931471805599453
iteration 3 batch 1650 training_loss 0.6931471805599453
iteration 3 batch 1660 training_loss 0.6931471805599453
iteration 3 batch 1670 training_loss 0.6931471805599453
iteration 3 batch 1680 training_loss 0.6931471805599453
iteration 3 batch 1690 training_loss 0.6931471805599453
iteration 3 batch 1700 training_loss 0.6931471805599453
iteration 3 batch 1710 training_loss 0.6931471805599453
iteration 3 batch 1720 training_loss 0.6931471805599453
iteration 3 batch 1730 training_loss 0.6931471805599453
iteration 3 batch 1740 training_loss 0.6931471805599453
iteration 3 batch 1750 training_loss 0.6931471805599453
iteration 3 batch 1760 training_loss 0.6931471805599453
iteration 3 batch 1770 training_loss 0.6931471805599453
iteration 3 batch 1780 training_loss 0.6931471805599453
iteration 3 batch 1790 training_loss 0.6931471805599453
iteration 3 batch 1800 training_loss 0.6931471805599453
iteration 3 batch 1810 training_loss 0.6931471805599453
iteration 3 batch 1820 training_loss 0.6931471805599453
iteration 3 batch 1830 training_loss 0.6931471805599453
iteration 3 batch 1840 training_loss 0.6931471805599453
iteration 3 batch 1850 training_loss 0.6931471805599453
iteration 3 batch 1860 training_loss 0.6931471805599453
iteration 3 batch 1870 training_loss 0.6931471805599453
iteration 3 batch 1880 training_loss 0.6931471805599453
iteration 3 batch 1890 training_loss 0.6931471805599453
iteration 3 batch 1900 training_loss 0.6931471805599453
iteration 3 batch 1910 training_loss 0.6931471805599453
iteration 3 batch 1920 training_loss 0.6931471805599453
iteration 3 batch 1930 training_loss 0.6931471805599453
iteration 3 batch 1940 training_loss 0.6931471805599453
iteration 3 batch 1950 training_loss 0.6931471805599453
iteration 3 batch 1960 training_loss 0.6931471805599453
iteration 3 batch 1970 training_loss 0.6931471805599453
iteration 3 batch 1980 training_loss 0.6931471805599453
iteration 3 batch 1990 training_loss 0.6931471805599453
iteration 3 batch 2000 training_loss 0.6931471805599453
iteration 3 batch 2010 training_loss 0.6931471805599453
iteration 3 batch 2020 training_loss 0.6931471805599453
iteration 3 batch 2030 training_loss 0.6931471805599453
iteration 3 batch 2040 training_loss 0.6931471805599453
iteration 3 batch 2050 training_loss 0.6931471805599453
iteration 3 batch 2060 training_loss 0.6931471805599453
iteration 3 batch 2070 training_loss 0.6916632528527511
iteration 3 batch 2080 training_loss 0.6931471805599453
iteration 3 batch 2090 training_loss 0.6931471805599453
iteration 3 batch 2100 training_loss 0.6931471805599453
iteration 3 batch 2110 training_loss 0.6931471805599453
iteration 3 batch 2120 training_loss 0.6931471805599453
iteration 3 batch 2130 training_loss 0.6931471805599453
iteration 3 batch 2140 training_loss 0.6931471805599453
iteration 3 batch 2150 training_loss 0.6931471805599453
iteration 3 batch 2160 training_loss 0.6931471805599453
iteration 3 batch 2170 training_loss 0.6931471805599453
iteration 3 batch 2180 training_loss 0.6931471805599453
iteration 3 batch 2190 training_loss 0.6931471805599453
iteration 3 batch 2200 training_loss 0.6931471805599453
iteration 3 batch 2210 training_loss 0.6931471805599453
iteration 3 batch 2220 training_loss 0.6931471805599453
iteration 3 batch 2230 training_loss 0.6931471805599453
iteration 3 batch 2240 training_loss 0.6916632528527511
iteration 3 batch 2250 training_loss 0.6931471805599453
iteration 3 batch 2260 training_loss 0.6931471805599453
iteration 3 batch 2270 training_loss 0.6931471805599453
iteration 3 batch 2280 training_loss 0.6916632528527511
iteration 3 batch 2290 training_loss 0.6931471805599453
iteration 3 batch 2300 training_loss 0.6931471805599453
iteration 3 batch 2310 training_loss 0.6931471805599453
iteration 3 batch 2320 training_loss 0.6931471805599453
iteration 3 batch 2330 training_loss 0.6931471805599453
iteration 3 batch 2340 training_loss 0.6931471805599453
iteration 3 batch 2350 training_loss 0.6931471805599453
iteration 3 batch 2360 training_loss 0.6931471805599453
iteration 3 batch 2370 training_loss 0.6931471805599453
iteration 3 batch 2380 training_loss 0.6931471805599453
iteration 3 batch 2390 training_loss 0.6931471805599453
iteration 3 batch 2400 training_loss 0.6931471805599453
iteration 3 batch 2410 training_loss 0.6931471805599453
iteration 3 batch 2420 training_loss 0.6931471805599453
iteration 3 batch 2430 training_loss 0.6931471805599453
iteration 3 batch 2440 training_loss 0.6931471805599453
iteration 3 batch 2450 training_loss 0.6931471805599453
iteration 3 batch 2460 training_loss 0.6931471805599453
iteration 3 batch 2470 training_loss 0.6931471805599453
iteration 3 batch 2480 training_loss 0.6931471805599453
iteration 3 batch 2490 training_loss 0.6931471805599453
iteration 3 batch 2500 training_loss 0.6931471805599453
iteration 3 batch 2510 training_loss 0.6931471805599453
iteration 3 batch 2520 training_loss 0.6931471805599453
iteration 3 batch 2530 training_loss 0.6916632528527511
iteration 3 batch 2540 training_loss 0.6931471805599453
iteration 3 batch 2550 training_loss 0.6931471805599453
iteration 3 batch 2560 training_loss 0.6931471805599453
iteration 3 batch 2570 training_loss 0.6931471805599453
iteration 3 batch 2580 training_loss 0.6931471805599453
iteration 3 batch 2590 training_loss 0.6931471805599453
iteration 3 batch 2600 training_loss 0.6916632528527511
iteration 3 batch 2610 training_loss 0.6931471805599453
iteration 3 batch 2620 training_loss 0.6931471805599453
iteration 3 batch 2630 training_loss 0.6931471805599453
iteration 3 batch 2640 training_loss 0.6931471805599453
iteration 3 batch 2650 training_loss 0.6931471805599453
iteration 3 batch 2660 training_loss 0.6931471805599453
iteration 3 batch 2670 training_loss 0.6931471805599453
iteration 3 batch 2680 training_loss 0.6916632528527511
iteration 3 batch 2690 training_loss 0.6931471805599453
iteration 3 batch 2700 training_loss 0.6931471805599453
iteration 3 batch 2710 training_loss 0.6916632528527511
iteration 3 batch 2720 training_loss 0.6931471805599453
iteration 3 batch 2730 training_loss 0.6931471805599453
iteration 3 batch 2740 training_loss 0.6931471805599453
iteration 3 batch 2750 training_loss 0.6931471805599453
iteration 3 batch 2760 training_loss 0.6931471805599453
iteration 3 batch 2770 training_loss 0.6931471805599453
iteration 3 batch 2780 training_loss 0.6931471805599453
iteration 3 batch 2790 training_loss 0.6931471805599453
iteration 3 batch 2800 training_loss 0.6931471805599453
iteration 3 batch 2810 training_loss 0.6931471805599453
iteration 3 batch 2820 training_loss 0.6931471805599453
iteration 3 batch 2830 training_loss 0.6931471805599453
iteration 3 batch 2840 training_loss 0.6916632528527511
iteration 3 batch 2850 training_loss 0.6931471805599453
iteration 3 batch 2860 training_loss 0.6916632528527511
iteration 3 batch 2870 training_loss 0.6931471805599453
iteration 3 batch 2880 training_loss 0.6931471805599453
iteration 3 batch 2890 training_loss 0.6931471805599453
iteration 3 batch 2900 training_loss 0.6931471805599453
iteration 3 batch 2910 training_loss 0.6931471805599453
iteration 3 batch 2920 training_loss 0.6901793251455568
iteration 3 batch 2930 training_loss 0.6931471805599453
iteration 3 batch 2940 training_loss 0.6931471805599453
iteration 3 batch 2950 training_loss 0.6931471805599453
iteration 3 batch 2960 training_loss 0.6931471805599453
iteration 3 batch 2970 training_loss 0.6931471805599453
iteration 3 batch 2980 training_loss 0.6931471805599453
iteration 3 batch 2990 training_loss 0.6931471805599453
iteration 3 batch 3000 training_loss 0.6931471805599453
iteration 3 batch 3010 training_loss 0.6931471805599453
iteration 3 batch 3020 training_loss 0.6916632528527511
iteration 3 batch 3030 training_loss 0.6931471805599453
iteration 3 batch 3040 training_loss 0.6931471805599453
iteration 3 batch 3050 training_loss 0.6931471805599453
iteration 3 batch 3060 training_loss 0.6931471805599453
iteration 3 batch 3070 training_loss 0.6931471805599453
iteration 3 batch 3080 training_loss 0.6931471805599453
iteration 3 batch 3090 training_loss 0.6931471805599453
iteration 3 batch 3100 training_loss 0.6931471805599453
iteration 3 batch 3110 training_loss 0.6931471805599453
iteration 3 batch 3120 training_loss 0.6931471805599453
iteration 3 batch 3130 training_loss 0.6931471805599453
iteration 3 batch 3140 training_loss 0.6931471805599453
iteration 3 batch 3150 training_loss 0.6931471805599453
iteration 3 batch 3160 training_loss 0.6931471805599453
iteration 3 batch 3170 training_loss 0.6931471805599453
iteration 3 batch 3180 training_loss 0.6931471805599453
iteration 3 batch 3190 training_loss 0.6901793251455568
iteration 3 batch 3200 training_loss 0.6931471805599453
iteration 3 batch 3210 training_loss 0.6931471805599453
iteration 3 batch 3220 training_loss 0.6931471805599453
iteration 3 batch 3230 training_loss 0.6931471805599453
iteration 3 batch 3240 training_loss 0.6931471805599453
iteration 3 batch 3250 training_loss 0.6931471805599453
iteration 3 batch 3260 training_loss 0.6931471805599453
iteration 3 batch 3270 training_loss 0.6931471805599453
iteration 3 batch 3280 training_loss 0.6916632528527511
iteration 3 batch 3290 training_loss 0.6931471805599453
iteration 3 batch 3300 training_loss 0.6931471805599453
iteration 3 batch 3310 training_loss 0.6916632528527511
iteration 3 batch 3320 training_loss 0.6931471805599453
iteration 3 batch 3330 training_loss 0.6931471805599453
iteration 3 batch 3340 training_loss 0.6931471805599453
iteration 3 batch 3350 training_loss 0.6931471805599453
iteration 3 batch 3360 training_loss 0.6931471805599453
iteration 3 batch 3370 training_loss 0.6931471805599453
iteration 3 batch 3380 training_loss 0.6931471805599453
iteration 3 batch 3390 training_loss 0.6931471805599453
iteration 3 batch 3400 training_loss 0.6931471805599453
iteration 3 batch 3410 training_loss 0.6931471805599453
iteration 3 batch 3420 training_loss 0.6931471805599453
iteration 3 batch 3430 training_loss 0.6931471805599453
iteration 3 batch 3440 training_loss 0.6931471805599453
iteration 3 batch 3450 training_loss 0.6931471805599453
iteration 3 batch 3460 training_loss 0.6931471805599453
iteration 3 batch 3470 training_loss 0.6931471805599453
iteration 3 batch 3480 training_loss 0.6931471805599453
iteration 3 batch 3490 training_loss 0.6931471805599453
iteration 3 batch 3500 training_loss 0.6931471805599453
iteration 3 batch 3510 training_loss 0.6931471805599453
iteration 3 batch 3520 training_loss 0.6931471805599453
iteration 3 batch 3530 training_loss 0.6931471805599453
iteration 3 batch 3540 training_loss 0.6931471805599453
iteration 3 batch 3550 training_loss 0.6931471805599453
iteration 3 batch 3560 training_loss 0.6931471805599453
iteration 3 batch 3570 training_loss 0.6931471805599453
iteration 3 batch 3580 training_loss 0.6931471805599453
iteration 3 batch 3590 training_loss 0.6931471805599453
iteration 3 batch 3600 training_loss 0.6931471805599453
iteration 3 batch 3610 training_loss 0.6931471805599453
iteration 3 batch 3620 training_loss 0.6931471805599453
iteration 3 batch 3630 training_loss 0.6931471805599453
iteration 3 batch 3640 training_loss 0.6931471805599453
iteration 3 batch 3650 training_loss 0.6931471805599453
iteration 3 batch 3660 training_loss 0.6931471805599453
iteration 3 batch 3670 training_loss 0.6931471805599453
iteration 3 batch 3680 training_loss 0.6931471805599453
iteration 3 batch 3690 training_loss 0.6931471805599453
iteration 3 batch 3700 training_loss 0.6931471805599453
iteration 3 batch 3710 training_loss 0.6931471805599453
iteration 3 batch 3720 training_loss 0.6931471805599453
iteration 3 batch 3730 training_loss 0.6931471805599453
iteration 3 batch 3740 training_loss 0.6931471805599453
iteration 3 batch 3750 training_loss 0.6931471805599453
iteration 3 batch 3760 training_loss 0.6931471805599453
iteration 3 batch 3770 training_loss 0.6931471805599453
iteration 3 batch 3780 training_loss 0.6931471805599453
iteration 3 batch 3790 training_loss 0.6931471805599453
iteration 3 batch 3800 training_loss 0.6916632528527511
iteration 3 batch 3810 training_loss 0.6916632528527511
iteration 3 batch 3820 training_loss 0.6931471805599453
iteration 3 batch 3830 training_loss 0.6931471805599453
iteration 3 batch 3840 training_loss 0.6931471805599453
iteration 3 batch 3850 training_loss 0.6931471805599453
iteration 3 batch 3860 training_loss 0.6931471805599453
iteration 3 batch 3870 training_loss 0.6931471805599453
iteration 3 batch 3880 training_loss 0.6931471805599453
iteration 3 batch 3890 training_loss 0.6931471805599453
iteration 3 batch 3900 training_loss 0.6931471805599453
iteration 3 batch 3910 training_loss 0.6916632528527511
iteration 3 batch 3920 training_loss 0.6931471805599453
iteration 3 batch 3930 training_loss 0.6931471805599453
iteration 3 batch 3940 training_loss 0.6931471805599453
iteration 3 batch 3950 training_loss 0.6931471805599453
iteration 3 batch 3960 training_loss 0.6931471805599453
iteration 3 batch 3970 training_loss 0.6931471805599453
iteration 3 batch 3980 training_loss 0.6931471805599453
iteration 3 batch 3990 training_loss 0.6931471805599453
iteration 3 batch 4000 training_loss 0.6916632528527511
iteration 3 batch 4010 training_loss 0.6916632528527511
iteration 3 batch 4020 training_loss 0.6931471805599453
iteration 3 batch 4030 training_loss 0.6931471805599453
iteration 3 batch 4040 training_loss 0.6931471805599453
iteration 3 batch 4050 training_loss 0.6931471805599453
iteration 3 batch 4060 training_loss 0.6931471805599453
iteration 3 batch 4070 training_loss 0.6931471805599453
iteration 3 batch 4080 training_loss 0.6931471805599453
iteration 3 batch 4090 training_loss 0.6931471805599453
iteration 3 batch 4100 training_loss 0.6931471805599453
iteration 3 batch 4110 training_loss 0.6931471805599453
iteration 3 batch 4120 training_loss 0.6931471805599453
iteration 3 batch 4130 training_loss 0.6931471805599453
iteration 3 batch 4140 training_loss 0.6931471805599453
iteration 3 batch 4150 training_loss 0.6931471805599453
iteration 3 batch 4160 training_loss 0.6931471805599453
iteration 3 batch 4170 training_loss 0.6931471805599453
iteration 3 batch 4180 training_loss 0.6931471805599453
iteration 3 batch 4190 training_loss 0.6931471805599453
iteration 3 batch 4200 training_loss 0.6931471805599453
iteration 3 batch 4210 training_loss 0.6931471805599453
iteration 3 batch 4220 training_loss 0.6931471805599453
iteration 3 batch 4230 training_loss 0.6931471805599453
iteration 3 batch 4240 training_loss 0.6931471805599453
iteration 3 batch 4250 training_loss 0.6916632528527511
iteration 3 batch 4260 training_loss 0.6931471805599453
iteration 3 batch 4270 training_loss 0.6931471805599453
iteration 3 batch 4280 training_loss 0.6931471805599453
iteration 3 batch 4290 training_loss 0.6931471805599453
iteration 3 batch 4300 training_loss 0.6931471805599453
iteration 3 batch 4310 training_loss 0.6931471805599453
iteration 3 batch 4320 training_loss 0.6931471805599453
iteration 3 batch 4330 training_loss 0.6931471805599453
iteration 3 batch 4340 training_loss 0.6931471805599453
iteration 3 batch 4350 training_loss 0.6931471805599453
iteration 3 batch 4360 training_loss 0.6931471805599453
iteration 3 batch 4370 training_loss 0.6931471805599453
iteration 3 batch 4380 training_loss 0.6931471805599453
iteration 3 batch 4390 training_loss 0.6931471805599453
iteration 3 batch 4400 training_loss 0.6901793251455568
iteration 3 batch 4410 training_loss 0.6931471805599453
iteration 3 batch 4420 training_loss 0.6931471805599453
iteration 3 batch 4430 training_loss 0.6931471805599453
iteration 3 batch 4440 training_loss 0.6931471805599453
iteration 3 batch 4450 training_loss 0.6931471805599453
iteration 3 batch 4460 training_loss 0.6931471805599453
iteration 3 batch 4470 training_loss 0.6931471805599453
iteration 3 batch 4480 training_loss 0.6931471805599453
iteration 3 batch 4490 training_loss 0.6931471805599453
iteration 3 batch 4500 training_loss 0.6931471805599453
iteration 3 batch 4510 training_loss 0.6916632528527511
iteration 3 batch 4520 training_loss 0.6931471805599453
iteration 3 batch 4530 training_loss 0.6931471805599453
iteration 3 batch 4540 training_loss 0.6916632528527511
iteration 3 batch 4550 training_loss 0.6916632528527511
iteration 3 batch 4560 training_loss 0.6931471805599453
iteration 3 batch 4570 training_loss 0.6931471805599453
iteration 3 batch 4580 training_loss 0.6931471805599453
iteration 3 batch 4590 training_loss 0.6931471805599453
iteration 3 batch 4600 training_loss 0.6931471805599453
iteration 3 batch 4610 training_loss 0.6931471805599453
iteration 3 batch 4620 training_loss 0.6931471805599453
iteration 3 batch 4630 training_loss 0.6931471805599453
iteration 3 batch 4640 training_loss 0.6931471805599453
iteration 3 batch 4650 training_loss 0.6931471805599453
iteration 3 batch 4660 training_loss 0.6931471805599453
iteration 3 batch 4670 training_loss 0.6931471805599453
iteration 3 batch 4680 training_loss 0.6931471805599453
iteration 3 batch 4690 training_loss 0.6931471805599453
iteration 3 batch 4700 training_loss 0.6931471805599453
iteration 3 batch 4710 training_loss 0.6931471805599453
iteration 3 batch 4720 training_loss 0.6931471805599453
iteration 3 batch 4730 training_loss 0.6931471805599453
iteration 3 batch 4740 training_loss 0.6931471805599453
iteration 3 batch 4750 training_loss 0.6931471805599453
iteration 3 batch 4760 training_loss 0.6916632528527511
iteration 3 batch 4770 training_loss 0.6931471805599453
iteration 3 batch 4780 training_loss 0.6916632528527511
iteration 3 batch 4790 training_loss 0.6931471805599453
iteration 3 batch 4800 training_loss 0.6916632528527511
iteration 3 batch 4810 training_loss 0.6931471805599453
iteration 3 batch 4820 training_loss 0.6931471805599453
iteration 3 batch 4830 training_loss 0.6931471805599453
iteration 3 batch 4840 training_loss 0.6931471805599453
iteration 3 batch 4850 training_loss 0.6931471805599453
iteration 3 batch 4860 training_loss 0.6931471805599453
iteration 3 batch 4870 training_loss 0.6931471805599453
iteration 3 batch 4880 training_loss 0.6931471805599453
iteration 3 batch 4890 training_loss 0.6931471805599453
iteration 3 batch 4900 training_loss 0.6931471805599453
iteration 3 batch 4910 training_loss 0.6931471805599453
iteration 3 batch 4920 training_loss 0.6931471805599453
iteration 3 batch 4930 training_loss 0.6931471805599453
iteration 3 batch 4940 training_loss 0.6931471805599453
iteration 3 batch 4950 training_loss 0.6931471805599453
iteration 3 batch 4960 training_loss 0.6931471805599453
iteration 3 batch 4970 training_loss 0.6916632528527511
iteration 3 batch 4980 training_loss 0.6931471805599453
iteration 3 batch 4990 training_loss 0.6931471805599453
iteration 3 batch 5000 training_loss 0.6931471805599453
iteration 3 batch 5010 training_loss 0.6931471805599453
iteration 3 batch 5020 training_loss 0.6931471805599453
iteration 3 batch 5030 training_loss 0.6931471805599453
iteration 3 batch 5040 training_loss 0.6931471805599453
iteration 3 batch 5050 training_loss 0.6931471805599453
iteration 3 batch 5060 training_loss 0.6931471805599453
iteration 3 batch 5070 training_loss 0.6931471805599453
iteration 3 batch 5080 training_loss 0.6931471805599453
iteration 3 batch 5090 training_loss 0.6931471805599453
iteration 3 batch 5100 training_loss 0.6931471805599453
iteration 3 batch 5110 training_loss 0.6931471805599453
iteration 3 batch 5120 training_loss 0.6931471805599453
iteration 3 batch 5130 training_loss 0.6931471805599453
iteration 3 batch 5140 training_loss 0.6931471805599453
iteration 3 batch 5150 training_loss 0.6931471805599453
iteration 3 batch 5160 training_loss 0.6931471805599453
iteration 3 batch 5170 training_loss 0.6931471805599453
iteration 3 batch 5180 training_loss 0.6931471805599453
iteration 3 batch 5190 training_loss 0.6931471805599453
iteration 3 batch 5200 training_loss 0.6916632528527511
iteration 3 batch 5210 training_loss 0.6931471805599453
iteration 3 batch 5220 training_loss 0.6931471805599453
iteration 3 batch 5230 training_loss 0.6931471805599453
iteration 3 batch 5240 training_loss 0.6931471805599453
iteration 3 batch 5250 training_loss 0.6931471805599453
iteration 3 batch 5260 training_loss 0.6931471805599453
iteration 3 batch 5270 training_loss 0.6931471805599453
iteration 3 batch 5280 training_loss 0.6931471805599453
iteration 3 batch 5290 training_loss 0.6931471805599453
iteration 3 batch 5300 training_loss 0.6931471805599453
iteration 3 batch 5310 training_loss 0.6931471805599453
iteration 3 batch 5320 training_loss 0.6931471805599453
iteration 3 batch 5330 training_loss 0.6931471805599453
iteration 3 batch 5340 training_loss 0.6931471805599453
iteration 3 batch 5350 training_loss 0.6931471805599453
iteration 3 batch 5360 training_loss 0.6931471805599453
iteration 3 batch 5370 training_loss 0.6931471805599453
iteration 3 batch 5380 training_loss 0.6931471805599453
iteration 3 batch 5390 training_loss 0.6931471805599453
iteration 3 batch 5400 training_loss 0.6931471805599453
iteration 3 batch 5410 training_loss 0.6931471805599453
iteration 3 batch 5420 training_loss 0.6931471805599453
iteration 3 batch 5430 training_loss 0.6931471805599453
iteration 3 batch 5440 training_loss 0.6931471805599453
iteration 3 batch 5450 training_loss 0.6931471805599453
iteration 3 batch 5460 training_loss 0.6931471805599453
iteration 3 batch 5470 training_loss 0.6916632528527511
iteration 3 batch 5480 training_loss 0.6931471805599453
iteration 3 batch 5490 training_loss 0.6931471805599453
iteration 3 batch 5500 training_loss 0.6931471805599453
iteration 3 batch 5510 training_loss 0.6931471805599453
iteration 3 batch 5520 training_loss 0.6916632528527511
iteration 3 batch 5530 training_loss 0.6931471805599453
iteration 3 batch 5540 training_loss 0.6931471805599453
iteration 3 batch 5550 training_loss 0.6931471805599453
iteration 3 batch 5560 training_loss 0.6931471805599453
iteration 3 batch 5570 training_loss 0.6931471805599453
iteration 3 batch 5580 training_loss 0.6931471805599453
iteration 3 batch 5590 training_loss 0.6931471805599453
iteration 3 batch 5600 training_loss 0.6931471805599453
iteration 3 batch 5610 training_loss 0.6931471805599453
iteration 3 batch 5620 training_loss 0.6931471805599453
iteration 3 batch 5630 training_loss 0.6931471805599453
iteration 3 batch 5640 training_loss 0.6931471805599453
iteration 3 batch 5650 training_loss 0.6931471805599453
iteration 3 batch 5660 training_loss 0.6931471805599453
iteration 3 batch 5670 training_loss 0.6931471805599453
iteration 3 batch 5680 training_loss 0.6931471805599453
iteration 3 batch 5690 training_loss 0.6931471805599453
iteration 3 batch 5700 training_loss 0.6931471805599453
iteration 3 batch 5710 training_loss 0.6931471805599453
iteration 3 batch 5720 training_loss 0.6931471805599453
iteration 3 batch 5730 training_loss 0.6931471805599453
iteration 3 batch 5740 training_loss 0.6931471805599453
iteration 3 batch 5750 training_loss 0.6931471805599453
iteration 3 batch 5760 training_loss 0.6931471805599453
iteration 3 batch 5770 training_loss 0.6931471805599453
iteration 3 batch 5780 training_loss 0.6916632528527511
iteration 3 batch 5790 training_loss 0.6931471805599453
iteration 3 batch 5800 training_loss 0.6931471805599453
iteration 3 batch 5810 training_loss 0.6931471805599453
iteration 3 batch 5820 training_loss 0.6931471805599453
iteration 3 batch 5830 training_loss 0.6931471805599453
iteration 3 batch 5840 training_loss 0.6931471805599453
iteration 3 batch 5850 training_loss 0.6931471805599453
iteration 3 batch 5860 training_loss 0.6931471805599453
iteration 3 batch 5870 training_loss 0.6931471805599453
iteration 3 batch 5880 training_loss 0.6931471805599453
iteration 3 batch 5890 training_loss 0.6916632528527511
iteration 3 batch 5900 training_loss 0.6916632528527511
iteration 3 batch 5910 training_loss 0.6931471805599453
iteration 3 batch 5920 training_loss 0.6931471805599453
iteration 3 batch 5930 training_loss 0.6931471805599453
iteration 3 batch 5940 training_loss 0.6931471805599453
iteration 3 batch 5950 training_loss 0.6931471805599453
iteration 3 batch 5960 training_loss 0.6931471805599453
iteration 3 batch 5970 training_loss 0.6931471805599453
iteration 3 batch 5980 training_loss 0.6931471805599453
iteration 3 batch 5990 training_loss 0.6931471805599453
iteration 3 batch 6000 training_loss 0.6931471805599453
iteration 3 batch 6010 training_loss 0.6931471805599453
iteration 3 batch 6020 training_loss 0.6931471805599453
iteration 3 batch 6030 training_loss 0.6901793251455568
iteration 3 batch 6040 training_loss 0.6931471805599453
iteration 3 batch 6050 training_loss 0.6931471805599453
iteration 3 batch 6060 training_loss 0.6931471805599453
iteration 3 batch 6070 training_loss 0.6931471805599453
iteration 3 batch 6080 training_loss 0.6931471805599453
iteration 3 batch 6090 training_loss 0.6931471805599453
iteration 3 batch 6100 training_loss 0.6931471805599453
iteration 3 batch 6110 training_loss 0.6931471805599453
iteration 3 batch 6120 training_loss 0.6931471805599453
iteration 3 batch 6130 training_loss 0.6931471805599453
iteration 3 batch 6140 training_loss 0.6931471805599453
iteration 3 batch 6150 training_loss 0.6931471805599453
iteration 3 batch 6160 training_loss 0.6931471805599453
iteration 3 batch 6170 training_loss 0.6931471805599453
iteration 3 batch 6180 training_loss 0.6931471805599453
iteration 3 batch 6190 training_loss 0.6931471805599453
iteration 3 batch 6200 training_loss 0.6916632528527511
iteration 3 batch 6210 training_loss 0.6931471805599453
iteration 3 batch 6220 training_loss 0.6916632528527511
iteration 3 batch 6230 training_loss 0.6916632528527511
iteration 3 batch 6240 training_loss 0.6931471805599453
iteration 3 batch 6250 training_loss 0.6931471805599453
iteration 3 batch 6260 training_loss 0.6916632528527511
iteration 3 batch 6270 training_loss 0.6931471805599453
iteration 3 batch 6280 training_loss 0.6901793251455568
iteration 3 batch 6290 training_loss 0.6916632528527511
iteration 3 batch 6300 training_loss 0.6931471805599453
iteration 3 batch 6310 training_loss 0.6931471805599453
iteration 3 batch 6320 training_loss 0.6931471805599453
iteration 3 batch 6330 training_loss 0.6916632528527511
iteration 3 batch 6340 training_loss 0.6931471805599453
iteration 3 batch 6350 training_loss 0.6931471805599453
iteration 3 batch 6360 training_loss 0.6916632528527511
iteration 3 batch 6370 training_loss 0.6931471805599453
iteration 3 batch 6380 training_loss 0.6931471805599453
iteration 3 batch 6390 training_loss 0.6931471805599453
iteration 3 batch 6400 training_loss 0.6931471805599453
iteration 3 batch 6410 training_loss 0.6931471805599453
iteration 3 batch 6420 training_loss 0.6931471805599453
iteration 3 batch 6430 training_loss 0.6916632528527511
iteration 3 batch 6440 training_loss 0.6931471805599453
iteration 3 batch 6450 training_loss 0.6931471805599453
iteration 3 batch 6460 training_loss 0.6931471805599453
iteration 3 batch 6470 training_loss 0.6931471805599453
iteration 3 batch 6480 training_loss 0.6931471805599453
iteration 3 batch 6490 training_loss 0.6931471805599453
iteration 3 batch 6500 training_loss 0.6931471805599453
iteration 3 batch 6510 training_loss 0.6931471805599453
iteration 3 batch 6520 training_loss 0.6931471805599453
iteration 3 batch 6530 training_loss 0.6931471805599453
iteration 3 batch 6540 training_loss 0.6931471805599453
iteration 3 batch 6550 training_loss 0.6931471805599453
iteration 3 batch 6560 training_loss 0.6931471805599453
iteration 3 batch 6570 training_loss 0.6931471805599453
iteration 3 batch 6580 training_loss 0.6931471805599453
iteration 3 batch 6590 training_loss 0.6931471805599453
iteration 3 batch 6600 training_loss 0.6931471805599453
iteration 3 batch 6610 training_loss 0.6931471805599453
iteration 3 batch 6620 training_loss 0.6931471805599453
iteration 3 batch 6630 training_loss 0.6916632528527511
iteration 3 batch 6640 training_loss 0.6931471805599453
iteration 3 batch 6650 training_loss 0.6931471805599453
iteration 3 batch 6660 training_loss 0.6931471805599453
iteration 3 batch 6670 training_loss 0.6931471805599453
iteration 3 batch 6680 training_loss 0.6931471805599453
iteration 3 batch 6690 training_loss 0.6931471805599453
iteration 3 batch 6700 training_loss 0.6931471805599453
iteration 3 batch 6710 training_loss 0.6931471805599453
iteration 3 batch 6720 training_loss 0.6931471805599453
iteration 3 batch 6730 training_loss 0.6931471805599453
iteration 3 batch 6740 training_loss 0.6931471805599453
iteration 3 batch 6750 training_loss 0.6931471805599453
iteration 3 batch 6760 training_loss 0.6931471805599453
iteration 3 batch 6770 training_loss 0.6931471805599453
iteration 3 batch 6780 training_loss 0.6931471805599453
iteration 3 batch 6790 training_loss 0.6931471805599453
iteration 3 batch 6800 training_loss 0.6931471805599453
iteration 3 batch 6810 training_loss 0.6931471805599453
iteration 3 batch 6820 training_loss 0.6931471805599453
iteration 3 batch 6830 training_loss 0.6931471805599453
iteration 3 batch 6840 training_loss 0.6931471805599453
iteration 3 batch 6850 training_loss 0.6931471805599453
iteration 3 batch 6860 training_loss 0.6931471805599453
iteration 3 batch 6870 training_loss 0.6931471805599453
iteration 3 batch 6880 training_loss 0.6931471805599453
iteration 3 batch 6890 training_loss 0.6916632528527511
iteration 3 batch 6900 training_loss 0.6931471805599453
iteration 3 batch 6910 training_loss 0.6931471805599453
iteration 3 batch 6920 training_loss 0.6931471805599453
iteration 3 batch 6930 training_loss 0.6931471805599453
iteration 3 batch 6940 training_loss 0.6916632528527511
iteration 3 batch 6950 training_loss 0.6931471805599453
iteration 3 batch 6960 training_loss 0.6931471805599453
iteration 3 batch 6970 training_loss 0.6931471805599453
iteration 3 batch 6980 training_loss 0.6931471805599453
iteration 3 batch 6990 training_loss 0.6931471805599453
iteration 3 batch 7000 training_loss 0.6931471805599453
iteration 3 batch 7010 training_loss 0.6931471805599453
iteration 3 batch 7020 training_loss 0.6931471805599453
iteration 3 batch 7030 training_loss 0.6931471805599453
iteration 3 batch 7040 training_loss 0.6931471805599453
iteration 3 batch 7050 training_loss 0.6931471805599453
iteration 3 batch 7060 training_loss 0.6931471805599453
iteration 3 batch 7070 training_loss 0.6931471805599453
iteration 3 batch 7080 training_loss 0.6931471805599453
iteration 3 batch 7090 training_loss 0.6931471805599453
iteration 3 batch 7100 training_loss 0.6931471805599453
iteration 3 batch 7110 training_loss 0.6931471805599453
iteration 3 batch 7120 training_loss 0.6931471805599453
iteration 3 batch 7130 training_loss 0.6931471805599453
iteration 3 batch 7140 training_loss 0.6931471805599453
iteration 3 batch 7150 training_loss 0.6931471805599453
iteration 3 batch 7160 training_loss 0.6931471805599453
iteration 3 batch 7170 training_loss 0.6931471805599453
iteration 3 batch 7180 training_loss 0.6931471805599453
iteration 3 batch 7190 training_loss 0.6931471805599453
iteration 3 batch 7200 training_loss 0.6931471805599453
iteration 3 batch 7210 training_loss 0.6931471805599453
iteration 3 batch 7220 training_loss 0.6931471805599453
iteration 3 batch 7230 training_loss 0.6931471805599453
iteration 3 batch 7240 training_loss 0.6931471805599453
iteration 3 batch 7250 training_loss 0.6931471805599453
iteration 3 batch 7260 training_loss 0.6931471805599453
iteration 3 batch 7270 training_loss 0.6931471805599453
iteration 3 batch 7280 training_loss 0.6931471805599453
iteration 3 batch 7290 training_loss 0.6931471805599453
iteration 3 batch 7300 training_loss 0.6931471805599453
iteration 3 batch 7310 training_loss 0.6931471805599453
iteration 3 batch 7320 training_loss 0.6931471805599453
iteration 3 batch 7330 training_loss 0.6931471805599453
iteration 3 batch 7340 training_loss 0.6916632528527511
iteration 3 batch 7350 training_loss 0.6931471805599453
iteration 3 batch 7360 training_loss 0.6931471805599453
iteration 3 batch 7370 training_loss 0.6931471805599453
iteration 3 batch 7380 training_loss 0.6931471805599453
iteration 3 batch 7390 training_loss 0.6931471805599453
iteration 3 batch 7400 training_loss 0.6931471805599453
iteration 3 batch 7410 training_loss 0.6931471805599453
iteration 3 batch 7420 training_loss 0.6931471805599453
iteration 3 batch 7430 training_loss 0.6931471805599453
iteration 3 batch 7440 training_loss 0.6931471805599453
iteration 3 batch 7450 training_loss 0.6916632528527511
iteration 3 batch 7460 training_loss 0.6931471805599453
iteration 3 batch 7470 training_loss 0.6931471805599453
iteration 3 batch 7480 training_loss 0.6931471805599453
iteration 3 batch 7490 training_loss 0.6916632528527511
iteration 3 batch 7500 training_loss 0.6931471805599453
iteration 3 batch 7510 training_loss 0.6931471805599453
iteration 3 batch 7520 training_loss 0.6931471805599453
iteration 3 batch 7530 training_loss 0.6931471805599453
iteration 3 batch 7540 training_loss 0.6931471805599453
iteration 3 batch 7550 training_loss 0.6931471805599453
iteration 3 batch 7560 training_loss 0.6931471805599453
iteration 3 batch 7570 training_loss 0.6931471805599453
iteration 3 batch 7580 training_loss 0.6916632528527511
iteration 3 batch 7590 training_loss 0.6931471805599453
iteration 3 batch 7600 training_loss 0.6931471805599453
iteration 3 batch 7610 training_loss 0.6931471805599453
iteration 3 batch 7620 training_loss 0.6931471805599453
iteration 3 batch 7630 training_loss 0.6931471805599453
iteration 3 batch 7640 training_loss 0.6916632528527511
iteration 3 batch 7650 training_loss 0.6931471805599453
iteration 3 batch 7660 training_loss 0.6931471805599453
iteration 3 batch 7670 training_loss 0.6931471805599453
iteration 3 batch 7680 training_loss 0.6931471805599453
iteration 3 batch 7690 training_loss 0.6931471805599453
iteration 3 batch 7700 training_loss 0.6931471805599453
iteration 3 batch 7710 training_loss 0.6931471805599453
iteration 3 batch 7720 training_loss 0.6931471805599453
iteration 3 batch 7730 training_loss 0.6931471805599453
iteration 3 batch 7740 training_loss 0.6931471805599453
iteration 3 batch 7750 training_loss 0.6931471805599453
iteration 3 batch 7760 training_loss 0.6931471805599453
iteration 3 batch 7770 training_loss 0.6916632528527511
iteration 3 batch 7780 training_loss 0.6931471805599453
iteration 3 batch 7790 training_loss 0.6931471805599453
iteration 3 batch 7800 training_loss 0.6931471805599453
iteration 3 batch 7810 training_loss 0.6931471805599453
iteration 3 batch 7820 training_loss 0.6931471805599453
iteration 3 batch 7830 training_loss 0.6931471805599453
iteration 3 batch 7840 training_loss 0.6931471805599453
iteration 3 batch 7850 training_loss 0.6931471805599453
iteration 3 batch 7860 training_loss 0.6931471805599453
iteration 3 batch 7870 training_loss 0.6931471805599453
iteration 3 batch 7880 training_loss 0.6931471805599453
iteration 3 batch 7890 training_loss 0.6931471805599453
iteration 3 batch 7900 training_loss 0.6931471805599453
iteration 3 batch 7910 training_loss 0.6916632528527511
iteration 3 batch 7920 training_loss 0.6931471805599453
iteration 3 batch 7930 training_loss 0.6931471805599453
iteration 3 batch 7940 training_loss 0.6916632528527511
iteration 3 batch 7950 training_loss 0.6931471805599453
iteration 3 batch 7960 training_loss 0.6931471805599453
iteration 3 batch 7970 training_loss 0.6931471805599453
iteration 3 batch 7980 training_loss 0.6931471805599453
iteration 3 batch 7990 training_loss 0.6931471805599453
iteration 3 batch 8000 training_loss 0.6931471805599453
iteration 3 batch 8010 training_loss 0.6931471805599453
iteration 3 batch 8020 training_loss 0.6931471805599453
iteration 3 batch 8030 training_loss 0.6931471805599453
iteration 3 batch 8040 training_loss 0.6916632528527511
iteration 3 batch 8050 training_loss 0.6931471805599453
iteration 3 batch 8060 training_loss 0.6931471805599453
iteration 3 batch 8070 training_loss 0.6931471805599453
iteration 3 batch 8080 training_loss 0.6931471805599453
iteration 3 batch 8090 training_loss 0.6931471805599453
iteration 3 batch 8100 training_loss 0.6931471805599453
iteration 3 batch 8110 training_loss 0.6931471805599453
iteration 3 batch 8120 training_loss 0.6931471805599453
iteration 3 batch 8130 training_loss 0.6931471805599453
iteration 3 batch 8140 training_loss 0.6931471805599453
iteration 3 batch 8150 training_loss 0.6931471805599453
iteration 3 batch 8160 training_loss 0.6931471805599453
iteration 3 batch 8170 training_loss 0.6916632528527511
iteration 3 batch 8180 training_loss 0.6931471805599453
iteration 3 batch 8190 training_loss 0.6931471805599453
iteration 3 batch 8200 training_loss 0.6931471805599453
iteration 3 batch 8210 training_loss 0.6931471805599453
iteration 3 batch 8220 training_loss 0.6931471805599453
iteration 3 batch 8230 training_loss 0.6931471805599453
iteration 3 batch 8240 training_loss 0.6931471805599453
iteration 3 batch 8250 training_loss 0.6931471805599453
iteration 3 batch 8260 training_loss 0.6931471805599453
iteration 3 batch 8270 training_loss 0.6931471805599453
iteration 3 batch 8280 training_loss 0.6931471805599453
iteration 3 batch 8290 training_loss 0.6931471805599453
iteration 3 batch 8300 training_loss 0.6931471805599453
iteration 3 batch 8310 training_loss 0.6931471805599453
iteration 3 batch 8320 training_loss 0.6931471805599453
iteration 3 batch 8330 training_loss 0.6931471805599453
iteration 3 batch 8340 training_loss 0.6916632528527511
iteration 3 batch 8350 training_loss 0.6931471805599453
iteration 3 batch 8360 training_loss 0.6931471805599453
iteration 3 batch 8370 training_loss 0.6931471805599453
iteration 3 batch 8380 training_loss 0.6931471805599453
iteration 3 batch 8390 training_loss 0.6931471805599453
iteration 3 batch 8400 training_loss 0.6931471805599453
iteration 3 batch 8410 training_loss 0.6916632528527511
iteration 3 batch 8420 training_loss 0.6931471805599453
iteration 3 batch 8430 training_loss 0.6931471805599453
iteration 3 batch 8440 training_loss 0.6931471805599453
iteration 3 batch 8450 training_loss 0.6931471805599453
iteration 3 batch 8460 training_loss 0.6931471805599453
iteration 3 batch 8470 training_loss 0.6931471805599453
iteration 3 batch 8480 training_loss 0.6931471805599453
iteration 3 batch 8490 training_loss 0.6931471805599453
iteration 3 batch 8500 training_loss 0.6931471805599453
iteration 3 batch 8510 training_loss 0.6931471805599453
iteration 3 batch 8520 training_loss 0.6931471805599453
iteration 3 batch 8530 training_loss 0.6931471805599453
iteration 3 batch 8540 training_loss 0.6931471805599453
iteration 3 batch 8550 training_loss 0.6916632528527511
iteration 3 batch 8560 training_loss 0.6916632528527511
iteration 3 batch 8570 training_loss 0.6931471805599453
iteration 3 batch 8580 training_loss 0.6931471805599453
iteration 3 batch 8590 training_loss 0.6931471805599453
iteration 3 batch 8600 training_loss 0.6931471805599453
iteration 3 batch 8610 training_loss 0.6931471805599453
iteration 3 batch 8620 training_loss 0.6916632528527511
iteration 3 batch 8630 training_loss 0.6931471805599453
iteration 3 batch 8640 training_loss 0.6931471805599453
iteration 3 batch 8650 training_loss 0.6931471805599453
iteration 3 batch 8660 training_loss 0.6931471805599453
iteration 3 batch 8670 training_loss 0.6931471805599453
iteration 3 batch 8680 training_loss 0.6931471805599453
iteration 3 batch 8690 training_loss 0.6931471805599453
iteration 3 batch 8700 training_loss 0.6931471805599453
iteration 3 batch 8710 training_loss 0.6931471805599453
iteration 3 batch 8720 training_loss 0.6931471805599453
iteration 3 batch 8730 training_loss 0.6931471805599453
iteration 3 batch 8740 training_loss 0.6931471805599453
iteration 3 batch 8750 training_loss 0.6931471805599453
iteration 3 batch 8760 training_loss 0.6916632528527511
iteration 3 batch 8770 training_loss 0.6931471805599453
iteration 3 batch 8780 training_loss 0.6931471805599453
iteration 3 batch 8790 training_loss 0.6931471805599453
iteration 3 batch 8800 training_loss 0.6931471805599453
iteration 3 batch 8810 training_loss 0.6931471805599453
iteration 3 batch 8820 training_loss 0.6931471805599453
iteration 3 batch 8830 training_loss 0.6931471805599453
iteration 3 batch 8840 training_loss 0.6931471805599453
iteration 3 batch 8850 training_loss 0.6931471805599453
iteration 3 batch 8860 training_loss 0.6931471805599453
iteration 3 batch 8870 training_loss 0.6931471805599453
iteration 3 batch 8880 training_loss 0.6931471805599453
iteration 3 batch 8890 training_loss 0.6931471805599453
iteration 3 batch 8900 training_loss 0.6931471805599453
iteration 3 batch 8910 training_loss 0.6931471805599453
iteration 3 batch 8920 training_loss 0.6931471805599453
iteration 3 batch 8930 training_loss 0.6931471805599453
iteration 3 batch 8940 training_loss 0.6931471805599453
iteration 3 batch 8950 training_loss 0.6931471805599453
iteration 3 batch 8960 training_loss 0.6916632528527511
iteration 3 batch 8970 training_loss 0.6931471805599453
iteration 3 batch 8980 training_loss 0.6931471805599453
iteration 3 batch 8990 training_loss 0.6931471805599453
iteration 3 batch 9000 training_loss 0.6931471805599453
iteration 3 batch 9010 training_loss 0.6931471805599453
iteration 3 batch 9020 training_loss 0.6931471805599453
iteration 3 batch 9030 training_loss 0.6931471805599453
iteration 3 batch 9040 training_loss 0.6931471805599453
iteration 3 batch 9050 training_loss 0.6931471805599453
iteration 3 batch 9060 training_loss 0.6931471805599453
iteration 3 batch 9070 training_loss 0.6931471805599453
iteration 3 batch 9080 training_loss 0.6931471805599453
iteration 3 batch 9090 training_loss 0.6931471805599453
iteration 3 batch 9100 training_loss 0.6931471805599453
iteration 3 batch 9110 training_loss 0.6931471805599453
iteration 3 batch 9120 training_loss 0.6916632528527511
iteration 3 batch 9130 training_loss 0.6931471805599453
iteration 3 batch 9140 training_loss 0.6931471805599453
iteration 3 batch 9150 training_loss 0.6916632528527511
iteration 3 batch 9160 training_loss 0.6931471805599453
iteration 3 batch 9170 training_loss 0.6931471805599453
iteration 3 batch 9180 training_loss 0.6931471805599453
iteration 3 batch 9190 training_loss 0.6931471805599453
iteration 3 batch 9200 training_loss 0.6931471805599453
iteration 3 batch 9210 training_loss 0.6931471805599453
iteration 3 batch 9220 training_loss 0.6931471805599453
iteration 3 batch 9230 training_loss 0.6931471805599453
iteration 3 batch 9240 training_loss 0.6916632528527511
iteration 3 batch 9250 training_loss 0.6931471805599453
iteration 3 batch 9260 training_loss 0.6931471805599453
iteration 3 batch 9270 training_loss 0.6931471805599453
iteration 3 batch 9280 training_loss 0.6931471805599453
iteration 3 batch 9290 training_loss 0.6931471805599453
iteration 3 batch 9300 training_loss 0.6931471805599453
iteration 3 batch 9310 training_loss 0.6931471805599453
iteration 3 batch 9320 training_loss 0.6931471805599453
iteration 3 batch 9330 training_loss 0.6931471805599453
iteration 3 batch 9340 training_loss 0.6931471805599453
iteration 3 batch 9350 training_loss 0.6931471805599453
iteration 3 batch 9360 training_loss 0.6931471805599453
iteration 3 batch 9370 training_loss 0.6931471805599453
iteration 3 batch 9380 training_loss 0.6931471805599453
iteration 3 batch 9390 training_loss 0.6931471805599453
iteration 3 batch 9400 training_loss 0.6931471805599453
iteration 3 batch 9410 training_loss 0.6931471805599453
iteration 3 batch 9420 training_loss 0.6931471805599453
iteration 3 batch 9430 training_loss 0.6931471805599453
iteration 3 batch 9440 training_loss 0.6931471805599453
iteration 3 batch 9450 training_loss 0.6931471805599453
iteration 3 batch 9460 training_loss 0.6931471805599453
iteration 3 batch 9470 training_loss 0.6931471805599453
iteration 3 batch 9480 training_loss 0.6931471805599453
iteration 3 batch 9490 training_loss 0.6931471805599453
iteration 3 batch 9500 training_loss 0.6931471805599453
iteration 3 batch 9510 training_loss 0.6931471805599453
iteration 3 batch 9520 training_loss 0.6931471805599453
iteration 3 batch 9530 training_loss 0.6931471805599453
iteration 3 batch 9540 training_loss 0.6931471805599453
iteration 3 batch 9550 training_loss 0.6931471805599453
iteration 3 batch 9560 training_loss 0.6931471805599453
iteration 3 batch 9570 training_loss 0.6931471805599453
iteration 3 batch 9580 training_loss 0.6931471805599453
iteration 3 batch 9590 training_loss 0.6931471805599453
iteration 3 batch 9600 training_loss 0.6931471805599453
iteration 3 batch 9610 training_loss 0.6931471805599453
iteration 3 batch 9620 training_loss 0.6916632528527511
iteration 3 batch 9630 training_loss 0.6931471805599453
iteration 3 batch 9640 training_loss 0.6916632528527511
iteration 3 batch 9650 training_loss 0.6931471805599453
iteration 3 batch 9660 training_loss 0.6931471805599453
iteration 3 batch 9670 training_loss 0.6931471805599453
iteration 3 batch 9680 training_loss 0.6931471805599453
iteration 3 batch 9690 training_loss 0.6931471805599453
iteration 3 batch 9700 training_loss 0.6931471805599453
iteration 3 batch 9710 training_loss 0.6931471805599453
iteration 3 batch 9720 training_loss 0.6931471805599453
iteration 3 batch 9730 training_loss 0.6931471805599453
iteration 3 batch 9740 training_loss 0.6931471805599453
iteration 3 batch 9750 training_loss 0.6931471805599453
iteration 3 batch 9760 training_loss 0.6931471805599453
iteration 3 batch 9770 training_loss 0.6931471805599453
iteration 3 batch 9780 training_loss 0.6931471805599453
iteration 3 batch 9790 training_loss 0.6931471805599453
iteration 3 batch 9800 training_loss 0.6931471805599453
iteration 3 batch 9810 training_loss 0.6931471805599453
iteration 3 batch 9820 training_loss 0.6931471805599453
iteration 3 batch 9830 training_loss 0.6931471805599453
iteration 3 batch 9840 training_loss 0.6916632528527511
iteration 3 batch 9850 training_loss 0.6916632528527511
iteration 3 batch 9860 training_loss 0.6931471805599453
iteration 3 batch 9870 training_loss 0.6931471805599453
iteration 3 batch 9880 training_loss 0.6931471805599453
iteration 3 batch 9890 training_loss 0.6931471805599453
iteration 3 batch 9900 training_loss 0.6931471805599453
iteration 3 batch 9910 training_loss 0.6931471805599453
iteration 3 batch 9920 training_loss 0.6931471805599453
iteration 3 batch 9930 training_loss 0.6931471805599453
iteration 3 batch 9940 training_loss 0.6931471805599453
iteration 3 batch 9950 training_loss 0.6931471805599453
iteration 3 batch 9960 training_loss 0.6931471805599453
iteration 3 batch 9970 training_loss 0.6901793251455568
iteration 3 batch 9980 training_loss 0.6916632528527511
iteration 3 batch 9990 training_loss 0.6931471805599453
iteration 3 batch 10000 training_loss 0.6931471805599453
iteration 3 batch 10010 training_loss 0.6931471805599453
iteration 3 batch 10020 training_loss 0.6931471805599453
iteration 3 batch 10030 training_loss 0.6931471805599453
iteration 3 batch 10040 training_loss 0.6931471805599453
iteration 3 batch 10050 training_loss 0.6931471805599453
iteration 3 batch 10060 training_loss 0.6931471805599453
iteration 3 batch 10070 training_loss 0.6931471805599453
iteration 3 batch 10080 training_loss 0.6931471805599453
iteration 3 batch 10090 training_loss 0.6931471805599453
iteration 3 batch 10100 training_loss 0.6931471805599453
iteration 3 batch 10110 training_loss 0.6931471805599453
iteration 3 batch 10120 training_loss 0.6931471805599453
iteration 3 batch 10130 training_loss 0.6916632528527511
iteration 3 batch 10140 training_loss 0.6931471805599453
iteration 3 batch 10150 training_loss 0.6931471805599453
iteration 3 batch 10160 training_loss 0.6931471805599453
iteration 3 batch 10170 training_loss 0.6931471805599453
iteration 3 batch 10180 training_loss 0.6931471805599453
iteration 3 batch 10190 training_loss 0.6931471805599453
iteration 3 batch 10200 training_loss 0.6931471805599453
iteration 3 batch 10210 training_loss 0.6931471805599453
iteration 3 batch 10220 training_loss 0.6916632528527511
iteration 3 batch 10230 training_loss 0.6931471805599453
iteration 3 batch 10240 training_loss 0.6931471805599453
iteration 3 batch 10250 training_loss 0.6931471805599453
iteration 3 batch 10260 training_loss 0.6931471805599453
iteration 3 batch 10270 training_loss 0.6931471805599453
iteration 3 batch 10280 training_loss 0.6931471805599453
iteration 3 batch 10290 training_loss 0.6931471805599453
iteration 3 batch 10300 training_loss 0.6901793251455568
iteration 3 batch 10310 training_loss 0.6916632528527511
iteration 3 batch 10320 training_loss 0.6931471805599453
iteration 3 batch 10330 training_loss 0.6931471805599453
iteration 3 batch 10340 training_loss 0.6931471805599453
iteration 3 batch 10350 training_loss 0.6931471805599453
iteration 3 batch 10360 training_loss 0.6931471805599453
iteration 3 batch 10370 training_loss 0.6931471805599453
iteration 3 batch 10380 training_loss 0.6931471805599453
iteration 3 batch 10390 training_loss 0.6931471805599453
iteration 3 batch 10400 training_loss 0.6916632528527511
iteration 3 batch 10410 training_loss 0.6931471805599453
iteration 3 batch 10420 training_loss 0.6931471805599453
iteration 3 batch 10430 training_loss 0.6931471805599453
iteration 3 batch 10440 training_loss 0.6931471805599453
iteration 3 batch 10450 training_loss 0.6931471805599453
iteration 3 batch 10460 training_loss 0.6931471805599453
iteration 3 batch 10470 training_loss 0.6931471805599453
iteration 3 batch 10480 training_loss 0.6931471805599453
iteration 3 batch 10490 training_loss 0.6931471805599453
iteration 3 batch 10500 training_loss 0.6931471805599453
iteration 3 batch 10510 training_loss 0.6931471805599453
iteration 3 batch 10520 training_loss 0.6931471805599453
iteration 3 batch 10530 training_loss 0.6931471805599453
iteration 3 batch 10540 training_loss 0.6931471805599453
iteration 3 batch 10550 training_loss 0.6916632528527511
iteration 3 batch 10560 training_loss 0.6931471805599453
iteration 3 batch 10570 training_loss 0.6931471805599453
iteration 3 batch 10580 training_loss 0.6931471805599453
iteration 3 batch 10590 training_loss 0.6931471805599453
iteration 3 batch 10600 training_loss 0.6916632528527511
iteration 3 batch 10610 training_loss 0.6931471805599453
iteration 3 batch 10620 training_loss 0.6931471805599453
iteration 3 batch 10630 training_loss 0.6931471805599453
iteration 3 batch 10640 training_loss 0.6931471805599453
iteration 3 batch 10650 training_loss 0.6931471805599453
iteration 3 batch 10660 training_loss 0.6916632528527511
iteration 3 batch 10670 training_loss 0.6931471805599453
iteration 3 batch 10680 training_loss 0.6931471805599453
iteration 3 batch 10690 training_loss 0.6931471805599453
iteration 3 batch 10700 training_loss 0.6931471805599453
iteration 3 batch 10710 training_loss 0.6931471805599453
iteration 3 batch 10720 training_loss 0.6931471805599453
iteration 3 batch 10730 training_loss 0.6931471805599453
iteration 3 batch 10740 training_loss 0.6931471805599453
iteration 3 batch 10750 training_loss 0.6931471805599453
iteration 3 batch 10760 training_loss 0.6931471805599453
iteration 3 batch 10770 training_loss 0.6931471805599453
iteration 3 batch 10780 training_loss 0.6931471805599453
iteration 3 batch 10790 training_loss 0.6931471805599453
iteration 3 batch 10800 training_loss 0.6931471805599453
iteration 3 batch 10810 training_loss 0.6931471805599453
iteration 3 batch 10820 training_loss 0.6931471805599453
iteration 3 batch 10830 training_loss 0.6931471805599453
iteration 3 batch 10840 training_loss 0.6931471805599453
iteration 3 batch 10850 training_loss 0.6931471805599453
iteration 3 batch 10860 training_loss 0.6931471805599453
iteration 3 batch 10870 training_loss 0.6931471805599453
iteration 3 batch 10880 training_loss 0.6916632528527511
iteration 3 batch 10890 training_loss 0.6931471805599453
iteration 3 batch 10900 training_loss 0.6931471805599453
iteration 3 batch 10910 training_loss 0.6931471805599453
iteration 3 batch 10920 training_loss 0.6931471805599453
iteration 3 batch 10930 training_loss 0.6931471805599453
iteration 3 batch 10940 training_loss 0.6931471805599453
iteration 3 batch 10950 training_loss 0.6931471805599453
iteration 3 batch 10960 training_loss 0.6931471805599453
iteration 3 batch 10970 training_loss 0.6931471805599453
iteration 3 batch 10980 training_loss 0.6931471805599453
iteration 3 batch 10990 training_loss 0.6931471805599453
iteration 3 batch 11000 training_loss 0.6931471805599453
iteration 3 batch 11010 training_loss 0.6916632528527511
iteration 3 batch 11020 training_loss 0.6931471805599453
iteration 3 batch 11030 training_loss 0.6931471805599453
iteration 3 batch 11040 training_loss 0.6931471805599453
iteration 3 batch 11050 training_loss 0.6931471805599453
iteration 3 batch 11060 training_loss 0.6931471805599453
iteration 3 batch 11070 training_loss 0.6931471805599453
iteration 3 batch 11080 training_loss 0.6931471805599453
iteration 3 batch 11090 training_loss 0.6931471805599453
iteration 3 batch 11100 training_loss 0.6931471805599453
iteration 3 batch 11110 training_loss 0.6931471805599453
iteration 3 batch 11120 training_loss 0.6931471805599453
iteration 3 batch 11130 training_loss 0.6931471805599453
iteration 3 batch 11140 training_loss 0.6931471805599453
iteration 3 batch 11150 training_loss 0.6931471805599453
iteration 3 batch 11160 training_loss 0.6931471805599453
iteration 3 batch 11170 training_loss 0.6931471805599453
iteration 3 batch 11180 training_loss 0.6931471805599453
iteration 3 batch 11190 training_loss 0.6916632528527511
iteration 3 batch 11200 training_loss 0.6931471805599453
iteration 3 batch 11210 training_loss 0.6931471805599453
iteration 3 batch 11220 training_loss 0.6931471805599453
iteration 3 batch 11230 training_loss 0.6931471805599453
iteration 3 batch 11240 training_loss 0.6931471805599453
iteration 3 batch 11250 training_loss 0.6916632528527511
iteration 3 batch 11260 training_loss 0.6931471805599453
iteration 3 batch 11270 training_loss 0.6931471805599453
iteration 3 batch 11280 training_loss 0.6931471805599453
iteration 3 batch 11290 training_loss 0.6931471805599453
iteration 3 batch 11300 training_loss 0.6931471805599453
iteration 3 batch 11310 training_loss 0.6931471805599453
iteration 3 batch 11320 training_loss 0.6931471805599453
iteration 3 batch 11330 training_loss 0.6931471805599453
iteration 3 batch 11340 training_loss 0.6931471805599453
iteration 3 batch 11350 training_loss 0.6931471805599453
iteration 3 batch 11360 training_loss 0.6931471805599453
iteration 3 batch 11370 training_loss 0.6931471805599453
iteration 3 batch 11380 training_loss 0.6931471805599453
iteration 3 batch 11390 training_loss 0.6931471805599453
iteration 3 batch 11400 training_loss 0.6931471805599453
iteration 3 batch 11410 training_loss 0.6931471805599453
iteration 3 batch 11420 training_loss 0.6931471805599453
iteration 3 batch 11430 training_loss 0.6931471805599453
iteration 3 batch 11440 training_loss 0.6931471805599453
iteration 3 batch 11450 training_loss 0.6931471805599453
iteration 3 batch 11460 training_loss 0.6931471805599453
iteration 3 batch 11470 training_loss 0.6931471805599453
iteration 3 batch 11480 training_loss 0.6931471805599453
iteration 3 batch 11490 training_loss 0.6931471805599453
iteration 3 batch 11500 training_loss 0.6931471805599453
iteration 3 batch 11510 training_loss 0.6931471805599453
iteration 3 batch 11520 training_loss 0.6931471805599453
iteration 3 batch 11530 training_loss 0.6931471805599453
iteration 3 batch 11540 training_loss 0.6931471805599453
iteration 3 batch 11550 training_loss 0.6931471805599453
iteration 3 batch 11560 training_loss 0.6931471805599453
iteration 3 batch 11570 training_loss 0.6931471805599453
iteration 3 batch 11580 training_loss 0.6931471805599453
iteration 3 batch 11590 training_loss 0.6931471805599453
iteration 3 batch 11600 training_loss 0.6931471805599453
iteration 3 batch 11610 training_loss 0.6931471805599453
iteration 3 batch 11620 training_loss 0.6931471805599453
iteration 3 batch 11630 training_loss 0.6931471805599453
iteration 3 batch 11640 training_loss 0.6931471805599453
iteration 3 batch 11650 training_loss 0.6931471805599453
iteration 3 batch 11660 training_loss 0.6931471805599453
iteration 3 batch 11670 training_loss 0.6931471805599453
iteration 3 batch 11680 training_loss 0.6901793251455568
iteration 3 batch 11690 training_loss 0.6931471805599453
iteration 3 batch 11700 training_loss 0.6931471805599453
iteration 3 batch 11710 training_loss 0.6931471805599453
iteration 3 batch 11720 training_loss 0.6931471805599453
iteration 3 batch 11730 training_loss 0.6931471805599453
iteration 3 batch 11740 training_loss 0.6931471805599453
iteration 3 batch 11750 training_loss 0.6931471805599453
iteration 3 batch 11760 training_loss 0.6931471805599453
iteration 3 batch 11770 training_loss 0.6931471805599453
iteration 3 batch 11780 training_loss 0.6916632528527511
iteration 3 batch 11790 training_loss 0.6931471805599453
iteration 3 batch 11800 training_loss 0.6931471805599453
iteration 3 batch 11810 training_loss 0.6931471805599453
iteration 3 batch 11820 training_loss 0.6931471805599453
iteration 3 batch 11830 training_loss 0.6916632528527511
iteration 3 batch 11840 training_loss 0.6931471805599453
iteration 3 batch 11850 training_loss 0.6931471805599453
iteration 3 batch 11860 training_loss 0.6931471805599453
iteration 3 batch 11870 training_loss 0.6931471805599453
iteration 3 batch 11880 training_loss 0.6931471805599453
iteration 3 batch 11890 training_loss 0.6916632528527511
iteration 3 batch 11900 training_loss 0.6931471805599453
iteration 3 batch 11910 training_loss 0.6931471805599453
iteration 3 batch 11920 training_loss 0.6931471805599453
iteration 3 batch 11930 training_loss 0.6931471805599453
iteration 3 batch 11940 training_loss 0.6931471805599453
iteration 3 batch 11950 training_loss 0.6931471805599453
iteration 3 batch 11960 training_loss 0.6931471805599453
iteration 3 batch 11970 training_loss 0.6931471805599453
iteration 3 batch 11980 training_loss 0.6931471805599453
iteration 3 batch 11990 training_loss 0.6931471805599453
iteration 3 batch 12000 training_loss 0.6931471805599453
iteration 3 batch 12010 training_loss 0.6931471805599453
iteration 3 batch 12020 training_loss 0.6931471805599453
iteration 3 batch 12030 training_loss 0.6931471805599453
iteration 3 batch 12040 training_loss 0.6931471805599453
iteration 3 batch 12050 training_loss 0.6931471805599453
iteration 3 batch 12060 training_loss 0.6931471805599453
iteration 3 batch 12070 training_loss 0.6931471805599453
iteration 3 batch 12080 training_loss 0.6916632528527511
iteration 3 batch 12090 training_loss 0.6931471805599453
iteration 3 batch 12100 training_loss 0.6931471805599453
iteration 3 batch 12110 training_loss 0.6916632528527511
iteration 3 batch 12120 training_loss 0.6931471805599453
iteration 3 batch 12130 training_loss 0.6931471805599453
iteration 3 batch 12140 training_loss 0.6931471805599453
iteration 3 batch 12150 training_loss 0.6931471805599453
iteration 3 batch 12160 training_loss 0.6931471805599453
iteration 3 batch 12170 training_loss 0.6931471805599453
iteration 3 batch 12180 training_loss 0.6931471805599453
iteration 3 batch 12190 training_loss 0.6931471805599453
iteration 3 batch 12200 training_loss 0.6931471805599453
iteration 3 batch 12210 training_loss 0.6931471805599453
iteration 3 batch 12220 training_loss 0.6931471805599453
iteration 3 batch 12230 training_loss 0.6931471805599453
iteration 3 batch 12240 training_loss 0.6931471805599453
iteration 3 batch 12250 training_loss 0.6916632528527511
iteration 3 batch 12260 training_loss 0.6931471805599453
iteration 3 batch 12270 training_loss 0.6931471805599453
iteration 3 batch 12280 training_loss 0.6931471805599453
iteration 3 batch 12290 training_loss 0.6931471805599453
iteration 3 batch 12300 training_loss 0.6931471805599453
iteration 3 batch 12310 training_loss 0.6916632528527511
iteration 3 batch 12320 training_loss 0.6931471805599453
iteration 3 batch 12330 training_loss 0.6931471805599453
iteration 3 batch 12340 training_loss 0.6916632528527511
iteration 3 batch 12350 training_loss 0.6931471805599453
iteration 3 batch 12360 training_loss 0.6931471805599453
iteration 3 batch 12370 training_loss 0.6931471805599453
iteration 3 batch 12380 training_loss 0.6931471805599453
iteration 3 batch 12390 training_loss 0.6931471805599453
iteration 3 batch 12400 training_loss 0.6931471805599453
iteration 3 batch 12410 training_loss 0.6931471805599453
iteration 3 batch 12420 training_loss 0.6931471805599453
iteration 3 batch 12430 training_loss 0.6931471805599453
iteration 3 batch 12440 training_loss 0.6931471805599453
iteration 3 batch 12450 training_loss 0.6931471805599453
iteration 3 batch 12460 training_loss 0.6931471805599453
iteration 3 batch 12470 training_loss 0.6931471805599453
iteration 3 batch 12480 training_loss 0.6931471805599453
iteration 3 batch 12490 training_loss 0.6931471805599453
iteration 3 batch 12500 training_loss 0.6931471805599453
iteration 3 batch 12510 training_loss 0.6931471805599453
iteration 3 batch 12520 training_loss 0.6931471805599453
iteration 3 batch 12530 training_loss 0.6931471805599453
iteration 3 batch 12540 training_loss 0.6931471805599453
iteration 3 batch 12550 training_loss 0.6931471805599453
iteration 3 batch 12560 training_loss 0.6931471805599453
iteration 3 batch 12570 training_loss 0.6916632528527511
iteration 3 batch 12580 training_loss 0.6931471805599453
iteration 3 batch 12590 training_loss 0.6931471805599453
iteration 3 batch 12600 training_loss 0.6931471805599453
iteration 3 batch 12610 training_loss 0.6916632528527511
iteration 3 batch 12620 training_loss 0.6931471805599453
iteration 3 batch 12630 training_loss 0.6931471805599453
iteration 3 batch 12640 training_loss 0.6931471805599453
iteration 3 batch 12650 training_loss 0.6931471805599453
iteration 3 batch 12660 training_loss 0.6931471805599453
iteration 3 batch 12670 training_loss 0.6931471805599453
iteration 3 batch 12680 training_loss 0.6931471805599453
iteration 3 batch 12690 training_loss 0.6931471805599453
iteration 3 batch 12700 training_loss 0.6931471805599453
iteration 3 batch 12710 training_loss 0.6931471805599453
iteration 3 batch 12720 training_loss 0.6931471805599453
iteration 3 batch 12730 training_loss 0.6931471805599453
iteration 3 batch 12740 training_loss 0.6931471805599453
iteration 3 batch 12750 training_loss 0.6931471805599453
iteration 3 batch 12760 training_loss 0.6931471805599453
iteration 3 batch 12770 training_loss 0.6931471805599453
iteration 3 batch 12780 training_loss 0.6916632528527511
iteration 3 batch 12790 training_loss 0.6931471805599453
iteration 3 batch 12800 training_loss 0.6931471805599453
iteration 3 batch 12810 training_loss 0.6931471805599453
iteration 3 batch 12820 training_loss 0.6931471805599453
iteration 3 batch 12830 training_loss 0.6931471805599453
iteration 3 batch 12840 training_loss 0.6931471805599453
iteration 3 batch 12850 training_loss 0.6931471805599453
iteration 3 batch 12860 training_loss 0.6931471805599453
iteration 3 batch 12870 training_loss 0.6931471805599453
iteration 3 batch 12880 training_loss 0.6931471805599453
iteration 3 batch 12890 training_loss 0.6931471805599453
iteration 3 batch 12900 training_loss 0.6916632528527511
iteration 3 batch 12910 training_loss 0.6931471805599453
iteration 3 batch 12920 training_loss 0.6916632528527511
iteration 3 batch 12930 training_loss 0.6931471805599453
iteration 3 batch 12940 training_loss 0.6931471805599453
iteration 3 batch 12950 training_loss 0.6931471805599453
iteration 3 batch 12960 training_loss 0.6931471805599453
iteration 3 batch 12970 training_loss 0.6931471805599453
iteration 3 batch 12980 training_loss 0.6931471805599453
iteration 3 batch 12990 training_loss 0.6931471805599453
iteration 3 batch 13000 training_loss 0.6931471805599453
iteration 3 batch 13010 training_loss 0.6931471805599453
iteration 3 batch 13020 training_loss 0.6931471805599453
iteration 3 batch 13030 training_loss 0.6931471805599453
iteration 3 batch 13040 training_loss 0.6931471805599453
iteration 3 batch 13050 training_loss 0.6931471805599453
iteration 3 batch 13060 training_loss 0.6931471805599453
iteration 3 batch 13070 training_loss 0.6931471805599453
iteration 3 batch 13080 training_loss 0.6931471805599453
iteration 3 batch 13090 training_loss 0.6931471805599453
iteration 3 batch 13100 training_loss 0.6931471805599453
iteration 3 batch 13110 training_loss 0.6916632528527511
iteration 3 batch 13120 training_loss 0.6931471805599453
iteration 3 batch 13130 training_loss 0.6931471805599453
iteration 3 batch 13140 training_loss 0.6916632528527511
iteration 3 batch 13150 training_loss 0.6931471805599453
iteration 3 batch 13160 training_loss 0.6931471805599453
iteration 3 batch 13170 training_loss 0.6931471805599453
iteration 3 batch 13180 training_loss 0.6931471805599453
iteration 3 batch 13190 training_loss 0.6931471805599453
iteration 3 batch 13200 training_loss 0.6916632528527511
iteration 3 batch 13210 training_loss 0.6916632528527511
iteration 3 batch 13220 training_loss 0.6931471805599453
iteration 3 batch 13230 training_loss 0.6931471805599453
iteration 3 batch 13240 training_loss 0.6931471805599453
iteration 3 batch 13250 training_loss 0.6931471805599453
iteration 3 batch 13260 training_loss 0.6931471805599453
iteration 3 batch 13270 training_loss 0.6931471805599453
iteration 3 batch 13280 training_loss 0.6931471805599453
iteration 3 batch 13290 training_loss 0.6931471805599453
iteration 3 batch 13300 training_loss 0.6931471805599453
iteration 3 batch 13310 training_loss 0.6931471805599453
iteration 3 batch 13320 training_loss 0.6931471805599453
iteration 3 batch 13330 training_loss 0.6931471805599453
iteration 3 batch 13340 training_loss 0.6931471805599453
iteration 3 batch 13350 training_loss 0.6931471805599453
iteration 3 batch 13360 training_loss 0.6916632528527511
iteration 3 batch 13370 training_loss 0.6931471805599453
iteration 3 batch 13380 training_loss 0.6931471805599453
iteration 3 batch 13390 training_loss 0.6916632528527511
iteration 3 batch 13400 training_loss 0.6931471805599453
iteration 3 batch 13410 training_loss 0.6931471805599453
iteration 3 batch 13420 training_loss 0.6931471805599453
iteration 3 batch 13430 training_loss 0.6931471805599453
iteration 3 batch 13440 training_loss 0.6931471805599453
iteration 3 batch 13450 training_loss 0.6931471805599453
iteration 3 batch 13460 training_loss 0.6931471805599453
iteration 3 batch 13470 training_loss 0.6931471805599453
iteration 3 batch 13480 training_loss 0.6931471805599453
iteration 3 batch 13490 training_loss 0.6931471805599453
iteration 3 batch 13500 training_loss 0.6931471805599453
iteration 3 batch 13510 training_loss 0.6931471805599453
iteration 3 batch 13520 training_loss 0.6931471805599453
iteration 3 batch 13530 training_loss 0.6931471805599453
iteration 3 batch 13540 training_loss 0.6931471805599453
iteration 3 batch 13550 training_loss 0.6931471805599453
iteration 3 batch 13560 training_loss 0.6931471805599453
iteration 3 batch 13570 training_loss 0.6931471805599453
iteration 3 batch 13580 training_loss 0.6916632528527511
iteration 3 batch 13590 training_loss 0.6931471805599453
iteration 3 batch 13600 training_loss 0.6931471805599453
iteration 3 batch 13610 training_loss 0.6931471805599453
iteration 3 batch 13620 training_loss 0.6931471805599453
iteration 3 batch 13630 training_loss 0.6931471805599453
iteration 3 batch 13640 training_loss 0.6931471805599453
iteration 3 batch 13650 training_loss 0.6931471805599453
iteration 3 batch 13660 training_loss 0.6931471805599453
iteration 3 batch 13670 training_loss 0.6931471805599453
iteration 3 batch 13680 training_loss 0.6931471805599453
iteration 3 batch 13690 training_loss 0.6931471805599453
iteration 3 batch 13700 training_loss 0.6931471805599453
iteration 3 batch 13710 training_loss 0.6931471805599453
iteration 3 batch 13720 training_loss 0.6931471805599453
iteration 3 batch 13730 training_loss 0.6931471805599453
iteration 3 batch 13740 training_loss 0.6931471805599453
iteration 3 batch 13750 training_loss 0.6931471805599453
iteration 3 batch 13760 training_loss 0.6931471805599453
iteration 3 batch 13770 training_loss 0.6931471805599453
iteration 3 batch 13780 training_loss 0.6931471805599453
iteration 3 batch 13790 training_loss 0.6931471805599453
iteration 3 batch 13800 training_loss 0.6931471805599453
iteration 3 batch 13810 training_loss 0.6931471805599453
iteration 3 batch 13820 training_loss 0.6931471805599453
iteration 3 batch 13830 training_loss 0.6931471805599453
iteration 3 batch 13840 training_loss 0.6931471805599453
iteration 3 batch 13850 training_loss 0.6931471805599453
iteration 3 batch 13860 training_loss 0.6931471805599453
iteration 3 batch 13870 training_loss 0.6931471805599453
iteration 3 batch 13880 training_loss 0.6931471805599453
iteration 3 batch 13890 training_loss 0.6931471805599453
iteration 3 batch 13900 training_loss 0.6931471805599453
iteration 3 batch 13910 training_loss 0.6931471805599453
iteration 3 batch 13920 training_loss 0.6931471805599453
iteration 3 batch 13930 training_loss 0.6916632528527511
iteration 3 batch 13940 training_loss 0.6931471805599453
iteration 3 batch 13950 training_loss 0.6931471805599453
iteration 3 batch 13960 training_loss 0.6931471805599453
iteration 3 batch 13970 training_loss 0.6931471805599453
iteration 3 batch 13980 training_loss 0.6916632528527511
iteration 3 batch 13990 training_loss 0.6931471805599453
iteration 3 batch 14000 training_loss 0.6931471805599453
iteration 3 batch 14010 training_loss 0.6916632528527511
iteration 3 batch 14020 training_loss 0.6931471805599453
iteration 3 batch 14030 training_loss 0.6916632528527511
iteration 3 batch 14040 training_loss 0.6931471805599453
iteration 3 batch 14050 training_loss 0.6931471805599453
iteration 3 batch 14060 training_loss 0.6931471805599453
iteration 3 batch 14070 training_loss 0.6931471805599453
iteration 3 batch 14080 training_loss 0.6931471805599453
iteration 3 batch 14090 training_loss 0.6931471805599453
iteration 3 batch 14100 training_loss 0.6931471805599453
iteration 3 batch 14110 training_loss 0.6931471805599453
iteration 3 batch 14120 training_loss 0.6931471805599453
iteration 3 batch 14130 training_loss 0.6931471805599453
iteration 3 batch 14140 training_loss 0.6931471805599453
iteration 3 batch 14150 training_loss 0.6931471805599453
iteration 3 batch 14160 training_loss 0.6931471805599453
iteration 3 batch 14170 training_loss 0.6931471805599453
iteration 3 batch 14180 training_loss 0.6931471805599453
iteration 3 batch 14190 training_loss 0.6931471805599453
iteration 3 batch 14200 training_loss 0.6931471805599453
iteration 3 batch 14210 training_loss 0.6916632528527511
iteration 3 batch 14220 training_loss 0.6931471805599453
iteration 3 batch 14230 training_loss 0.6931471805599453
iteration 3 batch 14240 training_loss 0.6931471805599453
iteration 3 batch 14250 training_loss 0.6931471805599453
iteration 3 batch 14260 training_loss 0.6931471805599453
iteration 3 batch 14270 training_loss 0.6931471805599453
iteration 3 batch 14280 training_loss 0.6931471805599453
iteration 3 batch 14290 training_loss 0.6931471805599453
iteration 3 batch 14300 training_loss 0.6931471805599453
iteration 3 batch 14310 training_loss 0.6931471805599453
iteration 3 batch 14320 training_loss 0.6931471805599453
iteration 3 batch 14330 training_loss 0.6916632528527511
iteration 3 batch 14340 training_loss 0.6931471805599453
iteration 3 batch 14350 training_loss 0.6931471805599453
iteration 3 batch 14360 training_loss 0.6931471805599453
iteration 3 batch 14370 training_loss 0.6931471805599453
iteration 3 batch 14380 training_loss 0.6916632528527511
iteration 3 batch 14390 training_loss 0.6916632528527511
iteration 3 batch 14400 training_loss 0.6931471805599453
iteration 3 batch 14410 training_loss 0.6931471805599453
iteration 3 batch 14420 training_loss 0.6931471805599453
iteration 3 batch 14430 training_loss 0.6931471805599453
iteration 3 batch 14440 training_loss 0.6931471805599453
iteration 3 batch 14450 training_loss 0.6931471805599453
iteration 3 batch 14460 training_loss 0.6931471805599453
iteration 3 batch 14470 training_loss 0.6916632528527511
iteration 3 batch 14480 training_loss 0.6916632528527511
iteration 3 batch 14490 training_loss 0.6931471805599453
iteration 3 batch 14500 training_loss 0.6931471805599453
iteration 3 batch 14510 training_loss 0.6931471805599453
iteration 3 batch 14520 training_loss 0.6931471805599453
iteration 3 batch 14530 training_loss 0.6931471805599453
iteration 3 batch 14540 training_loss 0.6931471805599453
iteration 3 batch 14550 training_loss 0.6931471805599453
iteration 3 batch 14560 training_loss 0.6931471805599453
iteration 3 batch 14570 training_loss 0.6931471805599453
iteration 3 batch 14580 training_loss 0.6931471805599453
iteration 3 batch 14590 training_loss 0.6916632528527511
iteration 3 batch 14600 training_loss 0.6931471805599453
iteration 3 batch 14610 training_loss 0.6931471805599453
iteration 3 batch 14620 training_loss 0.6931471805599453
iteration 3 batch 14630 training_loss 0.6931471805599453
iteration 3 batch 14640 training_loss 0.6916632528527511
iteration 3 batch 14650 training_loss 0.6916632528527511
iteration 3 batch 14660 training_loss 0.6931471805599453
iteration 3 batch 14670 training_loss 0.6931471805599453
iteration 3 batch 14680 training_loss 0.6931471805599453
iteration 3 batch 14690 training_loss 0.6931471805599453
iteration 3 batch 14700 training_loss 0.6931471805599453
iteration 3 batch 14710 training_loss 0.6931471805599453
iteration 3 batch 14720 training_loss 0.6931471805599453
iteration 3 batch 14730 training_loss 0.6916632528527511
iteration 3 batch 14740 training_loss 0.6931471805599453
iteration 3 batch 14750 training_loss 0.6931471805599453
iteration 3 batch 14760 training_loss 0.6931471805599453
iteration 3 batch 14770 training_loss 0.6931471805599453
iteration 3 batch 14780 training_loss 0.6931471805599453
iteration 3 batch 14790 training_loss 0.6931471805599453
iteration 3 batch 14800 training_loss 0.6931471805599453
iteration 3 batch 14810 training_loss 0.6931471805599453
iteration 3 batch 14820 training_loss 0.6931471805599453
iteration 3 batch 14830 training_loss 0.6931471805599453
iteration 3 batch 14840 training_loss 0.6931471805599453
iteration 3 batch 14850 training_loss 0.6931471805599453
iteration 3 batch 14860 training_loss 0.6931471805599453
iteration 3 batch 14870 training_loss 0.6931471805599453
iteration 3 batch 14880 training_loss 0.6931471805599453
iteration 3 batch 14890 training_loss 0.6931471805599453
iteration 3 batch 14900 training_loss 0.6931471805599453
iteration 3 batch 14910 training_loss 0.6931471805599453
iteration 3 batch 14920 training_loss 0.6931471805599453
iteration 3 batch 14930 training_loss 0.6931471805599453
iteration 3 batch 14940 training_loss 0.6931471805599453
iteration 3 batch 14950 training_loss 0.6931471805599453
iteration 3 batch 14960 training_loss 0.6931471805599453
iteration 3 batch 14970 training_loss 0.6931471805599453
iteration 3 batch 14980 training_loss 0.6931471805599453
iteration 3 batch 14990 training_loss 0.6931471805599453
iteration 3 batch 15000 training_loss 0.6931471805599453
iteration 3 batch 15010 training_loss 0.6931471805599453
iteration 3 batch 15020 training_loss 0.6931471805599453
iteration 3 batch 15030 training_loss 0.6931471805599453
iteration 3 batch 15040 training_loss 0.6931471805599453
iteration 3 batch 15050 training_loss 0.6931471805599453
iteration 3 batch 15060 training_loss 0.6931471805599453
iteration 3 batch 15070 training_loss 0.6931471805599453
iteration 3 batch 15080 training_loss 0.6931471805599453
iteration 3 batch 15090 training_loss 0.6931471805599453
iteration 3 batch 15100 training_loss 0.6931471805599453
iteration 3 batch 15110 training_loss 0.6931471805599453
iteration 3 batch 15120 training_loss 0.6931471805599453
iteration 3 batch 15130 training_loss 0.6931471805599453
iteration 3 batch 15140 training_loss 0.6931471805599453
iteration 3 batch 15150 training_loss 0.6931471805599453
iteration 3 batch 15160 training_loss 0.6931471805599453
iteration 3 batch 15170 training_loss 0.6931471805599453
iteration 3 batch 15180 training_loss 0.6931471805599453
iteration 3 batch 15190 training_loss 0.6931471805599453
iteration 3 batch 15200 training_loss 0.6931471805599453
iteration 3 batch 15210 training_loss 0.6931471805599453
iteration 3 batch 15220 training_loss 0.6931471805599453
iteration 3 batch 15230 training_loss 0.6931471805599453
iteration 3 batch 15240 training_loss 0.6931471805599453
iteration 3 batch 15250 training_loss 0.6931471805599453
iteration 3 batch 15260 training_loss 0.6931471805599453
iteration 3 batch 15270 training_loss 0.6931471805599453
iteration 3 batch 15280 training_loss 0.6931471805599453
iteration 3 batch 15290 training_loss 0.6931471805599453
iteration 3 batch 15300 training_loss 0.6931471805599453
iteration 3 batch 15310 training_loss 0.6931471805599453
iteration 3 batch 15320 training_loss 0.6931471805599453
iteration 3 batch 15330 training_loss 0.6931471805599453
iteration 3 batch 15340 training_loss 0.6931471805599453
iteration 3 batch 15350 training_loss 0.6931471805599453
iteration 3 batch 15360 training_loss 0.6931471805599453
iteration 3 batch 15370 training_loss 0.6931471805599453
iteration 3 batch 15380 training_loss 0.6931471805599453
iteration 3 batch 15390 training_loss 0.6931471805599453
iteration 3 batch 15400 training_loss 0.6931471805599453
iteration 3 batch 15410 training_loss 0.6931471805599453
iteration 3 batch 15420 training_loss 0.6931471805599453
iteration 3 batch 15430 training_loss 0.6916632528527511
iteration 3 batch 15440 training_loss 0.6931471805599453
iteration 3 batch 15450 training_loss 0.6931471805599453
iteration 3 batch 15460 training_loss 0.6931471805599453
iteration 3 batch 15470 training_loss 0.6931471805599453
iteration 3 batch 15480 training_loss 0.6931471805599453
iteration 3 batch 15490 training_loss 0.6931471805599453
iteration 3 batch 15500 training_loss 0.6931471805599453
iteration 3 batch 15510 training_loss 0.6931471805599453
iteration 3 batch 15520 training_loss 0.6931471805599453
iteration 3 batch 15530 training_loss 0.6931471805599453
iteration 3 batch 15540 training_loss 0.6931471805599453
iteration 3 batch 15550 training_loss 0.6931471805599453
iteration 3 batch 15560 training_loss 0.6931471805599453
iteration 3 batch 15570 training_loss 0.6916632528527511
iteration 3 batch 15580 training_loss 0.6931471805599453
iteration 3 batch 15590 training_loss 0.6931471805599453
iteration 3 batch 15600 training_loss 0.6931471805599453
iteration 3 batch 15610 training_loss 0.6931471805599453
iteration 3 batch 15620 training_loss 0.6931471805599453
iteration 3 batch 15630 training_loss 0.6931471805599453
iteration 3 batch 15640 training_loss 0.6916632528527511
iteration 3 batch 15650 training_loss 0.6931471805599453
iteration 3 batch 15660 training_loss 0.6916632528527511
iteration 3 batch 15670 training_loss 0.6931471805599453
iteration 3 batch 15680 training_loss 0.6931471805599453
iteration 3 batch 15690 training_loss 0.6931471805599453
iteration 3 batch 15700 training_loss 0.6931471805599453
iteration 3 batch 15710 training_loss 0.6931471805599453
iteration 3 batch 15720 training_loss 0.6931471805599453
iteration 3 batch 15730 training_loss 0.6931471805599453
iteration 3 batch 15740 training_loss 0.6931471805599453
iteration 3 batch 15750 training_loss 0.6931471805599453
iteration 3 batch 15760 training_loss 0.6931471805599453
iteration 3 batch 15770 training_loss 0.6931471805599453
iteration 3 batch 15780 training_loss 0.6931471805599453
iteration 3 batch 15790 training_loss 0.6931471805599453
iteration 3 batch 15800 training_loss 0.6931471805599453
iteration 3 batch 15810 training_loss 0.6931471805599453
iteration 3 batch 15820 training_loss 0.6931471805599453
iteration 3 batch 15830 training_loss 0.6916632528527511
iteration 3 batch 15840 training_loss 0.6931471805599453
iteration 3 batch 15850 training_loss 0.6916632528527511
iteration 3 batch 15860 training_loss 0.6931471805599453
iteration 3 batch 15870 training_loss 0.6931471805599453
iteration 3 batch 15880 training_loss 0.6931471805599453
iteration 3 batch 15890 training_loss 0.6931471805599453
iteration 3 batch 15900 training_loss 0.6931471805599453
iteration 3 batch 15910 training_loss 0.6931471805599453
iteration 3 batch 15920 training_loss 0.6931471805599453
iteration 3 batch 15930 training_loss 0.6916632528527511
iteration 3 batch 15940 training_loss 0.6931471805599453
iteration 3 batch 15950 training_loss 0.6931471805599453
iteration 3 batch 15960 training_loss 0.6931471805599453
iteration 3 batch 15970 training_loss 0.6931471805599453
iteration 3 batch 15980 training_loss 0.6931471805599453
iteration 3 batch 15990 training_loss 0.6931471805599453
iteration 3 batch 16000 training_loss 0.6931471805599453
iteration 3 batch 16010 training_loss 0.6931471805599453
iteration 3 batch 16020 training_loss 0.6931471805599453
iteration 3 batch 16030 training_loss 0.6931471805599453
iteration 3 batch 16040 training_loss 0.6916632528527511
iteration 3 batch 16050 training_loss 0.6931471805599453
iteration 3 batch 16060 training_loss 0.6931471805599453
iteration 3 batch 16070 training_loss 0.6931471805599453
iteration 3 batch 16080 training_loss 0.6931471805599453
iteration 3 batch 16090 training_loss 0.6931471805599453
iteration 3 batch 16100 training_loss 0.6931471805599453
iteration 3 batch 16110 training_loss 0.6931471805599453
iteration 3 batch 16120 training_loss 0.6931471805599453
iteration 3 batch 16130 training_loss 0.6931471805599453
iteration 3 batch 16140 training_loss 0.6931471805599453
iteration 3 batch 16150 training_loss 0.6931471805599453
iteration 3 batch 16160 training_loss 0.6931471805599453
iteration 3 batch 16170 training_loss 0.6931471805599453
iteration 3 batch 16180 training_loss 0.6916632528527511
iteration 3 batch 16190 training_loss 0.6931471805599453
iteration 3 batch 16200 training_loss 0.6931471805599453
iteration 3 batch 16210 training_loss 0.6931471805599453
iteration 3 batch 16220 training_loss 0.6931471805599453
iteration 3 batch 16230 training_loss 0.6931471805599453
iteration 3 batch 16240 training_loss 0.6931471805599453
iteration 3 batch 16250 training_loss 0.6931471805599453
iteration 3 batch 16260 training_loss 0.6916632528527511
iteration 3 batch 16270 training_loss 0.6931471805599453
iteration 3 batch 16280 training_loss 0.6931471805599453
iteration 3 batch 16290 training_loss 0.6931471805599453
iteration 3 batch 16300 training_loss 0.6931471805599453
iteration 3 batch 16310 training_loss 0.6931471805599453
iteration 3 batch 16320 training_loss 0.6931471805599453
iteration 3 batch 16330 training_loss 0.6916632528527511
iteration 3 batch 16340 training_loss 0.6931471805599453
iteration 3 batch 16350 training_loss 0.6931471805599453
iteration 3 batch 16360 training_loss 0.6931471805599453
iteration 3 batch 16370 training_loss 0.6931471805599453
iteration 3 batch 16380 training_loss 0.6931471805599453
iteration 3 batch 16390 training_loss 0.6931471805599453
iteration 3 batch 16400 training_loss 0.6931471805599453
iteration 3 batch 16410 training_loss 0.6931471805599453
iteration 3 batch 16420 training_loss 0.6931471805599453
iteration 3 batch 16430 training_loss 0.6931471805599453
iteration 3 batch 16440 training_loss 0.6931471805599453
iteration 3 batch 16450 training_loss 0.6931471805599453
iteration 3 batch 16460 training_loss 0.6931471805599453
iteration 3 batch 16470 training_loss 0.6931471805599453
iteration 3 batch 16480 training_loss 0.6931471805599453
iteration 3 batch 16490 training_loss 0.6931471805599453
iteration 3 batch 16500 training_loss 0.6931471805599453
iteration 3 batch 16510 training_loss 0.6931471805599453
iteration 3 batch 16520 training_loss 0.6931471805599453
iteration 3 batch 16530 training_loss 0.6931471805599453
iteration 3 batch 16540 training_loss 0.6931471805599453
iteration 3 batch 16550 training_loss 0.6931471805599453
iteration 3 batch 16560 training_loss 0.6931471805599453
iteration 3 batch 16570 training_loss 0.6916632528527511
iteration 3 batch 16580 training_loss 0.6931471805599453
iteration 3 batch 16590 training_loss 0.6931471805599453
iteration 3 batch 16600 training_loss 0.6931471805599453
iteration 3 batch 16610 training_loss 0.6931471805599453
iteration 3 batch 16620 training_loss 0.6931471805599453
iteration 3 batch 16630 training_loss 0.6931471805599453
iteration 3 batch 16640 training_loss 0.6931471805599453
iteration 3 batch 16650 training_loss 0.6916632528527511
iteration 3 batch 16660 training_loss 0.6931471805599453
iteration 3 batch 16670 training_loss 0.6931471805599453
iteration 3 batch 16680 training_loss 0.6931471805599453
iteration 3 batch 16690 training_loss 0.6931471805599453
iteration 3 batch 16700 training_loss 0.6931471805599453
iteration 3 batch 16710 training_loss 0.6931471805599453
iteration 3 batch 16720 training_loss 0.6931471805599453
iteration 3 batch 16730 training_loss 0.6931471805599453
iteration 3 batch 16740 training_loss 0.6916632528527511
iteration 3 batch 16750 training_loss 0.6931471805599453
iteration 3 batch 16760 training_loss 0.6931471805599453
iteration 3 batch 16770 training_loss 0.6931471805599453
iteration 3 batch 16780 training_loss 0.6931471805599453
iteration 3 batch 16790 training_loss 0.6931471805599453
iteration 3 batch 16800 training_loss 0.6931471805599453
iteration 3 batch 16810 training_loss 0.6916632528527511
iteration 3 batch 16820 training_loss 0.6931471805599453
iteration 3 batch 16830 training_loss 0.6916632528527511
iteration 3 batch 16840 training_loss 0.6931471805599453
iteration 3 batch 16850 training_loss 0.6931471805599453
iteration 3 batch 16860 training_loss 0.6931471805599453
iteration 3 batch 16870 training_loss 0.6931471805599453
iteration 3 batch 16880 training_loss 0.6931471805599453
iteration 3 batch 16890 training_loss 0.6931471805599453
iteration 3 batch 16900 training_loss 0.6916632528527511
iteration 3 batch 16910 training_loss 0.6931471805599453
iteration 3 batch 16920 training_loss 0.6931471805599453
iteration 3 batch 16930 training_loss 0.6931471805599453
iteration 3 batch 16940 training_loss 0.6931471805599453
iteration 3 batch 16950 training_loss 0.6931471805599453
iteration 3 batch 16960 training_loss 0.6931471805599453
iteration 3 batch 16970 training_loss 0.6931471805599453
iteration 3 batch 16980 training_loss 0.6931471805599453
iteration 3 batch 16990 training_loss 0.6931471805599453
iteration 3 batch 17000 training_loss 0.6931471805599453
iteration 3 batch 17010 training_loss 0.6931471805599453
iteration 3 batch 17020 training_loss 0.6931471805599453
iteration 3 batch 17030 training_loss 0.6931471805599453
iteration 3 batch 17040 training_loss 0.6931471805599453
iteration 3 batch 17050 training_loss 0.6931471805599453
iteration 3 batch 17060 training_loss 0.6931471805599453
iteration 3 batch 17070 training_loss 0.6931471805599453
iteration 3 batch 17080 training_loss 0.6916632528527511
iteration 3 batch 17090 training_loss 0.6931471805599453
iteration 3 batch 17100 training_loss 0.6931471805599453
iteration 3 batch 17110 training_loss 0.6931471805599453
iteration 3 batch 17120 training_loss 0.6931471805599453
iteration 3 batch 17130 training_loss 0.6931471805599453
iteration 3 batch 17140 training_loss 0.6931471805599453
iteration 3 batch 17150 training_loss 0.6931471805599453
iteration 3 batch 17160 training_loss 0.6931471805599453
iteration 3 batch 17170 training_loss 0.6931471805599453
iteration 3 batch 17180 training_loss 0.6931471805599453
iteration 3 batch 17190 training_loss 0.6931471805599453
iteration 3 batch 17200 training_loss 0.6931471805599453
iteration 3 batch 17210 training_loss 0.6931471805599453
iteration 3 batch 17220 training_loss 0.6931471805599453
iteration 3 batch 17230 training_loss 0.6931471805599453
iteration 3 batch 17240 training_loss 0.6931471805599453
iteration 3 batch 17250 training_loss 0.6931471805599453
iteration 3 batch 17260 training_loss 0.6931471805599453
iteration 3 batch 17270 training_loss 0.6916632528527511
iteration 3 batch 17280 training_loss 0.6931471805599453
iteration 3 batch 17290 training_loss 0.6931471805599453
iteration 3 batch 17300 training_loss 0.6931471805599453
iteration 3 batch 17310 training_loss 0.6931471805599453
iteration 3 batch 17320 training_loss 0.6931471805599453
iteration 3 batch 17330 training_loss 0.6931471805599453
iteration 3 batch 17340 training_loss 0.6931471805599453
iteration 3 batch 17350 training_loss 0.6931471805599453
iteration 3 batch 17360 training_loss 0.6931471805599453
iteration 3 batch 17370 training_loss 0.6931471805599453
iteration 3 batch 17380 training_loss 0.6931471805599453
iteration 3 batch 17390 training_loss 0.6931471805599453
iteration 3 batch 17400 training_loss 0.6931471805599453
iteration 3 batch 17410 training_loss 0.6931471805599453
iteration 3 batch 17420 training_loss 0.6931471805599453
iteration 3 batch 17430 training_loss 0.6931471805599453
iteration 3 batch 17440 training_loss 0.6931471805599453
iteration 3 batch 17450 training_loss 0.6931471805599453
iteration 3 batch 17460 training_loss 0.6931471805599453
iteration 3 batch 17470 training_loss 0.6931471805599453
iteration 3 batch 17480 training_loss 0.6931471805599453
iteration 3 batch 17490 training_loss 0.6931471805599453
iteration 3 batch 17500 training_loss 0.6931471805599453
iteration 3 batch 17510 training_loss 0.6931471805599453
iteration 3 batch 17520 training_loss 0.6931471805599453
iteration 3 batch 17530 training_loss 0.6931471805599453
iteration 3 batch 17540 training_loss 0.6931471805599453
iteration 3 batch 17550 training_loss 0.6931471805599453
iteration 3 batch 17560 training_loss 0.6931471805599453
iteration 3 batch 17570 training_loss 0.6931471805599453
iteration 3 batch 17580 training_loss 0.6931471805599453
iteration 3 batch 17590 training_loss 0.6931471805599453
iteration 3 batch 17600 training_loss 0.6931471805599453
iteration 3 batch 17610 training_loss 0.6931471805599453
iteration 3 batch 17620 training_loss 0.6931471805599453
iteration 3 batch 17630 training_loss 0.6931471805599453
iteration 3 batch 17640 training_loss 0.6931471805599453
iteration 3 batch 17650 training_loss 0.6916632528527511
iteration 3 batch 17660 training_loss 0.6931471805599453
iteration 3 batch 17670 training_loss 0.6931471805599453
iteration 3 batch 17680 training_loss 0.6931471805599453
iteration 3 batch 17690 training_loss 0.6931471805599453
iteration 3 batch 17700 training_loss 0.6931471805599453
iteration 3 batch 17710 training_loss 0.6931471805599453
iteration 3 batch 17720 training_loss 0.6931471805599453
iteration 3 batch 17730 training_loss 0.6931471805599453
iteration 3 batch 17740 training_loss 0.6931471805599453
iteration 3 batch 17750 training_loss 0.6931471805599453
iteration 3 batch 17760 training_loss 0.6931471805599453
iteration 3 batch 17770 training_loss 0.6931471805599453
iteration 3 batch 17780 training_loss 0.6931471805599453
iteration 3 batch 17790 training_loss 0.6931471805599453
iteration 3 batch 17800 training_loss 0.6916632528527511
iteration 3 batch 17810 training_loss 0.6916632528527511
iteration 3 batch 17820 training_loss 0.6931471805599453
iteration 3 batch 17830 training_loss 0.6931471805599453
iteration 3 batch 17840 training_loss 0.6916632528527511
iteration 3 batch 17850 training_loss 0.6931471805599453
iteration 3 batch 17860 training_loss 0.6931471805599453
iteration 3 batch 17870 training_loss 0.6931471805599453
iteration 3 batch 17880 training_loss 0.6931471805599453
iteration 3 batch 17890 training_loss 0.6931471805599453
iteration 3 batch 17900 training_loss 0.6931471805599453
iteration 3 batch 17910 training_loss 0.6931471805599453
iteration 3 batch 17920 training_loss 0.6931471805599453
iteration 3 batch 17930 training_loss 0.6931471805599453
iteration 3 batch 17940 training_loss 0.6931471805599453
iteration 3 batch 17950 training_loss 0.6931471805599453
iteration 3 batch 17960 training_loss 0.6931471805599453
iteration 3 batch 17970 training_loss 0.6931471805599453
iteration 3 batch 17980 training_loss 0.6931471805599453
iteration 3 batch 17990 training_loss 0.6931471805599453
iteration 3 batch 18000 training_loss 0.6931471805599453
iteration 3 batch 18010 training_loss 0.6931471805599453
iteration 3 batch 18020 training_loss 0.6931471805599453
iteration 3 batch 18030 training_loss 0.6931471805599453
iteration 3 batch 18040 training_loss 0.6931471805599453
iteration 3 batch 18050 training_loss 0.6916632528527511
iteration 3 batch 18060 training_loss 0.6931471805599453
iteration 3 batch 18070 training_loss 0.6931471805599453
iteration 3 batch 18080 training_loss 0.6931471805599453
iteration 3 batch 18090 training_loss 0.6931471805599453
iteration 3 batch 18100 training_loss 0.6931471805599453
iteration 3 batch 18110 training_loss 0.6931471805599453
iteration 3 batch 18120 training_loss 0.6931471805599453
iteration 3 batch 18130 training_loss 0.6931471805599453
iteration 3 batch 18140 training_loss 0.6931471805599453
iteration 3 batch 18150 training_loss 0.6916632528527511
iteration 3 batch 18160 training_loss 0.6931471805599453
iteration 3 batch 18170 training_loss 0.6931471805599453
iteration 3 batch 18180 training_loss 0.6931471805599453
iteration 3 batch 18190 training_loss 0.6916632528527511
iteration 3 batch 18200 training_loss 0.6931471805599453
iteration 3 batch 18210 training_loss 0.6931471805599453
iteration 3 batch 18220 training_loss 0.6931471805599453
iteration 3 batch 18230 training_loss 0.6931471805599453
iteration 3 batch 18240 training_loss 0.6931471805599453
iteration 3 batch 18250 training_loss 0.6931471805599453
iteration 3 batch 18260 training_loss 0.6931471805599453
iteration 3 batch 18270 training_loss 0.6931471805599453
iteration 3 batch 18280 training_loss 0.6931471805599453
iteration 3 batch 18290 training_loss 0.6931471805599453
iteration 3 batch 18300 training_loss 0.6931471805599453
iteration 3 batch 18310 training_loss 0.6931471805599453
iteration 3 batch 18320 training_loss 0.6916632528527511
iteration 3 batch 18330 training_loss 0.6931471805599453
iteration 3 batch 18340 training_loss 0.6931471805599453
iteration 3 batch 18350 training_loss 0.6916632528527511
iteration 3 batch 18360 training_loss 0.6916632528527511
iteration 3 batch 18370 training_loss 0.6931471805599453
iteration 3 batch 18380 training_loss 0.6931471805599453
iteration 3 batch 18390 training_loss 0.6931471805599453
iteration 3 batch 18400 training_loss 0.6931471805599453
iteration 3 batch 18410 training_loss 0.6931471805599453
iteration 3 batch 18420 training_loss 0.6931471805599453
iteration 3 batch 18430 training_loss 0.6931471805599453
iteration 3 batch 18440 training_loss 0.6931471805599453
iteration 3 batch 18450 training_loss 0.6931471805599453
iteration 3 batch 18460 training_loss 0.6931471805599453
iteration 3 batch 18470 training_loss 0.6901793251455568
iteration 3 batch 18480 training_loss 0.6931471805599453
iteration 3 batch 18490 training_loss 0.6916632528527511
iteration 3 batch 18500 training_loss 0.6916632528527511
iteration 3 batch 18510 training_loss 0.6931471805599453
iteration 3 batch 18520 training_loss 0.6931471805599453
iteration 3 batch 18530 training_loss 0.6931471805599453
iteration 3 batch 18540 training_loss 0.6931471805599453
iteration 3 batch 18550 training_loss 0.6931471805599453
iteration 3 batch 18560 training_loss 0.6931471805599453
iteration 3 batch 18570 training_loss 0.6931471805599453
iteration 3 batch 18580 training_loss 0.6916632528527511
iteration 3 batch 18590 training_loss 0.6931471805599453
iteration 3 batch 18600 training_loss 0.6931471805599453
iteration 3 batch 18610 training_loss 0.6931471805599453
iteration 4 batch 0 training_loss 0.6931471805599453
iteration 4 batch 10 training_loss 0.6931471805599453
iteration 4 batch 20 training_loss 0.6931471805599453
iteration 4 batch 30 training_loss 0.6931471805599453
iteration 4 batch 40 training_loss 0.6931471805599453
iteration 4 batch 50 training_loss 0.6931471805599453
iteration 4 batch 60 training_loss 0.6931471805599453
iteration 4 batch 70 training_loss 0.6931471805599453
iteration 4 batch 80 training_loss 0.6931471805599453
iteration 4 batch 90 training_loss 0.6931471805599453
iteration 4 batch 100 training_loss 0.6931471805599453
iteration 4 batch 110 training_loss 0.6931471805599453
iteration 4 batch 120 training_loss 0.6931471805599453
iteration 4 batch 130 training_loss 0.6931471805599453
iteration 4 batch 140 training_loss 0.6916632528527511
iteration 4 batch 150 training_loss 0.6931471805599453
iteration 4 batch 160 training_loss 0.6931471805599453
iteration 4 batch 170 training_loss 0.6931471805599453
iteration 4 batch 180 training_loss 0.6931471805599453
iteration 4 batch 190 training_loss 0.6931471805599453
iteration 4 batch 200 training_loss 0.6931471805599453
iteration 4 batch 210 training_loss 0.6931471805599453
iteration 4 batch 220 training_loss 0.6931471805599453
iteration 4 batch 230 training_loss 0.6931471805599453
iteration 4 batch 240 training_loss 0.6931471805599453
iteration 4 batch 250 training_loss 0.6931471805599453
iteration 4 batch 260 training_loss 0.6931471805599453
iteration 4 batch 270 training_loss 0.6931471805599453
iteration 4 batch 280 training_loss 0.6931471805599453
iteration 4 batch 290 training_loss 0.6931471805599453
iteration 4 batch 300 training_loss 0.6931471805599453
iteration 4 batch 310 training_loss 0.6931471805599453
iteration 4 batch 320 training_loss 0.6931471805599453
iteration 4 batch 330 training_loss 0.6931471805599453
iteration 4 batch 340 training_loss 0.6931471805599453
iteration 4 batch 350 training_loss 0.6931471805599453
iteration 4 batch 360 training_loss 0.6931471805599453
iteration 4 batch 370 training_loss 0.6931471805599453
iteration 4 batch 380 training_loss 0.6916632528527511
iteration 4 batch 390 training_loss 0.6931471805599453
iteration 4 batch 400 training_loss 0.6931471805599453
iteration 4 batch 410 training_loss 0.6931471805599453
iteration 4 batch 420 training_loss 0.6931471805599453
iteration 4 batch 430 training_loss 0.6916632528527511
iteration 4 batch 440 training_loss 0.6916632528527511
iteration 4 batch 450 training_loss 0.6931471805599453
iteration 4 batch 460 training_loss 0.6931471805599453
iteration 4 batch 470 training_loss 0.6931471805599453
iteration 4 batch 480 training_loss 0.6931471805599453
iteration 4 batch 490 training_loss 0.6931471805599453
iteration 4 batch 500 training_loss 0.6931471805599453
iteration 4 batch 510 training_loss 0.6931471805599453
iteration 4 batch 520 training_loss 0.6931471805599453
iteration 4 batch 530 training_loss 0.6931471805599453
iteration 4 batch 540 training_loss 0.6916632528527511
iteration 4 batch 550 training_loss 0.6931471805599453
iteration 4 batch 560 training_loss 0.6916632528527511
iteration 4 batch 570 training_loss 0.6931471805599453
iteration 4 batch 580 training_loss 0.6931471805599453
iteration 4 batch 590 training_loss 0.6916632528527511
iteration 4 batch 600 training_loss 0.6916632528527511
iteration 4 batch 610 training_loss 0.6931471805599453
iteration 4 batch 620 training_loss 0.6931471805599453
iteration 4 batch 630 training_loss 0.6931471805599453
iteration 4 batch 640 training_loss 0.6931471805599453
iteration 4 batch 650 training_loss 0.6931471805599453
iteration 4 batch 660 training_loss 0.6931471805599453
iteration 4 batch 670 training_loss 0.6931471805599453
iteration 4 batch 680 training_loss 0.6931471805599453
iteration 4 batch 690 training_loss 0.6916632528527511
iteration 4 batch 700 training_loss 0.6931471805599453
iteration 4 batch 710 training_loss 0.6931471805599453
iteration 4 batch 720 training_loss 0.6931471805599453
iteration 4 batch 730 training_loss 0.6931471805599453
iteration 4 batch 740 training_loss 0.6931471805599453
iteration 4 batch 750 training_loss 0.6931471805599453
iteration 4 batch 760 training_loss 0.6931471805599453
iteration 4 batch 770 training_loss 0.6931471805599453
iteration 4 batch 780 training_loss 0.6931471805599453
iteration 4 batch 790 training_loss 0.6931471805599453
iteration 4 batch 800 training_loss 0.6931471805599453
iteration 4 batch 810 training_loss 0.6931471805599453
iteration 4 batch 820 training_loss 0.6931471805599453
iteration 4 batch 830 training_loss 0.6931471805599453
iteration 4 batch 840 training_loss 0.6931471805599453
iteration 4 batch 850 training_loss 0.6916632528527511
iteration 4 batch 860 training_loss 0.6931471805599453
iteration 4 batch 870 training_loss 0.6931471805599453
iteration 4 batch 880 training_loss 0.6931471805599453
iteration 4 batch 890 training_loss 0.6931471805599453
iteration 4 batch 900 training_loss 0.6931471805599453
iteration 4 batch 910 training_loss 0.6931471805599453
iteration 4 batch 920 training_loss 0.6931471805599453
iteration 4 batch 930 training_loss 0.6931471805599453
iteration 4 batch 940 training_loss 0.6931471805599453
iteration 4 batch 950 training_loss 0.6931471805599453
iteration 4 batch 960 training_loss 0.6931471805599453
iteration 4 batch 970 training_loss 0.6931471805599453
iteration 4 batch 980 training_loss 0.6931471805599453
iteration 4 batch 990 training_loss 0.6931471805599453
iteration 4 batch 1000 training_loss 0.6931471805599453
iteration 4 batch 1010 training_loss 0.6931471805599453
iteration 4 batch 1020 training_loss 0.6931471805599453
iteration 4 batch 1030 training_loss 0.6931471805599453
iteration 4 batch 1040 training_loss 0.6901793251455568
iteration 4 batch 1050 training_loss 0.6931471805599453
iteration 4 batch 1060 training_loss 0.6931471805599453
iteration 4 batch 1070 training_loss 0.6931471805599453
iteration 4 batch 1080 training_loss 0.6931471805599453
iteration 4 batch 1090 training_loss 0.6931471805599453
iteration 4 batch 1100 training_loss 0.6931471805599453
iteration 4 batch 1110 training_loss 0.6931471805599453
iteration 4 batch 1120 training_loss 0.6931471805599453
iteration 4 batch 1130 training_loss 0.6931471805599453
iteration 4 batch 1140 training_loss 0.6931471805599453
iteration 4 batch 1150 training_loss 0.6931471805599453
iteration 4 batch 1160 training_loss 0.6931471805599453
iteration 4 batch 1170 training_loss 0.6931471805599453
iteration 4 batch 1180 training_loss 0.6931471805599453
iteration 4 batch 1190 training_loss 0.6931471805599453
iteration 4 batch 1200 training_loss 0.6931471805599453
iteration 4 batch 1210 training_loss 0.6931471805599453
iteration 4 batch 1220 training_loss 0.6931471805599453
iteration 4 batch 1230 training_loss 0.6931471805599453
iteration 4 batch 1240 training_loss 0.6931471805599453
iteration 4 batch 1250 training_loss 0.6931471805599453
iteration 4 batch 1260 training_loss 0.6931471805599453
iteration 4 batch 1270 training_loss 0.6931471805599453
iteration 4 batch 1280 training_loss 0.6931471805599453
iteration 4 batch 1290 training_loss 0.6916632528527511
iteration 4 batch 1300 training_loss 0.6931471805599453
iteration 4 batch 1310 training_loss 0.6931471805599453
iteration 4 batch 1320 training_loss 0.6931471805599453
iteration 4 batch 1330 training_loss 0.6931471805599453
iteration 4 batch 1340 training_loss 0.6931471805599453
iteration 4 batch 1350 training_loss 0.6931471805599453
iteration 4 batch 1360 training_loss 0.6916632528527511
iteration 4 batch 1370 training_loss 0.6931471805599453
iteration 4 batch 1380 training_loss 0.6931471805599453
iteration 4 batch 1390 training_loss 0.6931471805599453
iteration 4 batch 1400 training_loss 0.6916632528527511
iteration 4 batch 1410 training_loss 0.6931471805599453
iteration 4 batch 1420 training_loss 0.6931471805599453
iteration 4 batch 1430 training_loss 0.6931471805599453
iteration 4 batch 1440 training_loss 0.6931471805599453
iteration 4 batch 1450 training_loss 0.6931471805599453
iteration 4 batch 1460 training_loss 0.6931471805599453
iteration 4 batch 1470 training_loss 0.6931471805599453
iteration 4 batch 1480 training_loss 0.6931471805599453
iteration 4 batch 1490 training_loss 0.6931471805599453
iteration 4 batch 1500 training_loss 0.6931471805599453
iteration 4 batch 1510 training_loss 0.6931471805599453
iteration 4 batch 1520 training_loss 0.6916632528527511
iteration 4 batch 1530 training_loss 0.6931471805599453
iteration 4 batch 1540 training_loss 0.6931471805599453
iteration 4 batch 1550 training_loss 0.6931471805599453
iteration 4 batch 1560 training_loss 0.6931471805599453
iteration 4 batch 1570 training_loss 0.6931471805599453
iteration 4 batch 1580 training_loss 0.6931471805599453
iteration 4 batch 1590 training_loss 0.6931471805599453
iteration 4 batch 1600 training_loss 0.6931471805599453
iteration 4 batch 1610 training_loss 0.6931471805599453
iteration 4 batch 1620 training_loss 0.6931471805599453
iteration 4 batch 1630 training_loss 0.6931471805599453
iteration 4 batch 1640 training_loss 0.6931471805599453
iteration 4 batch 1650 training_loss 0.6931471805599453
iteration 4 batch 1660 training_loss 0.6931471805599453
iteration 4 batch 1670 training_loss 0.6931471805599453
iteration 4 batch 1680 training_loss 0.6931471805599453
iteration 4 batch 1690 training_loss 0.6931471805599453
iteration 4 batch 1700 training_loss 0.6931471805599453
iteration 4 batch 1710 training_loss 0.6931471805599453
iteration 4 batch 1720 training_loss 0.6931471805599453
iteration 4 batch 1730 training_loss 0.6931471805599453
iteration 4 batch 1740 training_loss 0.6931471805599453
iteration 4 batch 1750 training_loss 0.6931471805599453
iteration 4 batch 1760 training_loss 0.6931471805599453
iteration 4 batch 1770 training_loss 0.6931471805599453
iteration 4 batch 1780 training_loss 0.6931471805599453
iteration 4 batch 1790 training_loss 0.6931471805599453
iteration 4 batch 1800 training_loss 0.6931471805599453
iteration 4 batch 1810 training_loss 0.6931471805599453
iteration 4 batch 1820 training_loss 0.6931471805599453
iteration 4 batch 1830 training_loss 0.6931471805599453
iteration 4 batch 1840 training_loss 0.6931471805599453
iteration 4 batch 1850 training_loss 0.6931471805599453
iteration 4 batch 1860 training_loss 0.6931471805599453
iteration 4 batch 1870 training_loss 0.6931471805599453
iteration 4 batch 1880 training_loss 0.6931471805599453
iteration 4 batch 1890 training_loss 0.6931471805599453
iteration 4 batch 1900 training_loss 0.6931471805599453
iteration 4 batch 1910 training_loss 0.6931471805599453
iteration 4 batch 1920 training_loss 0.6931471805599453
iteration 4 batch 1930 training_loss 0.6931471805599453
iteration 4 batch 1940 training_loss 0.6931471805599453
iteration 4 batch 1950 training_loss 0.6931471805599453
iteration 4 batch 1960 training_loss 0.6931471805599453
iteration 4 batch 1970 training_loss 0.6931471805599453
iteration 4 batch 1980 training_loss 0.6931471805599453
iteration 4 batch 1990 training_loss 0.6931471805599453
iteration 4 batch 2000 training_loss 0.6931471805599453
iteration 4 batch 2010 training_loss 0.6931471805599453
iteration 4 batch 2020 training_loss 0.6931471805599453
iteration 4 batch 2030 training_loss 0.6931471805599453
iteration 4 batch 2040 training_loss 0.6931471805599453
iteration 4 batch 2050 training_loss 0.6931471805599453
iteration 4 batch 2060 training_loss 0.6931471805599453
iteration 4 batch 2070 training_loss 0.6931471805599453
iteration 4 batch 2080 training_loss 0.6916632528527511
iteration 4 batch 2090 training_loss 0.6931471805599453
iteration 4 batch 2100 training_loss 0.6931471805599453
iteration 4 batch 2110 training_loss 0.6916632528527511
iteration 4 batch 2120 training_loss 0.6931471805599453
iteration 4 batch 2130 training_loss 0.6931471805599453
iteration 4 batch 2140 training_loss 0.6931471805599453
iteration 4 batch 2150 training_loss 0.6931471805599453
iteration 4 batch 2160 training_loss 0.6931471805599453
iteration 4 batch 2170 training_loss 0.6931471805599453
iteration 4 batch 2180 training_loss 0.6931471805599453
iteration 4 batch 2190 training_loss 0.6931471805599453
iteration 4 batch 2200 training_loss 0.6931471805599453
iteration 4 batch 2210 training_loss 0.6931471805599453
iteration 4 batch 2220 training_loss 0.6931471805599453
iteration 4 batch 2230 training_loss 0.6931471805599453
iteration 4 batch 2240 training_loss 0.6931471805599453
iteration 4 batch 2250 training_loss 0.6931471805599453
iteration 4 batch 2260 training_loss 0.6931471805599453
iteration 4 batch 2270 training_loss 0.6931471805599453
iteration 4 batch 2280 training_loss 0.6931471805599453
iteration 4 batch 2290 training_loss 0.6931471805599453
iteration 4 batch 2300 training_loss 0.6931471805599453
iteration 4 batch 2310 training_loss 0.6931471805599453
iteration 4 batch 2320 training_loss 0.6931471805599453
iteration 4 batch 2330 training_loss 0.6931471805599453
iteration 4 batch 2340 training_loss 0.6931471805599453
iteration 4 batch 2350 training_loss 0.6931471805599453
iteration 4 batch 2360 training_loss 0.6931471805599453
iteration 4 batch 2370 training_loss 0.6931471805599453
iteration 4 batch 2380 training_loss 0.6931471805599453
iteration 4 batch 2390 training_loss 0.6931471805599453
iteration 4 batch 2400 training_loss 0.6931471805599453
iteration 4 batch 2410 training_loss 0.6931471805599453
iteration 4 batch 2420 training_loss 0.6931471805599453
iteration 4 batch 2430 training_loss 0.6916632528527511
iteration 4 batch 2440 training_loss 0.6931471805599453
iteration 4 batch 2450 training_loss 0.6931471805599453
iteration 4 batch 2460 training_loss 0.6931471805599453
iteration 4 batch 2470 training_loss 0.6931471805599453
iteration 4 batch 2480 training_loss 0.6931471805599453
iteration 4 batch 2490 training_loss 0.6931471805599453
iteration 4 batch 2500 training_loss 0.6931471805599453
iteration 4 batch 2510 training_loss 0.6931471805599453
iteration 4 batch 2520 training_loss 0.6916632528527511
iteration 4 batch 2530 training_loss 0.6931471805599453
iteration 4 batch 2540 training_loss 0.6931471805599453
iteration 4 batch 2550 training_loss 0.6931471805599453
iteration 4 batch 2560 training_loss 0.6931471805599453
iteration 4 batch 2570 training_loss 0.6916632528527511
iteration 4 batch 2580 training_loss 0.6931471805599453
iteration 4 batch 2590 training_loss 0.6931471805599453
iteration 4 batch 2600 training_loss 0.6931471805599453
iteration 4 batch 2610 training_loss 0.6931471805599453
iteration 4 batch 2620 training_loss 0.6931471805599453
iteration 4 batch 2630 training_loss 0.6931471805599453
iteration 4 batch 2640 training_loss 0.6931471805599453
iteration 4 batch 2650 training_loss 0.6931471805599453
iteration 4 batch 2660 training_loss 0.6931471805599453
iteration 4 batch 2670 training_loss 0.6931471805599453
iteration 4 batch 2680 training_loss 0.6931471805599453
iteration 4 batch 2690 training_loss 0.6931471805599453
iteration 4 batch 2700 training_loss 0.6931471805599453
iteration 4 batch 2710 training_loss 0.6931471805599453
iteration 4 batch 2720 training_loss 0.6931471805599453
iteration 4 batch 2730 training_loss 0.6931471805599453
iteration 4 batch 2740 training_loss 0.6931471805599453
iteration 4 batch 2750 training_loss 0.6931471805599453
iteration 4 batch 2760 training_loss 0.6931471805599453
iteration 4 batch 2770 training_loss 0.6931471805599453
iteration 4 batch 2780 training_loss 0.6931471805599453
iteration 4 batch 2790 training_loss 0.6931471805599453
iteration 4 batch 2800 training_loss 0.6931471805599453
iteration 4 batch 2810 training_loss 0.6931471805599453
iteration 4 batch 2820 training_loss 0.6931471805599453
iteration 4 batch 2830 training_loss 0.6916632528527511
iteration 4 batch 2840 training_loss 0.6931471805599453
iteration 4 batch 2850 training_loss 0.6931471805599453
iteration 4 batch 2860 training_loss 0.6931471805599453
iteration 4 batch 2870 training_loss 0.6931471805599453
iteration 4 batch 2880 training_loss 0.6916632528527511
iteration 4 batch 2890 training_loss 0.6916632528527511
iteration 4 batch 2900 training_loss 0.6931471805599453
iteration 4 batch 2910 training_loss 0.6931471805599453
iteration 4 batch 2920 training_loss 0.6931471805599453
iteration 4 batch 2930 training_loss 0.6931471805599453
iteration 4 batch 2940 training_loss 0.6931471805599453
iteration 4 batch 2950 training_loss 0.6931471805599453
iteration 4 batch 2960 training_loss 0.6916632528527511
iteration 4 batch 2970 training_loss 0.6931471805599453
iteration 4 batch 2980 training_loss 0.6931471805599453
iteration 4 batch 2990 training_loss 0.6931471805599453
iteration 4 batch 3000 training_loss 0.6931471805599453
iteration 4 batch 3010 training_loss 0.6931471805599453
iteration 4 batch 3020 training_loss 0.6931471805599453
iteration 4 batch 3030 training_loss 0.6931471805599453
iteration 4 batch 3040 training_loss 0.6931471805599453
iteration 4 batch 3050 training_loss 0.6931471805599453
iteration 4 batch 3060 training_loss 0.6931471805599453
iteration 4 batch 3070 training_loss 0.6931471805599453
iteration 4 batch 3080 training_loss 0.6931471805599453
iteration 4 batch 3090 training_loss 0.6931471805599453
iteration 4 batch 3100 training_loss 0.6931471805599453
iteration 4 batch 3110 training_loss 0.6931471805599453
iteration 4 batch 3120 training_loss 0.6931471805599453
iteration 4 batch 3130 training_loss 0.6931471805599453
iteration 4 batch 3140 training_loss 0.6931471805599453
iteration 4 batch 3150 training_loss 0.6931471805599453
iteration 4 batch 3160 training_loss 0.6931471805599453
iteration 4 batch 3170 training_loss 0.6931471805599453
iteration 4 batch 3180 training_loss 0.6931471805599453
iteration 4 batch 3190 training_loss 0.6931471805599453
iteration 4 batch 3200 training_loss 0.6931471805599453
iteration 4 batch 3210 training_loss 0.6931471805599453
iteration 4 batch 3220 training_loss 0.6931471805599453
iteration 4 batch 3230 training_loss 0.6931471805599453
iteration 4 batch 3240 training_loss 0.6931471805599453
iteration 4 batch 3250 training_loss 0.6931471805599453
iteration 4 batch 3260 training_loss 0.6931471805599453
iteration 4 batch 3270 training_loss 0.6931471805599453
iteration 4 batch 3280 training_loss 0.6931471805599453
iteration 4 batch 3290 training_loss 0.6931471805599453
iteration 4 batch 3300 training_loss 0.6931471805599453
iteration 4 batch 3310 training_loss 0.6916632528527511
iteration 4 batch 3320 training_loss 0.6931471805599453
iteration 4 batch 3330 training_loss 0.6931471805599453
iteration 4 batch 3340 training_loss 0.6931471805599453
iteration 4 batch 3350 training_loss 0.6931471805599453
iteration 4 batch 3360 training_loss 0.6931471805599453
iteration 4 batch 3370 training_loss 0.6931471805599453
iteration 4 batch 3380 training_loss 0.6931471805599453
iteration 4 batch 3390 training_loss 0.6916632528527511
iteration 4 batch 3400 training_loss 0.6931471805599453
iteration 4 batch 3410 training_loss 0.6931471805599453
iteration 4 batch 3420 training_loss 0.6931471805599453
iteration 4 batch 3430 training_loss 0.6916632528527511
iteration 4 batch 3440 training_loss 0.6931471805599453
iteration 4 batch 3450 training_loss 0.6931471805599453
iteration 4 batch 3460 training_loss 0.6931471805599453
iteration 4 batch 3470 training_loss 0.6931471805599453
iteration 4 batch 3480 training_loss 0.6931471805599453
iteration 4 batch 3490 training_loss 0.6931471805599453
iteration 4 batch 3500 training_loss 0.6931471805599453
iteration 4 batch 3510 training_loss 0.6916632528527511
iteration 4 batch 3520 training_loss 0.6916632528527511
iteration 4 batch 3530 training_loss 0.6931471805599453
iteration 4 batch 3540 training_loss 0.6931471805599453
iteration 4 batch 3550 training_loss 0.6931471805599453
iteration 4 batch 3560 training_loss 0.6931471805599453
iteration 4 batch 3570 training_loss 0.6916632528527511
iteration 4 batch 3580 training_loss 0.6931471805599453
iteration 4 batch 3590 training_loss 0.6916632528527511
iteration 4 batch 3600 training_loss 0.6931471805599453
iteration 4 batch 3610 training_loss 0.6931471805599453
iteration 4 batch 3620 training_loss 0.6931471805599453
iteration 4 batch 3630 training_loss 0.6931471805599453
iteration 4 batch 3640 training_loss 0.6931471805599453
iteration 4 batch 3650 training_loss 0.6931471805599453
iteration 4 batch 3660 training_loss 0.6931471805599453
iteration 4 batch 3670 training_loss 0.6931471805599453
iteration 4 batch 3680 training_loss 0.6931471805599453
iteration 4 batch 3690 training_loss 0.6931471805599453
iteration 4 batch 3700 training_loss 0.6931471805599453
iteration 4 batch 3710 training_loss 0.6916632528527511
iteration 4 batch 3720 training_loss 0.6931471805599453
iteration 4 batch 3730 training_loss 0.6931471805599453
iteration 4 batch 3740 training_loss 0.6931471805599453
iteration 4 batch 3750 training_loss 0.6931471805599453
iteration 4 batch 3760 training_loss 0.6931471805599453
iteration 4 batch 3770 training_loss 0.6931471805599453
iteration 4 batch 3780 training_loss 0.6931471805599453
iteration 4 batch 3790 training_loss 0.6931471805599453
iteration 4 batch 3800 training_loss 0.6931471805599453
iteration 4 batch 3810 training_loss 0.6931471805599453
iteration 4 batch 3820 training_loss 0.6931471805599453
iteration 4 batch 3830 training_loss 0.6931471805599453
iteration 4 batch 3840 training_loss 0.6931471805599453
iteration 4 batch 3850 training_loss 0.6931471805599453
iteration 4 batch 3860 training_loss 0.6931471805599453
iteration 4 batch 3870 training_loss 0.6931471805599453
iteration 4 batch 3880 training_loss 0.6931471805599453
iteration 4 batch 3890 training_loss 0.6931471805599453
iteration 4 batch 3900 training_loss 0.6931471805599453
iteration 4 batch 3910 training_loss 0.6931471805599453
iteration 4 batch 3920 training_loss 0.6931471805599453
iteration 4 batch 3930 training_loss 0.6931471805599453
iteration 4 batch 3940 training_loss 0.6931471805599453
iteration 4 batch 3950 training_loss 0.6931471805599453
iteration 4 batch 3960 training_loss 0.6931471805599453
iteration 4 batch 3970 training_loss 0.6931471805599453
iteration 4 batch 3980 training_loss 0.6931471805599453
iteration 4 batch 3990 training_loss 0.6931471805599453
iteration 4 batch 4000 training_loss 0.6931471805599453
iteration 4 batch 4010 training_loss 0.6931471805599453
iteration 4 batch 4020 training_loss 0.6931471805599453
iteration 4 batch 4030 training_loss 0.6931471805599453
iteration 4 batch 4040 training_loss 0.6931471805599453
iteration 4 batch 4050 training_loss 0.6931471805599453
iteration 4 batch 4060 training_loss 0.6931471805599453
iteration 4 batch 4070 training_loss 0.6931471805599453
iteration 4 batch 4080 training_loss 0.6931471805599453
iteration 4 batch 4090 training_loss 0.6931471805599453
iteration 4 batch 4100 training_loss 0.6931471805599453
iteration 4 batch 4110 training_loss 0.6916632528527511
iteration 4 batch 4120 training_loss 0.6931471805599453
iteration 4 batch 4130 training_loss 0.6916632528527511
iteration 4 batch 4140 training_loss 0.6931471805599453
iteration 4 batch 4150 training_loss 0.6931471805599453
iteration 4 batch 4160 training_loss 0.6931471805599453
iteration 4 batch 4170 training_loss 0.6931471805599453
iteration 4 batch 4180 training_loss 0.6931471805599453
iteration 4 batch 4190 training_loss 0.6931471805599453
iteration 4 batch 4200 training_loss 0.6931471805599453
iteration 4 batch 4210 training_loss 0.6931471805599453
iteration 4 batch 4220 training_loss 0.6931471805599453
iteration 4 batch 4230 training_loss 0.6931471805599453
iteration 4 batch 4240 training_loss 0.6931471805599453
iteration 4 batch 4250 training_loss 0.6931471805599453
iteration 4 batch 4260 training_loss 0.6931471805599453
iteration 4 batch 4270 training_loss 0.6931471805599453
iteration 4 batch 4280 training_loss 0.6931471805599453
iteration 4 batch 4290 training_loss 0.6931471805599453
iteration 4 batch 4300 training_loss 0.6931471805599453
iteration 4 batch 4310 training_loss 0.6931471805599453
iteration 4 batch 4320 training_loss 0.6931471805599453
iteration 4 batch 4330 training_loss 0.6931471805599453
iteration 4 batch 4340 training_loss 0.6931471805599453
iteration 4 batch 4350 training_loss 0.6916632528527511
iteration 4 batch 4360 training_loss 0.6931471805599453
iteration 4 batch 4370 training_loss 0.6931471805599453
iteration 4 batch 4380 training_loss 0.6931471805599453
iteration 4 batch 4390 training_loss 0.6931471805599453
iteration 4 batch 4400 training_loss 0.6931471805599453
iteration 4 batch 4410 training_loss 0.6931471805599453
iteration 4 batch 4420 training_loss 0.6916632528527511
iteration 4 batch 4430 training_loss 0.6931471805599453
iteration 4 batch 4440 training_loss 0.6931471805599453
iteration 4 batch 4450 training_loss 0.6931471805599453
iteration 4 batch 4460 training_loss 0.6931471805599453
iteration 4 batch 4470 training_loss 0.6931471805599453
iteration 4 batch 4480 training_loss 0.6931471805599453
iteration 4 batch 4490 training_loss 0.6931471805599453
iteration 4 batch 4500 training_loss 0.6931471805599453
iteration 4 batch 4510 training_loss 0.6931471805599453
iteration 4 batch 4520 training_loss 0.6931471805599453
iteration 4 batch 4530 training_loss 0.6931471805599453
iteration 4 batch 4540 training_loss 0.6931471805599453
iteration 4 batch 4550 training_loss 0.6931471805599453
iteration 4 batch 4560 training_loss 0.6931471805599453
iteration 4 batch 4570 training_loss 0.6931471805599453
iteration 4 batch 4580 training_loss 0.6931471805599453
iteration 4 batch 4590 training_loss 0.6931471805599453
iteration 4 batch 4600 training_loss 0.6931471805599453
iteration 4 batch 4610 training_loss 0.6931471805599453
iteration 4 batch 4620 training_loss 0.6931471805599453
iteration 4 batch 4630 training_loss 0.6916632528527511
iteration 4 batch 4640 training_loss 0.6931471805599453
iteration 4 batch 4650 training_loss 0.6931471805599453
iteration 4 batch 4660 training_loss 0.6931471805599453
iteration 4 batch 4670 training_loss 0.6931471805599453
iteration 4 batch 4680 training_loss 0.6931471805599453
iteration 4 batch 4690 training_loss 0.6931471805599453
iteration 4 batch 4700 training_loss 0.6931471805599453
iteration 4 batch 4710 training_loss 0.6931471805599453
iteration 4 batch 4720 training_loss 0.6931471805599453
iteration 4 batch 4730 training_loss 0.6931471805599453
iteration 4 batch 4740 training_loss 0.6931471805599453
iteration 4 batch 4750 training_loss 0.6916632528527511
iteration 4 batch 4760 training_loss 0.6916632528527511
iteration 4 batch 4770 training_loss 0.6931471805599453
iteration 4 batch 4780 training_loss 0.6931471805599453
iteration 4 batch 4790 training_loss 0.6931471805599453
iteration 4 batch 4800 training_loss 0.6931471805599453
iteration 4 batch 4810 training_loss 0.6931471805599453
iteration 4 batch 4820 training_loss 0.6931471805599453
iteration 4 batch 4830 training_loss 0.6931471805599453
iteration 4 batch 4840 training_loss 0.6931471805599453
iteration 4 batch 4850 training_loss 0.6931471805599453
iteration 4 batch 4860 training_loss 0.6931471805599453
iteration 4 batch 4870 training_loss 0.6931471805599453
iteration 4 batch 4880 training_loss 0.6931471805599453
iteration 4 batch 4890 training_loss 0.6931471805599453
iteration 4 batch 4900 training_loss 0.6931471805599453
iteration 4 batch 4910 training_loss 0.6916632528527511
iteration 4 batch 4920 training_loss 0.6931471805599453
iteration 4 batch 4930 training_loss 0.6931471805599453
iteration 4 batch 4940 training_loss 0.6931471805599453
iteration 4 batch 4950 training_loss 0.6931471805599453
iteration 4 batch 4960 training_loss 0.6931471805599453
iteration 4 batch 4970 training_loss 0.6931471805599453
iteration 4 batch 4980 training_loss 0.6931471805599453
iteration 4 batch 4990 training_loss 0.6931471805599453
iteration 4 batch 5000 training_loss 0.6931471805599453
iteration 4 batch 5010 training_loss 0.6931471805599453
iteration 4 batch 5020 training_loss 0.6931471805599453
iteration 4 batch 5030 training_loss 0.6931471805599453
iteration 4 batch 5040 training_loss 0.6931471805599453
iteration 4 batch 5050 training_loss 0.6931471805599453
iteration 4 batch 5060 training_loss 0.6931471805599453
iteration 4 batch 5070 training_loss 0.6931471805599453
iteration 4 batch 5080 training_loss 0.6931471805599453
iteration 4 batch 5090 training_loss 0.6931471805599453
iteration 4 batch 5100 training_loss 0.6931471805599453
iteration 4 batch 5110 training_loss 0.6931471805599453
iteration 4 batch 5120 training_loss 0.6931471805599453
iteration 4 batch 5130 training_loss 0.6916632528527511
iteration 4 batch 5140 training_loss 0.6931471805599453
iteration 4 batch 5150 training_loss 0.6931471805599453
iteration 4 batch 5160 training_loss 0.6931471805599453
iteration 4 batch 5170 training_loss 0.6931471805599453
iteration 4 batch 5180 training_loss 0.6931471805599453
iteration 4 batch 5190 training_loss 0.6931471805599453
iteration 4 batch 5200 training_loss 0.6931471805599453
iteration 4 batch 5210 training_loss 0.6931471805599453
iteration 4 batch 5220 training_loss 0.6931471805599453
iteration 4 batch 5230 training_loss 0.6931471805599453
iteration 4 batch 5240 training_loss 0.6931471805599453
iteration 4 batch 5250 training_loss 0.6931471805599453
iteration 4 batch 5260 training_loss 0.6916632528527511
iteration 4 batch 5270 training_loss 0.6931471805599453
iteration 4 batch 5280 training_loss 0.6931471805599453
iteration 4 batch 5290 training_loss 0.6916632528527511
iteration 4 batch 5300 training_loss 0.6931471805599453
iteration 4 batch 5310 training_loss 0.6931471805599453
iteration 4 batch 5320 training_loss 0.6931471805599453
iteration 4 batch 5330 training_loss 0.6931471805599453
iteration 4 batch 5340 training_loss 0.6931471805599453
iteration 4 batch 5350 training_loss 0.6931471805599453
iteration 4 batch 5360 training_loss 0.6931471805599453
iteration 4 batch 5370 training_loss 0.6931471805599453
iteration 4 batch 5380 training_loss 0.6931471805599453
iteration 4 batch 5390 training_loss 0.6916632528527511
iteration 4 batch 5400 training_loss 0.6931471805599453
iteration 4 batch 5410 training_loss 0.6931471805599453
iteration 4 batch 5420 training_loss 0.6931471805599453
iteration 4 batch 5430 training_loss 0.6931471805599453
iteration 4 batch 5440 training_loss 0.6931471805599453
iteration 4 batch 5450 training_loss 0.6931471805599453
iteration 4 batch 5460 training_loss 0.6916632528527511
iteration 4 batch 5470 training_loss 0.6931471805599453
iteration 4 batch 5480 training_loss 0.6931471805599453
iteration 4 batch 5490 training_loss 0.6916632528527511
iteration 4 batch 5500 training_loss 0.6931471805599453
iteration 4 batch 5510 training_loss 0.6931471805599453
iteration 4 batch 5520 training_loss 0.6931471805599453
iteration 4 batch 5530 training_loss 0.6931471805599453
iteration 4 batch 5540 training_loss 0.6931471805599453
iteration 4 batch 5550 training_loss 0.6931471805599453
iteration 4 batch 5560 training_loss 0.6916632528527511
iteration 4 batch 5570 training_loss 0.6931471805599453
iteration 4 batch 5580 training_loss 0.6931471805599453
iteration 4 batch 5590 training_loss 0.6931471805599453
iteration 4 batch 5600 training_loss 0.6931471805599453
iteration 4 batch 5610 training_loss 0.6931471805599453
iteration 4 batch 5620 training_loss 0.6931471805599453
iteration 4 batch 5630 training_loss 0.6931471805599453
iteration 4 batch 5640 training_loss 0.6916632528527511
iteration 4 batch 5650 training_loss 0.6931471805599453
iteration 4 batch 5660 training_loss 0.6931471805599453
iteration 4 batch 5670 training_loss 0.6931471805599453
iteration 4 batch 5680 training_loss 0.6931471805599453
iteration 4 batch 5690 training_loss 0.6931471805599453
iteration 4 batch 5700 training_loss 0.6931471805599453
iteration 4 batch 5710 training_loss 0.6931471805599453
iteration 4 batch 5720 training_loss 0.6931471805599453
iteration 4 batch 5730 training_loss 0.6931471805599453
iteration 4 batch 5740 training_loss 0.6931471805599453
iteration 4 batch 5750 training_loss 0.6931471805599453
iteration 4 batch 5760 training_loss 0.6931471805599453
iteration 4 batch 5770 training_loss 0.6931471805599453
iteration 4 batch 5780 training_loss 0.6931471805599453
iteration 4 batch 5790 training_loss 0.6931471805599453
iteration 4 batch 5800 training_loss 0.6916632528527511
iteration 4 batch 5810 training_loss 0.6931471805599453
iteration 4 batch 5820 training_loss 0.6931471805599453
iteration 4 batch 5830 training_loss 0.6931471805599453
iteration 4 batch 5840 training_loss 0.6931471805599453
iteration 4 batch 5850 training_loss 0.6931471805599453
iteration 4 batch 5860 training_loss 0.6931471805599453
iteration 4 batch 5870 training_loss 0.6931471805599453
iteration 4 batch 5880 training_loss 0.6931471805599453
iteration 4 batch 5890 training_loss 0.6931471805599453
iteration 4 batch 5900 training_loss 0.6931471805599453
iteration 4 batch 5910 training_loss 0.6931471805599453
iteration 4 batch 5920 training_loss 0.6931471805599453
iteration 4 batch 5930 training_loss 0.6931471805599453
iteration 4 batch 5940 training_loss 0.6931471805599453
iteration 4 batch 5950 training_loss 0.6931471805599453
iteration 4 batch 5960 training_loss 0.6931471805599453
iteration 4 batch 5970 training_loss 0.6931471805599453
iteration 4 batch 5980 training_loss 0.6931471805599453
iteration 4 batch 5990 training_loss 0.6931471805599453
iteration 4 batch 6000 training_loss 0.6931471805599453
iteration 4 batch 6010 training_loss 0.6931471805599453
iteration 4 batch 6020 training_loss 0.6931471805599453
iteration 4 batch 6030 training_loss 0.6931471805599453
iteration 4 batch 6040 training_loss 0.6931471805599453
iteration 4 batch 6050 training_loss 0.6931471805599453
iteration 4 batch 6060 training_loss 0.6931471805599453
iteration 4 batch 6070 training_loss 0.6931471805599453
iteration 4 batch 6080 training_loss 0.6931471805599453
iteration 4 batch 6090 training_loss 0.6931471805599453
iteration 4 batch 6100 training_loss 0.6931471805599453
iteration 4 batch 6110 training_loss 0.6931471805599453
iteration 4 batch 6120 training_loss 0.6931471805599453
iteration 4 batch 6130 training_loss 0.6916632528527511
iteration 4 batch 6140 training_loss 0.6931471805599453
iteration 4 batch 6150 training_loss 0.6916632528527511
iteration 4 batch 6160 training_loss 0.6931471805599453
iteration 4 batch 6170 training_loss 0.6931471805599453
iteration 4 batch 6180 training_loss 0.6931471805599453
iteration 4 batch 6190 training_loss 0.6931471805599453
iteration 4 batch 6200 training_loss 0.6931471805599453
iteration 4 batch 6210 training_loss 0.6931471805599453
iteration 4 batch 6220 training_loss 0.6931471805599453
iteration 4 batch 6230 training_loss 0.6931471805599453
iteration 4 batch 6240 training_loss 0.6931471805599453
iteration 4 batch 6250 training_loss 0.6931471805599453
iteration 4 batch 6260 training_loss 0.6931471805599453
iteration 4 batch 6270 training_loss 0.6931471805599453
iteration 4 batch 6280 training_loss 0.6931471805599453
iteration 4 batch 6290 training_loss 0.6931471805599453
iteration 4 batch 6300 training_loss 0.6931471805599453
iteration 4 batch 6310 training_loss 0.6931471805599453
iteration 4 batch 6320 training_loss 0.6916632528527511
iteration 4 batch 6330 training_loss 0.6916632528527511
iteration 4 batch 6340 training_loss 0.6931471805599453
iteration 4 batch 6350 training_loss 0.6916632528527511
iteration 4 batch 6360 training_loss 0.6931471805599453
iteration 4 batch 6370 training_loss 0.6931471805599453
iteration 4 batch 6380 training_loss 0.6931471805599453
iteration 4 batch 6390 training_loss 0.6931471805599453
iteration 4 batch 6400 training_loss 0.6931471805599453
iteration 4 batch 6410 training_loss 0.6931471805599453
iteration 4 batch 6420 training_loss 0.6916632528527511
iteration 4 batch 6430 training_loss 0.6931471805599453
iteration 4 batch 6440 training_loss 0.6931471805599453
iteration 4 batch 6450 training_loss 0.6931471805599453
iteration 4 batch 6460 training_loss 0.6931471805599453
iteration 4 batch 6470 training_loss 0.6931471805599453
iteration 4 batch 6480 training_loss 0.6931471805599453
iteration 4 batch 6490 training_loss 0.6931471805599453
iteration 4 batch 6500 training_loss 0.6931471805599453
iteration 4 batch 6510 training_loss 0.6931471805599453
iteration 4 batch 6520 training_loss 0.6931471805599453
iteration 4 batch 6530 training_loss 0.6931471805599453
iteration 4 batch 6540 training_loss 0.6931471805599453
iteration 4 batch 6550 training_loss 0.6931471805599453
iteration 4 batch 6560 training_loss 0.6931471805599453
iteration 4 batch 6570 training_loss 0.6931471805599453
iteration 4 batch 6580 training_loss 0.6931471805599453
iteration 4 batch 6590 training_loss 0.6931471805599453
iteration 4 batch 6600 training_loss 0.6931471805599453
iteration 4 batch 6610 training_loss 0.6931471805599453
iteration 4 batch 6620 training_loss 0.6931471805599453
iteration 4 batch 6630 training_loss 0.6931471805599453
iteration 4 batch 6640 training_loss 0.6931471805599453
iteration 4 batch 6650 training_loss 0.6931471805599453
iteration 4 batch 6660 training_loss 0.6931471805599453
iteration 4 batch 6670 training_loss 0.6931471805599453
iteration 4 batch 6680 training_loss 0.6931471805599453
iteration 4 batch 6690 training_loss 0.6931471805599453
iteration 4 batch 6700 training_loss 0.6931471805599453
iteration 4 batch 6710 training_loss 0.6931471805599453
iteration 4 batch 6720 training_loss 0.6931471805599453
iteration 4 batch 6730 training_loss 0.6931471805599453
iteration 4 batch 6740 training_loss 0.6931471805599453
iteration 4 batch 6750 training_loss 0.6931471805599453
iteration 4 batch 6760 training_loss 0.6931471805599453
iteration 4 batch 6770 training_loss 0.6931471805599453
iteration 4 batch 6780 training_loss 0.6931471805599453
iteration 4 batch 6790 training_loss 0.6931471805599453
iteration 4 batch 6800 training_loss 0.6931471805599453
iteration 4 batch 6810 training_loss 0.6931471805599453
iteration 4 batch 6820 training_loss 0.6931471805599453
iteration 4 batch 6830 training_loss 0.6931471805599453
iteration 4 batch 6840 training_loss 0.6931471805599453
iteration 4 batch 6850 training_loss 0.6931471805599453
iteration 4 batch 6860 training_loss 0.6931471805599453
iteration 4 batch 6870 training_loss 0.6931471805599453
iteration 4 batch 6880 training_loss 0.6931471805599453
iteration 4 batch 6890 training_loss 0.6931471805599453
iteration 4 batch 6900 training_loss 0.6931471805599453
iteration 4 batch 6910 training_loss 0.6931471805599453
iteration 4 batch 6920 training_loss 0.6931471805599453
iteration 4 batch 6930 training_loss 0.6931471805599453
iteration 4 batch 6940 training_loss 0.6916632528527511
iteration 4 batch 6950 training_loss 0.6931471805599453
iteration 4 batch 6960 training_loss 0.6931471805599453
iteration 4 batch 6970 training_loss 0.6931471805599453
iteration 4 batch 6980 training_loss 0.6931471805599453
iteration 4 batch 6990 training_loss 0.6931471805599453
iteration 4 batch 7000 training_loss 0.6931471805599453
iteration 4 batch 7010 training_loss 0.6931471805599453
iteration 4 batch 7020 training_loss 0.6931471805599453
iteration 4 batch 7030 training_loss 0.6931471805599453
iteration 4 batch 7040 training_loss 0.6931471805599453
iteration 4 batch 7050 training_loss 0.6931471805599453
iteration 4 batch 7060 training_loss 0.6931471805599453
iteration 4 batch 7070 training_loss 0.6931471805599453
iteration 4 batch 7080 training_loss 0.6931471805599453
iteration 4 batch 7090 training_loss 0.6931471805599453
iteration 4 batch 7100 training_loss 0.6931471805599453
iteration 4 batch 7110 training_loss 0.6931471805599453
iteration 4 batch 7120 training_loss 0.6931471805599453
iteration 4 batch 7130 training_loss 0.6931471805599453
iteration 4 batch 7140 training_loss 0.6931471805599453
iteration 4 batch 7150 training_loss 0.6931471805599453
iteration 4 batch 7160 training_loss 0.6931471805599453
iteration 4 batch 7170 training_loss 0.6931471805599453
iteration 4 batch 7180 training_loss 0.6931471805599453
iteration 4 batch 7190 training_loss 0.6931471805599453
iteration 4 batch 7200 training_loss 0.6931471805599453
iteration 4 batch 7210 training_loss 0.6931471805599453
iteration 4 batch 7220 training_loss 0.6931471805599453
iteration 4 batch 7230 training_loss 0.6931471805599453
iteration 4 batch 7240 training_loss 0.6931471805599453
iteration 4 batch 7250 training_loss 0.6931471805599453
iteration 4 batch 7260 training_loss 0.6931471805599453
iteration 4 batch 7270 training_loss 0.6931471805599453
iteration 4 batch 7280 training_loss 0.6931471805599453
iteration 4 batch 7290 training_loss 0.6931471805599453
iteration 4 batch 7300 training_loss 0.6931471805599453
iteration 4 batch 7310 training_loss 0.6931471805599453
iteration 4 batch 7320 training_loss 0.6931471805599453
iteration 4 batch 7330 training_loss 0.6931471805599453
iteration 4 batch 7340 training_loss 0.6931471805599453
iteration 4 batch 7350 training_loss 0.6931471805599453
iteration 4 batch 7360 training_loss 0.6931471805599453
iteration 4 batch 7370 training_loss 0.6931471805599453
iteration 4 batch 7380 training_loss 0.6931471805599453
iteration 4 batch 7390 training_loss 0.6931471805599453
iteration 4 batch 7400 training_loss 0.6931471805599453
iteration 4 batch 7410 training_loss 0.6931471805599453
iteration 4 batch 7420 training_loss 0.6931471805599453
iteration 4 batch 7430 training_loss 0.6931471805599453
iteration 4 batch 7440 training_loss 0.6916632528527511
iteration 4 batch 7450 training_loss 0.6931471805599453
iteration 4 batch 7460 training_loss 0.6931471805599453
iteration 4 batch 7470 training_loss 0.6931471805599453
iteration 4 batch 7480 training_loss 0.6931471805599453
iteration 4 batch 7490 training_loss 0.6931471805599453
iteration 4 batch 7500 training_loss 0.6931471805599453
iteration 4 batch 7510 training_loss 0.6931471805599453
iteration 4 batch 7520 training_loss 0.6931471805599453
iteration 4 batch 7530 training_loss 0.6916632528527511
iteration 4 batch 7540 training_loss 0.6931471805599453
iteration 4 batch 7550 training_loss 0.6916632528527511
iteration 4 batch 7560 training_loss 0.6931471805599453
iteration 4 batch 7570 training_loss 0.6931471805599453
iteration 4 batch 7580 training_loss 0.6931471805599453
iteration 4 batch 7590 training_loss 0.6931471805599453
iteration 4 batch 7600 training_loss 0.6931471805599453
iteration 4 batch 7610 training_loss 0.6931471805599453
iteration 4 batch 7620 training_loss 0.6931471805599453
iteration 4 batch 7630 training_loss 0.6931471805599453
iteration 4 batch 7640 training_loss 0.6931471805599453
iteration 4 batch 7650 training_loss 0.6931471805599453
iteration 4 batch 7660 training_loss 0.6916632528527511
iteration 4 batch 7670 training_loss 0.6931471805599453
iteration 4 batch 7680 training_loss 0.6931471805599453
iteration 4 batch 7690 training_loss 0.6931471805599453
iteration 4 batch 7700 training_loss 0.6931471805599453
iteration 4 batch 7710 training_loss 0.6916632528527511
iteration 4 batch 7720 training_loss 0.6931471805599453
iteration 4 batch 7730 training_loss 0.6931471805599453
iteration 4 batch 7740 training_loss 0.6931471805599453
iteration 4 batch 7750 training_loss 0.6931471805599453
iteration 4 batch 7760 training_loss 0.6931471805599453
iteration 4 batch 7770 training_loss 0.6931471805599453
iteration 4 batch 7780 training_loss 0.6931471805599453
iteration 4 batch 7790 training_loss 0.6931471805599453
iteration 4 batch 7800 training_loss 0.6931471805599453
iteration 4 batch 7810 training_loss 0.6931471805599453
iteration 4 batch 7820 training_loss 0.6931471805599453
iteration 4 batch 7830 training_loss 0.6931471805599453
iteration 4 batch 7840 training_loss 0.6931471805599453
iteration 4 batch 7850 training_loss 0.6931471805599453
iteration 4 batch 7860 training_loss 0.6931471805599453
iteration 4 batch 7870 training_loss 0.6931471805599453
iteration 4 batch 7880 training_loss 0.6931471805599453
iteration 4 batch 7890 training_loss 0.6931471805599453
iteration 4 batch 7900 training_loss 0.6916632528527511
iteration 4 batch 7910 training_loss 0.6916632528527511
iteration 4 batch 7920 training_loss 0.6916632528527511
iteration 4 batch 7930 training_loss 0.6931471805599453
iteration 4 batch 7940 training_loss 0.6931471805599453
iteration 4 batch 7950 training_loss 0.6931471805599453
iteration 4 batch 7960 training_loss 0.6931471805599453
iteration 4 batch 7970 training_loss 0.6931471805599453
iteration 4 batch 7980 training_loss 0.6931471805599453
iteration 4 batch 7990 training_loss 0.6931471805599453
iteration 4 batch 8000 training_loss 0.6931471805599453
iteration 4 batch 8010 training_loss 0.6931471805599453
iteration 4 batch 8020 training_loss 0.6931471805599453
iteration 4 batch 8030 training_loss 0.6931471805599453
iteration 4 batch 8040 training_loss 0.6931471805599453
iteration 4 batch 8050 training_loss 0.6931471805599453
iteration 4 batch 8060 training_loss 0.6931471805599453
iteration 4 batch 8070 training_loss 0.6931471805599453
iteration 4 batch 8080 training_loss 0.6931471805599453
iteration 4 batch 8090 training_loss 0.6931471805599453
iteration 4 batch 8100 training_loss 0.6931471805599453
iteration 4 batch 8110 training_loss 0.6931471805599453
iteration 4 batch 8120 training_loss 0.6931471805599453
iteration 4 batch 8130 training_loss 0.6931471805599453
iteration 4 batch 8140 training_loss 0.6931471805599453
iteration 4 batch 8150 training_loss 0.6931471805599453
iteration 4 batch 8160 training_loss 0.6931471805599453
iteration 4 batch 8170 training_loss 0.6931471805599453
iteration 4 batch 8180 training_loss 0.6916632528527511
iteration 4 batch 8190 training_loss 0.6916632528527511
iteration 4 batch 8200 training_loss 0.6931471805599453
iteration 4 batch 8210 training_loss 0.6931471805599453
iteration 4 batch 8220 training_loss 0.6931471805599453
iteration 4 batch 8230 training_loss 0.6931471805599453
iteration 4 batch 8240 training_loss 0.6931471805599453
iteration 4 batch 8250 training_loss 0.6931471805599453
iteration 4 batch 8260 training_loss 0.6931471805599453
iteration 4 batch 8270 training_loss 0.6916632528527511
iteration 4 batch 8280 training_loss 0.6931471805599453
iteration 4 batch 8290 training_loss 0.6931471805599453
iteration 4 batch 8300 training_loss 0.6916632528527511
iteration 4 batch 8310 training_loss 0.6931471805599453
iteration 4 batch 8320 training_loss 0.6931471805599453
iteration 4 batch 8330 training_loss 0.6931471805599453
iteration 4 batch 8340 training_loss 0.6931471805599453
iteration 4 batch 8350 training_loss 0.6931471805599453
iteration 4 batch 8360 training_loss 0.6931471805599453
iteration 4 batch 8370 training_loss 0.6931471805599453
iteration 4 batch 8380 training_loss 0.6931471805599453
iteration 4 batch 8390 training_loss 0.6931471805599453
iteration 4 batch 8400 training_loss 0.6931471805599453
iteration 4 batch 8410 training_loss 0.6916632528527511
iteration 4 batch 8420 training_loss 0.6931471805599453
iteration 4 batch 8430 training_loss 0.6931471805599453
iteration 4 batch 8440 training_loss 0.6931471805599453
iteration 4 batch 8450 training_loss 0.6931471805599453
iteration 4 batch 8460 training_loss 0.6931471805599453
iteration 4 batch 8470 training_loss 0.6931471805599453
iteration 4 batch 8480 training_loss 0.6931471805599453
iteration 4 batch 8490 training_loss 0.6931471805599453
iteration 4 batch 8500 training_loss 0.6931471805599453
iteration 4 batch 8510 training_loss 0.6931471805599453
iteration 4 batch 8520 training_loss 0.6901793251455568
iteration 4 batch 8530 training_loss 0.6931471805599453
iteration 4 batch 8540 training_loss 0.6931471805599453
iteration 4 batch 8550 training_loss 0.6931471805599453
iteration 4 batch 8560 training_loss 0.6931471805599453
iteration 4 batch 8570 training_loss 0.6931471805599453
iteration 4 batch 8580 training_loss 0.6916632528527511
iteration 4 batch 8590 training_loss 0.6931471805599453
iteration 4 batch 8600 training_loss 0.6931471805599453
iteration 4 batch 8610 training_loss 0.6931471805599453
iteration 4 batch 8620 training_loss 0.6931471805599453
iteration 4 batch 8630 training_loss 0.6931471805599453
iteration 4 batch 8640 training_loss 0.6931471805599453
iteration 4 batch 8650 training_loss 0.6916632528527511
iteration 4 batch 8660 training_loss 0.6931471805599453
iteration 4 batch 8670 training_loss 0.6931471805599453
iteration 4 batch 8680 training_loss 0.6916632528527511
iteration 4 batch 8690 training_loss 0.6931471805599453
iteration 4 batch 8700 training_loss 0.6931471805599453
iteration 4 batch 8710 training_loss 0.6931471805599453
iteration 4 batch 8720 training_loss 0.6916632528527511
iteration 4 batch 8730 training_loss 0.6931471805599453
iteration 4 batch 8740 training_loss 0.6931471805599453
iteration 4 batch 8750 training_loss 0.6916632528527511
iteration 4 batch 8760 training_loss 0.6931471805599453
iteration 4 batch 8770 training_loss 0.6931471805599453
iteration 4 batch 8780 training_loss 0.6931471805599453
iteration 4 batch 8790 training_loss 0.6931471805599453
iteration 4 batch 8800 training_loss 0.6931471805599453
iteration 4 batch 8810 training_loss 0.6931471805599453
iteration 4 batch 8820 training_loss 0.6931471805599453
iteration 4 batch 8830 training_loss 0.6931471805599453
iteration 4 batch 8840 training_loss 0.6931471805599453
iteration 4 batch 8850 training_loss 0.6931471805599453
iteration 4 batch 8860 training_loss 0.6931471805599453
iteration 4 batch 8870 training_loss 0.6931471805599453
iteration 4 batch 8880 training_loss 0.6931471805599453
iteration 4 batch 8890 training_loss 0.6931471805599453
iteration 4 batch 8900 training_loss 0.6916632528527511
iteration 4 batch 8910 training_loss 0.6931471805599453
iteration 4 batch 8920 training_loss 0.6931471805599453
iteration 4 batch 8930 training_loss 0.6931471805599453
iteration 4 batch 8940 training_loss 0.6931471805599453
iteration 4 batch 8950 training_loss 0.6931471805599453
iteration 4 batch 8960 training_loss 0.6931471805599453
iteration 4 batch 8970 training_loss 0.6931471805599453
iteration 4 batch 8980 training_loss 0.6931471805599453
iteration 4 batch 8990 training_loss 0.6931471805599453
iteration 4 batch 9000 training_loss 0.6931471805599453
iteration 4 batch 9010 training_loss 0.6931471805599453
iteration 4 batch 9020 training_loss 0.6931471805599453
iteration 4 batch 9030 training_loss 0.6931471805599453
iteration 4 batch 9040 training_loss 0.6931471805599453
iteration 4 batch 9050 training_loss 0.6931471805599453
iteration 4 batch 9060 training_loss 0.6931471805599453
iteration 4 batch 9070 training_loss 0.6931471805599453
iteration 4 batch 9080 training_loss 0.6931471805599453
iteration 4 batch 9090 training_loss 0.6931471805599453
iteration 4 batch 9100 training_loss 0.6931471805599453
iteration 4 batch 9110 training_loss 0.6931471805599453
iteration 4 batch 9120 training_loss 0.6931471805599453
iteration 4 batch 9130 training_loss 0.6931471805599453
iteration 4 batch 9140 training_loss 0.6931471805599453
iteration 4 batch 9150 training_loss 0.6931471805599453
iteration 4 batch 9160 training_loss 0.6931471805599453
iteration 4 batch 9170 training_loss 0.6931471805599453
iteration 4 batch 9180 training_loss 0.6931471805599453
iteration 4 batch 9190 training_loss 0.6931471805599453
iteration 4 batch 9200 training_loss 0.6931471805599453
iteration 4 batch 9210 training_loss 0.6931471805599453
iteration 4 batch 9220 training_loss 0.6931471805599453
iteration 4 batch 9230 training_loss 0.6931471805599453
iteration 4 batch 9240 training_loss 0.6931471805599453
iteration 4 batch 9250 training_loss 0.6931471805599453
iteration 4 batch 9260 training_loss 0.6931471805599453
iteration 4 batch 9270 training_loss 0.6931471805599453
iteration 4 batch 9280 training_loss 0.6931471805599453
iteration 4 batch 9290 training_loss 0.6931471805599453
iteration 4 batch 9300 training_loss 0.6931471805599453
iteration 4 batch 9310 training_loss 0.6931471805599453
iteration 4 batch 9320 training_loss 0.6931471805599453
iteration 4 batch 9330 training_loss 0.6931471805599453
iteration 4 batch 9340 training_loss 0.6931471805599453
iteration 4 batch 9350 training_loss 0.6931471805599453
iteration 4 batch 9360 training_loss 0.6931471805599453
iteration 4 batch 9370 training_loss 0.6916632528527511
iteration 4 batch 9380 training_loss 0.6931471805599453
iteration 4 batch 9390 training_loss 0.6931471805599453
iteration 4 batch 9400 training_loss 0.6931471805599453
iteration 4 batch 9410 training_loss 0.6931471805599453
iteration 4 batch 9420 training_loss 0.6931471805599453
iteration 4 batch 9430 training_loss 0.6931471805599453
iteration 4 batch 9440 training_loss 0.6931471805599453
iteration 4 batch 9450 training_loss 0.6931471805599453
iteration 4 batch 9460 training_loss 0.6931471805599453
iteration 4 batch 9470 training_loss 0.6931471805599453
iteration 4 batch 9480 training_loss 0.6931471805599453
iteration 4 batch 9490 training_loss 0.6931471805599453
iteration 4 batch 9500 training_loss 0.6931471805599453
iteration 4 batch 9510 training_loss 0.6931471805599453
iteration 4 batch 9520 training_loss 0.6931471805599453
iteration 4 batch 9530 training_loss 0.6931471805599453
iteration 4 batch 9540 training_loss 0.6931471805599453
iteration 4 batch 9550 training_loss 0.6931471805599453
iteration 4 batch 9560 training_loss 0.6931471805599453
iteration 4 batch 9570 training_loss 0.6916632528527511
iteration 4 batch 9580 training_loss 0.6931471805599453
iteration 4 batch 9590 training_loss 0.6931471805599453
iteration 4 batch 9600 training_loss 0.6931471805599453
iteration 4 batch 9610 training_loss 0.6931471805599453
iteration 4 batch 9620 training_loss 0.6931471805599453
iteration 4 batch 9630 training_loss 0.6931471805599453
iteration 4 batch 9640 training_loss 0.6931471805599453
iteration 4 batch 9650 training_loss 0.6931471805599453
iteration 4 batch 9660 training_loss 0.6916632528527511
iteration 4 batch 9670 training_loss 0.6931471805599453
iteration 4 batch 9680 training_loss 0.6931471805599453
iteration 4 batch 9690 training_loss 0.6931471805599453
iteration 4 batch 9700 training_loss 0.6931471805599453
iteration 4 batch 9710 training_loss 0.6931471805599453
iteration 4 batch 9720 training_loss 0.6931471805599453
iteration 4 batch 9730 training_loss 0.6931471805599453
iteration 4 batch 9740 training_loss 0.6931471805599453
iteration 4 batch 9750 training_loss 0.6931471805599453
iteration 4 batch 9760 training_loss 0.6931471805599453
iteration 4 batch 9770 training_loss 0.6931471805599453
iteration 4 batch 9780 training_loss 0.6931471805599453
iteration 4 batch 9790 training_loss 0.6916632528527511
iteration 4 batch 9800 training_loss 0.6931471805599453
iteration 4 batch 9810 training_loss 0.6931471805599453
iteration 4 batch 9820 training_loss 0.6931471805599453
iteration 4 batch 9830 training_loss 0.6931471805599453
iteration 4 batch 9840 training_loss 0.6931471805599453
iteration 4 batch 9850 training_loss 0.6931471805599453
iteration 4 batch 9860 training_loss 0.6931471805599453
iteration 4 batch 9870 training_loss 0.6931471805599453
iteration 4 batch 9880 training_loss 0.6931471805599453
iteration 4 batch 9890 training_loss 0.6916632528527511
iteration 4 batch 9900 training_loss 0.6931471805599453
iteration 4 batch 9910 training_loss 0.6931471805599453
iteration 4 batch 9920 training_loss 0.6931471805599453
iteration 4 batch 9930 training_loss 0.6931471805599453
iteration 4 batch 9940 training_loss 0.6931471805599453
iteration 4 batch 9950 training_loss 0.6931471805599453
iteration 4 batch 9960 training_loss 0.6931471805599453
iteration 4 batch 9970 training_loss 0.6916632528527511
iteration 4 batch 9980 training_loss 0.6931471805599453
iteration 4 batch 9990 training_loss 0.6931471805599453
iteration 4 batch 10000 training_loss 0.6931471805599453
iteration 4 batch 10010 training_loss 0.6931471805599453
iteration 4 batch 10020 training_loss 0.6931471805599453
iteration 4 batch 10030 training_loss 0.6931471805599453
iteration 4 batch 10040 training_loss 0.6931471805599453
iteration 4 batch 10050 training_loss 0.6931471805599453
iteration 4 batch 10060 training_loss 0.6931471805599453
iteration 4 batch 10070 training_loss 0.6916632528527511
iteration 4 batch 10080 training_loss 0.6931471805599453
iteration 4 batch 10090 training_loss 0.6931471805599453
iteration 4 batch 10100 training_loss 0.6931471805599453
iteration 4 batch 10110 training_loss 0.6931471805599453
iteration 4 batch 10120 training_loss 0.6931471805599453
iteration 4 batch 10130 training_loss 0.6931471805599453
iteration 4 batch 10140 training_loss 0.6931471805599453
iteration 4 batch 10150 training_loss 0.6931471805599453
iteration 4 batch 10160 training_loss 0.6931471805599453
iteration 4 batch 10170 training_loss 0.6931471805599453
iteration 4 batch 10180 training_loss 0.6931471805599453
iteration 4 batch 10190 training_loss 0.6931471805599453
iteration 4 batch 10200 training_loss 0.6931471805599453
iteration 4 batch 10210 training_loss 0.6931471805599453
iteration 4 batch 10220 training_loss 0.6931471805599453
iteration 4 batch 10230 training_loss 0.6931471805599453
iteration 4 batch 10240 training_loss 0.6931471805599453
iteration 4 batch 10250 training_loss 0.6931471805599453
iteration 4 batch 10260 training_loss 0.6931471805599453
iteration 4 batch 10270 training_loss 0.6931471805599453
iteration 4 batch 10280 training_loss 0.6931471805599453
iteration 4 batch 10290 training_loss 0.6931471805599453
iteration 4 batch 10300 training_loss 0.6931471805599453
iteration 4 batch 10310 training_loss 0.6931471805599453
iteration 4 batch 10320 training_loss 0.6931471805599453
iteration 4 batch 10330 training_loss 0.6931471805599453
iteration 4 batch 10340 training_loss 0.6931471805599453
iteration 4 batch 10350 training_loss 0.6931471805599453
iteration 4 batch 10360 training_loss 0.6931471805599453
iteration 4 batch 10370 training_loss 0.6931471805599453
iteration 4 batch 10380 training_loss 0.6916632528527511
iteration 4 batch 10390 training_loss 0.6931471805599453
iteration 4 batch 10400 training_loss 0.6931471805599453
iteration 4 batch 10410 training_loss 0.6931471805599453
iteration 4 batch 10420 training_loss 0.6931471805599453
iteration 4 batch 10430 training_loss 0.6916632528527511
iteration 4 batch 10440 training_loss 0.6931471805599453
iteration 4 batch 10450 training_loss 0.6931471805599453
iteration 4 batch 10460 training_loss 0.6931471805599453
iteration 4 batch 10470 training_loss 0.6931471805599453
iteration 4 batch 10480 training_loss 0.6931471805599453
iteration 4 batch 10490 training_loss 0.6916632528527511
iteration 4 batch 10500 training_loss 0.6931471805599453
iteration 4 batch 10510 training_loss 0.6916632528527511
iteration 4 batch 10520 training_loss 0.6931471805599453
iteration 4 batch 10530 training_loss 0.6931471805599453
iteration 4 batch 10540 training_loss 0.6931471805599453
iteration 4 batch 10550 training_loss 0.6931471805599453
iteration 4 batch 10560 training_loss 0.6931471805599453
iteration 4 batch 10570 training_loss 0.6931471805599453
iteration 4 batch 10580 training_loss 0.6931471805599453
iteration 4 batch 10590 training_loss 0.6931471805599453
iteration 4 batch 10600 training_loss 0.6931471805599453
iteration 4 batch 10610 training_loss 0.6931471805599453
iteration 4 batch 10620 training_loss 0.6931471805599453
iteration 4 batch 10630 training_loss 0.6931471805599453
iteration 4 batch 10640 training_loss 0.6916632528527511
iteration 4 batch 10650 training_loss 0.6931471805599453
iteration 4 batch 10660 training_loss 0.6931471805599453
iteration 4 batch 10670 training_loss 0.6916632528527511
iteration 4 batch 10680 training_loss 0.6931471805599453
iteration 4 batch 10690 training_loss 0.6931471805599453
iteration 4 batch 10700 training_loss 0.6931471805599453
iteration 4 batch 10710 training_loss 0.6931471805599453
iteration 4 batch 10720 training_loss 0.6916632528527511
iteration 4 batch 10730 training_loss 0.6931471805599453
iteration 4 batch 10740 training_loss 0.6931471805599453
iteration 4 batch 10750 training_loss 0.6931471805599453
iteration 4 batch 10760 training_loss 0.6931471805599453
iteration 4 batch 10770 training_loss 0.6931471805599453
iteration 4 batch 10780 training_loss 0.6931471805599453
iteration 4 batch 10790 training_loss 0.6931471805599453
iteration 4 batch 10800 training_loss 0.6931471805599453
iteration 4 batch 10810 training_loss 0.6931471805599453
iteration 4 batch 10820 training_loss 0.6931471805599453
iteration 4 batch 10830 training_loss 0.6931471805599453
iteration 4 batch 10840 training_loss 0.6931471805599453
iteration 4 batch 10850 training_loss 0.6931471805599453
iteration 4 batch 10860 training_loss 0.6916632528527511
iteration 4 batch 10870 training_loss 0.6931471805599453
iteration 4 batch 10880 training_loss 0.6931471805599453
iteration 4 batch 10890 training_loss 0.6931471805599453
iteration 4 batch 10900 training_loss 0.6931471805599453
iteration 4 batch 10910 training_loss 0.6931471805599453
iteration 4 batch 10920 training_loss 0.6931471805599453
iteration 4 batch 10930 training_loss 0.6931471805599453
iteration 4 batch 10940 training_loss 0.6931471805599453
iteration 4 batch 10950 training_loss 0.6931471805599453
iteration 4 batch 10960 training_loss 0.6916632528527511
iteration 4 batch 10970 training_loss 0.6931471805599453
iteration 4 batch 10980 training_loss 0.6916632528527511
iteration 4 batch 10990 training_loss 0.6931471805599453
iteration 4 batch 11000 training_loss 0.6931471805599453
iteration 4 batch 11010 training_loss 0.6931471805599453
iteration 4 batch 11020 training_loss 0.6931471805599453
iteration 4 batch 11030 training_loss 0.6931471805599453
iteration 4 batch 11040 training_loss 0.6931471805599453
iteration 4 batch 11050 training_loss 0.6931471805599453
iteration 4 batch 11060 training_loss 0.6931471805599453
iteration 4 batch 11070 training_loss 0.6931471805599453
iteration 4 batch 11080 training_loss 0.6931471805599453
iteration 4 batch 11090 training_loss 0.6931471805599453
iteration 4 batch 11100 training_loss 0.6931471805599453
iteration 4 batch 11110 training_loss 0.6931471805599453
iteration 4 batch 11120 training_loss 0.6931471805599453
iteration 4 batch 11130 training_loss 0.6931471805599453
iteration 4 batch 11140 training_loss 0.6931471805599453
iteration 4 batch 11150 training_loss 0.6931471805599453
iteration 4 batch 11160 training_loss 0.6916632528527511
iteration 4 batch 11170 training_loss 0.6931471805599453
iteration 4 batch 11180 training_loss 0.6931471805599453
iteration 4 batch 11190 training_loss 0.6931471805599453
iteration 4 batch 11200 training_loss 0.6931471805599453
iteration 4 batch 11210 training_loss 0.6931471805599453
iteration 4 batch 11220 training_loss 0.6931471805599453
iteration 4 batch 11230 training_loss 0.6931471805599453
iteration 4 batch 11240 training_loss 0.6931471805599453
iteration 4 batch 11250 training_loss 0.6931471805599453
iteration 4 batch 11260 training_loss 0.6931471805599453
iteration 4 batch 11270 training_loss 0.6931471805599453
iteration 4 batch 11280 training_loss 0.6931471805599453
iteration 4 batch 11290 training_loss 0.6931471805599453
iteration 4 batch 11300 training_loss 0.6931471805599453
iteration 4 batch 11310 training_loss 0.6931471805599453
iteration 4 batch 11320 training_loss 0.6931471805599453
iteration 4 batch 11330 training_loss 0.6931471805599453
iteration 4 batch 11340 training_loss 0.6931471805599453
iteration 4 batch 11350 training_loss 0.6931471805599453
iteration 4 batch 11360 training_loss 0.6931471805599453
iteration 4 batch 11370 training_loss 0.6931471805599453
iteration 4 batch 11380 training_loss 0.6931471805599453
iteration 4 batch 11390 training_loss 0.6931471805599453
iteration 4 batch 11400 training_loss 0.6931471805599453
iteration 4 batch 11410 training_loss 0.6931471805599453
iteration 4 batch 11420 training_loss 0.6931471805599453
iteration 4 batch 11430 training_loss 0.6931471805599453
iteration 4 batch 11440 training_loss 0.6931471805599453
iteration 4 batch 11450 training_loss 0.6931471805599453
iteration 4 batch 11460 training_loss 0.6931471805599453
iteration 4 batch 11470 training_loss 0.6931471805599453
iteration 4 batch 11480 training_loss 0.6931471805599453
iteration 4 batch 11490 training_loss 0.6931471805599453
iteration 4 batch 11500 training_loss 0.6931471805599453
iteration 4 batch 11510 training_loss 0.6931471805599453
iteration 4 batch 11520 training_loss 0.6931471805599453
iteration 4 batch 11530 training_loss 0.6931471805599453
iteration 4 batch 11540 training_loss 0.6931471805599453
iteration 4 batch 11550 training_loss 0.6916632528527511
iteration 4 batch 11560 training_loss 0.6931471805599453
iteration 4 batch 11570 training_loss 0.6931471805599453
iteration 4 batch 11580 training_loss 0.6931471805599453
iteration 4 batch 11590 training_loss 0.6931471805599453
iteration 4 batch 11600 training_loss 0.6916632528527511
iteration 4 batch 11610 training_loss 0.6931471805599453
iteration 4 batch 11620 training_loss 0.6931471805599453
iteration 4 batch 11630 training_loss 0.6931471805599453
iteration 4 batch 11640 training_loss 0.6931471805599453
iteration 4 batch 11650 training_loss 0.6931471805599453
iteration 4 batch 11660 training_loss 0.6916632528527511
iteration 4 batch 11670 training_loss 0.6931471805599453
iteration 4 batch 11680 training_loss 0.6931471805599453
iteration 4 batch 11690 training_loss 0.6931471805599453
iteration 4 batch 11700 training_loss 0.6931471805599453
iteration 4 batch 11710 training_loss 0.6931471805599453
iteration 4 batch 11720 training_loss 0.6931471805599453
iteration 4 batch 11730 training_loss 0.6931471805599453
iteration 4 batch 11740 training_loss 0.6931471805599453
iteration 4 batch 11750 training_loss 0.6931471805599453
iteration 4 batch 11760 training_loss 0.6931471805599453
iteration 4 batch 11770 training_loss 0.6931471805599453
iteration 4 batch 11780 training_loss 0.6931471805599453
iteration 4 batch 11790 training_loss 0.6931471805599453
iteration 4 batch 11800 training_loss 0.6931471805599453
iteration 4 batch 11810 training_loss 0.6931471805599453
iteration 4 batch 11820 training_loss 0.6931471805599453
iteration 4 batch 11830 training_loss 0.6931471805599453
iteration 4 batch 11840 training_loss 0.6931471805599453
iteration 4 batch 11850 training_loss 0.6931471805599453
iteration 4 batch 11860 training_loss 0.6931471805599453
iteration 4 batch 11870 training_loss 0.6931471805599453
iteration 4 batch 11880 training_loss 0.6916632528527511
iteration 4 batch 11890 training_loss 0.6931471805599453
iteration 4 batch 11900 training_loss 0.6931471805599453
iteration 4 batch 11910 training_loss 0.6931471805599453
iteration 4 batch 11920 training_loss 0.6931471805599453
iteration 4 batch 11930 training_loss 0.6931471805599453
iteration 4 batch 11940 training_loss 0.6931471805599453
iteration 4 batch 11950 training_loss 0.6931471805599453
iteration 4 batch 11960 training_loss 0.6931471805599453
iteration 4 batch 11970 training_loss 0.6931471805599453
iteration 4 batch 11980 training_loss 0.6931471805599453
iteration 4 batch 11990 training_loss 0.6916632528527511
iteration 4 batch 12000 training_loss 0.6931471805599453
iteration 4 batch 12010 training_loss 0.6931471805599453
iteration 4 batch 12020 training_loss 0.6916632528527511
iteration 4 batch 12030 training_loss 0.6931471805599453
iteration 4 batch 12040 training_loss 0.6931471805599453
iteration 4 batch 12050 training_loss 0.6931471805599453
iteration 4 batch 12060 training_loss 0.6931471805599453
iteration 4 batch 12070 training_loss 0.6931471805599453
iteration 4 batch 12080 training_loss 0.6931471805599453
iteration 4 batch 12090 training_loss 0.6931471805599453
iteration 4 batch 12100 training_loss 0.6931471805599453
iteration 4 batch 12110 training_loss 0.6931471805599453
iteration 4 batch 12120 training_loss 0.6931471805599453
iteration 4 batch 12130 training_loss 0.6931471805599453
iteration 4 batch 12140 training_loss 0.6931471805599453
iteration 4 batch 12150 training_loss 0.6931471805599453
iteration 4 batch 12160 training_loss 0.6931471805599453
iteration 4 batch 12170 training_loss 0.6931471805599453
iteration 4 batch 12180 training_loss 0.6931471805599453
iteration 4 batch 12190 training_loss 0.6931471805599453
iteration 4 batch 12200 training_loss 0.6931471805599453
iteration 4 batch 12210 training_loss 0.6931471805599453
iteration 4 batch 12220 training_loss 0.6931471805599453
iteration 4 batch 12230 training_loss 0.6931471805599453
iteration 4 batch 12240 training_loss 0.6931471805599453
iteration 4 batch 12250 training_loss 0.6931471805599453
iteration 4 batch 12260 training_loss 0.6931471805599453
iteration 4 batch 12270 training_loss 0.6931471805599453
iteration 4 batch 12280 training_loss 0.6931471805599453
iteration 4 batch 12290 training_loss 0.6931471805599453
iteration 4 batch 12300 training_loss 0.6931471805599453
iteration 4 batch 12310 training_loss 0.6931471805599453
iteration 4 batch 12320 training_loss 0.6931471805599453
iteration 4 batch 12330 training_loss 0.6931471805599453
iteration 4 batch 12340 training_loss 0.6931471805599453
iteration 4 batch 12350 training_loss 0.6931471805599453
iteration 4 batch 12360 training_loss 0.6931471805599453
iteration 4 batch 12370 training_loss 0.6931471805599453
iteration 4 batch 12380 training_loss 0.6931471805599453
iteration 4 batch 12390 training_loss 0.6931471805599453
iteration 4 batch 12400 training_loss 0.6931471805599453
iteration 4 batch 12410 training_loss 0.6931471805599453
iteration 4 batch 12420 training_loss 0.6931471805599453
iteration 4 batch 12430 training_loss 0.6931471805599453
iteration 4 batch 12440 training_loss 0.6931471805599453
iteration 4 batch 12450 training_loss 0.6931471805599453
iteration 4 batch 12460 training_loss 0.6931471805599453
iteration 4 batch 12470 training_loss 0.6931471805599453
iteration 4 batch 12480 training_loss 0.6916632528527511
iteration 4 batch 12490 training_loss 0.6916632528527511
iteration 4 batch 12500 training_loss 0.6931471805599453
iteration 4 batch 12510 training_loss 0.6931471805599453
iteration 4 batch 12520 training_loss 0.6931471805599453
iteration 4 batch 12530 training_loss 0.6931471805599453
iteration 4 batch 12540 training_loss 0.6931471805599453
iteration 4 batch 12550 training_loss 0.6931471805599453
iteration 4 batch 12560 training_loss 0.6931471805599453
iteration 4 batch 12570 training_loss 0.6931471805599453
iteration 4 batch 12580 training_loss 0.6931471805599453
iteration 4 batch 12590 training_loss 0.6916632528527511
iteration 4 batch 12600 training_loss 0.6931471805599453
iteration 4 batch 12610 training_loss 0.6916632528527511
iteration 4 batch 12620 training_loss 0.6931471805599453
iteration 4 batch 12630 training_loss 0.6931471805599453
iteration 4 batch 12640 training_loss 0.6931471805599453
iteration 4 batch 12650 training_loss 0.6916632528527511
iteration 4 batch 12660 training_loss 0.6931471805599453
iteration 4 batch 12670 training_loss 0.6931471805599453
iteration 4 batch 12680 training_loss 0.6916632528527511
iteration 4 batch 12690 training_loss 0.6931471805599453
iteration 4 batch 12700 training_loss 0.6931471805599453
iteration 4 batch 12710 training_loss 0.6931471805599453
iteration 4 batch 12720 training_loss 0.6931471805599453
iteration 4 batch 12730 training_loss 0.6931471805599453
iteration 4 batch 12740 training_loss 0.6931471805599453
iteration 4 batch 12750 training_loss 0.6931471805599453
iteration 4 batch 12760 training_loss 0.6931471805599453
iteration 4 batch 12770 training_loss 0.6931471805599453
iteration 4 batch 12780 training_loss 0.6931471805599453
iteration 4 batch 12790 training_loss 0.6931471805599453
iteration 4 batch 12800 training_loss 0.6931471805599453
iteration 4 batch 12810 training_loss 0.6931471805599453
iteration 4 batch 12820 training_loss 0.6931471805599453
iteration 4 batch 12830 training_loss 0.6931471805599453
iteration 4 batch 12840 training_loss 0.6931471805599453
iteration 4 batch 12850 training_loss 0.6931471805599453
iteration 4 batch 12860 training_loss 0.6931471805599453
iteration 4 batch 12870 training_loss 0.6931471805599453
iteration 4 batch 12880 training_loss 0.6931471805599453
iteration 4 batch 12890 training_loss 0.6931471805599453
iteration 4 batch 12900 training_loss 0.6931471805599453
iteration 4 batch 12910 training_loss 0.6931471805599453
iteration 4 batch 12920 training_loss 0.6931471805599453
iteration 4 batch 12930 training_loss 0.6931471805599453
iteration 4 batch 12940 training_loss 0.6931471805599453
iteration 4 batch 12950 training_loss 0.6931471805599453
iteration 4 batch 12960 training_loss 0.6916632528527511
iteration 4 batch 12970 training_loss 0.6931471805599453
iteration 4 batch 12980 training_loss 0.6931471805599453
iteration 4 batch 12990 training_loss 0.6931471805599453
iteration 4 batch 13000 training_loss 0.6931471805599453
iteration 4 batch 13010 training_loss 0.6931471805599453
iteration 4 batch 13020 training_loss 0.6931471805599453
iteration 4 batch 13030 training_loss 0.6931471805599453
iteration 4 batch 13040 training_loss 0.6931471805599453
iteration 4 batch 13050 training_loss 0.6931471805599453
iteration 4 batch 13060 training_loss 0.6931471805599453
iteration 4 batch 13070 training_loss 0.6931471805599453
iteration 4 batch 13080 training_loss 0.6931471805599453
iteration 4 batch 13090 training_loss 0.6931471805599453
iteration 4 batch 13100 training_loss 0.6931471805599453
iteration 4 batch 13110 training_loss 0.6931471805599453
iteration 4 batch 13120 training_loss 0.6931471805599453
iteration 4 batch 13130 training_loss 0.6931471805599453
iteration 4 batch 13140 training_loss 0.6931471805599453
iteration 4 batch 13150 training_loss 0.6931471805599453
iteration 4 batch 13160 training_loss 0.6931471805599453
iteration 4 batch 13170 training_loss 0.6931471805599453
iteration 4 batch 13180 training_loss 0.6931471805599453
iteration 4 batch 13190 training_loss 0.6931471805599453
iteration 4 batch 13200 training_loss 0.6931471805599453
iteration 4 batch 13210 training_loss 0.6931471805599453
iteration 4 batch 13220 training_loss 0.6916632528527511
iteration 4 batch 13230 training_loss 0.6931471805599453
iteration 4 batch 13240 training_loss 0.6916632528527511
iteration 4 batch 13250 training_loss 0.6931471805599453
iteration 4 batch 13260 training_loss 0.6931471805599453
iteration 4 batch 13270 training_loss 0.6931471805599453
iteration 4 batch 13280 training_loss 0.6931471805599453
iteration 4 batch 13290 training_loss 0.6931471805599453
iteration 4 batch 13300 training_loss 0.6931471805599453
iteration 4 batch 13310 training_loss 0.6931471805599453
iteration 4 batch 13320 training_loss 0.6931471805599453
iteration 4 batch 13330 training_loss 0.6931471805599453
iteration 4 batch 13340 training_loss 0.6931471805599453
iteration 4 batch 13350 training_loss 0.6931471805599453
iteration 4 batch 13360 training_loss 0.6931471805599453
iteration 4 batch 13370 training_loss 0.6931471805599453
iteration 4 batch 13380 training_loss 0.6931471805599453
iteration 4 batch 13390 training_loss 0.6916632528527511
iteration 4 batch 13400 training_loss 0.6931471805599453
iteration 4 batch 13410 training_loss 0.6931471805599453
iteration 4 batch 13420 training_loss 0.6931471805599453
iteration 4 batch 13430 training_loss 0.6931471805599453
iteration 4 batch 13440 training_loss 0.6931471805599453
iteration 4 batch 13450 training_loss 0.6931471805599453
iteration 4 batch 13460 training_loss 0.6931471805599453
iteration 4 batch 13470 training_loss 0.6931471805599453
iteration 4 batch 13480 training_loss 0.6931471805599453
iteration 4 batch 13490 training_loss 0.6931471805599453
iteration 4 batch 13500 training_loss 0.6931471805599453
iteration 4 batch 13510 training_loss 0.6931471805599453
iteration 4 batch 13520 training_loss 0.6931471805599453
iteration 4 batch 13530 training_loss 0.6931471805599453
iteration 4 batch 13540 training_loss 0.6931471805599453
iteration 4 batch 13550 training_loss 0.6931471805599453
iteration 4 batch 13560 training_loss 0.6931471805599453
iteration 4 batch 13570 training_loss 0.6931471805599453
iteration 4 batch 13580 training_loss 0.6931471805599453
iteration 4 batch 13590 training_loss 0.6931471805599453
iteration 4 batch 13600 training_loss 0.6931471805599453
iteration 4 batch 13610 training_loss 0.6916632528527511
iteration 4 batch 13620 training_loss 0.6931471805599453
iteration 4 batch 13630 training_loss 0.6931471805599453
iteration 4 batch 13640 training_loss 0.6931471805599453
iteration 4 batch 13650 training_loss 0.6931471805599453
iteration 4 batch 13660 training_loss 0.6931471805599453
iteration 4 batch 13670 training_loss 0.6916632528527511
iteration 4 batch 13680 training_loss 0.6931471805599453
iteration 4 batch 13690 training_loss 0.6931471805599453
iteration 4 batch 13700 training_loss 0.6931471805599453
iteration 4 batch 13710 training_loss 0.6931471805599453
iteration 4 batch 13720 training_loss 0.6931471805599453
iteration 4 batch 13730 training_loss 0.6931471805599453
iteration 4 batch 13740 training_loss 0.6931471805599453
iteration 4 batch 13750 training_loss 0.6916632528527511
iteration 4 batch 13760 training_loss 0.6931471805599453
iteration 4 batch 13770 training_loss 0.6931471805599453
iteration 4 batch 13780 training_loss 0.6916632528527511
iteration 4 batch 13790 training_loss 0.6931471805599453
iteration 4 batch 13800 training_loss 0.6931471805599453
iteration 4 batch 13810 training_loss 0.6931471805599453
iteration 4 batch 13820 training_loss 0.6931471805599453
iteration 4 batch 13830 training_loss 0.6931471805599453
iteration 4 batch 13840 training_loss 0.6931471805599453
iteration 4 batch 13850 training_loss 0.6931471805599453
iteration 4 batch 13860 training_loss 0.6931471805599453
iteration 4 batch 13870 training_loss 0.6931471805599453
iteration 4 batch 13880 training_loss 0.6931471805599453
iteration 4 batch 13890 training_loss 0.6931471805599453
iteration 4 batch 13900 training_loss 0.6931471805599453
iteration 4 batch 13910 training_loss 0.6931471805599453
iteration 4 batch 13920 training_loss 0.6931471805599453
iteration 4 batch 13930 training_loss 0.6931471805599453
iteration 4 batch 13940 training_loss 0.6931471805599453
iteration 4 batch 13950 training_loss 0.6916632528527511
iteration 4 batch 13960 training_loss 0.6931471805599453
iteration 4 batch 13970 training_loss 0.6916632528527511
iteration 4 batch 13980 training_loss 0.6931471805599453
iteration 4 batch 13990 training_loss 0.6931471805599453
iteration 4 batch 14000 training_loss 0.6931471805599453
iteration 4 batch 14010 training_loss 0.6931471805599453
iteration 4 batch 14020 training_loss 0.6931471805599453
iteration 4 batch 14030 training_loss 0.6931471805599453
iteration 4 batch 14040 training_loss 0.6931471805599453
iteration 4 batch 14050 training_loss 0.6916632528527511
iteration 4 batch 14060 training_loss 0.6931471805599453
iteration 4 batch 14070 training_loss 0.6931471805599453
iteration 4 batch 14080 training_loss 0.6931471805599453
iteration 4 batch 14090 training_loss 0.6931471805599453
iteration 4 batch 14100 training_loss 0.6931471805599453
iteration 4 batch 14110 training_loss 0.6931471805599453
iteration 4 batch 14120 training_loss 0.6916632528527511
iteration 4 batch 14130 training_loss 0.6931471805599453
iteration 4 batch 14140 training_loss 0.6931471805599453
iteration 4 batch 14150 training_loss 0.6916632528527511
iteration 4 batch 14160 training_loss 0.6931471805599453
iteration 4 batch 14170 training_loss 0.6931471805599453
iteration 4 batch 14180 training_loss 0.6931471805599453
iteration 4 batch 14190 training_loss 0.6931471805599453
iteration 4 batch 14200 training_loss 0.6931471805599453
iteration 4 batch 14210 training_loss 0.6931471805599453
iteration 4 batch 14220 training_loss 0.6931471805599453
iteration 4 batch 14230 training_loss 0.6931471805599453
iteration 4 batch 14240 training_loss 0.6931471805599453
iteration 4 batch 14250 training_loss 0.6931471805599453
iteration 4 batch 14260 training_loss 0.6931471805599453
iteration 4 batch 14270 training_loss 0.6931471805599453
iteration 4 batch 14280 training_loss 0.6931471805599453
iteration 4 batch 14290 training_loss 0.6931471805599453
iteration 4 batch 14300 training_loss 0.6931471805599453
iteration 4 batch 14310 training_loss 0.6931471805599453
iteration 4 batch 14320 training_loss 0.6931471805599453
iteration 4 batch 14330 training_loss 0.6931471805599453
iteration 4 batch 14340 training_loss 0.6931471805599453
iteration 4 batch 14350 training_loss 0.6931471805599453
iteration 4 batch 14360 training_loss 0.6931471805599453
iteration 4 batch 14370 training_loss 0.6916632528527511
iteration 4 batch 14380 training_loss 0.6931471805599453
iteration 4 batch 14390 training_loss 0.6931471805599453
iteration 4 batch 14400 training_loss 0.6931471805599453
iteration 4 batch 14410 training_loss 0.6931471805599453
iteration 4 batch 14420 training_loss 0.6931471805599453
iteration 4 batch 14430 training_loss 0.6931471805599453
iteration 4 batch 14440 training_loss 0.6931471805599453
iteration 4 batch 14450 training_loss 0.6931471805599453
iteration 4 batch 14460 training_loss 0.6931471805599453
iteration 4 batch 14470 training_loss 0.6931471805599453
iteration 4 batch 14480 training_loss 0.6916632528527511
iteration 4 batch 14490 training_loss 0.6931471805599453
iteration 4 batch 14500 training_loss 0.6931471805599453
iteration 4 batch 14510 training_loss 0.6931471805599453
iteration 4 batch 14520 training_loss 0.6931471805599453
iteration 4 batch 14530 training_loss 0.6931471805599453
iteration 4 batch 14540 training_loss 0.6931471805599453
iteration 4 batch 14550 training_loss 0.6931471805599453
iteration 4 batch 14560 training_loss 0.6931471805599453
iteration 4 batch 14570 training_loss 0.6931471805599453
iteration 4 batch 14580 training_loss 0.6931471805599453
iteration 4 batch 14590 training_loss 0.6931471805599453
iteration 4 batch 14600 training_loss 0.6931471805599453
iteration 4 batch 14610 training_loss 0.6916632528527511
iteration 4 batch 14620 training_loss 0.6931471805599453
iteration 4 batch 14630 training_loss 0.6931471805599453
iteration 4 batch 14640 training_loss 0.6931471805599453
iteration 4 batch 14650 training_loss 0.6931471805599453
iteration 4 batch 14660 training_loss 0.6931471805599453
iteration 4 batch 14670 training_loss 0.6931471805599453
iteration 4 batch 14680 training_loss 0.6931471805599453
iteration 4 batch 14690 training_loss 0.6931471805599453
iteration 4 batch 14700 training_loss 0.6931471805599453
iteration 4 batch 14710 training_loss 0.6931471805599453
iteration 4 batch 14720 training_loss 0.6931471805599453
iteration 4 batch 14730 training_loss 0.6931471805599453
iteration 4 batch 14740 training_loss 0.6931471805599453
iteration 4 batch 14750 training_loss 0.6931471805599453
iteration 4 batch 14760 training_loss 0.6931471805599453
iteration 4 batch 14770 training_loss 0.6931471805599453
iteration 4 batch 14780 training_loss 0.6931471805599453
iteration 4 batch 14790 training_loss 0.6931471805599453
iteration 4 batch 14800 training_loss 0.6931471805599453
iteration 4 batch 14810 training_loss 0.6931471805599453
iteration 4 batch 14820 training_loss 0.6931471805599453
iteration 4 batch 14830 training_loss 0.6931471805599453
iteration 4 batch 14840 training_loss 0.6931471805599453
iteration 4 batch 14850 training_loss 0.6931471805599453
iteration 4 batch 14860 training_loss 0.6931471805599453
iteration 4 batch 14870 training_loss 0.6916632528527511
iteration 4 batch 14880 training_loss 0.6931471805599453
iteration 4 batch 14890 training_loss 0.6931471805599453
iteration 4 batch 14900 training_loss 0.6931471805599453
iteration 4 batch 14910 training_loss 0.6931471805599453
iteration 4 batch 14920 training_loss 0.6931471805599453
iteration 4 batch 14930 training_loss 0.6931471805599453
iteration 4 batch 14940 training_loss 0.6931471805599453
iteration 4 batch 14950 training_loss 0.6916632528527511
iteration 4 batch 14960 training_loss 0.6931471805599453
iteration 4 batch 14970 training_loss 0.6931471805599453
iteration 4 batch 14980 training_loss 0.6931471805599453
iteration 4 batch 14990 training_loss 0.6931471805599453
iteration 4 batch 15000 training_loss 0.6931471805599453
iteration 4 batch 15010 training_loss 0.6931471805599453
iteration 4 batch 15020 training_loss 0.6916632528527511
iteration 4 batch 15030 training_loss 0.6931471805599453
iteration 4 batch 15040 training_loss 0.6931471805599453
iteration 4 batch 15050 training_loss 0.6931471805599453
iteration 4 batch 15060 training_loss 0.6931471805599453
iteration 4 batch 15070 training_loss 0.6931471805599453
iteration 4 batch 15080 training_loss 0.6931471805599453
iteration 4 batch 15090 training_loss 0.6931471805599453
iteration 4 batch 15100 training_loss 0.6931471805599453
iteration 4 batch 15110 training_loss 0.6931471805599453
iteration 4 batch 15120 training_loss 0.6931471805599453
iteration 4 batch 15130 training_loss 0.6931471805599453
iteration 4 batch 15140 training_loss 0.6931471805599453
iteration 4 batch 15150 training_loss 0.6931471805599453
iteration 4 batch 15160 training_loss 0.6931471805599453
iteration 4 batch 15170 training_loss 0.6931471805599453
iteration 4 batch 15180 training_loss 0.6931471805599453
iteration 4 batch 15190 training_loss 0.6931471805599453
iteration 4 batch 15200 training_loss 0.6931471805599453
iteration 4 batch 15210 training_loss 0.6931471805599453
iteration 4 batch 15220 training_loss 0.6931471805599453
iteration 4 batch 15230 training_loss 0.6931471805599453
iteration 4 batch 15240 training_loss 0.6931471805599453
iteration 4 batch 15250 training_loss 0.6931471805599453
iteration 4 batch 15260 training_loss 0.6931471805599453
iteration 4 batch 15270 training_loss 0.6931471805599453
iteration 4 batch 15280 training_loss 0.6931471805599453
iteration 4 batch 15290 training_loss 0.6931471805599453
iteration 4 batch 15300 training_loss 0.6916632528527511
iteration 4 batch 15310 training_loss 0.6931471805599453
iteration 4 batch 15320 training_loss 0.6931471805599453
iteration 4 batch 15330 training_loss 0.6931471805599453
iteration 4 batch 15340 training_loss 0.6931471805599453
iteration 4 batch 15350 training_loss 0.6931471805599453
iteration 4 batch 15360 training_loss 0.6931471805599453
iteration 4 batch 15370 training_loss 0.6931471805599453
iteration 4 batch 15380 training_loss 0.6931471805599453
iteration 4 batch 15390 training_loss 0.6931471805599453
iteration 4 batch 15400 training_loss 0.6931471805599453
iteration 4 batch 15410 training_loss 0.6931471805599453
iteration 4 batch 15420 training_loss 0.6931471805599453
iteration 4 batch 15430 training_loss 0.6931471805599453
iteration 4 batch 15440 training_loss 0.6931471805599453
iteration 4 batch 15450 training_loss 0.6931471805599453
iteration 4 batch 15460 training_loss 0.6931471805599453
iteration 4 batch 15470 training_loss 0.6931471805599453
iteration 4 batch 15480 training_loss 0.6931471805599453
iteration 4 batch 15490 training_loss 0.6931471805599453
iteration 4 batch 15500 training_loss 0.6931471805599453
iteration 4 batch 15510 training_loss 0.6931471805599453
iteration 4 batch 15520 training_loss 0.6931471805599453
iteration 4 batch 15530 training_loss 0.6916632528527511
iteration 4 batch 15540 training_loss 0.6931471805599453
iteration 4 batch 15550 training_loss 0.6931471805599453
iteration 4 batch 15560 training_loss 0.6931471805599453
iteration 4 batch 15570 training_loss 0.6931471805599453
iteration 4 batch 15580 training_loss 0.6931471805599453
iteration 4 batch 15590 training_loss 0.6931471805599453
iteration 4 batch 15600 training_loss 0.6931471805599453
iteration 4 batch 15610 training_loss 0.6931471805599453
iteration 4 batch 15620 training_loss 0.6931471805599453
iteration 4 batch 15630 training_loss 0.6931471805599453
iteration 4 batch 15640 training_loss 0.6931471805599453
iteration 4 batch 15650 training_loss 0.6931471805599453
iteration 4 batch 15660 training_loss 0.6931471805599453
iteration 4 batch 15670 training_loss 0.6931471805599453
iteration 4 batch 15680 training_loss 0.6931471805599453
iteration 4 batch 15690 training_loss 0.6916632528527511
iteration 4 batch 15700 training_loss 0.6931471805599453
iteration 4 batch 15710 training_loss 0.6931471805599453
iteration 4 batch 15720 training_loss 0.6931471805599453
iteration 4 batch 15730 training_loss 0.6916632528527511
iteration 4 batch 15740 training_loss 0.6931471805599453
iteration 4 batch 15750 training_loss 0.6931471805599453
iteration 4 batch 15760 training_loss 0.6931471805599453
iteration 4 batch 15770 training_loss 0.6931471805599453
iteration 4 batch 15780 training_loss 0.6931471805599453
iteration 4 batch 15790 training_loss 0.6931471805599453
iteration 4 batch 15800 training_loss 0.6931471805599453
iteration 4 batch 15810 training_loss 0.6931471805599453
iteration 4 batch 15820 training_loss 0.6931471805599453
iteration 4 batch 15830 training_loss 0.6931471805599453
iteration 4 batch 15840 training_loss 0.6931471805599453
iteration 4 batch 15850 training_loss 0.6931471805599453
iteration 4 batch 15860 training_loss 0.6931471805599453
iteration 4 batch 15870 training_loss 0.6916632528527511
iteration 4 batch 15880 training_loss 0.6931471805599453
iteration 4 batch 15890 training_loss 0.6931471805599453
iteration 4 batch 15900 training_loss 0.6931471805599453
iteration 4 batch 15910 training_loss 0.6931471805599453
iteration 4 batch 15920 training_loss 0.6931471805599453
iteration 4 batch 15930 training_loss 0.6931471805599453
iteration 4 batch 15940 training_loss 0.6931471805599453
iteration 4 batch 15950 training_loss 0.6916632528527511
iteration 4 batch 15960 training_loss 0.6931471805599453
iteration 4 batch 15970 training_loss 0.6916632528527511
iteration 4 batch 15980 training_loss 0.6931471805599453
iteration 4 batch 15990 training_loss 0.6931471805599453
iteration 4 batch 16000 training_loss 0.6931471805599453
iteration 4 batch 16010 training_loss 0.6916632528527511
iteration 4 batch 16020 training_loss 0.6916632528527511
iteration 4 batch 16030 training_loss 0.6931471805599453
iteration 4 batch 16040 training_loss 0.6931471805599453
iteration 4 batch 16050 training_loss 0.6931471805599453
iteration 4 batch 16060 training_loss 0.6931471805599453
iteration 4 batch 16070 training_loss 0.6931471805599453
iteration 4 batch 16080 training_loss 0.6931471805599453
iteration 4 batch 16090 training_loss 0.6916632528527511
iteration 4 batch 16100 training_loss 0.6931471805599453
iteration 4 batch 16110 training_loss 0.6931471805599453
iteration 4 batch 16120 training_loss 0.6931471805599453
iteration 4 batch 16130 training_loss 0.6931471805599453
iteration 4 batch 16140 training_loss 0.6931471805599453
iteration 4 batch 16150 training_loss 0.6931471805599453
iteration 4 batch 16160 training_loss 0.6931471805599453
iteration 4 batch 16170 training_loss 0.6931471805599453
iteration 4 batch 16180 training_loss 0.6931471805599453
iteration 4 batch 16190 training_loss 0.6931471805599453
iteration 4 batch 16200 training_loss 0.6931471805599453
iteration 4 batch 16210 training_loss 0.6931471805599453
iteration 4 batch 16220 training_loss 0.6931471805599453
iteration 4 batch 16230 training_loss 0.6931471805599453
iteration 4 batch 16240 training_loss 0.6931471805599453
iteration 4 batch 16250 training_loss 0.6931471805599453
iteration 4 batch 16260 training_loss 0.6931471805599453
iteration 4 batch 16270 training_loss 0.6916632528527511
iteration 4 batch 16280 training_loss 0.6931471805599453
iteration 4 batch 16290 training_loss 0.6931471805599453
iteration 4 batch 16300 training_loss 0.6931471805599453
iteration 4 batch 16310 training_loss 0.6931471805599453
iteration 4 batch 16320 training_loss 0.6931471805599453
iteration 4 batch 16330 training_loss 0.6916632528527511
iteration 4 batch 16340 training_loss 0.6931471805599453
iteration 4 batch 16350 training_loss 0.6931471805599453
iteration 4 batch 16360 training_loss 0.6931471805599453
iteration 4 batch 16370 training_loss 0.6916632528527511
iteration 4 batch 16380 training_loss 0.6931471805599453
iteration 4 batch 16390 training_loss 0.6916632528527511
iteration 4 batch 16400 training_loss 0.6931471805599453
iteration 4 batch 16410 training_loss 0.6931471805599453
iteration 4 batch 16420 training_loss 0.6931471805599453
iteration 4 batch 16430 training_loss 0.6931471805599453
iteration 4 batch 16440 training_loss 0.6931471805599453
iteration 4 batch 16450 training_loss 0.6931471805599453
iteration 4 batch 16460 training_loss 0.6931471805599453
iteration 4 batch 16470 training_loss 0.6931471805599453
iteration 4 batch 16480 training_loss 0.6931471805599453
iteration 4 batch 16490 training_loss 0.6931471805599453
iteration 4 batch 16500 training_loss 0.6931471805599453
iteration 4 batch 16510 training_loss 0.6931471805599453
iteration 4 batch 16520 training_loss 0.6931471805599453
iteration 4 batch 16530 training_loss 0.6931471805599453
iteration 4 batch 16540 training_loss 0.6931471805599453
iteration 4 batch 16550 training_loss 0.6931471805599453
iteration 4 batch 16560 training_loss 0.6931471805599453
iteration 4 batch 16570 training_loss 0.6916632528527511
iteration 4 batch 16580 training_loss 0.6931471805599453
iteration 4 batch 16590 training_loss 0.6931471805599453
iteration 4 batch 16600 training_loss 0.6931471805599453
iteration 4 batch 16610 training_loss 0.6931471805599453
iteration 4 batch 16620 training_loss 0.6931471805599453
iteration 4 batch 16630 training_loss 0.6931471805599453
iteration 4 batch 16640 training_loss 0.6931471805599453
iteration 4 batch 16650 training_loss 0.6931471805599453
iteration 4 batch 16660 training_loss 0.6931471805599453
iteration 4 batch 16670 training_loss 0.6931471805599453
iteration 4 batch 16680 training_loss 0.6931471805599453
iteration 4 batch 16690 training_loss 0.6931471805599453
iteration 4 batch 16700 training_loss 0.6931471805599453
iteration 4 batch 16710 training_loss 0.6931471805599453
iteration 4 batch 16720 training_loss 0.6931471805599453
iteration 4 batch 16730 training_loss 0.6931471805599453
iteration 4 batch 16740 training_loss 0.6931471805599453
iteration 4 batch 16750 training_loss 0.6931471805599453
iteration 4 batch 16760 training_loss 0.6931471805599453
iteration 4 batch 16770 training_loss 0.6931471805599453
iteration 4 batch 16780 training_loss 0.6931471805599453
iteration 4 batch 16790 training_loss 0.6931471805599453
iteration 4 batch 16800 training_loss 0.6931471805599453
iteration 4 batch 16810 training_loss 0.6931471805599453
iteration 4 batch 16820 training_loss 0.6931471805599453
iteration 4 batch 16830 training_loss 0.6931471805599453
iteration 4 batch 16840 training_loss 0.6931471805599453
iteration 4 batch 16850 training_loss 0.6931471805599453
iteration 4 batch 16860 training_loss 0.6931471805599453
iteration 4 batch 16870 training_loss 0.6931471805599453
iteration 4 batch 16880 training_loss 0.6931471805599453
iteration 4 batch 16890 training_loss 0.6931471805599453
iteration 4 batch 16900 training_loss 0.6931471805599453
iteration 4 batch 16910 training_loss 0.6931471805599453
iteration 4 batch 16920 training_loss 0.6931471805599453
iteration 4 batch 16930 training_loss 0.6931471805599453
iteration 4 batch 16940 training_loss 0.6931471805599453
iteration 4 batch 16950 training_loss 0.6916632528527511
iteration 4 batch 16960 training_loss 0.6931471805599453
iteration 4 batch 16970 training_loss 0.6931471805599453
iteration 4 batch 16980 training_loss 0.6931471805599453
iteration 4 batch 16990 training_loss 0.6931471805599453
iteration 4 batch 17000 training_loss 0.6931471805599453
iteration 4 batch 17010 training_loss 0.6931471805599453
iteration 4 batch 17020 training_loss 0.6931471805599453
iteration 4 batch 17030 training_loss 0.6931471805599453
iteration 4 batch 17040 training_loss 0.6931471805599453
iteration 4 batch 17050 training_loss 0.6931471805599453
iteration 4 batch 17060 training_loss 0.6931471805599453
iteration 4 batch 17070 training_loss 0.6931471805599453
iteration 4 batch 17080 training_loss 0.6931471805599453
iteration 4 batch 17090 training_loss 0.6931471805599453
iteration 4 batch 17100 training_loss 0.6931471805599453
iteration 4 batch 17110 training_loss 0.6931471805599453
iteration 4 batch 17120 training_loss 0.6931471805599453
iteration 4 batch 17130 training_loss 0.6931471805599453
iteration 4 batch 17140 training_loss 0.6931471805599453
iteration 4 batch 17150 training_loss 0.6931471805599453
iteration 4 batch 17160 training_loss 0.6931471805599453
iteration 4 batch 17170 training_loss 0.6931471805599453
iteration 4 batch 17180 training_loss 0.6931471805599453
iteration 4 batch 17190 training_loss 0.6931471805599453
iteration 4 batch 17200 training_loss 0.6931471805599453
iteration 4 batch 17210 training_loss 0.6931471805599453
iteration 4 batch 17220 training_loss 0.6931471805599453
iteration 4 batch 17230 training_loss 0.6931471805599453
iteration 4 batch 17240 training_loss 0.6931471805599453
iteration 4 batch 17250 training_loss 0.6931471805599453
iteration 4 batch 17260 training_loss 0.6931471805599453
iteration 4 batch 17270 training_loss 0.6931471805599453
iteration 4 batch 17280 training_loss 0.6931471805599453
iteration 4 batch 17290 training_loss 0.6931471805599453
iteration 4 batch 17300 training_loss 0.6931471805599453
iteration 4 batch 17310 training_loss 0.6931471805599453
iteration 4 batch 17320 training_loss 0.6931471805599453
iteration 4 batch 17330 training_loss 0.6931471805599453
iteration 4 batch 17340 training_loss 0.6931471805599453
iteration 4 batch 17350 training_loss 0.6931471805599453
iteration 4 batch 17360 training_loss 0.6931471805599453
iteration 4 batch 17370 training_loss 0.6931471805599453
iteration 4 batch 17380 training_loss 0.6931471805599453
iteration 4 batch 17390 training_loss 0.6931471805599453
iteration 4 batch 17400 training_loss 0.6931471805599453
iteration 4 batch 17410 training_loss 0.6931471805599453
iteration 4 batch 17420 training_loss 0.6931471805599453
iteration 4 batch 17430 training_loss 0.6931471805599453
iteration 4 batch 17440 training_loss 0.6931471805599453
iteration 4 batch 17450 training_loss 0.6931471805599453
iteration 4 batch 17460 training_loss 0.6931471805599453
iteration 4 batch 17470 training_loss 0.6931471805599453
iteration 4 batch 17480 training_loss 0.6931471805599453
iteration 4 batch 17490 training_loss 0.6931471805599453
iteration 4 batch 17500 training_loss 0.6931471805599453
iteration 4 batch 17510 training_loss 0.6916632528527511
iteration 4 batch 17520 training_loss 0.6931471805599453
iteration 4 batch 17530 training_loss 0.6931471805599453
iteration 4 batch 17540 training_loss 0.6931471805599453
iteration 4 batch 17550 training_loss 0.6931471805599453
iteration 4 batch 17560 training_loss 0.6931471805599453
iteration 4 batch 17570 training_loss 0.6931471805599453
iteration 4 batch 17580 training_loss 0.6931471805599453
iteration 4 batch 17590 training_loss 0.6931471805599453
iteration 4 batch 17600 training_loss 0.6931471805599453
iteration 4 batch 17610 training_loss 0.6931471805599453
iteration 4 batch 17620 training_loss 0.6931471805599453
iteration 4 batch 17630 training_loss 0.6931471805599453
iteration 4 batch 17640 training_loss 0.6916632528527511
iteration 4 batch 17650 training_loss 0.6931471805599453
iteration 4 batch 17660 training_loss 0.6916632528527511
iteration 4 batch 17670 training_loss 0.6931471805599453
iteration 4 batch 17680 training_loss 0.6931471805599453
iteration 4 batch 17690 training_loss 0.6931471805599453
iteration 4 batch 17700 training_loss 0.6931471805599453
iteration 4 batch 17710 training_loss 0.6931471805599453
iteration 4 batch 17720 training_loss 0.6931471805599453
iteration 4 batch 17730 training_loss 0.6916632528527511
iteration 4 batch 17740 training_loss 0.6931471805599453
iteration 4 batch 17750 training_loss 0.6931471805599453
iteration 4 batch 17760 training_loss 0.6931471805599453
iteration 4 batch 17770 training_loss 0.6931471805599453
iteration 4 batch 17780 training_loss 0.6931471805599453
iteration 4 batch 17790 training_loss 0.6931471805599453
iteration 4 batch 17800 training_loss 0.6931471805599453
iteration 4 batch 17810 training_loss 0.6931471805599453
iteration 4 batch 17820 training_loss 0.6931471805599453
iteration 4 batch 17830 training_loss 0.6931471805599453
iteration 4 batch 17840 training_loss 0.6931471805599453
iteration 4 batch 17850 training_loss 0.6931471805599453
iteration 4 batch 17860 training_loss 0.6931471805599453
iteration 4 batch 17870 training_loss 0.6931471805599453
iteration 4 batch 17880 training_loss 0.6931471805599453
iteration 4 batch 17890 training_loss 0.6931471805599453
iteration 4 batch 17900 training_loss 0.6931471805599453
iteration 4 batch 17910 training_loss 0.6931471805599453
iteration 4 batch 17920 training_loss 0.6931471805599453
iteration 4 batch 17930 training_loss 0.6931471805599453
iteration 4 batch 17940 training_loss 0.6931471805599453
iteration 4 batch 17950 training_loss 0.6931471805599453
iteration 4 batch 17960 training_loss 0.6931471805599453
iteration 4 batch 17970 training_loss 0.6931471805599453
iteration 4 batch 17980 training_loss 0.6931471805599453
iteration 4 batch 17990 training_loss 0.6931471805599453
iteration 4 batch 18000 training_loss 0.6931471805599453
iteration 4 batch 18010 training_loss 0.6916632528527511
iteration 4 batch 18020 training_loss 0.6931471805599453
iteration 4 batch 18030 training_loss 0.6931471805599453
iteration 4 batch 18040 training_loss 0.6931471805599453
iteration 4 batch 18050 training_loss 0.6931471805599453
iteration 4 batch 18060 training_loss 0.6931471805599453
iteration 4 batch 18070 training_loss 0.6931471805599453
iteration 4 batch 18080 training_loss 0.6931471805599453
iteration 4 batch 18090 training_loss 0.6931471805599453
iteration 4 batch 18100 training_loss 0.6931471805599453
iteration 4 batch 18110 training_loss 0.6931471805599453
iteration 4 batch 18120 training_loss 0.6931471805599453
iteration 4 batch 18130 training_loss 0.6931471805599453
iteration 4 batch 18140 training_loss 0.6931471805599453
iteration 4 batch 18150 training_loss 0.6931471805599453
iteration 4 batch 18160 training_loss 0.6931471805599453
iteration 4 batch 18170 training_loss 0.6931471805599453
iteration 4 batch 18180 training_loss 0.6931471805599453
iteration 4 batch 18190 training_loss 0.6931471805599453
iteration 4 batch 18200 training_loss 0.6931471805599453
iteration 4 batch 18210 training_loss 0.6931471805599453
iteration 4 batch 18220 training_loss 0.6931471805599453
iteration 4 batch 18230 training_loss 0.6931471805599453
iteration 4 batch 18240 training_loss 0.6931471805599453
iteration 4 batch 18250 training_loss 0.6931471805599453
iteration 4 batch 18260 training_loss 0.6931471805599453
iteration 4 batch 18270 training_loss 0.6931471805599453
iteration 4 batch 18280 training_loss 0.6931471805599453
iteration 4 batch 18290 training_loss 0.6931471805599453
iteration 4 batch 18300 training_loss 0.6931471805599453
iteration 4 batch 18310 training_loss 0.6931471805599453
iteration 4 batch 18320 training_loss 0.6916632528527511
iteration 4 batch 18330 training_loss 0.6931471805599453
iteration 4 batch 18340 training_loss 0.6931471805599453
iteration 4 batch 18350 training_loss 0.6931471805599453
iteration 4 batch 18360 training_loss 0.6931471805599453
iteration 4 batch 18370 training_loss 0.6931471805599453
iteration 4 batch 18380 training_loss 0.6931471805599453
iteration 4 batch 18390 training_loss 0.6931471805599453
iteration 4 batch 18400 training_loss 0.6931471805599453
iteration 4 batch 18410 training_loss 0.6931471805599453
iteration 4 batch 18420 training_loss 0.6931471805599453
iteration 4 batch 18430 training_loss 0.6931471805599453
iteration 4 batch 18440 training_loss 0.6931471805599453
iteration 4 batch 18450 training_loss 0.6931471805599453
iteration 4 batch 18460 training_loss 0.6916632528527511
iteration 4 batch 18470 training_loss 0.6931471805599453
iteration 4 batch 18480 training_loss 0.6931471805599453
iteration 4 batch 18490 training_loss 0.6931471805599453
iteration 4 batch 18500 training_loss 0.6931471805599453
iteration 4 batch 18510 training_loss 0.6931471805599453
iteration 4 batch 18520 training_loss 0.6931471805599453
iteration 4 batch 18530 training_loss 0.6931471805599453
iteration 4 batch 18540 training_loss 0.6931471805599453
iteration 4 batch 18550 training_loss 0.6931471805599453
iteration 4 batch 18560 training_loss 0.6931471805599453
iteration 4 batch 18570 training_loss 0.6931471805599453
iteration 4 batch 18580 training_loss 0.6931471805599453
iteration 4 batch 18590 training_loss 0.6931471805599453
iteration 4 batch 18600 training_loss 0.6916632528527511
iteration 4 batch 18610 training_loss 0.6931471805599453
iteration 5 batch 0 training_loss 0.6916632528527511
iteration 5 batch 10 training_loss 0.6931471805599453
iteration 5 batch 20 training_loss 0.6931471805599453
iteration 5 batch 30 training_loss 0.6916632528527511
iteration 5 batch 40 training_loss 0.6931471805599453
iteration 5 batch 50 training_loss 0.6931471805599453
iteration 5 batch 60 training_loss 0.6931471805599453
iteration 5 batch 70 training_loss 0.6931471805599453
iteration 5 batch 80 training_loss 0.6931471805599453
iteration 5 batch 90 training_loss 0.6931471805599453
iteration 5 batch 100 training_loss 0.6931471805599453
iteration 5 batch 110 training_loss 0.6931471805599453
iteration 5 batch 120 training_loss 0.6931471805599453
iteration 5 batch 130 training_loss 0.6931471805599453
iteration 5 batch 140 training_loss 0.6931471805599453
iteration 5 batch 150 training_loss 0.6931471805599453
iteration 5 batch 160 training_loss 0.6931471805599453
iteration 5 batch 170 training_loss 0.6931471805599453
iteration 5 batch 180 training_loss 0.6931471805599453
iteration 5 batch 190 training_loss 0.6931471805599453
iteration 5 batch 200 training_loss 0.6931471805599453
iteration 5 batch 210 training_loss 0.6931471805599453
iteration 5 batch 220 training_loss 0.6931471805599453
iteration 5 batch 230 training_loss 0.6931471805599453
iteration 5 batch 240 training_loss 0.6931471805599453
iteration 5 batch 250 training_loss 0.6931471805599453
iteration 5 batch 260 training_loss 0.6931471805599453
iteration 5 batch 270 training_loss 0.6931471805599453
iteration 5 batch 280 training_loss 0.6931471805599453
iteration 5 batch 290 training_loss 0.6931471805599453
iteration 5 batch 300 training_loss 0.6931471805599453
iteration 5 batch 310 training_loss 0.6931471805599453
iteration 5 batch 320 training_loss 0.6916632528527511
iteration 5 batch 330 training_loss 0.6916632528527511
iteration 5 batch 340 training_loss 0.6931471805599453
iteration 5 batch 350 training_loss 0.6931471805599453
iteration 5 batch 360 training_loss 0.6931471805599453
iteration 5 batch 370 training_loss 0.6931471805599453
iteration 5 batch 380 training_loss 0.6931471805599453
iteration 5 batch 390 training_loss 0.6931471805599453
iteration 5 batch 400 training_loss 0.6931471805599453
iteration 5 batch 410 training_loss 0.6931471805599453
iteration 5 batch 420 training_loss 0.6931471805599453
iteration 5 batch 430 training_loss 0.6931471805599453
iteration 5 batch 440 training_loss 0.6931471805599453
iteration 5 batch 450 training_loss 0.6931471805599453
iteration 5 batch 460 training_loss 0.6916632528527511
iteration 5 batch 470 training_loss 0.6931471805599453
iteration 5 batch 480 training_loss 0.6931471805599453
iteration 5 batch 490 training_loss 0.6931471805599453
iteration 5 batch 500 training_loss 0.6931471805599453
iteration 5 batch 510 training_loss 0.6931471805599453
iteration 5 batch 520 training_loss 0.6931471805599453
iteration 5 batch 530 training_loss 0.6931471805599453
iteration 5 batch 540 training_loss 0.6931471805599453
iteration 5 batch 550 training_loss 0.6931471805599453
iteration 5 batch 560 training_loss 0.6931471805599453
iteration 5 batch 570 training_loss 0.6931471805599453
iteration 5 batch 580 training_loss 0.6931471805599453
iteration 5 batch 590 training_loss 0.6931471805599453
iteration 5 batch 600 training_loss 0.6931471805599453
iteration 5 batch 610 training_loss 0.6931471805599453
iteration 5 batch 620 training_loss 0.6931471805599453
iteration 5 batch 630 training_loss 0.6931471805599453
iteration 5 batch 640 training_loss 0.6931471805599453
iteration 5 batch 650 training_loss 0.6931471805599453
iteration 5 batch 660 training_loss 0.6931471805599453
iteration 5 batch 670 training_loss 0.6931471805599453
iteration 5 batch 680 training_loss 0.6931471805599453
iteration 5 batch 690 training_loss 0.6931471805599453
iteration 5 batch 700 training_loss 0.6931471805599453
iteration 5 batch 710 training_loss 0.6931471805599453
iteration 5 batch 720 training_loss 0.6931471805599453
iteration 5 batch 730 training_loss 0.6931471805599453
iteration 5 batch 740 training_loss 0.6931471805599453
iteration 5 batch 750 training_loss 0.6931471805599453
iteration 5 batch 760 training_loss 0.6931471805599453
iteration 5 batch 770 training_loss 0.6931471805599453
iteration 5 batch 780 training_loss 0.6931471805599453
iteration 5 batch 790 training_loss 0.6931471805599453
iteration 5 batch 800 training_loss 0.6931471805599453
iteration 5 batch 810 training_loss 0.6931471805599453
iteration 5 batch 820 training_loss 0.6931471805599453
iteration 5 batch 830 training_loss 0.6931471805599453
iteration 5 batch 840 training_loss 0.6931471805599453
iteration 5 batch 850 training_loss 0.6931471805599453
iteration 5 batch 860 training_loss 0.6931471805599453
iteration 5 batch 870 training_loss 0.6931471805599453
iteration 5 batch 880 training_loss 0.6931471805599453
iteration 5 batch 890 training_loss 0.6931471805599453
iteration 5 batch 900 training_loss 0.6931471805599453
iteration 5 batch 910 training_loss 0.6931471805599453
iteration 5 batch 920 training_loss 0.6931471805599453
iteration 5 batch 930 training_loss 0.6931471805599453
iteration 5 batch 940 training_loss 0.6931471805599453
iteration 5 batch 950 training_loss 0.6916632528527511
iteration 5 batch 960 training_loss 0.6931471805599453
iteration 5 batch 970 training_loss 0.6931471805599453
iteration 5 batch 980 training_loss 0.6931471805599453
iteration 5 batch 990 training_loss 0.6931471805599453
iteration 5 batch 1000 training_loss 0.6931471805599453
iteration 5 batch 1010 training_loss 0.6931471805599453
iteration 5 batch 1020 training_loss 0.6931471805599453
iteration 5 batch 1030 training_loss 0.6931471805599453
iteration 5 batch 1040 training_loss 0.6931471805599453
iteration 5 batch 1050 training_loss 0.6931471805599453
iteration 5 batch 1060 training_loss 0.6931471805599453
iteration 5 batch 1070 training_loss 0.6931471805599453
iteration 5 batch 1080 training_loss 0.6931471805599453
iteration 5 batch 1090 training_loss 0.6931471805599453
iteration 5 batch 1100 training_loss 0.6931471805599453
iteration 5 batch 1110 training_loss 0.6916632528527511
iteration 5 batch 1120 training_loss 0.6931471805599453
iteration 5 batch 1130 training_loss 0.6931471805599453
iteration 5 batch 1140 training_loss 0.6931471805599453
iteration 5 batch 1150 training_loss 0.6931471805599453
iteration 5 batch 1160 training_loss 0.6931471805599453
iteration 5 batch 1170 training_loss 0.6931471805599453
iteration 5 batch 1180 training_loss 0.6931471805599453
iteration 5 batch 1190 training_loss 0.6931471805599453
iteration 5 batch 1200 training_loss 0.6931471805599453
iteration 5 batch 1210 training_loss 0.6931471805599453
iteration 5 batch 1220 training_loss 0.6931471805599453
iteration 5 batch 1230 training_loss 0.6931471805599453
iteration 5 batch 1240 training_loss 0.6931471805599453
iteration 5 batch 1250 training_loss 0.6931471805599453
iteration 5 batch 1260 training_loss 0.6931471805599453
iteration 5 batch 1270 training_loss 0.6931471805599453
iteration 5 batch 1280 training_loss 0.6931471805599453
iteration 5 batch 1290 training_loss 0.6931471805599453
iteration 5 batch 1300 training_loss 0.6931471805599453
iteration 5 batch 1310 training_loss 0.6931471805599453
iteration 5 batch 1320 training_loss 0.6931471805599453
iteration 5 batch 1330 training_loss 0.6931471805599453
iteration 5 batch 1340 training_loss 0.6916632528527511
iteration 5 batch 1350 training_loss 0.6931471805599453
iteration 5 batch 1360 training_loss 0.6931471805599453
iteration 5 batch 1370 training_loss 0.6931471805599453
iteration 5 batch 1380 training_loss 0.6931471805599453
iteration 5 batch 1390 training_loss 0.6931471805599453
iteration 5 batch 1400 training_loss 0.6931471805599453
iteration 5 batch 1410 training_loss 0.6931471805599453
iteration 5 batch 1420 training_loss 0.6931471805599453
iteration 5 batch 1430 training_loss 0.6931471805599453
iteration 5 batch 1440 training_loss 0.6931471805599453
iteration 5 batch 1450 training_loss 0.6931471805599453
iteration 5 batch 1460 training_loss 0.6931471805599453
iteration 5 batch 1470 training_loss 0.6931471805599453
iteration 5 batch 1480 training_loss 0.6931471805599453
iteration 5 batch 1490 training_loss 0.6916632528527511
iteration 5 batch 1500 training_loss 0.6931471805599453
iteration 5 batch 1510 training_loss 0.6916632528527511
iteration 5 batch 1520 training_loss 0.6931471805599453
iteration 5 batch 1530 training_loss 0.6931471805599453
iteration 5 batch 1540 training_loss 0.6931471805599453
iteration 5 batch 1550 training_loss 0.6931471805599453
iteration 5 batch 1560 training_loss 0.6931471805599453
iteration 5 batch 1570 training_loss 0.6931471805599453
iteration 5 batch 1580 training_loss 0.6931471805599453
iteration 5 batch 1590 training_loss 0.6931471805599453
iteration 5 batch 1600 training_loss 0.6931471805599453
iteration 5 batch 1610 training_loss 0.6931471805599453
iteration 5 batch 1620 training_loss 0.6931471805599453
iteration 5 batch 1630 training_loss 0.6931471805599453
iteration 5 batch 1640 training_loss 0.6931471805599453
iteration 5 batch 1650 training_loss 0.6931471805599453
iteration 5 batch 1660 training_loss 0.6931471805599453
iteration 5 batch 1670 training_loss 0.6931471805599453
iteration 5 batch 1680 training_loss 0.6931471805599453
iteration 5 batch 1690 training_loss 0.6931471805599453
iteration 5 batch 1700 training_loss 0.6931471805599453
iteration 5 batch 1710 training_loss 0.6931471805599453
iteration 5 batch 1720 training_loss 0.6931471805599453
iteration 5 batch 1730 training_loss 0.6931471805599453
iteration 5 batch 1740 training_loss 0.6931471805599453
iteration 5 batch 1750 training_loss 0.6931471805599453
iteration 5 batch 1760 training_loss 0.6931471805599453
iteration 5 batch 1770 training_loss 0.6931471805599453
iteration 5 batch 1780 training_loss 0.6931471805599453
iteration 5 batch 1790 training_loss 0.6931471805599453
iteration 5 batch 1800 training_loss 0.6931471805599453
iteration 5 batch 1810 training_loss 0.6931471805599453
iteration 5 batch 1820 training_loss 0.6931471805599453
iteration 5 batch 1830 training_loss 0.6931471805599453
iteration 5 batch 1840 training_loss 0.6931471805599453
iteration 5 batch 1850 training_loss 0.6931471805599453
iteration 5 batch 1860 training_loss 0.6916632528527511
iteration 5 batch 1870 training_loss 0.6931471805599453
iteration 5 batch 1880 training_loss 0.6931471805599453
iteration 5 batch 1890 training_loss 0.6931471805599453
iteration 5 batch 1900 training_loss 0.6931471805599453
iteration 5 batch 1910 training_loss 0.6931471805599453
iteration 5 batch 1920 training_loss 0.6931471805599453
iteration 5 batch 1930 training_loss 0.6901793251455568
iteration 5 batch 1940 training_loss 0.6931471805599453
iteration 5 batch 1950 training_loss 0.6931471805599453
iteration 5 batch 1960 training_loss 0.6931471805599453
iteration 5 batch 1970 training_loss 0.6931471805599453
iteration 5 batch 1980 training_loss 0.6931471805599453
iteration 5 batch 1990 training_loss 0.6931471805599453
iteration 5 batch 2000 training_loss 0.6916632528527511
iteration 5 batch 2010 training_loss 0.6916632528527511
iteration 5 batch 2020 training_loss 0.6931471805599453
iteration 5 batch 2030 training_loss 0.6931471805599453
iteration 5 batch 2040 training_loss 0.6931471805599453
iteration 5 batch 2050 training_loss 0.6931471805599453
iteration 5 batch 2060 training_loss 0.6931471805599453
iteration 5 batch 2070 training_loss 0.6931471805599453
iteration 5 batch 2080 training_loss 0.6931471805599453
iteration 5 batch 2090 training_loss 0.6931471805599453
iteration 5 batch 2100 training_loss 0.6931471805599453
iteration 5 batch 2110 training_loss 0.6931471805599453
iteration 5 batch 2120 training_loss 0.6931471805599453
iteration 5 batch 2130 training_loss 0.6931471805599453
iteration 5 batch 2140 training_loss 0.6916632528527511
iteration 5 batch 2150 training_loss 0.6931471805599453
iteration 5 batch 2160 training_loss 0.6931471805599453
iteration 5 batch 2170 training_loss 0.6916632528527511
iteration 5 batch 2180 training_loss 0.6916632528527511
iteration 5 batch 2190 training_loss 0.6931471805599453
iteration 5 batch 2200 training_loss 0.6931471805599453
iteration 5 batch 2210 training_loss 0.6931471805599453
iteration 5 batch 2220 training_loss 0.6931471805599453
iteration 5 batch 2230 training_loss 0.6931471805599453
iteration 5 batch 2240 training_loss 0.6931471805599453
iteration 5 batch 2250 training_loss 0.6931471805599453
iteration 5 batch 2260 training_loss 0.6931471805599453
iteration 5 batch 2270 training_loss 0.6931471805599453
iteration 5 batch 2280 training_loss 0.6931471805599453
iteration 5 batch 2290 training_loss 0.6931471805599453
iteration 5 batch 2300 training_loss 0.6931471805599453
iteration 5 batch 2310 training_loss 0.6931471805599453
iteration 5 batch 2320 training_loss 0.6931471805599453
iteration 5 batch 2330 training_loss 0.6931471805599453
iteration 5 batch 2340 training_loss 0.6931471805599453
iteration 5 batch 2350 training_loss 0.6931471805599453
iteration 5 batch 2360 training_loss 0.6931471805599453
iteration 5 batch 2370 training_loss 0.6931471805599453
iteration 5 batch 2380 training_loss 0.6931471805599453
iteration 5 batch 2390 training_loss 0.6931471805599453
iteration 5 batch 2400 training_loss 0.6916632528527511
iteration 5 batch 2410 training_loss 0.6931471805599453
iteration 5 batch 2420 training_loss 0.6931471805599453
iteration 5 batch 2430 training_loss 0.6931471805599453
iteration 5 batch 2440 training_loss 0.6931471805599453
iteration 5 batch 2450 training_loss 0.6931471805599453
iteration 5 batch 2460 training_loss 0.6931471805599453
iteration 5 batch 2470 training_loss 0.6931471805599453
iteration 5 batch 2480 training_loss 0.6931471805599453
iteration 5 batch 2490 training_loss 0.6931471805599453
iteration 5 batch 2500 training_loss 0.6931471805599453
iteration 5 batch 2510 training_loss 0.6931471805599453
iteration 5 batch 2520 training_loss 0.6931471805599453
iteration 5 batch 2530 training_loss 0.6931471805599453
iteration 5 batch 2540 training_loss 0.6931471805599453
iteration 5 batch 2550 training_loss 0.6931471805599453
iteration 5 batch 2560 training_loss 0.6931471805599453
iteration 5 batch 2570 training_loss 0.6931471805599453
iteration 5 batch 2580 training_loss 0.6916632528527511
iteration 5 batch 2590 training_loss 0.6931471805599453
iteration 5 batch 2600 training_loss 0.6931471805599453
iteration 5 batch 2610 training_loss 0.6931471805599453
iteration 5 batch 2620 training_loss 0.6931471805599453
iteration 5 batch 2630 training_loss 0.6931471805599453
iteration 5 batch 2640 training_loss 0.6931471805599453
iteration 5 batch 2650 training_loss 0.6931471805599453
iteration 5 batch 2660 training_loss 0.6931471805599453
iteration 5 batch 2670 training_loss 0.6931471805599453
iteration 5 batch 2680 training_loss 0.6931471805599453
iteration 5 batch 2690 training_loss 0.6931471805599453
iteration 5 batch 2700 training_loss 0.6931471805599453
iteration 5 batch 2710 training_loss 0.6931471805599453
iteration 5 batch 2720 training_loss 0.6931471805599453
iteration 5 batch 2730 training_loss 0.6931471805599453
iteration 5 batch 2740 training_loss 0.6931471805599453
iteration 5 batch 2750 training_loss 0.6931471805599453
iteration 5 batch 2760 training_loss 0.6931471805599453
iteration 5 batch 2770 training_loss 0.6931471805599453
iteration 5 batch 2780 training_loss 0.6931471805599453
iteration 5 batch 2790 training_loss 0.6931471805599453
iteration 5 batch 2800 training_loss 0.6916632528527511
iteration 5 batch 2810 training_loss 0.6931471805599453
iteration 5 batch 2820 training_loss 0.6931471805599453
iteration 5 batch 2830 training_loss 0.6931471805599453
iteration 5 batch 2840 training_loss 0.6931471805599453
iteration 5 batch 2850 training_loss 0.6931471805599453
iteration 5 batch 2860 training_loss 0.6916632528527511
iteration 5 batch 2870 training_loss 0.6931471805599453
iteration 5 batch 2880 training_loss 0.6931471805599453
iteration 5 batch 2890 training_loss 0.6931471805599453
iteration 5 batch 2900 training_loss 0.6931471805599453
iteration 5 batch 2910 training_loss 0.6931471805599453
iteration 5 batch 2920 training_loss 0.6931471805599453
iteration 5 batch 2930 training_loss 0.6931471805599453
iteration 5 batch 2940 training_loss 0.6931471805599453
iteration 5 batch 2950 training_loss 0.6931471805599453
iteration 5 batch 2960 training_loss 0.6931471805599453
iteration 5 batch 2970 training_loss 0.6916632528527511
iteration 5 batch 2980 training_loss 0.6931471805599453
iteration 5 batch 2990 training_loss 0.6931471805599453
iteration 5 batch 3000 training_loss 0.6931471805599453
iteration 5 batch 3010 training_loss 0.6931471805599453
iteration 5 batch 3020 training_loss 0.6931471805599453
iteration 5 batch 3030 training_loss 0.6931471805599453
iteration 5 batch 3040 training_loss 0.6931471805599453
iteration 5 batch 3050 training_loss 0.6916632528527511
iteration 5 batch 3060 training_loss 0.6931471805599453
iteration 5 batch 3070 training_loss 0.6931471805599453
iteration 5 batch 3080 training_loss 0.6931471805599453
iteration 5 batch 3090 training_loss 0.6931471805599453
iteration 5 batch 3100 training_loss 0.6931471805599453
iteration 5 batch 3110 training_loss 0.6931471805599453
iteration 5 batch 3120 training_loss 0.6931471805599453
iteration 5 batch 3130 training_loss 0.6931471805599453
iteration 5 batch 3140 training_loss 0.6931471805599453
iteration 5 batch 3150 training_loss 0.6931471805599453
iteration 5 batch 3160 training_loss 0.6931471805599453
iteration 5 batch 3170 training_loss 0.6931471805599453
iteration 5 batch 3180 training_loss 0.6931471805599453
iteration 5 batch 3190 training_loss 0.6931471805599453
iteration 5 batch 3200 training_loss 0.6931471805599453
iteration 5 batch 3210 training_loss 0.6931471805599453
iteration 5 batch 3220 training_loss 0.6931471805599453
iteration 5 batch 3230 training_loss 0.6931471805599453
iteration 5 batch 3240 training_loss 0.6931471805599453
iteration 5 batch 3250 training_loss 0.6931471805599453
iteration 5 batch 3260 training_loss 0.6931471805599453
iteration 5 batch 3270 training_loss 0.6931471805599453
iteration 5 batch 3280 training_loss 0.6931471805599453
iteration 5 batch 3290 training_loss 0.6931471805599453
iteration 5 batch 3300 training_loss 0.6931471805599453
iteration 5 batch 3310 training_loss 0.6931471805599453
iteration 5 batch 3320 training_loss 0.6931471805599453
iteration 5 batch 3330 training_loss 0.6931471805599453
iteration 5 batch 3340 training_loss 0.6931471805599453
iteration 5 batch 3350 training_loss 0.6931471805599453
iteration 5 batch 3360 training_loss 0.6931471805599453
iteration 5 batch 3370 training_loss 0.6931471805599453
iteration 5 batch 3380 training_loss 0.6931471805599453
iteration 5 batch 3390 training_loss 0.6931471805599453
iteration 5 batch 3400 training_loss 0.6931471805599453
iteration 5 batch 3410 training_loss 0.6916632528527511
iteration 5 batch 3420 training_loss 0.6931471805599453
iteration 5 batch 3430 training_loss 0.6931471805599453
iteration 5 batch 3440 training_loss 0.6931471805599453
iteration 5 batch 3450 training_loss 0.6931471805599453
iteration 5 batch 3460 training_loss 0.6931471805599453
iteration 5 batch 3470 training_loss 0.6931471805599453
iteration 5 batch 3480 training_loss 0.6931471805599453
iteration 5 batch 3490 training_loss 0.6931471805599453
iteration 5 batch 3500 training_loss 0.6931471805599453
iteration 5 batch 3510 training_loss 0.6931471805599453
iteration 5 batch 3520 training_loss 0.6931471805599453
iteration 5 batch 3530 training_loss 0.6931471805599453
iteration 5 batch 3540 training_loss 0.6931471805599453
iteration 5 batch 3550 training_loss 0.6931471805599453
iteration 5 batch 3560 training_loss 0.6931471805599453
iteration 5 batch 3570 training_loss 0.6931471805599453
iteration 5 batch 3580 training_loss 0.6931471805599453
iteration 5 batch 3590 training_loss 0.6931471805599453
iteration 5 batch 3600 training_loss 0.6931471805599453
iteration 5 batch 3610 training_loss 0.6931471805599453
iteration 5 batch 3620 training_loss 0.6931471805599453
iteration 5 batch 3630 training_loss 0.6931471805599453
iteration 5 batch 3640 training_loss 0.6931471805599453
iteration 5 batch 3650 training_loss 0.6931471805599453
iteration 5 batch 3660 training_loss 0.6931471805599453
iteration 5 batch 3670 training_loss 0.6931471805599453
iteration 5 batch 3680 training_loss 0.6931471805599453
iteration 5 batch 3690 training_loss 0.6931471805599453
iteration 5 batch 3700 training_loss 0.6931471805599453
iteration 5 batch 3710 training_loss 0.6931471805599453
iteration 5 batch 3720 training_loss 0.6931471805599453
iteration 5 batch 3730 training_loss 0.6931471805599453
iteration 5 batch 3740 training_loss 0.6931471805599453
iteration 5 batch 3750 training_loss 0.6931471805599453
iteration 5 batch 3760 training_loss 0.6931471805599453
iteration 5 batch 3770 training_loss 0.6931471805599453
iteration 5 batch 3780 training_loss 0.6931471805599453
iteration 5 batch 3790 training_loss 0.6931471805599453
iteration 5 batch 3800 training_loss 0.6931471805599453
iteration 5 batch 3810 training_loss 0.6931471805599453
iteration 5 batch 3820 training_loss 0.6931471805599453
iteration 5 batch 3830 training_loss 0.6931471805599453
iteration 5 batch 3840 training_loss 0.6931471805599453
iteration 5 batch 3850 training_loss 0.6931471805599453
iteration 5 batch 3860 training_loss 0.6931471805599453
iteration 5 batch 3870 training_loss 0.6931471805599453
iteration 5 batch 3880 training_loss 0.6931471805599453
iteration 5 batch 3890 training_loss 0.6931471805599453
iteration 5 batch 3900 training_loss 0.6931471805599453
iteration 5 batch 3910 training_loss 0.6931471805599453
iteration 5 batch 3920 training_loss 0.6931471805599453
iteration 5 batch 3930 training_loss 0.6931471805599453
iteration 5 batch 3940 training_loss 0.6931471805599453
iteration 5 batch 3950 training_loss 0.6931471805599453
iteration 5 batch 3960 training_loss 0.6931471805599453
iteration 5 batch 3970 training_loss 0.6931471805599453
iteration 5 batch 3980 training_loss 0.6931471805599453
iteration 5 batch 3990 training_loss 0.6931471805599453
iteration 5 batch 4000 training_loss 0.6931471805599453
iteration 5 batch 4010 training_loss 0.6931471805599453
iteration 5 batch 4020 training_loss 0.6931471805599453
iteration 5 batch 4030 training_loss 0.6931471805599453
iteration 5 batch 4040 training_loss 0.6916632528527511
iteration 5 batch 4050 training_loss 0.6931471805599453
iteration 5 batch 4060 training_loss 0.6931471805599453
iteration 5 batch 4070 training_loss 0.6931471805599453
iteration 5 batch 4080 training_loss 0.6931471805599453
iteration 5 batch 4090 training_loss 0.6931471805599453
iteration 5 batch 4100 training_loss 0.6931471805599453
iteration 5 batch 4110 training_loss 0.6931471805599453
iteration 5 batch 4120 training_loss 0.6931471805599453
iteration 5 batch 4130 training_loss 0.6931471805599453
iteration 5 batch 4140 training_loss 0.6931471805599453
iteration 5 batch 4150 training_loss 0.6931471805599453
iteration 5 batch 4160 training_loss 0.6931471805599453
iteration 5 batch 4170 training_loss 0.6931471805599453
iteration 5 batch 4180 training_loss 0.6931471805599453
iteration 5 batch 4190 training_loss 0.6931471805599453
iteration 5 batch 4200 training_loss 0.6931471805599453
iteration 5 batch 4210 training_loss 0.6931471805599453
iteration 5 batch 4220 training_loss 0.6931471805599453
iteration 5 batch 4230 training_loss 0.6931471805599453
iteration 5 batch 4240 training_loss 0.6931471805599453
iteration 5 batch 4250 training_loss 0.6931471805599453
iteration 5 batch 4260 training_loss 0.6931471805599453
iteration 5 batch 4270 training_loss 0.6931471805599453
iteration 5 batch 4280 training_loss 0.6931471805599453
iteration 5 batch 4290 training_loss 0.6931471805599453
iteration 5 batch 4300 training_loss 0.6931471805599453
iteration 5 batch 4310 training_loss 0.6931471805599453
iteration 5 batch 4320 training_loss 0.6931471805599453
iteration 5 batch 4330 training_loss 0.6931471805599453
iteration 5 batch 4340 training_loss 0.6931471805599453
iteration 5 batch 4350 training_loss 0.6931471805599453
iteration 5 batch 4360 training_loss 0.6931471805599453
iteration 5 batch 4370 training_loss 0.6931471805599453
iteration 5 batch 4380 training_loss 0.6931471805599453
iteration 5 batch 4390 training_loss 0.6916632528527511
iteration 5 batch 4400 training_loss 0.6931471805599453
iteration 5 batch 4410 training_loss 0.6931471805599453
iteration 5 batch 4420 training_loss 0.6931471805599453
iteration 5 batch 4430 training_loss 0.6931471805599453
iteration 5 batch 4440 training_loss 0.6931471805599453
iteration 5 batch 4450 training_loss 0.6931471805599453
iteration 5 batch 4460 training_loss 0.6931471805599453
iteration 5 batch 4470 training_loss 0.6931471805599453
iteration 5 batch 4480 training_loss 0.6931471805599453
iteration 5 batch 4490 training_loss 0.6931471805599453
iteration 5 batch 4500 training_loss 0.6931471805599453
iteration 5 batch 4510 training_loss 0.6916632528527511
iteration 5 batch 4520 training_loss 0.6931471805599453
iteration 5 batch 4530 training_loss 0.6931471805599453
iteration 5 batch 4540 training_loss 0.6916632528527511
iteration 5 batch 4550 training_loss 0.6931471805599453
iteration 5 batch 4560 training_loss 0.6931471805599453
iteration 5 batch 4570 training_loss 0.6931471805599453
iteration 5 batch 4580 training_loss 0.6931471805599453
iteration 5 batch 4590 training_loss 0.6931471805599453
iteration 5 batch 4600 training_loss 0.6931471805599453
iteration 5 batch 4610 training_loss 0.6931471805599453
iteration 5 batch 4620 training_loss 0.6931471805599453
iteration 5 batch 4630 training_loss 0.6931471805599453
iteration 5 batch 4640 training_loss 0.6916632528527511
iteration 5 batch 4650 training_loss 0.6931471805599453
iteration 5 batch 4660 training_loss 0.6931471805599453
iteration 5 batch 4670 training_loss 0.6931471805599453
iteration 5 batch 4680 training_loss 0.6931471805599453
iteration 5 batch 4690 training_loss 0.6931471805599453
iteration 5 batch 4700 training_loss 0.6931471805599453
iteration 5 batch 4710 training_loss 0.6931471805599453
iteration 5 batch 4720 training_loss 0.6931471805599453
iteration 5 batch 4730 training_loss 0.6931471805599453
iteration 5 batch 4740 training_loss 0.6916632528527511
iteration 5 batch 4750 training_loss 0.6931471805599453
iteration 5 batch 4760 training_loss 0.6916632528527511
iteration 5 batch 4770 training_loss 0.6931471805599453
iteration 5 batch 4780 training_loss 0.6931471805599453
iteration 5 batch 4790 training_loss 0.6931471805599453
iteration 5 batch 4800 training_loss 0.6931471805599453
iteration 5 batch 4810 training_loss 0.6931471805599453
iteration 5 batch 4820 training_loss 0.6931471805599453
iteration 5 batch 4830 training_loss 0.6931471805599453
iteration 5 batch 4840 training_loss 0.6931471805599453
iteration 5 batch 4850 training_loss 0.6916632528527511
iteration 5 batch 4860 training_loss 0.6931471805599453
iteration 5 batch 4870 training_loss 0.6931471805599453
iteration 5 batch 4880 training_loss 0.6931471805599453
iteration 5 batch 4890 training_loss 0.6931471805599453
iteration 5 batch 4900 training_loss 0.6931471805599453
iteration 5 batch 4910 training_loss 0.6931471805599453
iteration 5 batch 4920 training_loss 0.6931471805599453
iteration 5 batch 4930 training_loss 0.6931471805599453
iteration 5 batch 4940 training_loss 0.6931471805599453
iteration 5 batch 4950 training_loss 0.6931471805599453
iteration 5 batch 4960 training_loss 0.6931471805599453
iteration 5 batch 4970 training_loss 0.6916632528527511
iteration 5 batch 4980 training_loss 0.6931471805599453
iteration 5 batch 4990 training_loss 0.6931471805599453
iteration 5 batch 5000 training_loss 0.6931471805599453
iteration 5 batch 5010 training_loss 0.6931471805599453
iteration 5 batch 5020 training_loss 0.6931471805599453
iteration 5 batch 5030 training_loss 0.6931471805599453
iteration 5 batch 5040 training_loss 0.6931471805599453
iteration 5 batch 5050 training_loss 0.6931471805599453
iteration 5 batch 5060 training_loss 0.6931471805599453
iteration 5 batch 5070 training_loss 0.6931471805599453
iteration 5 batch 5080 training_loss 0.6931471805599453
iteration 5 batch 5090 training_loss 0.6931471805599453
iteration 5 batch 5100 training_loss 0.6931471805599453
iteration 5 batch 5110 training_loss 0.6931471805599453
iteration 5 batch 5120 training_loss 0.6931471805599453
iteration 5 batch 5130 training_loss 0.6931471805599453
iteration 5 batch 5140 training_loss 0.6931471805599453
iteration 5 batch 5150 training_loss 0.6931471805599453
iteration 5 batch 5160 training_loss 0.6931471805599453
iteration 5 batch 5170 training_loss 0.6931471805599453
iteration 5 batch 5180 training_loss 0.6931471805599453
iteration 5 batch 5190 training_loss 0.6931471805599453
iteration 5 batch 5200 training_loss 0.6931471805599453
iteration 5 batch 5210 training_loss 0.6916632528527511
iteration 5 batch 5220 training_loss 0.6931471805599453
iteration 5 batch 5230 training_loss 0.6931471805599453
iteration 5 batch 5240 training_loss 0.6916632528527511
iteration 5 batch 5250 training_loss 0.6931471805599453
iteration 5 batch 5260 training_loss 0.6931471805599453
iteration 5 batch 5270 training_loss 0.6931471805599453
iteration 5 batch 5280 training_loss 0.6931471805599453
iteration 5 batch 5290 training_loss 0.6931471805599453
iteration 5 batch 5300 training_loss 0.6931471805599453
iteration 5 batch 5310 training_loss 0.6931471805599453
iteration 5 batch 5320 training_loss 0.6931471805599453
iteration 5 batch 5330 training_loss 0.6931471805599453
iteration 5 batch 5340 training_loss 0.6931471805599453
iteration 5 batch 5350 training_loss 0.6931471805599453
iteration 5 batch 5360 training_loss 0.6931471805599453
iteration 5 batch 5370 training_loss 0.6931471805599453
iteration 5 batch 5380 training_loss 0.6931471805599453
iteration 5 batch 5390 training_loss 0.6931471805599453
iteration 5 batch 5400 training_loss 0.6931471805599453
iteration 5 batch 5410 training_loss 0.6931471805599453
iteration 5 batch 5420 training_loss 0.6931471805599453
iteration 5 batch 5430 training_loss 0.6931471805599453
iteration 5 batch 5440 training_loss 0.6931471805599453
iteration 5 batch 5450 training_loss 0.6931471805599453
iteration 5 batch 5460 training_loss 0.6931471805599453
iteration 5 batch 5470 training_loss 0.6931471805599453
iteration 5 batch 5480 training_loss 0.6931471805599453
iteration 5 batch 5490 training_loss 0.6931471805599453
iteration 5 batch 5500 training_loss 0.6931471805599453
iteration 5 batch 5510 training_loss 0.6931471805599453
iteration 5 batch 5520 training_loss 0.6931471805599453
iteration 5 batch 5530 training_loss 0.6931471805599453
iteration 5 batch 5540 training_loss 0.6931471805599453
iteration 5 batch 5550 training_loss 0.6931471805599453
iteration 5 batch 5560 training_loss 0.6931471805599453
iteration 5 batch 5570 training_loss 0.6931471805599453
iteration 5 batch 5580 training_loss 0.6931471805599453
iteration 5 batch 5590 training_loss 0.6931471805599453
iteration 5 batch 5600 training_loss 0.6931471805599453
iteration 5 batch 5610 training_loss 0.6931471805599453
iteration 5 batch 5620 training_loss 0.6931471805599453
iteration 5 batch 5630 training_loss 0.6931471805599453
iteration 5 batch 5640 training_loss 0.6931471805599453
iteration 5 batch 5650 training_loss 0.6931471805599453
iteration 5 batch 5660 training_loss 0.6931471805599453
iteration 5 batch 5670 training_loss 0.6931471805599453
iteration 5 batch 5680 training_loss 0.6931471805599453
iteration 5 batch 5690 training_loss 0.6931471805599453
iteration 5 batch 5700 training_loss 0.6931471805599453
iteration 5 batch 5710 training_loss 0.6931471805599453
iteration 5 batch 5720 training_loss 0.6931471805599453
iteration 5 batch 5730 training_loss 0.6931471805599453
iteration 5 batch 5740 training_loss 0.6931471805599453
iteration 5 batch 5750 training_loss 0.6931471805599453
iteration 5 batch 5760 training_loss 0.6931471805599453
iteration 5 batch 5770 training_loss 0.6931471805599453
iteration 5 batch 5780 training_loss 0.6931471805599453
iteration 5 batch 5790 training_loss 0.6931471805599453
iteration 5 batch 5800 training_loss 0.6931471805599453
iteration 5 batch 5810 training_loss 0.6931471805599453
iteration 5 batch 5820 training_loss 0.6931471805599453
iteration 5 batch 5830 training_loss 0.6931471805599453
iteration 5 batch 5840 training_loss 0.6931471805599453
iteration 5 batch 5850 training_loss 0.6931471805599453
iteration 5 batch 5860 training_loss 0.6931471805599453
iteration 5 batch 5870 training_loss 0.6931471805599453
iteration 5 batch 5880 training_loss 0.6931471805599453
iteration 5 batch 5890 training_loss 0.6931471805599453
iteration 5 batch 5900 training_loss 0.6931471805599453
iteration 5 batch 5910 training_loss 0.6931471805599453
iteration 5 batch 5920 training_loss 0.6931471805599453
iteration 5 batch 5930 training_loss 0.6931471805599453
iteration 5 batch 5940 training_loss 0.6931471805599453
iteration 5 batch 5950 training_loss 0.6931471805599453
iteration 5 batch 5960 training_loss 0.6931471805599453
iteration 5 batch 5970 training_loss 0.6931471805599453
iteration 5 batch 5980 training_loss 0.6931471805599453
iteration 5 batch 5990 training_loss 0.6916632528527511
iteration 5 batch 6000 training_loss 0.6931471805599453
iteration 5 batch 6010 training_loss 0.6931471805599453
iteration 5 batch 6020 training_loss 0.6931471805599453
iteration 5 batch 6030 training_loss 0.6931471805599453
iteration 5 batch 6040 training_loss 0.6931471805599453
iteration 5 batch 6050 training_loss 0.6931471805599453
iteration 5 batch 6060 training_loss 0.6931471805599453
iteration 5 batch 6070 training_loss 0.6931471805599453
iteration 5 batch 6080 training_loss 0.6931471805599453
iteration 5 batch 6090 training_loss 0.6931471805599453
iteration 5 batch 6100 training_loss 0.6931471805599453
iteration 5 batch 6110 training_loss 0.6931471805599453
iteration 5 batch 6120 training_loss 0.6931471805599453
iteration 5 batch 6130 training_loss 0.6931471805599453
iteration 5 batch 6140 training_loss 0.6931471805599453
iteration 5 batch 6150 training_loss 0.6931471805599453
iteration 5 batch 6160 training_loss 0.6931471805599453
iteration 5 batch 6170 training_loss 0.6931471805599453
iteration 5 batch 6180 training_loss 0.6931471805599453
iteration 5 batch 6190 training_loss 0.6931471805599453
iteration 5 batch 6200 training_loss 0.6931471805599453
iteration 5 batch 6210 training_loss 0.6931471805599453
iteration 5 batch 6220 training_loss 0.6931471805599453
iteration 5 batch 6230 training_loss 0.6931471805599453
iteration 5 batch 6240 training_loss 0.6931471805599453
iteration 5 batch 6250 training_loss 0.6931471805599453
iteration 5 batch 6260 training_loss 0.6931471805599453
iteration 5 batch 6270 training_loss 0.6931471805599453
iteration 5 batch 6280 training_loss 0.6931471805599453
iteration 5 batch 6290 training_loss 0.6931471805599453
iteration 5 batch 6300 training_loss 0.6931471805599453
iteration 5 batch 6310 training_loss 0.6931471805599453
iteration 5 batch 6320 training_loss 0.6931471805599453
iteration 5 batch 6330 training_loss 0.6931471805599453
iteration 5 batch 6340 training_loss 0.6931471805599453
iteration 5 batch 6350 training_loss 0.6916632528527511
iteration 5 batch 6360 training_loss 0.6916632528527511
iteration 5 batch 6370 training_loss 0.6931471805599453
iteration 5 batch 6380 training_loss 0.6931471805599453
iteration 5 batch 6390 training_loss 0.6931471805599453
iteration 5 batch 6400 training_loss 0.6931471805599453
iteration 5 batch 6410 training_loss 0.6931471805599453
iteration 5 batch 6420 training_loss 0.6931471805599453
iteration 5 batch 6430 training_loss 0.6931471805599453
iteration 5 batch 6440 training_loss 0.6931471805599453
iteration 5 batch 6450 training_loss 0.6931471805599453
iteration 5 batch 6460 training_loss 0.6916632528527511
iteration 5 batch 6470 training_loss 0.6931471805599453
iteration 5 batch 6480 training_loss 0.6931471805599453
iteration 5 batch 6490 training_loss 0.6931471805599453
iteration 5 batch 6500 training_loss 0.6931471805599453
iteration 5 batch 6510 training_loss 0.6931471805599453
iteration 5 batch 6520 training_loss 0.6931471805599453
iteration 5 batch 6530 training_loss 0.6931471805599453
iteration 5 batch 6540 training_loss 0.6931471805599453
iteration 5 batch 6550 training_loss 0.6931471805599453
iteration 5 batch 6560 training_loss 0.6931471805599453
iteration 5 batch 6570 training_loss 0.6931471805599453
iteration 5 batch 6580 training_loss 0.6931471805599453
iteration 5 batch 6590 training_loss 0.6931471805599453
iteration 5 batch 6600 training_loss 0.6931471805599453
iteration 5 batch 6610 training_loss 0.6931471805599453
iteration 5 batch 6620 training_loss 0.6931471805599453
iteration 5 batch 6630 training_loss 0.6931471805599453
iteration 5 batch 6640 training_loss 0.6931471805599453
iteration 5 batch 6650 training_loss 0.6931471805599453
iteration 5 batch 6660 training_loss 0.6931471805599453
iteration 5 batch 6670 training_loss 0.6931471805599453
iteration 5 batch 6680 training_loss 0.6931471805599453
iteration 5 batch 6690 training_loss 0.6916632528527511
iteration 5 batch 6700 training_loss 0.6931471805599453
iteration 5 batch 6710 training_loss 0.6931471805599453
iteration 5 batch 6720 training_loss 0.6931471805599453
iteration 5 batch 6730 training_loss 0.6931471805599453
iteration 5 batch 6740 training_loss 0.6931471805599453
iteration 5 batch 6750 training_loss 0.6931471805599453
iteration 5 batch 6760 training_loss 0.6931471805599453
iteration 5 batch 6770 training_loss 0.6931471805599453
iteration 5 batch 6780 training_loss 0.6931471805599453
iteration 5 batch 6790 training_loss 0.6931471805599453
iteration 5 batch 6800 training_loss 0.6931471805599453
iteration 5 batch 6810 training_loss 0.6931471805599453
iteration 5 batch 6820 training_loss 0.6931471805599453
iteration 5 batch 6830 training_loss 0.6931471805599453
iteration 5 batch 6840 training_loss 0.6931471805599453
iteration 5 batch 6850 training_loss 0.6931471805599453
iteration 5 batch 6860 training_loss 0.6931471805599453
iteration 5 batch 6870 training_loss 0.6931471805599453
iteration 5 batch 6880 training_loss 0.6931471805599453
iteration 5 batch 6890 training_loss 0.6916632528527511
iteration 5 batch 6900 training_loss 0.6931471805599453
iteration 5 batch 6910 training_loss 0.6931471805599453
iteration 5 batch 6920 training_loss 0.6931471805599453
iteration 5 batch 6930 training_loss 0.6931471805599453
iteration 5 batch 6940 training_loss 0.6931471805599453
iteration 5 batch 6950 training_loss 0.6931471805599453
iteration 5 batch 6960 training_loss 0.6931471805599453
iteration 5 batch 6970 training_loss 0.6931471805599453
iteration 5 batch 6980 training_loss 0.6931471805599453
iteration 5 batch 6990 training_loss 0.6931471805599453
iteration 5 batch 7000 training_loss 0.6931471805599453
iteration 5 batch 7010 training_loss 0.6931471805599453
iteration 5 batch 7020 training_loss 0.6931471805599453
iteration 5 batch 7030 training_loss 0.6931471805599453
iteration 5 batch 7040 training_loss 0.6931471805599453
iteration 5 batch 7050 training_loss 0.6931471805599453
iteration 5 batch 7060 training_loss 0.6931471805599453
iteration 5 batch 7070 training_loss 0.6931471805599453
iteration 5 batch 7080 training_loss 0.6931471805599453
iteration 5 batch 7090 training_loss 0.6931471805599453
iteration 5 batch 7100 training_loss 0.6931471805599453
iteration 5 batch 7110 training_loss 0.6931471805599453
iteration 5 batch 7120 training_loss 0.6931471805599453
iteration 5 batch 7130 training_loss 0.6931471805599453
iteration 5 batch 7140 training_loss 0.6931471805599453
iteration 5 batch 7150 training_loss 0.6931471805599453
iteration 5 batch 7160 training_loss 0.6931471805599453
iteration 5 batch 7170 training_loss 0.6931471805599453
iteration 5 batch 7180 training_loss 0.6931471805599453
iteration 5 batch 7190 training_loss 0.6931471805599453
iteration 5 batch 7200 training_loss 0.6931471805599453
iteration 5 batch 7210 training_loss 0.6931471805599453
iteration 5 batch 7220 training_loss 0.6931471805599453
iteration 5 batch 7230 training_loss 0.6931471805599453
iteration 5 batch 7240 training_loss 0.6931471805599453
iteration 5 batch 7250 training_loss 0.6931471805599453
iteration 5 batch 7260 training_loss 0.6916632528527511
iteration 5 batch 7270 training_loss 0.6931471805599453
iteration 5 batch 7280 training_loss 0.6931471805599453
iteration 5 batch 7290 training_loss 0.6931471805599453
iteration 5 batch 7300 training_loss 0.6931471805599453
iteration 5 batch 7310 training_loss 0.6931471805599453
iteration 5 batch 7320 training_loss 0.6931471805599453
iteration 5 batch 7330 training_loss 0.6931471805599453
iteration 5 batch 7340 training_loss 0.6931471805599453
iteration 5 batch 7350 training_loss 0.6931471805599453
iteration 5 batch 7360 training_loss 0.6931471805599453
iteration 5 batch 7370 training_loss 0.6931471805599453
iteration 5 batch 7380 training_loss 0.6931471805599453
iteration 5 batch 7390 training_loss 0.6931471805599453
iteration 5 batch 7400 training_loss 0.6931471805599453
iteration 5 batch 7410 training_loss 0.6916632528527511
iteration 5 batch 7420 training_loss 0.6931471805599453
iteration 5 batch 7430 training_loss 0.6931471805599453
iteration 5 batch 7440 training_loss 0.6931471805599453
iteration 5 batch 7450 training_loss 0.6931471805599453
iteration 5 batch 7460 training_loss 0.6931471805599453
iteration 5 batch 7470 training_loss 0.6931471805599453
iteration 5 batch 7480 training_loss 0.6931471805599453
iteration 5 batch 7490 training_loss 0.6916632528527511
iteration 5 batch 7500 training_loss 0.6931471805599453
iteration 5 batch 7510 training_loss 0.6931471805599453
iteration 5 batch 7520 training_loss 0.6931471805599453
iteration 5 batch 7530 training_loss 0.6931471805599453
iteration 5 batch 7540 training_loss 0.6931471805599453
iteration 5 batch 7550 training_loss 0.6931471805599453
iteration 5 batch 7560 training_loss 0.6931471805599453
iteration 5 batch 7570 training_loss 0.6931471805599453
iteration 5 batch 7580 training_loss 0.6931471805599453
iteration 5 batch 7590 training_loss 0.6931471805599453
iteration 5 batch 7600 training_loss 0.6931471805599453
iteration 5 batch 7610 training_loss 0.6931471805599453
iteration 5 batch 7620 training_loss 0.6931471805599453
iteration 5 batch 7630 training_loss 0.6931471805599453
iteration 5 batch 7640 training_loss 0.6931471805599453
iteration 5 batch 7650 training_loss 0.6931471805599453
iteration 5 batch 7660 training_loss 0.6931471805599453
iteration 5 batch 7670 training_loss 0.6931471805599453
iteration 5 batch 7680 training_loss 0.6931471805599453
iteration 5 batch 7690 training_loss 0.6931471805599453
iteration 5 batch 7700 training_loss 0.6931471805599453
iteration 5 batch 7710 training_loss 0.6931471805599453
iteration 5 batch 7720 training_loss 0.6931471805599453
iteration 5 batch 7730 training_loss 0.6931471805599453
iteration 5 batch 7740 training_loss 0.6931471805599453
iteration 5 batch 7750 training_loss 0.6931471805599453
iteration 5 batch 7760 training_loss 0.6931471805599453
iteration 5 batch 7770 training_loss 0.6931471805599453
iteration 5 batch 7780 training_loss 0.6931471805599453
iteration 5 batch 7790 training_loss 0.6916632528527511
iteration 5 batch 7800 training_loss 0.6931471805599453
iteration 5 batch 7810 training_loss 0.6931471805599453
iteration 5 batch 7820 training_loss 0.6931471805599453
iteration 5 batch 7830 training_loss 0.6931471805599453
iteration 5 batch 7840 training_loss 0.6931471805599453
iteration 5 batch 7850 training_loss 0.6916632528527511
iteration 5 batch 7860 training_loss 0.6916632528527511
iteration 5 batch 7870 training_loss 0.6931471805599453
iteration 5 batch 7880 training_loss 0.6931471805599453
iteration 5 batch 7890 training_loss 0.6931471805599453
iteration 5 batch 7900 training_loss 0.6931471805599453
iteration 5 batch 7910 training_loss 0.6916632528527511
iteration 5 batch 7920 training_loss 0.6931471805599453
iteration 5 batch 7930 training_loss 0.6931471805599453
iteration 5 batch 7940 training_loss 0.6931471805599453
iteration 5 batch 7950 training_loss 0.6931471805599453
iteration 5 batch 7960 training_loss 0.6931471805599453
iteration 5 batch 7970 training_loss 0.6931471805599453
iteration 5 batch 7980 training_loss 0.6931471805599453
iteration 5 batch 7990 training_loss 0.6931471805599453
iteration 5 batch 8000 training_loss 0.6931471805599453
iteration 5 batch 8010 training_loss 0.6931471805599453
iteration 5 batch 8020 training_loss 0.6931471805599453
iteration 5 batch 8030 training_loss 0.6931471805599453
iteration 5 batch 8040 training_loss 0.6931471805599453
iteration 5 batch 8050 training_loss 0.6931471805599453
iteration 5 batch 8060 training_loss 0.6916632528527511
iteration 5 batch 8070 training_loss 0.6931471805599453
iteration 5 batch 8080 training_loss 0.6931471805599453
iteration 5 batch 8090 training_loss 0.6931471805599453
iteration 5 batch 8100 training_loss 0.6931471805599453
iteration 5 batch 8110 training_loss 0.6931471805599453
iteration 5 batch 8120 training_loss 0.6931471805599453
iteration 5 batch 8130 training_loss 0.6931471805599453
iteration 5 batch 8140 training_loss 0.6931471805599453
iteration 5 batch 8150 training_loss 0.6931471805599453
iteration 5 batch 8160 training_loss 0.6931471805599453
iteration 5 batch 8170 training_loss 0.6931471805599453
iteration 5 batch 8180 training_loss 0.6916632528527511
iteration 5 batch 8190 training_loss 0.6931471805599453
iteration 5 batch 8200 training_loss 0.6931471805599453
iteration 5 batch 8210 training_loss 0.6931471805599453
iteration 5 batch 8220 training_loss 0.6931471805599453
iteration 5 batch 8230 training_loss 0.6931471805599453
iteration 5 batch 8240 training_loss 0.6931471805599453
iteration 5 batch 8250 training_loss 0.6931471805599453
iteration 5 batch 8260 training_loss 0.6931471805599453
iteration 5 batch 8270 training_loss 0.6931471805599453
iteration 5 batch 8280 training_loss 0.6931471805599453
iteration 5 batch 8290 training_loss 0.6931471805599453
iteration 5 batch 8300 training_loss 0.6931471805599453
iteration 5 batch 8310 training_loss 0.6931471805599453
iteration 5 batch 8320 training_loss 0.6931471805599453
iteration 5 batch 8330 training_loss 0.6916632528527511
iteration 5 batch 8340 training_loss 0.6931471805599453
iteration 5 batch 8350 training_loss 0.6931471805599453
iteration 5 batch 8360 training_loss 0.6931471805599453
iteration 5 batch 8370 training_loss 0.6931471805599453
iteration 5 batch 8380 training_loss 0.6916632528527511
iteration 5 batch 8390 training_loss 0.6931471805599453
iteration 5 batch 8400 training_loss 0.6931471805599453
iteration 5 batch 8410 training_loss 0.6931471805599453
iteration 5 batch 8420 training_loss 0.6931471805599453
iteration 5 batch 8430 training_loss 0.6931471805599453
iteration 5 batch 8440 training_loss 0.6931471805599453
iteration 5 batch 8450 training_loss 0.6931471805599453
iteration 5 batch 8460 training_loss 0.6931471805599453
iteration 5 batch 8470 training_loss 0.6931471805599453
iteration 5 batch 8480 training_loss 0.6931471805599453
iteration 5 batch 8490 training_loss 0.6931471805599453
iteration 5 batch 8500 training_loss 0.6931471805599453
iteration 5 batch 8510 training_loss 0.6931471805599453
iteration 5 batch 8520 training_loss 0.6931471805599453
iteration 5 batch 8530 training_loss 0.6931471805599453
iteration 5 batch 8540 training_loss 0.6931471805599453
iteration 5 batch 8550 training_loss 0.6931471805599453
iteration 5 batch 8560 training_loss 0.6931471805599453
iteration 5 batch 8570 training_loss 0.6931471805599453
iteration 5 batch 8580 training_loss 0.6931471805599453
iteration 5 batch 8590 training_loss 0.6931471805599453
iteration 5 batch 8600 training_loss 0.6931471805599453
iteration 5 batch 8610 training_loss 0.6931471805599453
iteration 5 batch 8620 training_loss 0.6931471805599453
iteration 5 batch 8630 training_loss 0.6931471805599453
iteration 5 batch 8640 training_loss 0.6916632528527511
iteration 5 batch 8650 training_loss 0.6931471805599453
iteration 5 batch 8660 training_loss 0.6931471805599453
iteration 5 batch 8670 training_loss 0.6931471805599453
iteration 5 batch 8680 training_loss 0.6931471805599453
iteration 5 batch 8690 training_loss 0.6916632528527511
iteration 5 batch 8700 training_loss 0.6931471805599453
iteration 5 batch 8710 training_loss 0.6931471805599453
iteration 5 batch 8720 training_loss 0.6931471805599453
iteration 5 batch 8730 training_loss 0.6931471805599453
iteration 5 batch 8740 training_loss 0.6916632528527511
iteration 5 batch 8750 training_loss 0.6931471805599453
iteration 5 batch 8760 training_loss 0.6931471805599453
iteration 5 batch 8770 training_loss 0.6931471805599453
iteration 5 batch 8780 training_loss 0.6931471805599453
iteration 5 batch 8790 training_loss 0.6931471805599453
iteration 5 batch 8800 training_loss 0.6931471805599453
iteration 5 batch 8810 training_loss 0.6931471805599453
iteration 5 batch 8820 training_loss 0.6916632528527511
iteration 5 batch 8830 training_loss 0.6931471805599453
iteration 5 batch 8840 training_loss 0.6931471805599453
iteration 5 batch 8850 training_loss 0.6931471805599453
iteration 5 batch 8860 training_loss 0.6916632528527511
iteration 5 batch 8870 training_loss 0.6931471805599453
iteration 5 batch 8880 training_loss 0.6931471805599453
iteration 5 batch 8890 training_loss 0.6931471805599453
iteration 5 batch 8900 training_loss 0.6931471805599453
iteration 5 batch 8910 training_loss 0.6931471805599453
iteration 5 batch 8920 training_loss 0.6931471805599453
iteration 5 batch 8930 training_loss 0.6931471805599453
iteration 5 batch 8940 training_loss 0.6931471805599453
iteration 5 batch 8950 training_loss 0.6931471805599453
iteration 5 batch 8960 training_loss 0.6931471805599453
iteration 5 batch 8970 training_loss 0.6931471805599453
iteration 5 batch 8980 training_loss 0.6931471805599453
iteration 5 batch 8990 training_loss 0.6931471805599453
iteration 5 batch 9000 training_loss 0.6931471805599453
iteration 5 batch 9010 training_loss 0.6931471805599453
iteration 5 batch 9020 training_loss 0.6931471805599453
iteration 5 batch 9030 training_loss 0.6931471805599453
iteration 5 batch 9040 training_loss 0.6931471805599453
iteration 5 batch 9050 training_loss 0.6931471805599453
iteration 5 batch 9060 training_loss 0.6916632528527511
iteration 5 batch 9070 training_loss 0.6931471805599453
iteration 5 batch 9080 training_loss 0.6931471805599453
iteration 5 batch 9090 training_loss 0.6916632528527511
iteration 5 batch 9100 training_loss 0.6931471805599453
iteration 5 batch 9110 training_loss 0.6931471805599453
iteration 5 batch 9120 training_loss 0.6931471805599453
iteration 5 batch 9130 training_loss 0.6931471805599453
iteration 5 batch 9140 training_loss 0.6931471805599453
iteration 5 batch 9150 training_loss 0.6931471805599453
iteration 5 batch 9160 training_loss 0.6931471805599453
iteration 5 batch 9170 training_loss 0.6931471805599453
iteration 5 batch 9180 training_loss 0.6931471805599453
iteration 5 batch 9190 training_loss 0.6931471805599453
iteration 5 batch 9200 training_loss 0.6931471805599453
iteration 5 batch 9210 training_loss 0.6931471805599453
iteration 5 batch 9220 training_loss 0.6931471805599453
iteration 5 batch 9230 training_loss 0.6931471805599453
iteration 5 batch 9240 training_loss 0.6931471805599453
iteration 5 batch 9250 training_loss 0.6931471805599453
iteration 5 batch 9260 training_loss 0.6931471805599453
iteration 5 batch 9270 training_loss 0.6931471805599453
iteration 5 batch 9280 training_loss 0.6931471805599453
iteration 5 batch 9290 training_loss 0.6931471805599453
iteration 5 batch 9300 training_loss 0.6931471805599453
iteration 5 batch 9310 training_loss 0.6931471805599453
iteration 5 batch 9320 training_loss 0.6931471805599453
iteration 5 batch 9330 training_loss 0.6931471805599453
iteration 5 batch 9340 training_loss 0.6931471805599453
iteration 5 batch 9350 training_loss 0.6931471805599453
iteration 5 batch 9360 training_loss 0.6931471805599453
iteration 5 batch 9370 training_loss 0.6931471805599453
iteration 5 batch 9380 training_loss 0.6931471805599453
iteration 5 batch 9390 training_loss 0.6931471805599453
iteration 5 batch 9400 training_loss 0.6931471805599453
iteration 5 batch 9410 training_loss 0.6931471805599453
iteration 5 batch 9420 training_loss 0.6931471805599453
iteration 5 batch 9430 training_loss 0.6931471805599453
iteration 5 batch 9440 training_loss 0.6931471805599453
iteration 5 batch 9450 training_loss 0.6931471805599453
iteration 5 batch 9460 training_loss 0.6931471805599453
iteration 5 batch 9470 training_loss 0.6931471805599453
iteration 5 batch 9480 training_loss 0.6931471805599453
iteration 5 batch 9490 training_loss 0.6931471805599453
iteration 5 batch 9500 training_loss 0.6931471805599453
iteration 5 batch 9510 training_loss 0.6931471805599453
iteration 5 batch 9520 training_loss 0.6916632528527511
iteration 5 batch 9530 training_loss 0.6931471805599453
iteration 5 batch 9540 training_loss 0.6931471805599453
iteration 5 batch 9550 training_loss 0.6931471805599453
iteration 5 batch 9560 training_loss 0.6931471805599453
iteration 5 batch 9570 training_loss 0.6931471805599453
iteration 5 batch 9580 training_loss 0.6931471805599453
iteration 5 batch 9590 training_loss 0.6931471805599453
iteration 5 batch 9600 training_loss 0.6931471805599453
iteration 5 batch 9610 training_loss 0.6931471805599453
iteration 5 batch 9620 training_loss 0.6931471805599453
iteration 5 batch 9630 training_loss 0.6931471805599453
iteration 5 batch 9640 training_loss 0.6931471805599453
iteration 5 batch 9650 training_loss 0.6931471805599453
iteration 5 batch 9660 training_loss 0.6931471805599453
iteration 5 batch 9670 training_loss 0.6931471805599453
iteration 5 batch 9680 training_loss 0.6931471805599453
iteration 5 batch 9690 training_loss 0.6931471805599453
iteration 5 batch 9700 training_loss 0.6931471805599453
iteration 5 batch 9710 training_loss 0.6931471805599453
iteration 5 batch 9720 training_loss 0.6931471805599453
iteration 5 batch 9730 training_loss 0.6931471805599453
iteration 5 batch 9740 training_loss 0.6931471805599453
iteration 5 batch 9750 training_loss 0.6931471805599453
iteration 5 batch 9760 training_loss 0.6931471805599453
iteration 5 batch 9770 training_loss 0.6931471805599453
iteration 5 batch 9780 training_loss 0.6931471805599453
iteration 5 batch 9790 training_loss 0.6931471805599453
iteration 5 batch 9800 training_loss 0.6931471805599453
iteration 5 batch 9810 training_loss 0.6931471805599453
iteration 5 batch 9820 training_loss 0.6931471805599453
iteration 5 batch 9830 training_loss 0.6931471805599453
iteration 5 batch 9840 training_loss 0.6931471805599453
iteration 5 batch 9850 training_loss 0.6931471805599453
iteration 5 batch 9860 training_loss 0.6931471805599453
iteration 5 batch 9870 training_loss 0.6931471805599453
iteration 5 batch 9880 training_loss 0.6931471805599453
iteration 5 batch 9890 training_loss 0.6931471805599453
iteration 5 batch 9900 training_loss 0.6931471805599453
iteration 5 batch 9910 training_loss 0.6931471805599453
iteration 5 batch 9920 training_loss 0.6931471805599453
iteration 5 batch 9930 training_loss 0.6931471805599453
iteration 5 batch 9940 training_loss 0.6931471805599453
iteration 5 batch 9950 training_loss 0.6931471805599453
iteration 5 batch 9960 training_loss 0.6931471805599453
iteration 5 batch 9970 training_loss 0.6931471805599453
iteration 5 batch 9980 training_loss 0.6931471805599453
iteration 5 batch 9990 training_loss 0.6931471805599453
iteration 5 batch 10000 training_loss 0.6931471805599453
iteration 5 batch 10010 training_loss 0.6931471805599453
iteration 5 batch 10020 training_loss 0.6931471805599453
iteration 5 batch 10030 training_loss 0.6931471805599453
iteration 5 batch 10040 training_loss 0.6931471805599453
iteration 5 batch 10050 training_loss 0.6931471805599453
iteration 5 batch 10060 training_loss 0.6931471805599453
iteration 5 batch 10070 training_loss 0.6931471805599453
iteration 5 batch 10080 training_loss 0.6931471805599453
iteration 5 batch 10090 training_loss 0.6931471805599453
iteration 5 batch 10100 training_loss 0.6931471805599453
iteration 5 batch 10110 training_loss 0.6931471805599453
iteration 5 batch 10120 training_loss 0.6931471805599453
iteration 5 batch 10130 training_loss 0.6931471805599453
iteration 5 batch 10140 training_loss 0.6931471805599453
iteration 5 batch 10150 training_loss 0.6931471805599453
iteration 5 batch 10160 training_loss 0.6931471805599453
iteration 5 batch 10170 training_loss 0.6931471805599453
iteration 5 batch 10180 training_loss 0.6931471805599453
iteration 5 batch 10190 training_loss 0.6931471805599453
iteration 5 batch 10200 training_loss 0.6931471805599453
iteration 5 batch 10210 training_loss 0.6931471805599453
iteration 5 batch 10220 training_loss 0.6931471805599453
iteration 5 batch 10230 training_loss 0.6931471805599453
iteration 5 batch 10240 training_loss 0.6931471805599453
iteration 5 batch 10250 training_loss 0.6931471805599453
iteration 5 batch 10260 training_loss 0.6931471805599453
iteration 5 batch 10270 training_loss 0.6931471805599453
iteration 5 batch 10280 training_loss 0.6931471805599453
iteration 5 batch 10290 training_loss 0.6916632528527511
iteration 5 batch 10300 training_loss 0.6931471805599453
iteration 5 batch 10310 training_loss 0.6931471805599453
iteration 5 batch 10320 training_loss 0.6931471805599453
iteration 5 batch 10330 training_loss 0.6931471805599453
iteration 5 batch 10340 training_loss 0.6931471805599453
iteration 5 batch 10350 training_loss 0.6931471805599453
iteration 5 batch 10360 training_loss 0.6931471805599453
iteration 5 batch 10370 training_loss 0.6931471805599453
iteration 5 batch 10380 training_loss 0.6931471805599453
iteration 5 batch 10390 training_loss 0.6931471805599453
iteration 5 batch 10400 training_loss 0.6931471805599453
iteration 5 batch 10410 training_loss 0.6931471805599453
iteration 5 batch 10420 training_loss 0.6931471805599453
iteration 5 batch 10430 training_loss 0.6916632528527511
iteration 5 batch 10440 training_loss 0.6931471805599453
iteration 5 batch 10450 training_loss 0.6931471805599453
iteration 5 batch 10460 training_loss 0.6931471805599453
iteration 5 batch 10470 training_loss 0.6931471805599453
iteration 5 batch 10480 training_loss 0.6931471805599453
iteration 5 batch 10490 training_loss 0.6931471805599453
iteration 5 batch 10500 training_loss 0.6916632528527511
iteration 5 batch 10510 training_loss 0.6931471805599453
iteration 5 batch 10520 training_loss 0.6931471805599453
iteration 5 batch 10530 training_loss 0.6931471805599453
iteration 5 batch 10540 training_loss 0.6931471805599453
iteration 5 batch 10550 training_loss 0.6931471805599453
iteration 5 batch 10560 training_loss 0.6931471805599453
iteration 5 batch 10570 training_loss 0.6931471805599453
iteration 5 batch 10580 training_loss 0.6931471805599453
iteration 5 batch 10590 training_loss 0.6931471805599453
iteration 5 batch 10600 training_loss 0.6931471805599453
iteration 5 batch 10610 training_loss 0.6931471805599453
iteration 5 batch 10620 training_loss 0.6916632528527511
iteration 5 batch 10630 training_loss 0.6931471805599453
iteration 5 batch 10640 training_loss 0.6931471805599453
iteration 5 batch 10650 training_loss 0.6931471805599453
iteration 5 batch 10660 training_loss 0.6931471805599453
iteration 5 batch 10670 training_loss 0.6916632528527511
iteration 5 batch 10680 training_loss 0.6931471805599453
iteration 5 batch 10690 training_loss 0.6916632528527511
iteration 5 batch 10700 training_loss 0.6931471805599453
iteration 5 batch 10710 training_loss 0.6931471805599453
iteration 5 batch 10720 training_loss 0.6931471805599453
iteration 5 batch 10730 training_loss 0.6931471805599453
iteration 5 batch 10740 training_loss 0.6931471805599453
iteration 5 batch 10750 training_loss 0.6931471805599453
iteration 5 batch 10760 training_loss 0.6931471805599453
iteration 5 batch 10770 training_loss 0.6916632528527511
iteration 5 batch 10780 training_loss 0.6931471805599453
iteration 5 batch 10790 training_loss 0.6931471805599453
iteration 5 batch 10800 training_loss 0.6931471805599453
iteration 5 batch 10810 training_loss 0.6931471805599453
iteration 5 batch 10820 training_loss 0.6931471805599453
iteration 5 batch 10830 training_loss 0.6931471805599453
iteration 5 batch 10840 training_loss 0.6916632528527511
iteration 5 batch 10850 training_loss 0.6931471805599453
iteration 5 batch 10860 training_loss 0.6931471805599453
iteration 5 batch 10870 training_loss 0.6931471805599453
iteration 5 batch 10880 training_loss 0.6931471805599453
iteration 5 batch 10890 training_loss 0.6931471805599453
iteration 5 batch 10900 training_loss 0.6931471805599453
iteration 5 batch 10910 training_loss 0.6931471805599453
iteration 5 batch 10920 training_loss 0.6931471805599453
iteration 5 batch 10930 training_loss 0.6931471805599453
iteration 5 batch 10940 training_loss 0.6931471805599453
iteration 5 batch 10950 training_loss 0.6931471805599453
iteration 5 batch 10960 training_loss 0.6931471805599453
iteration 5 batch 10970 training_loss 0.6931471805599453
iteration 5 batch 10980 training_loss 0.6931471805599453
iteration 5 batch 10990 training_loss 0.6931471805599453
iteration 5 batch 11000 training_loss 0.6931471805599453
iteration 5 batch 11010 training_loss 0.6931471805599453
iteration 5 batch 11020 training_loss 0.6916632528527511
iteration 5 batch 11030 training_loss 0.6931471805599453
iteration 5 batch 11040 training_loss 0.6931471805599453
iteration 5 batch 11050 training_loss 0.6931471805599453
iteration 5 batch 11060 training_loss 0.6916632528527511
iteration 5 batch 11070 training_loss 0.6931471805599453
iteration 5 batch 11080 training_loss 0.6931471805599453
iteration 5 batch 11090 training_loss 0.6931471805599453
iteration 5 batch 11100 training_loss 0.6931471805599453
iteration 5 batch 11110 training_loss 0.6931471805599453
iteration 5 batch 11120 training_loss 0.6931471805599453
iteration 5 batch 11130 training_loss 0.6931471805599453
iteration 5 batch 11140 training_loss 0.6916632528527511
iteration 5 batch 11150 training_loss 0.6931471805599453
iteration 5 batch 11160 training_loss 0.6931471805599453
iteration 5 batch 11170 training_loss 0.6931471805599453
iteration 5 batch 11180 training_loss 0.6931471805599453
iteration 5 batch 11190 training_loss 0.6931471805599453
iteration 5 batch 11200 training_loss 0.6931471805599453
iteration 5 batch 11210 training_loss 0.6931471805599453
iteration 5 batch 11220 training_loss 0.6931471805599453
iteration 5 batch 11230 training_loss 0.6931471805599453
iteration 5 batch 11240 training_loss 0.6931471805599453
iteration 5 batch 11250 training_loss 0.6931471805599453
iteration 5 batch 11260 training_loss 0.6931471805599453
iteration 5 batch 11270 training_loss 0.6931471805599453
iteration 5 batch 11280 training_loss 0.6931471805599453
iteration 5 batch 11290 training_loss 0.6931471805599453
iteration 5 batch 11300 training_loss 0.6916632528527511
iteration 5 batch 11310 training_loss 0.6931471805599453
iteration 5 batch 11320 training_loss 0.6931471805599453
iteration 5 batch 11330 training_loss 0.6931471805599453
iteration 5 batch 11340 training_loss 0.6931471805599453
iteration 5 batch 11350 training_loss 0.6931471805599453
iteration 5 batch 11360 training_loss 0.6931471805599453
iteration 5 batch 11370 training_loss 0.6931471805599453
iteration 5 batch 11380 training_loss 0.6931471805599453
iteration 5 batch 11390 training_loss 0.6931471805599453
iteration 5 batch 11400 training_loss 0.6931471805599453
iteration 5 batch 11410 training_loss 0.6931471805599453
iteration 5 batch 11420 training_loss 0.6931471805599453
iteration 5 batch 11430 training_loss 0.6931471805599453
iteration 5 batch 11440 training_loss 0.6931471805599453
iteration 5 batch 11450 training_loss 0.6931471805599453
iteration 5 batch 11460 training_loss 0.6931471805599453
iteration 5 batch 11470 training_loss 0.6931471805599453
iteration 5 batch 11480 training_loss 0.6931471805599453
iteration 5 batch 11490 training_loss 0.6916632528527511
iteration 5 batch 11500 training_loss 0.6931471805599453
iteration 5 batch 11510 training_loss 0.6931471805599453
iteration 5 batch 11520 training_loss 0.6931471805599453
iteration 5 batch 11530 training_loss 0.6931471805599453
iteration 5 batch 11540 training_loss 0.6931471805599453
iteration 5 batch 11550 training_loss 0.6931471805599453
iteration 5 batch 11560 training_loss 0.6931471805599453
iteration 5 batch 11570 training_loss 0.6931471805599453
iteration 5 batch 11580 training_loss 0.6916632528527511
iteration 5 batch 11590 training_loss 0.6931471805599453
iteration 5 batch 11600 training_loss 0.6916632528527511
iteration 5 batch 11610 training_loss 0.6931471805599453
iteration 5 batch 11620 training_loss 0.6931471805599453
iteration 5 batch 11630 training_loss 0.6931471805599453
iteration 5 batch 11640 training_loss 0.6931471805599453
iteration 5 batch 11650 training_loss 0.6931471805599453
iteration 5 batch 11660 training_loss 0.6931471805599453
iteration 5 batch 11670 training_loss 0.6916632528527511
iteration 5 batch 11680 training_loss 0.6931471805599453
iteration 5 batch 11690 training_loss 0.6931471805599453
iteration 5 batch 11700 training_loss 0.6931471805599453
iteration 5 batch 11710 training_loss 0.6931471805599453
iteration 5 batch 11720 training_loss 0.6931471805599453
iteration 5 batch 11730 training_loss 0.6931471805599453
iteration 5 batch 11740 training_loss 0.6931471805599453
iteration 5 batch 11750 training_loss 0.6931471805599453
iteration 5 batch 11760 training_loss 0.6931471805599453
iteration 5 batch 11770 training_loss 0.6931471805599453
iteration 5 batch 11780 training_loss 0.6931471805599453
iteration 5 batch 11790 training_loss 0.6931471805599453
iteration 5 batch 11800 training_loss 0.6931471805599453
iteration 5 batch 11810 training_loss 0.6931471805599453
iteration 5 batch 11820 training_loss 0.6931471805599453
iteration 5 batch 11830 training_loss 0.6931471805599453
iteration 5 batch 11840 training_loss 0.6931471805599453
iteration 5 batch 11850 training_loss 0.6931471805599453
iteration 5 batch 11860 training_loss 0.6931471805599453
iteration 5 batch 11870 training_loss 0.6931471805599453
iteration 5 batch 11880 training_loss 0.6931471805599453
iteration 5 batch 11890 training_loss 0.6916632528527511
iteration 5 batch 11900 training_loss 0.6931471805599453
iteration 5 batch 11910 training_loss 0.6931471805599453
iteration 5 batch 11920 training_loss 0.6931471805599453
iteration 5 batch 11930 training_loss 0.6931471805599453
iteration 5 batch 11940 training_loss 0.6931471805599453
iteration 5 batch 11950 training_loss 0.6931471805599453
iteration 5 batch 11960 training_loss 0.6931471805599453
iteration 5 batch 11970 training_loss 0.6931471805599453
iteration 5 batch 11980 training_loss 0.6931471805599453
iteration 5 batch 11990 training_loss 0.6931471805599453
iteration 5 batch 12000 training_loss 0.6931471805599453
iteration 5 batch 12010 training_loss 0.6931471805599453
iteration 5 batch 12020 training_loss 0.6931471805599453
iteration 5 batch 12030 training_loss 0.6931471805599453
iteration 5 batch 12040 training_loss 0.6931471805599453
iteration 5 batch 12050 training_loss 0.6931471805599453
iteration 5 batch 12060 training_loss 0.6931471805599453
iteration 5 batch 12070 training_loss 0.6931471805599453
iteration 5 batch 12080 training_loss 0.6931471805599453
iteration 5 batch 12090 training_loss 0.6931471805599453
iteration 5 batch 12100 training_loss 0.6931471805599453
iteration 5 batch 12110 training_loss 0.6931471805599453
iteration 5 batch 12120 training_loss 0.6931471805599453
iteration 5 batch 12130 training_loss 0.6931471805599453
iteration 5 batch 12140 training_loss 0.6931471805599453
iteration 5 batch 12150 training_loss 0.6931471805599453
iteration 5 batch 12160 training_loss 0.6931471805599453
iteration 5 batch 12170 training_loss 0.6931471805599453
iteration 5 batch 12180 training_loss 0.6931471805599453
iteration 5 batch 12190 training_loss 0.6931471805599453
iteration 5 batch 12200 training_loss 0.6931471805599453
iteration 5 batch 12210 training_loss 0.6931471805599453
iteration 5 batch 12220 training_loss 0.6931471805599453
iteration 5 batch 12230 training_loss 0.6931471805599453
iteration 5 batch 12240 training_loss 0.6931471805599453
iteration 5 batch 12250 training_loss 0.6916632528527511
iteration 5 batch 12260 training_loss 0.6931471805599453
iteration 5 batch 12270 training_loss 0.6931471805599453
iteration 5 batch 12280 training_loss 0.6931471805599453
iteration 5 batch 12290 training_loss 0.6931471805599453
iteration 5 batch 12300 training_loss 0.6931471805599453
iteration 5 batch 12310 training_loss 0.6931471805599453
iteration 5 batch 12320 training_loss 0.6931471805599453
iteration 5 batch 12330 training_loss 0.6916632528527511
iteration 5 batch 12340 training_loss 0.6931471805599453
iteration 5 batch 12350 training_loss 0.6931471805599453
iteration 5 batch 12360 training_loss 0.6931471805599453
iteration 5 batch 12370 training_loss 0.6931471805599453
iteration 5 batch 12380 training_loss 0.6916632528527511
iteration 5 batch 12390 training_loss 0.6931471805599453
iteration 5 batch 12400 training_loss 0.6931471805599453
iteration 5 batch 12410 training_loss 0.6931471805599453
iteration 5 batch 12420 training_loss 0.6931471805599453
iteration 5 batch 12430 training_loss 0.6916632528527511
iteration 5 batch 12440 training_loss 0.6931471805599453
iteration 5 batch 12450 training_loss 0.6931471805599453
iteration 5 batch 12460 training_loss 0.6931471805599453
iteration 5 batch 12470 training_loss 0.6931471805599453
iteration 5 batch 12480 training_loss 0.6931471805599453
iteration 5 batch 12490 training_loss 0.6931471805599453
iteration 5 batch 12500 training_loss 0.6931471805599453
iteration 5 batch 12510 training_loss 0.6931471805599453
iteration 5 batch 12520 training_loss 0.6916632528527511
iteration 5 batch 12530 training_loss 0.6931471805599453
iteration 5 batch 12540 training_loss 0.6931471805599453
iteration 5 batch 12550 training_loss 0.6916632528527511
iteration 5 batch 12560 training_loss 0.6931471805599453
iteration 5 batch 12570 training_loss 0.6931471805599453
iteration 5 batch 12580 training_loss 0.6931471805599453
iteration 5 batch 12590 training_loss 0.6931471805599453
iteration 5 batch 12600 training_loss 0.6931471805599453
iteration 5 batch 12610 training_loss 0.6931471805599453
iteration 5 batch 12620 training_loss 0.6931471805599453
iteration 5 batch 12630 training_loss 0.6931471805599453
iteration 5 batch 12640 training_loss 0.6931471805599453
iteration 5 batch 12650 training_loss 0.6916632528527511
iteration 5 batch 12660 training_loss 0.6931471805599453
iteration 5 batch 12670 training_loss 0.6931471805599453
iteration 5 batch 12680 training_loss 0.6931471805599453
iteration 5 batch 12690 training_loss 0.6931471805599453
iteration 5 batch 12700 training_loss 0.6931471805599453
iteration 5 batch 12710 training_loss 0.6931471805599453
iteration 5 batch 12720 training_loss 0.6931471805599453
iteration 5 batch 12730 training_loss 0.6931471805599453
iteration 5 batch 12740 training_loss 0.6931471805599453
iteration 5 batch 12750 training_loss 0.6916632528527511
iteration 5 batch 12760 training_loss 0.6931471805599453
iteration 5 batch 12770 training_loss 0.6931471805599453
iteration 5 batch 12780 training_loss 0.6931471805599453
iteration 5 batch 12790 training_loss 0.6931471805599453
iteration 5 batch 12800 training_loss 0.6931471805599453
iteration 5 batch 12810 training_loss 0.6931471805599453
iteration 5 batch 12820 training_loss 0.6931471805599453
iteration 5 batch 12830 training_loss 0.6931471805599453
iteration 5 batch 12840 training_loss 0.6931471805599453
iteration 5 batch 12850 training_loss 0.6931471805599453
iteration 5 batch 12860 training_loss 0.6931471805599453
iteration 5 batch 12870 training_loss 0.6931471805599453
iteration 5 batch 12880 training_loss 0.6931471805599453
iteration 5 batch 12890 training_loss 0.6931471805599453
iteration 5 batch 12900 training_loss 0.6931471805599453
iteration 5 batch 12910 training_loss 0.6931471805599453
iteration 5 batch 12920 training_loss 0.6931471805599453
iteration 5 batch 12930 training_loss 0.6931471805599453
iteration 5 batch 12940 training_loss 0.6931471805599453
iteration 5 batch 12950 training_loss 0.6931471805599453
iteration 5 batch 12960 training_loss 0.6931471805599453
iteration 5 batch 12970 training_loss 0.6931471805599453
iteration 5 batch 12980 training_loss 0.6931471805599453
iteration 5 batch 12990 training_loss 0.6931471805599453
iteration 5 batch 13000 training_loss 0.6931471805599453
iteration 5 batch 13010 training_loss 0.6931471805599453
iteration 5 batch 13020 training_loss 0.6931471805599453
iteration 5 batch 13030 training_loss 0.6916632528527511
iteration 5 batch 13040 training_loss 0.6931471805599453
iteration 5 batch 13050 training_loss 0.6931471805599453
iteration 5 batch 13060 training_loss 0.6931471805599453
iteration 5 batch 13070 training_loss 0.6931471805599453
iteration 5 batch 13080 training_loss 0.6931471805599453
iteration 5 batch 13090 training_loss 0.6931471805599453
iteration 5 batch 13100 training_loss 0.6931471805599453
iteration 5 batch 13110 training_loss 0.6931471805599453
iteration 5 batch 13120 training_loss 0.6931471805599453
iteration 5 batch 13130 training_loss 0.6931471805599453
iteration 5 batch 13140 training_loss 0.6931471805599453
iteration 5 batch 13150 training_loss 0.6916632528527511
iteration 5 batch 13160 training_loss 0.6931471805599453
iteration 5 batch 13170 training_loss 0.6931471805599453
iteration 5 batch 13180 training_loss 0.6931471805599453
iteration 5 batch 13190 training_loss 0.6931471805599453
iteration 5 batch 13200 training_loss 0.6931471805599453
iteration 5 batch 13210 training_loss 0.6931471805599453
iteration 5 batch 13220 training_loss 0.6931471805599453
iteration 5 batch 13230 training_loss 0.6931471805599453
iteration 5 batch 13240 training_loss 0.6916632528527511
iteration 5 batch 13250 training_loss 0.6931471805599453
iteration 5 batch 13260 training_loss 0.6931471805599453
iteration 5 batch 13270 training_loss 0.6916632528527511
iteration 5 batch 13280 training_loss 0.6931471805599453
iteration 5 batch 13290 training_loss 0.6931471805599453
iteration 5 batch 13300 training_loss 0.6931471805599453
iteration 5 batch 13310 training_loss 0.6931471805599453
iteration 5 batch 13320 training_loss 0.6931471805599453
iteration 5 batch 13330 training_loss 0.6916632528527511
iteration 5 batch 13340 training_loss 0.6931471805599453
iteration 5 batch 13350 training_loss 0.6931471805599453
iteration 5 batch 13360 training_loss 0.6931471805599453
iteration 5 batch 13370 training_loss 0.6931471805599453
iteration 5 batch 13380 training_loss 0.6931471805599453
iteration 5 batch 13390 training_loss 0.6916632528527511
iteration 5 batch 13400 training_loss 0.6931471805599453
iteration 5 batch 13410 training_loss 0.6931471805599453
iteration 5 batch 13420 training_loss 0.6931471805599453
iteration 5 batch 13430 training_loss 0.6931471805599453
iteration 5 batch 13440 training_loss 0.6931471805599453
iteration 5 batch 13450 training_loss 0.6931471805599453
iteration 5 batch 13460 training_loss 0.6931471805599453
iteration 5 batch 13470 training_loss 0.6931471805599453
iteration 5 batch 13480 training_loss 0.6931471805599453
iteration 5 batch 13490 training_loss 0.6931471805599453
iteration 5 batch 13500 training_loss 0.6931471805599453
iteration 5 batch 13510 training_loss 0.6931471805599453
iteration 5 batch 13520 training_loss 0.6931471805599453
iteration 5 batch 13530 training_loss 0.6901793251455568
iteration 5 batch 13540 training_loss 0.6931471805599453
iteration 5 batch 13550 training_loss 0.6931471805599453
iteration 5 batch 13560 training_loss 0.6931471805599453
iteration 5 batch 13570 training_loss 0.6931471805599453
iteration 5 batch 13580 training_loss 0.6931471805599453
iteration 5 batch 13590 training_loss 0.6931471805599453
iteration 5 batch 13600 training_loss 0.6931471805599453
iteration 5 batch 13610 training_loss 0.6931471805599453
iteration 5 batch 13620 training_loss 0.6931471805599453
iteration 5 batch 13630 training_loss 0.6931471805599453
iteration 5 batch 13640 training_loss 0.6931471805599453
iteration 5 batch 13650 training_loss 0.6931471805599453
iteration 5 batch 13660 training_loss 0.6931471805599453
iteration 5 batch 13670 training_loss 0.6931471805599453
iteration 5 batch 13680 training_loss 0.6931471805599453
iteration 5 batch 13690 training_loss 0.6931471805599453
iteration 5 batch 13700 training_loss 0.6931471805599453
iteration 5 batch 13710 training_loss 0.6931471805599453
iteration 5 batch 13720 training_loss 0.6931471805599453
iteration 5 batch 13730 training_loss 0.6931471805599453
iteration 5 batch 13740 training_loss 0.6931471805599453
iteration 5 batch 13750 training_loss 0.6931471805599453
iteration 5 batch 13760 training_loss 0.6931471805599453
iteration 5 batch 13770 training_loss 0.6931471805599453
iteration 5 batch 13780 training_loss 0.6931471805599453
iteration 5 batch 13790 training_loss 0.6931471805599453
iteration 5 batch 13800 training_loss 0.6931471805599453
iteration 5 batch 13810 training_loss 0.6931471805599453
iteration 5 batch 13820 training_loss 0.6931471805599453
iteration 5 batch 13830 training_loss 0.6931471805599453
iteration 5 batch 13840 training_loss 0.6931471805599453
iteration 5 batch 13850 training_loss 0.6931471805599453
iteration 5 batch 13860 training_loss 0.6916632528527511
iteration 5 batch 13870 training_loss 0.6931471805599453
iteration 5 batch 13880 training_loss 0.6931471805599453
iteration 5 batch 13890 training_loss 0.6931471805599453
iteration 5 batch 13900 training_loss 0.6931471805599453
iteration 5 batch 13910 training_loss 0.6931471805599453
iteration 5 batch 13920 training_loss 0.6931471805599453
iteration 5 batch 13930 training_loss 0.6931471805599453
iteration 5 batch 13940 training_loss 0.6931471805599453
iteration 5 batch 13950 training_loss 0.6931471805599453
iteration 5 batch 13960 training_loss 0.6931471805599453
iteration 5 batch 13970 training_loss 0.6931471805599453
iteration 5 batch 13980 training_loss 0.6931471805599453
iteration 5 batch 13990 training_loss 0.6931471805599453
iteration 5 batch 14000 training_loss 0.6931471805599453
iteration 5 batch 14010 training_loss 0.6931471805599453
iteration 5 batch 14020 training_loss 0.6931471805599453
iteration 5 batch 14030 training_loss 0.6931471805599453
iteration 5 batch 14040 training_loss 0.6931471805599453
iteration 5 batch 14050 training_loss 0.6931471805599453
iteration 5 batch 14060 training_loss 0.6931471805599453
iteration 5 batch 14070 training_loss 0.6931471805599453
iteration 5 batch 14080 training_loss 0.6931471805599453
iteration 5 batch 14090 training_loss 0.6931471805599453
iteration 5 batch 14100 training_loss 0.6931471805599453
iteration 5 batch 14110 training_loss 0.6931471805599453
iteration 5 batch 14120 training_loss 0.6916632528527511
iteration 5 batch 14130 training_loss 0.6931471805599453
iteration 5 batch 14140 training_loss 0.6931471805599453
iteration 5 batch 14150 training_loss 0.6931471805599453
iteration 5 batch 14160 training_loss 0.6931471805599453
iteration 5 batch 14170 training_loss 0.6931471805599453
iteration 5 batch 14180 training_loss 0.6931471805599453
iteration 5 batch 14190 training_loss 0.6931471805599453
iteration 5 batch 14200 training_loss 0.6931471805599453
iteration 5 batch 14210 training_loss 0.6931471805599453
iteration 5 batch 14220 training_loss 0.6931471805599453
iteration 5 batch 14230 training_loss 0.6931471805599453
iteration 5 batch 14240 training_loss 0.6931471805599453
iteration 5 batch 14250 training_loss 0.6931471805599453
iteration 5 batch 14260 training_loss 0.6931471805599453
iteration 5 batch 14270 training_loss 0.6931471805599453
iteration 5 batch 14280 training_loss 0.6931471805599453
iteration 5 batch 14290 training_loss 0.6931471805599453
iteration 5 batch 14300 training_loss 0.6931471805599453
iteration 5 batch 14310 training_loss 0.6931471805599453
iteration 5 batch 14320 training_loss 0.6931471805599453
iteration 5 batch 14330 training_loss 0.6931471805599453
iteration 5 batch 14340 training_loss 0.6916632528527511
iteration 5 batch 14350 training_loss 0.6931471805599453
iteration 5 batch 14360 training_loss 0.6931471805599453
iteration 5 batch 14370 training_loss 0.6931471805599453
iteration 5 batch 14380 training_loss 0.6916632528527511
iteration 5 batch 14390 training_loss 0.6931471805599453
iteration 5 batch 14400 training_loss 0.6931471805599453
iteration 5 batch 14410 training_loss 0.6916632528527511
iteration 5 batch 14420 training_loss 0.6931471805599453
iteration 5 batch 14430 training_loss 0.6931471805599453
iteration 5 batch 14440 training_loss 0.6931471805599453
iteration 5 batch 14450 training_loss 0.6931471805599453
iteration 5 batch 14460 training_loss 0.6931471805599453
iteration 5 batch 14470 training_loss 0.6931471805599453
iteration 5 batch 14480 training_loss 0.6931471805599453
iteration 5 batch 14490 training_loss 0.6931471805599453
iteration 5 batch 14500 training_loss 0.6931471805599453
iteration 5 batch 14510 training_loss 0.6931471805599453
iteration 5 batch 14520 training_loss 0.6931471805599453
iteration 5 batch 14530 training_loss 0.6916632528527511
iteration 5 batch 14540 training_loss 0.6931471805599453
iteration 5 batch 14550 training_loss 0.6931471805599453
iteration 5 batch 14560 training_loss 0.6931471805599453
iteration 5 batch 14570 training_loss 0.6931471805599453
iteration 5 batch 14580 training_loss 0.6931471805599453
iteration 5 batch 14590 training_loss 0.6931471805599453
iteration 5 batch 14600 training_loss 0.6931471805599453
iteration 5 batch 14610 training_loss 0.6931471805599453
iteration 5 batch 14620 training_loss 0.6931471805599453
iteration 5 batch 14630 training_loss 0.6931471805599453
iteration 5 batch 14640 training_loss 0.6931471805599453
iteration 5 batch 14650 training_loss 0.6931471805599453
iteration 5 batch 14660 training_loss 0.6931471805599453
iteration 5 batch 14670 training_loss 0.6931471805599453
iteration 5 batch 14680 training_loss 0.6931471805599453
iteration 5 batch 14690 training_loss 0.6931471805599453
iteration 5 batch 14700 training_loss 0.6931471805599453
iteration 5 batch 14710 training_loss 0.6931471805599453
iteration 5 batch 14720 training_loss 0.6931471805599453
iteration 5 batch 14730 training_loss 0.6931471805599453
iteration 5 batch 14740 training_loss 0.6931471805599453
iteration 5 batch 14750 training_loss 0.6916632528527511
iteration 5 batch 14760 training_loss 0.6931471805599453
iteration 5 batch 14770 training_loss 0.6931471805599453
iteration 5 batch 14780 training_loss 0.6931471805599453
iteration 5 batch 14790 training_loss 0.6916632528527511
iteration 5 batch 14800 training_loss 0.6931471805599453
iteration 5 batch 14810 training_loss 0.6931471805599453
iteration 5 batch 14820 training_loss 0.6931471805599453
iteration 5 batch 14830 training_loss 0.6931471805599453
iteration 5 batch 14840 training_loss 0.6931471805599453
iteration 5 batch 14850 training_loss 0.6916632528527511
iteration 5 batch 14860 training_loss 0.6931471805599453
iteration 5 batch 14870 training_loss 0.6931471805599453
iteration 5 batch 14880 training_loss 0.6931471805599453
iteration 5 batch 14890 training_loss 0.6931471805599453
iteration 5 batch 14900 training_loss 0.6931471805599453
iteration 5 batch 14910 training_loss 0.6931471805599453
iteration 5 batch 14920 training_loss 0.6931471805599453
iteration 5 batch 14930 training_loss 0.6931471805599453
iteration 5 batch 14940 training_loss 0.6931471805599453
iteration 5 batch 14950 training_loss 0.6931471805599453
iteration 5 batch 14960 training_loss 0.6931471805599453
iteration 5 batch 14970 training_loss 0.6931471805599453
iteration 5 batch 14980 training_loss 0.6931471805599453
iteration 5 batch 14990 training_loss 0.6931471805599453
iteration 5 batch 15000 training_loss 0.6931471805599453
iteration 5 batch 15010 training_loss 0.6931471805599453
iteration 5 batch 15020 training_loss 0.6931471805599453
iteration 5 batch 15030 training_loss 0.6916632528527511
iteration 5 batch 15040 training_loss 0.6931471805599453
iteration 5 batch 15050 training_loss 0.6931471805599453
iteration 5 batch 15060 training_loss 0.6931471805599453
iteration 5 batch 15070 training_loss 0.6931471805599453
iteration 5 batch 15080 training_loss 0.6931471805599453
iteration 5 batch 15090 training_loss 0.6931471805599453
iteration 5 batch 15100 training_loss 0.6931471805599453
iteration 5 batch 15110 training_loss 0.6931471805599453
iteration 5 batch 15120 training_loss 0.6931471805599453
iteration 5 batch 15130 training_loss 0.6931471805599453
iteration 5 batch 15140 training_loss 0.6931471805599453
iteration 5 batch 15150 training_loss 0.6931471805599453
iteration 5 batch 15160 training_loss 0.6931471805599453
iteration 5 batch 15170 training_loss 0.6931471805599453
iteration 5 batch 15180 training_loss 0.6916632528527511
iteration 5 batch 15190 training_loss 0.6931471805599453
iteration 5 batch 15200 training_loss 0.6931471805599453
iteration 5 batch 15210 training_loss 0.6931471805599453
iteration 5 batch 15220 training_loss 0.6931471805599453
iteration 5 batch 15230 training_loss 0.6931471805599453
iteration 5 batch 15240 training_loss 0.6931471805599453
iteration 5 batch 15250 training_loss 0.6931471805599453
iteration 5 batch 15260 training_loss 0.6931471805599453
iteration 5 batch 15270 training_loss 0.6931471805599453
iteration 5 batch 15280 training_loss 0.6931471805599453
iteration 5 batch 15290 training_loss 0.6931471805599453
iteration 5 batch 15300 training_loss 0.6916632528527511
iteration 5 batch 15310 training_loss 0.6931471805599453
iteration 5 batch 15320 training_loss 0.6931471805599453
iteration 5 batch 15330 training_loss 0.6931471805599453
iteration 5 batch 15340 training_loss 0.6931471805599453
iteration 5 batch 15350 training_loss 0.6916632528527511
iteration 5 batch 15360 training_loss 0.6931471805599453
iteration 5 batch 15370 training_loss 0.6916632528527511
iteration 5 batch 15380 training_loss 0.6931471805599453
iteration 5 batch 15390 training_loss 0.6916632528527511
iteration 5 batch 15400 training_loss 0.6916632528527511
iteration 5 batch 15410 training_loss 0.6931471805599453
iteration 5 batch 15420 training_loss 0.6916632528527511
iteration 5 batch 15430 training_loss 0.6931471805599453
iteration 5 batch 15440 training_loss 0.6931471805599453
iteration 5 batch 15450 training_loss 0.6931471805599453
iteration 5 batch 15460 training_loss 0.6931471805599453
iteration 5 batch 15470 training_loss 0.6931471805599453
iteration 5 batch 15480 training_loss 0.6931471805599453
iteration 5 batch 15490 training_loss 0.6931471805599453
iteration 5 batch 15500 training_loss 0.6931471805599453
iteration 5 batch 15510 training_loss 0.6931471805599453
iteration 5 batch 15520 training_loss 0.6931471805599453
iteration 5 batch 15530 training_loss 0.6931471805599453
iteration 5 batch 15540 training_loss 0.6931471805599453
iteration 5 batch 15550 training_loss 0.6931471805599453
iteration 5 batch 15560 training_loss 0.6931471805599453
iteration 5 batch 15570 training_loss 0.6931471805599453
iteration 5 batch 15580 training_loss 0.6931471805599453
iteration 5 batch 15590 training_loss 0.6931471805599453
iteration 5 batch 15600 training_loss 0.6931471805599453
iteration 5 batch 15610 training_loss 0.6931471805599453
iteration 5 batch 15620 training_loss 0.6931471805599453
iteration 5 batch 15630 training_loss 0.6931471805599453
iteration 5 batch 15640 training_loss 0.6931471805599453
iteration 5 batch 15650 training_loss 0.6931471805599453
iteration 5 batch 15660 training_loss 0.6931471805599453
iteration 5 batch 15670 training_loss 0.6931471805599453
iteration 5 batch 15680 training_loss 0.6931471805599453
iteration 5 batch 15690 training_loss 0.6931471805599453
iteration 5 batch 15700 training_loss 0.6931471805599453
iteration 5 batch 15710 training_loss 0.6931471805599453
iteration 5 batch 15720 training_loss 0.6931471805599453
iteration 5 batch 15730 training_loss 0.6931471805599453
iteration 5 batch 15740 training_loss 0.6931471805599453
iteration 5 batch 15750 training_loss 0.6931471805599453
iteration 5 batch 15760 training_loss 0.6916632528527511
iteration 5 batch 15770 training_loss 0.6931471805599453
iteration 5 batch 15780 training_loss 0.6931471805599453
iteration 5 batch 15790 training_loss 0.6931471805599453
iteration 5 batch 15800 training_loss 0.6931471805599453
iteration 5 batch 15810 training_loss 0.6931471805599453
iteration 5 batch 15820 training_loss 0.6931471805599453
iteration 5 batch 15830 training_loss 0.6931471805599453
iteration 5 batch 15840 training_loss 0.6931471805599453
iteration 5 batch 15850 training_loss 0.6931471805599453
iteration 5 batch 15860 training_loss 0.6931471805599453
iteration 5 batch 15870 training_loss 0.6931471805599453
iteration 5 batch 15880 training_loss 0.6931471805599453
iteration 5 batch 15890 training_loss 0.6931471805599453
iteration 5 batch 15900 training_loss 0.6931471805599453
iteration 5 batch 15910 training_loss 0.6931471805599453
iteration 5 batch 15920 training_loss 0.6931471805599453
iteration 5 batch 15930 training_loss 0.6931471805599453
iteration 5 batch 15940 training_loss 0.6931471805599453
iteration 5 batch 15950 training_loss 0.6931471805599453
iteration 5 batch 15960 training_loss 0.6931471805599453
iteration 5 batch 15970 training_loss 0.6931471805599453
iteration 5 batch 15980 training_loss 0.6931471805599453
iteration 5 batch 15990 training_loss 0.6931471805599453
iteration 5 batch 16000 training_loss 0.6931471805599453
iteration 5 batch 16010 training_loss 0.6931471805599453
iteration 5 batch 16020 training_loss 0.6931471805599453
iteration 5 batch 16030 training_loss 0.6931471805599453
iteration 5 batch 16040 training_loss 0.6931471805599453
iteration 5 batch 16050 training_loss 0.6931471805599453
iteration 5 batch 16060 training_loss 0.6931471805599453
iteration 5 batch 16070 training_loss 0.6931471805599453
iteration 5 batch 16080 training_loss 0.6931471805599453
iteration 5 batch 16090 training_loss 0.6931471805599453
iteration 5 batch 16100 training_loss 0.6931471805599453
iteration 5 batch 16110 training_loss 0.6931471805599453
iteration 5 batch 16120 training_loss 0.6931471805599453
iteration 5 batch 16130 training_loss 0.6931471805599453
iteration 5 batch 16140 training_loss 0.6931471805599453
iteration 5 batch 16150 training_loss 0.6931471805599453
iteration 5 batch 16160 training_loss 0.6931471805599453
iteration 5 batch 16170 training_loss 0.6931471805599453
iteration 5 batch 16180 training_loss 0.6931471805599453
iteration 5 batch 16190 training_loss 0.6931471805599453
iteration 5 batch 16200 training_loss 0.6931471805599453
iteration 5 batch 16210 training_loss 0.6916632528527511
iteration 5 batch 16220 training_loss 0.6931471805599453
iteration 5 batch 16230 training_loss 0.6931471805599453
iteration 5 batch 16240 training_loss 0.6916632528527511
iteration 5 batch 16250 training_loss 0.6931471805599453
iteration 5 batch 16260 training_loss 0.6931471805599453
iteration 5 batch 16270 training_loss 0.6931471805599453
iteration 5 batch 16280 training_loss 0.6931471805599453
iteration 5 batch 16290 training_loss 0.6931471805599453
iteration 5 batch 16300 training_loss 0.6931471805599453
iteration 5 batch 16310 training_loss 0.6931471805599453
iteration 5 batch 16320 training_loss 0.6931471805599453
iteration 5 batch 16330 training_loss 0.6931471805599453
iteration 5 batch 16340 training_loss 0.6931471805599453
iteration 5 batch 16350 training_loss 0.6931471805599453
iteration 5 batch 16360 training_loss 0.6931471805599453
iteration 5 batch 16370 training_loss 0.6931471805599453
iteration 5 batch 16380 training_loss 0.6931471805599453
iteration 5 batch 16390 training_loss 0.6931471805599453
iteration 5 batch 16400 training_loss 0.6931471805599453
iteration 5 batch 16410 training_loss 0.6931471805599453
iteration 5 batch 16420 training_loss 0.6931471805599453
iteration 5 batch 16430 training_loss 0.6931471805599453
iteration 5 batch 16440 training_loss 0.6931471805599453
iteration 5 batch 16450 training_loss 0.6931471805599453
iteration 5 batch 16460 training_loss 0.6931471805599453
iteration 5 batch 16470 training_loss 0.6931471805599453
iteration 5 batch 16480 training_loss 0.6931471805599453
iteration 5 batch 16490 training_loss 0.6931471805599453
iteration 5 batch 16500 training_loss 0.6931471805599453
iteration 5 batch 16510 training_loss 0.6931471805599453
iteration 5 batch 16520 training_loss 0.6916632528527511
iteration 5 batch 16530 training_loss 0.6931471805599453
iteration 5 batch 16540 training_loss 0.6931471805599453
iteration 5 batch 16550 training_loss 0.6931471805599453
iteration 5 batch 16560 training_loss 0.6931471805599453
iteration 5 batch 16570 training_loss 0.6931471805599453
iteration 5 batch 16580 training_loss 0.6931471805599453
iteration 5 batch 16590 training_loss 0.6931471805599453
iteration 5 batch 16600 training_loss 0.6931471805599453
iteration 5 batch 16610 training_loss 0.6931471805599453
iteration 5 batch 16620 training_loss 0.6931471805599453
iteration 5 batch 16630 training_loss 0.6931471805599453
iteration 5 batch 16640 training_loss 0.6931471805599453
iteration 5 batch 16650 training_loss 0.6931471805599453
iteration 5 batch 16660 training_loss 0.6916632528527511
iteration 5 batch 16670 training_loss 0.6931471805599453
iteration 5 batch 16680 training_loss 0.6931471805599453
iteration 5 batch 16690 training_loss 0.6931471805599453
iteration 5 batch 16700 training_loss 0.6931471805599453
iteration 5 batch 16710 training_loss 0.6931471805599453
iteration 5 batch 16720 training_loss 0.6931471805599453
iteration 5 batch 16730 training_loss 0.6916632528527511
iteration 5 batch 16740 training_loss 0.6931471805599453
iteration 5 batch 16750 training_loss 0.6931471805599453
iteration 5 batch 16760 training_loss 0.6931471805599453
iteration 5 batch 16770 training_loss 0.6931471805599453
iteration 5 batch 16780 training_loss 0.6931471805599453
iteration 5 batch 16790 training_loss 0.6931471805599453
iteration 5 batch 16800 training_loss 0.6931471805599453
iteration 5 batch 16810 training_loss 0.6931471805599453
iteration 5 batch 16820 training_loss 0.6931471805599453
iteration 5 batch 16830 training_loss 0.6931471805599453
iteration 5 batch 16840 training_loss 0.6931471805599453
iteration 5 batch 16850 training_loss 0.6931471805599453
iteration 5 batch 16860 training_loss 0.6931471805599453
iteration 5 batch 16870 training_loss 0.6931471805599453
iteration 5 batch 16880 training_loss 0.6931471805599453
iteration 5 batch 16890 training_loss 0.6931471805599453
iteration 5 batch 16900 training_loss 0.6931471805599453
iteration 5 batch 16910 training_loss 0.6931471805599453
iteration 5 batch 16920 training_loss 0.6931471805599453
iteration 5 batch 16930 training_loss 0.6931471805599453
iteration 5 batch 16940 training_loss 0.6931471805599453
iteration 5 batch 16950 training_loss 0.6931471805599453
iteration 5 batch 16960 training_loss 0.6931471805599453
iteration 5 batch 16970 training_loss 0.6931471805599453
iteration 5 batch 16980 training_loss 0.6931471805599453
iteration 5 batch 16990 training_loss 0.6931471805599453
iteration 5 batch 17000 training_loss 0.6931471805599453
iteration 5 batch 17010 training_loss 0.6931471805599453
iteration 5 batch 17020 training_loss 0.6931471805599453
iteration 5 batch 17030 training_loss 0.6931471805599453
iteration 5 batch 17040 training_loss 0.6931471805599453
iteration 5 batch 17050 training_loss 0.6916632528527511
iteration 5 batch 17060 training_loss 0.6931471805599453
iteration 5 batch 17070 training_loss 0.6916632528527511
iteration 5 batch 17080 training_loss 0.6931471805599453
iteration 5 batch 17090 training_loss 0.6931471805599453
iteration 5 batch 17100 training_loss 0.6931471805599453
iteration 5 batch 17110 training_loss 0.6931471805599453
iteration 5 batch 17120 training_loss 0.6916632528527511
iteration 5 batch 17130 training_loss 0.6931471805599453
iteration 5 batch 17140 training_loss 0.6931471805599453
iteration 5 batch 17150 training_loss 0.6931471805599453
iteration 5 batch 17160 training_loss 0.6931471805599453
iteration 5 batch 17170 training_loss 0.6931471805599453
iteration 5 batch 17180 training_loss 0.6931471805599453
iteration 5 batch 17190 training_loss 0.6931471805599453
iteration 5 batch 17200 training_loss 0.6931471805599453
iteration 5 batch 17210 training_loss 0.6931471805599453
iteration 5 batch 17220 training_loss 0.6931471805599453
iteration 5 batch 17230 training_loss 0.6931471805599453
iteration 5 batch 17240 training_loss 0.6931471805599453
iteration 5 batch 17250 training_loss 0.6931471805599453
iteration 5 batch 17260 training_loss 0.6931471805599453
iteration 5 batch 17270 training_loss 0.6931471805599453
iteration 5 batch 17280 training_loss 0.6916632528527511
iteration 5 batch 17290 training_loss 0.6931471805599453
iteration 5 batch 17300 training_loss 0.6931471805599453
iteration 5 batch 17310 training_loss 0.6931471805599453
iteration 5 batch 17320 training_loss 0.6931471805599453
iteration 5 batch 17330 training_loss 0.6931471805599453
iteration 5 batch 17340 training_loss 0.6931471805599453
iteration 5 batch 17350 training_loss 0.6931471805599453
iteration 5 batch 17360 training_loss 0.6931471805599453
iteration 5 batch 17370 training_loss 0.6916632528527511
iteration 5 batch 17380 training_loss 0.6931471805599453
iteration 5 batch 17390 training_loss 0.6931471805599453
iteration 5 batch 17400 training_loss 0.6931471805599453
iteration 5 batch 17410 training_loss 0.6931471805599453
iteration 5 batch 17420 training_loss 0.6931471805599453
iteration 5 batch 17430 training_loss 0.6931471805599453
iteration 5 batch 17440 training_loss 0.6931471805599453
iteration 5 batch 17450 training_loss 0.6931471805599453
iteration 5 batch 17460 training_loss 0.6931471805599453
iteration 5 batch 17470 training_loss 0.6931471805599453
iteration 5 batch 17480 training_loss 0.6931471805599453
iteration 5 batch 17490 training_loss 0.6931471805599453
iteration 5 batch 17500 training_loss 0.6931471805599453
iteration 5 batch 17510 training_loss 0.6931471805599453
iteration 5 batch 17520 training_loss 0.6931471805599453
iteration 5 batch 17530 training_loss 0.6916632528527511
iteration 5 batch 17540 training_loss 0.6931471805599453
iteration 5 batch 17550 training_loss 0.6931471805599453
iteration 5 batch 17560 training_loss 0.6931471805599453
iteration 5 batch 17570 training_loss 0.6931471805599453
iteration 5 batch 17580 training_loss 0.6931471805599453
iteration 5 batch 17590 training_loss 0.6931471805599453
iteration 5 batch 17600 training_loss 0.6931471805599453
iteration 5 batch 17610 training_loss 0.6931471805599453
iteration 5 batch 17620 training_loss 0.6916632528527511
iteration 5 batch 17630 training_loss 0.6931471805599453
iteration 5 batch 17640 training_loss 0.6931471805599453
iteration 5 batch 17650 training_loss 0.6931471805599453
iteration 5 batch 17660 training_loss 0.6931471805599453
iteration 5 batch 17670 training_loss 0.6931471805599453
iteration 5 batch 17680 training_loss 0.6916632528527511
iteration 5 batch 17690 training_loss 0.6931471805599453
iteration 5 batch 17700 training_loss 0.6931471805599453
iteration 5 batch 17710 training_loss 0.6931471805599453
iteration 5 batch 17720 training_loss 0.6931471805599453
iteration 5 batch 17730 training_loss 0.6931471805599453
iteration 5 batch 17740 training_loss 0.6931471805599453
iteration 5 batch 17750 training_loss 0.6931471805599453
iteration 5 batch 17760 training_loss 0.6931471805599453
iteration 5 batch 17770 training_loss 0.6931471805599453
iteration 5 batch 17780 training_loss 0.6931471805599453
iteration 5 batch 17790 training_loss 0.6931471805599453
iteration 5 batch 17800 training_loss 0.6931471805599453
iteration 5 batch 17810 training_loss 0.6931471805599453
iteration 5 batch 17820 training_loss 0.6916632528527511
iteration 5 batch 17830 training_loss 0.6931471805599453
iteration 5 batch 17840 training_loss 0.6931471805599453
iteration 5 batch 17850 training_loss 0.6916632528527511
iteration 5 batch 17860 training_loss 0.6931471805599453
iteration 5 batch 17870 training_loss 0.6931471805599453
iteration 5 batch 17880 training_loss 0.6931471805599453
iteration 5 batch 17890 training_loss 0.6931471805599453
iteration 5 batch 17900 training_loss 0.6931471805599453
iteration 5 batch 17910 training_loss 0.6931471805599453
iteration 5 batch 17920 training_loss 0.6931471805599453
iteration 5 batch 17930 training_loss 0.6916632528527511
iteration 5 batch 17940 training_loss 0.6931471805599453
iteration 5 batch 17950 training_loss 0.6931471805599453
iteration 5 batch 17960 training_loss 0.6931471805599453
iteration 5 batch 17970 training_loss 0.6931471805599453
iteration 5 batch 17980 training_loss 0.6916632528527511
iteration 5 batch 17990 training_loss 0.6931471805599453
iteration 5 batch 18000 training_loss 0.6931471805599453
iteration 5 batch 18010 training_loss 0.6931471805599453
iteration 5 batch 18020 training_loss 0.6931471805599453
iteration 5 batch 18030 training_loss 0.6931471805599453
iteration 5 batch 18040 training_loss 0.6931471805599453
iteration 5 batch 18050 training_loss 0.6931471805599453
iteration 5 batch 18060 training_loss 0.6931471805599453
iteration 5 batch 18070 training_loss 0.6931471805599453
iteration 5 batch 18080 training_loss 0.6931471805599453
iteration 5 batch 18090 training_loss 0.6931471805599453
iteration 5 batch 18100 training_loss 0.6931471805599453
iteration 5 batch 18110 training_loss 0.6931471805599453
iteration 5 batch 18120 training_loss 0.6931471805599453
iteration 5 batch 18130 training_loss 0.6931471805599453
iteration 5 batch 18140 training_loss 0.6931471805599453
iteration 5 batch 18150 training_loss 0.6931471805599453
iteration 5 batch 18160 training_loss 0.6931471805599453
iteration 5 batch 18170 training_loss 0.6931471805599453
iteration 5 batch 18180 training_loss 0.6931471805599453
iteration 5 batch 18190 training_loss 0.6931471805599453
iteration 5 batch 18200 training_loss 0.6931471805599453
iteration 5 batch 18210 training_loss 0.6931471805599453
iteration 5 batch 18220 training_loss 0.6931471805599453
iteration 5 batch 18230 training_loss 0.6931471805599453
iteration 5 batch 18240 training_loss 0.6931471805599453
iteration 5 batch 18250 training_loss 0.6931471805599453
iteration 5 batch 18260 training_loss 0.6931471805599453
iteration 5 batch 18270 training_loss 0.6931471805599453
iteration 5 batch 18280 training_loss 0.6931471805599453
iteration 5 batch 18290 training_loss 0.6916632528527511
iteration 5 batch 18300 training_loss 0.6931471805599453
iteration 5 batch 18310 training_loss 0.6931471805599453
iteration 5 batch 18320 training_loss 0.6931471805599453
iteration 5 batch 18330 training_loss 0.6931471805599453
iteration 5 batch 18340 training_loss 0.6931471805599453
iteration 5 batch 18350 training_loss 0.6931471805599453
iteration 5 batch 18360 training_loss 0.6931471805599453
iteration 5 batch 18370 training_loss 0.6931471805599453
iteration 5 batch 18380 training_loss 0.6931471805599453
iteration 5 batch 18390 training_loss 0.6931471805599453
iteration 5 batch 18400 training_loss 0.6916632528527511
iteration 5 batch 18410 training_loss 0.6931471805599453
iteration 5 batch 18420 training_loss 0.6931471805599453
iteration 5 batch 18430 training_loss 0.6931471805599453
iteration 5 batch 18440 training_loss 0.6931471805599453
iteration 5 batch 18450 training_loss 0.6931471805599453
iteration 5 batch 18460 training_loss 0.6931471805599453
iteration 5 batch 18470 training_loss 0.6931471805599453
iteration 5 batch 18480 training_loss 0.6931471805599453
iteration 5 batch 18490 training_loss 0.6931471805599453
iteration 5 batch 18500 training_loss 0.6931471805599453
iteration 5 batch 18510 training_loss 0.6931471805599453
iteration 5 batch 18520 training_loss 0.6931471805599453
iteration 5 batch 18530 training_loss 0.6931471805599453
iteration 5 batch 18540 training_loss 0.6931471805599453
iteration 5 batch 18550 training_loss 0.6931471805599453
iteration 5 batch 18560 training_loss 0.6931471805599453
iteration 5 batch 18570 training_loss 0.6931471805599453
iteration 5 batch 18580 training_loss 0.6931471805599453
iteration 5 batch 18590 training_loss 0.6931471805599453
iteration 5 batch 18600 training_loss 0.6931471805599453
iteration 5 batch 18610 training_loss 0.6931471805599453
iteration 6 batch 0 training_loss 0.6931471805599453
iteration 6 batch 10 training_loss 0.6931471805599453
iteration 6 batch 20 training_loss 0.6931471805599453
iteration 6 batch 30 training_loss 0.6931471805599453
iteration 6 batch 40 training_loss 0.6931471805599453
iteration 6 batch 50 training_loss 0.6931471805599453
iteration 6 batch 60 training_loss 0.6931471805599453
iteration 6 batch 70 training_loss 0.6916632528527511
iteration 6 batch 80 training_loss 0.6931471805599453
iteration 6 batch 90 training_loss 0.6931471805599453
iteration 6 batch 100 training_loss 0.6931471805599453
iteration 6 batch 110 training_loss 0.6931471805599453
iteration 6 batch 120 training_loss 0.6931471805599453
iteration 6 batch 130 training_loss 0.6931471805599453
iteration 6 batch 140 training_loss 0.6931471805599453
iteration 6 batch 150 training_loss 0.6931471805599453
iteration 6 batch 160 training_loss 0.6931471805599453
iteration 6 batch 170 training_loss 0.6931471805599453
iteration 6 batch 180 training_loss 0.6931471805599453
iteration 6 batch 190 training_loss 0.6931471805599453
iteration 6 batch 200 training_loss 0.6931471805599453
iteration 6 batch 210 training_loss 0.6931471805599453
iteration 6 batch 220 training_loss 0.6931471805599453
iteration 6 batch 230 training_loss 0.6931471805599453
iteration 6 batch 240 training_loss 0.6916632528527511
iteration 6 batch 250 training_loss 0.6931471805599453
iteration 6 batch 260 training_loss 0.6931471805599453
iteration 6 batch 270 training_loss 0.6916632528527511
iteration 6 batch 280 training_loss 0.6931471805599453
iteration 6 batch 290 training_loss 0.6931471805599453
iteration 6 batch 300 training_loss 0.6931471805599453
iteration 6 batch 310 training_loss 0.6931471805599453
iteration 6 batch 320 training_loss 0.6931471805599453
iteration 6 batch 330 training_loss 0.6931471805599453
iteration 6 batch 340 training_loss 0.6931471805599453
iteration 6 batch 350 training_loss 0.6931471805599453
iteration 6 batch 360 training_loss 0.6931471805599453
iteration 6 batch 370 training_loss 0.6931471805599453
iteration 6 batch 380 training_loss 0.6931471805599453
iteration 6 batch 390 training_loss 0.6931471805599453
iteration 6 batch 400 training_loss 0.6931471805599453
iteration 6 batch 410 training_loss 0.6931471805599453
iteration 6 batch 420 training_loss 0.6931471805599453
iteration 6 batch 430 training_loss 0.6931471805599453
iteration 6 batch 440 training_loss 0.6931471805599453
iteration 6 batch 450 training_loss 0.6931471805599453
iteration 6 batch 460 training_loss 0.6931471805599453
iteration 6 batch 470 training_loss 0.6931471805599453
iteration 6 batch 480 training_loss 0.6931471805599453
iteration 6 batch 490 training_loss 0.6931471805599453
iteration 6 batch 500 training_loss 0.6931471805599453
iteration 6 batch 510 training_loss 0.6931471805599453
iteration 6 batch 520 training_loss 0.6931471805599453
iteration 6 batch 530 training_loss 0.6931471805599453
iteration 6 batch 540 training_loss 0.6931471805599453
iteration 6 batch 550 training_loss 0.6931471805599453
iteration 6 batch 560 training_loss 0.6931471805599453
iteration 6 batch 570 training_loss 0.6916632528527511
iteration 6 batch 580 training_loss 0.6931471805599453
iteration 6 batch 590 training_loss 0.6931471805599453
iteration 6 batch 600 training_loss 0.6931471805599453
iteration 6 batch 610 training_loss 0.6931471805599453
iteration 6 batch 620 training_loss 0.6931471805599453
iteration 6 batch 630 training_loss 0.6931471805599453
iteration 6 batch 640 training_loss 0.6931471805599453
iteration 6 batch 650 training_loss 0.6931471805599453
iteration 6 batch 660 training_loss 0.6931471805599453
iteration 6 batch 670 training_loss 0.6931471805599453
iteration 6 batch 680 training_loss 0.6931471805599453
iteration 6 batch 690 training_loss 0.6931471805599453
iteration 6 batch 700 training_loss 0.6931471805599453
iteration 6 batch 710 training_loss 0.6931471805599453
iteration 6 batch 720 training_loss 0.6931471805599453
iteration 6 batch 730 training_loss 0.6931471805599453
iteration 6 batch 740 training_loss 0.6916632528527511
iteration 6 batch 750 training_loss 0.6931471805599453
iteration 6 batch 760 training_loss 0.6931471805599453
iteration 6 batch 770 training_loss 0.6916632528527511
iteration 6 batch 780 training_loss 0.6931471805599453
iteration 6 batch 790 training_loss 0.6931471805599453
iteration 6 batch 800 training_loss 0.6931471805599453
iteration 6 batch 810 training_loss 0.6931471805599453
iteration 6 batch 820 training_loss 0.6931471805599453
iteration 6 batch 830 training_loss 0.6931471805599453
iteration 6 batch 840 training_loss 0.6931471805599453
iteration 6 batch 850 training_loss 0.6931471805599453
iteration 6 batch 860 training_loss 0.6931471805599453
iteration 6 batch 870 training_loss 0.6931471805599453
iteration 6 batch 880 training_loss 0.6931471805599453
iteration 6 batch 890 training_loss 0.6931471805599453
iteration 6 batch 900 training_loss 0.6931471805599453
iteration 6 batch 910 training_loss 0.6931471805599453
iteration 6 batch 920 training_loss 0.6931471805599453
iteration 6 batch 930 training_loss 0.6931471805599453
iteration 6 batch 940 training_loss 0.6931471805599453
iteration 6 batch 950 training_loss 0.6931471805599453
iteration 6 batch 960 training_loss 0.6931471805599453
iteration 6 batch 970 training_loss 0.6931471805599453
iteration 6 batch 980 training_loss 0.6931471805599453
iteration 6 batch 990 training_loss 0.6931471805599453
iteration 6 batch 1000 training_loss 0.6931471805599453
iteration 6 batch 1010 training_loss 0.6931471805599453
iteration 6 batch 1020 training_loss 0.6916632528527511
iteration 6 batch 1030 training_loss 0.6931471805599453
iteration 6 batch 1040 training_loss 0.6931471805599453
iteration 6 batch 1050 training_loss 0.6931471805599453
iteration 6 batch 1060 training_loss 0.6931471805599453
iteration 6 batch 1070 training_loss 0.6931471805599453
iteration 6 batch 1080 training_loss 0.6931471805599453
iteration 6 batch 1090 training_loss 0.6931471805599453
iteration 6 batch 1100 training_loss 0.6931471805599453
iteration 6 batch 1110 training_loss 0.6931471805599453
iteration 6 batch 1120 training_loss 0.6931471805599453
iteration 6 batch 1130 training_loss 0.6931471805599453
iteration 6 batch 1140 training_loss 0.6931471805599453
iteration 6 batch 1150 training_loss 0.6931471805599453
iteration 6 batch 1160 training_loss 0.6931471805599453
iteration 6 batch 1170 training_loss 0.6931471805599453
iteration 6 batch 1180 training_loss 0.6916632528527511
iteration 6 batch 1190 training_loss 0.6931471805599453
iteration 6 batch 1200 training_loss 0.6931471805599453
iteration 6 batch 1210 training_loss 0.6931471805599453
iteration 6 batch 1220 training_loss 0.6931471805599453
iteration 6 batch 1230 training_loss 0.6931471805599453
iteration 6 batch 1240 training_loss 0.6931471805599453
iteration 6 batch 1250 training_loss 0.6931471805599453
iteration 6 batch 1260 training_loss 0.6931471805599453
iteration 6 batch 1270 training_loss 0.6931471805599453
iteration 6 batch 1280 training_loss 0.6931471805599453
iteration 6 batch 1290 training_loss 0.6931471805599453
iteration 6 batch 1300 training_loss 0.6931471805599453
iteration 6 batch 1310 training_loss 0.6931471805599453
iteration 6 batch 1320 training_loss 0.6931471805599453
iteration 6 batch 1330 training_loss 0.6931471805599453
iteration 6 batch 1340 training_loss 0.6931471805599453
iteration 6 batch 1350 training_loss 0.6931471805599453
iteration 6 batch 1360 training_loss 0.6931471805599453
iteration 6 batch 1370 training_loss 0.6931471805599453
iteration 6 batch 1380 training_loss 0.6931471805599453
iteration 6 batch 1390 training_loss 0.6931471805599453
iteration 6 batch 1400 training_loss 0.6931471805599453
iteration 6 batch 1410 training_loss 0.6931471805599453
iteration 6 batch 1420 training_loss 0.6931471805599453
iteration 6 batch 1430 training_loss 0.6931471805599453
iteration 6 batch 1440 training_loss 0.6931471805599453
iteration 6 batch 1450 training_loss 0.6931471805599453
iteration 6 batch 1460 training_loss 0.6931471805599453
iteration 6 batch 1470 training_loss 0.6931471805599453
iteration 6 batch 1480 training_loss 0.6931471805599453
iteration 6 batch 1490 training_loss 0.6931471805599453
iteration 6 batch 1500 training_loss 0.6931471805599453
iteration 6 batch 1510 training_loss 0.6931471805599453
iteration 6 batch 1520 training_loss 0.6931471805599453
iteration 6 batch 1530 training_loss 0.6931471805599453
iteration 6 batch 1540 training_loss 0.6901793251455568
iteration 6 batch 1550 training_loss 0.6931471805599453
iteration 6 batch 1560 training_loss 0.6931471805599453
iteration 6 batch 1570 training_loss 0.6931471805599453
iteration 6 batch 1580 training_loss 0.6931471805599453
iteration 6 batch 1590 training_loss 0.6916632528527511
iteration 6 batch 1600 training_loss 0.6931471805599453
iteration 6 batch 1610 training_loss 0.6931471805599453
iteration 6 batch 1620 training_loss 0.6931471805599453
iteration 6 batch 1630 training_loss 0.6931471805599453
iteration 6 batch 1640 training_loss 0.6931471805599453
iteration 6 batch 1650 training_loss 0.6931471805599453
iteration 6 batch 1660 training_loss 0.6931471805599453
iteration 6 batch 1670 training_loss 0.6931471805599453
iteration 6 batch 1680 training_loss 0.6931471805599453
iteration 6 batch 1690 training_loss 0.6931471805599453
iteration 6 batch 1700 training_loss 0.6931471805599453
iteration 6 batch 1710 training_loss 0.6931471805599453
iteration 6 batch 1720 training_loss 0.6931471805599453
iteration 6 batch 1730 training_loss 0.6931471805599453
iteration 6 batch 1740 training_loss 0.6931471805599453
iteration 6 batch 1750 training_loss 0.6931471805599453
iteration 6 batch 1760 training_loss 0.6916632528527511
iteration 6 batch 1770 training_loss 0.6931471805599453
iteration 6 batch 1780 training_loss 0.6931471805599453
iteration 6 batch 1790 training_loss 0.6931471805599453
iteration 6 batch 1800 training_loss 0.6931471805599453
iteration 6 batch 1810 training_loss 0.6931471805599453
iteration 6 batch 1820 training_loss 0.6931471805599453
iteration 6 batch 1830 training_loss 0.6931471805599453
iteration 6 batch 1840 training_loss 0.6931471805599453
iteration 6 batch 1850 training_loss 0.6916632528527511
iteration 6 batch 1860 training_loss 0.6931471805599453
iteration 6 batch 1870 training_loss 0.6931471805599453
iteration 6 batch 1880 training_loss 0.6931471805599453
iteration 6 batch 1890 training_loss 0.6931471805599453
iteration 6 batch 1900 training_loss 0.6931471805599453
iteration 6 batch 1910 training_loss 0.6931471805599453
iteration 6 batch 1920 training_loss 0.6931471805599453
iteration 6 batch 1930 training_loss 0.6931471805599453
iteration 6 batch 1940 training_loss 0.6931471805599453
iteration 6 batch 1950 training_loss 0.6931471805599453
iteration 6 batch 1960 training_loss 0.6931471805599453
iteration 6 batch 1970 training_loss 0.6931471805599453
iteration 6 batch 1980 training_loss 0.6931471805599453
iteration 6 batch 1990 training_loss 0.6931471805599453
iteration 6 batch 2000 training_loss 0.6931471805599453
iteration 6 batch 2010 training_loss 0.6931471805599453
iteration 6 batch 2020 training_loss 0.6931471805599453
iteration 6 batch 2030 training_loss 0.6931471805599453
iteration 6 batch 2040 training_loss 0.6916632528527511
iteration 6 batch 2050 training_loss 0.6931471805599453
iteration 6 batch 2060 training_loss 0.6931471805599453
iteration 6 batch 2070 training_loss 0.6931471805599453
iteration 6 batch 2080 training_loss 0.6931471805599453
iteration 6 batch 2090 training_loss 0.6931471805599453
iteration 6 batch 2100 training_loss 0.6931471805599453
iteration 6 batch 2110 training_loss 0.6931471805599453
iteration 6 batch 2120 training_loss 0.6916632528527511
iteration 6 batch 2130 training_loss 0.6931471805599453
iteration 6 batch 2140 training_loss 0.6931471805599453
iteration 6 batch 2150 training_loss 0.6931471805599453
iteration 6 batch 2160 training_loss 0.6931471805599453
iteration 6 batch 2170 training_loss 0.6931471805599453
iteration 6 batch 2180 training_loss 0.6931471805599453
iteration 6 batch 2190 training_loss 0.6931471805599453
iteration 6 batch 2200 training_loss 0.6931471805599453
iteration 6 batch 2210 training_loss 0.6931471805599453
iteration 6 batch 2220 training_loss 0.6931471805599453
iteration 6 batch 2230 training_loss 0.6931471805599453
iteration 6 batch 2240 training_loss 0.6931471805599453
iteration 6 batch 2250 training_loss 0.6931471805599453
iteration 6 batch 2260 training_loss 0.6931471805599453
iteration 6 batch 2270 training_loss 0.6931471805599453
iteration 6 batch 2280 training_loss 0.6931471805599453
iteration 6 batch 2290 training_loss 0.6931471805599453
iteration 6 batch 2300 training_loss 0.6931471805599453
iteration 6 batch 2310 training_loss 0.6931471805599453
iteration 6 batch 2320 training_loss 0.6931471805599453
iteration 6 batch 2330 training_loss 0.6931471805599453
iteration 6 batch 2340 training_loss 0.6931471805599453
iteration 6 batch 2350 training_loss 0.6916632528527511
iteration 6 batch 2360 training_loss 0.6931471805599453
iteration 6 batch 2370 training_loss 0.6931471805599453
iteration 6 batch 2380 training_loss 0.6931471805599453
iteration 6 batch 2390 training_loss 0.6931471805599453
iteration 6 batch 2400 training_loss 0.6931471805599453
iteration 6 batch 2410 training_loss 0.6931471805599453
iteration 6 batch 2420 training_loss 0.6931471805599453
iteration 6 batch 2430 training_loss 0.6931471805599453
iteration 6 batch 2440 training_loss 0.6931471805599453
iteration 6 batch 2450 training_loss 0.6931471805599453
iteration 6 batch 2460 training_loss 0.6931471805599453
iteration 6 batch 2470 training_loss 0.6931471805599453
iteration 6 batch 2480 training_loss 0.6931471805599453
iteration 6 batch 2490 training_loss 0.6916632528527511
iteration 6 batch 2500 training_loss 0.6931471805599453
iteration 6 batch 2510 training_loss 0.6931471805599453
iteration 6 batch 2520 training_loss 0.6931471805599453
iteration 6 batch 2530 training_loss 0.6931471805599453
iteration 6 batch 2540 training_loss 0.6931471805599453
iteration 6 batch 2550 training_loss 0.6931471805599453
iteration 6 batch 2560 training_loss 0.6931471805599453
iteration 6 batch 2570 training_loss 0.6931471805599453
iteration 6 batch 2580 training_loss 0.6916632528527511
iteration 6 batch 2590 training_loss 0.6931471805599453
iteration 6 batch 2600 training_loss 0.6931471805599453
iteration 6 batch 2610 training_loss 0.6931471805599453
iteration 6 batch 2620 training_loss 0.6931471805599453
iteration 6 batch 2630 training_loss 0.6931471805599453
iteration 6 batch 2640 training_loss 0.6931471805599453
iteration 6 batch 2650 training_loss 0.6931471805599453
iteration 6 batch 2660 training_loss 0.6931471805599453
iteration 6 batch 2670 training_loss 0.6931471805599453
iteration 6 batch 2680 training_loss 0.6901793251455568
iteration 6 batch 2690 training_loss 0.6931471805599453
iteration 6 batch 2700 training_loss 0.6931471805599453
iteration 6 batch 2710 training_loss 0.6931471805599453
iteration 6 batch 2720 training_loss 0.6916632528527511
iteration 6 batch 2730 training_loss 0.6931471805599453
iteration 6 batch 2740 training_loss 0.6931471805599453
iteration 6 batch 2750 training_loss 0.6931471805599453
iteration 6 batch 2760 training_loss 0.6931471805599453
iteration 6 batch 2770 training_loss 0.6931471805599453
iteration 6 batch 2780 training_loss 0.6931471805599453
iteration 6 batch 2790 training_loss 0.6931471805599453
iteration 6 batch 2800 training_loss 0.6931471805599453
iteration 6 batch 2810 training_loss 0.6931471805599453
iteration 6 batch 2820 training_loss 0.6916632528527511
iteration 6 batch 2830 training_loss 0.6931471805599453
iteration 6 batch 2840 training_loss 0.6931471805599453
iteration 6 batch 2850 training_loss 0.6931471805599453
iteration 6 batch 2860 training_loss 0.6931471805599453
iteration 6 batch 2870 training_loss 0.6931471805599453
iteration 6 batch 2880 training_loss 0.6931471805599453
iteration 6 batch 2890 training_loss 0.6931471805599453
iteration 6 batch 2900 training_loss 0.6931471805599453
iteration 6 batch 2910 training_loss 0.6931471805599453
iteration 6 batch 2920 training_loss 0.6931471805599453
iteration 6 batch 2930 training_loss 0.6931471805599453
iteration 6 batch 2940 training_loss 0.6931471805599453
iteration 6 batch 2950 training_loss 0.6931471805599453
iteration 6 batch 2960 training_loss 0.6931471805599453
iteration 6 batch 2970 training_loss 0.6931471805599453
iteration 6 batch 2980 training_loss 0.6931471805599453
iteration 6 batch 2990 training_loss 0.6931471805599453
iteration 6 batch 3000 training_loss 0.6931471805599453
iteration 6 batch 3010 training_loss 0.6931471805599453
iteration 6 batch 3020 training_loss 0.6931471805599453
iteration 6 batch 3030 training_loss 0.6931471805599453
iteration 6 batch 3040 training_loss 0.6931471805599453
iteration 6 batch 3050 training_loss 0.6931471805599453
iteration 6 batch 3060 training_loss 0.6931471805599453
iteration 6 batch 3070 training_loss 0.6931471805599453
iteration 6 batch 3080 training_loss 0.6931471805599453
iteration 6 batch 3090 training_loss 0.6931471805599453
iteration 6 batch 3100 training_loss 0.6931471805599453
iteration 6 batch 3110 training_loss 0.6931471805599453
iteration 6 batch 3120 training_loss 0.6931471805599453
iteration 6 batch 3130 training_loss 0.6931471805599453
iteration 6 batch 3140 training_loss 0.6931471805599453
iteration 6 batch 3150 training_loss 0.6931471805599453
iteration 6 batch 3160 training_loss 0.6931471805599453
iteration 6 batch 3170 training_loss 0.6931471805599453
iteration 6 batch 3180 training_loss 0.6931471805599453
iteration 6 batch 3190 training_loss 0.6931471805599453
iteration 6 batch 3200 training_loss 0.6931471805599453
iteration 6 batch 3210 training_loss 0.6931471805599453
iteration 6 batch 3220 training_loss 0.6931471805599453
iteration 6 batch 3230 training_loss 0.6931471805599453
iteration 6 batch 3240 training_loss 0.6931471805599453
iteration 6 batch 3250 training_loss 0.6931471805599453
iteration 6 batch 3260 training_loss 0.6931471805599453
iteration 6 batch 3270 training_loss 0.6931471805599453
iteration 6 batch 3280 training_loss 0.6931471805599453
iteration 6 batch 3290 training_loss 0.6931471805599453
iteration 6 batch 3300 training_loss 0.6931471805599453
iteration 6 batch 3310 training_loss 0.6931471805599453
iteration 6 batch 3320 training_loss 0.6931471805599453
iteration 6 batch 3330 training_loss 0.6931471805599453
iteration 6 batch 3340 training_loss 0.6916632528527511
iteration 6 batch 3350 training_loss 0.6931471805599453
iteration 6 batch 3360 training_loss 0.6931471805599453
iteration 6 batch 3370 training_loss 0.6931471805599453
iteration 6 batch 3380 training_loss 0.6931471805599453
iteration 6 batch 3390 training_loss 0.6931471805599453
iteration 6 batch 3400 training_loss 0.6931471805599453
iteration 6 batch 3410 training_loss 0.6931471805599453
iteration 6 batch 3420 training_loss 0.6931471805599453
iteration 6 batch 3430 training_loss 0.6931471805599453
iteration 6 batch 3440 training_loss 0.6931471805599453
iteration 6 batch 3450 training_loss 0.6931471805599453
iteration 6 batch 3460 training_loss 0.6931471805599453
iteration 6 batch 3470 training_loss 0.6931471805599453
iteration 6 batch 3480 training_loss 0.6931471805599453
iteration 6 batch 3490 training_loss 0.6916632528527511
iteration 6 batch 3500 training_loss 0.6931471805599453
iteration 6 batch 3510 training_loss 0.6916632528527511
iteration 6 batch 3520 training_loss 0.6931471805599453
iteration 6 batch 3530 training_loss 0.6931471805599453
iteration 6 batch 3540 training_loss 0.6931471805599453
iteration 6 batch 3550 training_loss 0.6931471805599453
iteration 6 batch 3560 training_loss 0.6931471805599453
iteration 6 batch 3570 training_loss 0.6931471805599453
iteration 6 batch 3580 training_loss 0.6931471805599453
iteration 6 batch 3590 training_loss 0.6931471805599453
iteration 6 batch 3600 training_loss 0.6931471805599453
iteration 6 batch 3610 training_loss 0.6931471805599453
iteration 6 batch 3620 training_loss 0.6931471805599453
iteration 6 batch 3630 training_loss 0.6931471805599453
iteration 6 batch 3640 training_loss 0.6931471805599453
iteration 6 batch 3650 training_loss 0.6931471805599453
iteration 6 batch 3660 training_loss 0.6931471805599453
iteration 6 batch 3670 training_loss 0.6931471805599453
iteration 6 batch 3680 training_loss 0.6931471805599453
iteration 6 batch 3690 training_loss 0.6931471805599453
iteration 6 batch 3700 training_loss 0.6916632528527511
iteration 6 batch 3710 training_loss 0.6931471805599453
iteration 6 batch 3720 training_loss 0.6931471805599453
iteration 6 batch 3730 training_loss 0.6931471805599453
iteration 6 batch 3740 training_loss 0.6931471805599453
iteration 6 batch 3750 training_loss 0.6931471805599453
iteration 6 batch 3760 training_loss 0.6916632528527511
iteration 6 batch 3770 training_loss 0.6931471805599453
iteration 6 batch 3780 training_loss 0.6916632528527511
iteration 6 batch 3790 training_loss 0.6931471805599453
iteration 6 batch 3800 training_loss 0.6931471805599453
iteration 6 batch 3810 training_loss 0.6931471805599453
iteration 6 batch 3820 training_loss 0.6931471805599453
iteration 6 batch 3830 training_loss 0.6931471805599453
iteration 6 batch 3840 training_loss 0.6931471805599453
iteration 6 batch 3850 training_loss 0.6931471805599453
iteration 6 batch 3860 training_loss 0.6931471805599453
iteration 6 batch 3870 training_loss 0.6931471805599453
iteration 6 batch 3880 training_loss 0.6931471805599453
iteration 6 batch 3890 training_loss 0.6931471805599453
iteration 6 batch 3900 training_loss 0.6931471805599453
iteration 6 batch 3910 training_loss 0.6931471805599453
iteration 6 batch 3920 training_loss 0.6931471805599453
iteration 6 batch 3930 training_loss 0.6931471805599453
iteration 6 batch 3940 training_loss 0.6931471805599453
iteration 6 batch 3950 training_loss 0.6931471805599453
iteration 6 batch 3960 training_loss 0.6931471805599453
iteration 6 batch 3970 training_loss 0.6931471805599453
iteration 6 batch 3980 training_loss 0.6931471805599453
iteration 6 batch 3990 training_loss 0.6931471805599453
iteration 6 batch 4000 training_loss 0.6931471805599453
iteration 6 batch 4010 training_loss 0.6931471805599453
iteration 6 batch 4020 training_loss 0.6916632528527511
iteration 6 batch 4030 training_loss 0.6931471805599453
iteration 6 batch 4040 training_loss 0.6931471805599453
iteration 6 batch 4050 training_loss 0.6931471805599453
iteration 6 batch 4060 training_loss 0.6931471805599453
iteration 6 batch 4070 training_loss 0.6931471805599453
iteration 6 batch 4080 training_loss 0.6931471805599453
iteration 6 batch 4090 training_loss 0.6931471805599453
iteration 6 batch 4100 training_loss 0.6931471805599453
iteration 6 batch 4110 training_loss 0.6931471805599453
iteration 6 batch 4120 training_loss 0.6931471805599453
iteration 6 batch 4130 training_loss 0.6931471805599453
iteration 6 batch 4140 training_loss 0.6931471805599453
iteration 6 batch 4150 training_loss 0.6931471805599453
iteration 6 batch 4160 training_loss 0.6931471805599453
iteration 6 batch 4170 training_loss 0.6931471805599453
iteration 6 batch 4180 training_loss 0.6931471805599453
iteration 6 batch 4190 training_loss 0.6931471805599453
iteration 6 batch 4200 training_loss 0.6931471805599453
iteration 6 batch 4210 training_loss 0.6931471805599453
iteration 6 batch 4220 training_loss 0.6931471805599453
iteration 6 batch 4230 training_loss 0.6931471805599453
iteration 6 batch 4240 training_loss 0.6931471805599453
iteration 6 batch 4250 training_loss 0.6931471805599453
iteration 6 batch 4260 training_loss 0.6931471805599453
iteration 6 batch 4270 training_loss 0.6931471805599453
iteration 6 batch 4280 training_loss 0.6931471805599453
iteration 6 batch 4290 training_loss 0.6931471805599453
iteration 6 batch 4300 training_loss 0.6931471805599453
iteration 6 batch 4310 training_loss 0.6931471805599453
iteration 6 batch 4320 training_loss 0.6931471805599453
iteration 6 batch 4330 training_loss 0.6931471805599453
iteration 6 batch 4340 training_loss 0.6931471805599453
iteration 6 batch 4350 training_loss 0.6931471805599453
iteration 6 batch 4360 training_loss 0.6931471805599453
iteration 6 batch 4370 training_loss 0.6931471805599453
iteration 6 batch 4380 training_loss 0.6931471805599453
iteration 6 batch 4390 training_loss 0.6931471805599453
iteration 6 batch 4400 training_loss 0.6931471805599453
iteration 6 batch 4410 training_loss 0.6931471805599453
iteration 6 batch 4420 training_loss 0.6931471805599453
iteration 6 batch 4430 training_loss 0.6931471805599453
iteration 6 batch 4440 training_loss 0.6931471805599453
iteration 6 batch 4450 training_loss 0.6931471805599453
iteration 6 batch 4460 training_loss 0.6931471805599453
iteration 6 batch 4470 training_loss 0.6931471805599453
iteration 6 batch 4480 training_loss 0.6931471805599453
iteration 6 batch 4490 training_loss 0.6931471805599453
iteration 6 batch 4500 training_loss 0.6931471805599453
iteration 6 batch 4510 training_loss 0.6931471805599453
iteration 6 batch 4520 training_loss 0.6931471805599453
iteration 6 batch 4530 training_loss 0.6931471805599453
iteration 6 batch 4540 training_loss 0.6931471805599453
iteration 6 batch 4550 training_loss 0.6931471805599453
iteration 6 batch 4560 training_loss 0.6931471805599453
iteration 6 batch 4570 training_loss 0.6931471805599453
iteration 6 batch 4580 training_loss 0.6931471805599453
iteration 6 batch 4590 training_loss 0.6931471805599453
iteration 6 batch 4600 training_loss 0.6916632528527511
iteration 6 batch 4610 training_loss 0.6931471805599453
iteration 6 batch 4620 training_loss 0.6931471805599453
iteration 6 batch 4630 training_loss 0.6931471805599453
iteration 6 batch 4640 training_loss 0.6931471805599453
iteration 6 batch 4650 training_loss 0.6931471805599453
iteration 6 batch 4660 training_loss 0.6931471805599453
iteration 6 batch 4670 training_loss 0.6931471805599453
iteration 6 batch 4680 training_loss 0.6931471805599453
iteration 6 batch 4690 training_loss 0.6931471805599453
iteration 6 batch 4700 training_loss 0.6931471805599453
iteration 6 batch 4710 training_loss 0.6916632528527511
iteration 6 batch 4720 training_loss 0.6931471805599453
iteration 6 batch 4730 training_loss 0.6931471805599453
iteration 6 batch 4740 training_loss 0.6931471805599453
iteration 6 batch 4750 training_loss 0.6931471805599453
iteration 6 batch 4760 training_loss 0.6931471805599453
iteration 6 batch 4770 training_loss 0.6931471805599453
iteration 6 batch 4780 training_loss 0.6931471805599453
iteration 6 batch 4790 training_loss 0.6931471805599453
iteration 6 batch 4800 training_loss 0.6931471805599453
iteration 6 batch 4810 training_loss 0.6931471805599453
iteration 6 batch 4820 training_loss 0.6931471805599453
iteration 6 batch 4830 training_loss 0.6931471805599453
iteration 6 batch 4840 training_loss 0.6931471805599453
iteration 6 batch 4850 training_loss 0.6931471805599453
iteration 6 batch 4860 training_loss 0.6916632528527511
iteration 6 batch 4870 training_loss 0.6931471805599453
iteration 6 batch 4880 training_loss 0.6931471805599453
iteration 6 batch 4890 training_loss 0.6931471805599453
iteration 6 batch 4900 training_loss 0.6931471805599453
iteration 6 batch 4910 training_loss 0.6931471805599453
iteration 6 batch 4920 training_loss 0.6916632528527511
iteration 6 batch 4930 training_loss 0.6931471805599453
iteration 6 batch 4940 training_loss 0.6931471805599453
iteration 6 batch 4950 training_loss 0.6931471805599453
iteration 6 batch 4960 training_loss 0.6931471805599453
iteration 6 batch 4970 training_loss 0.6931471805599453
iteration 6 batch 4980 training_loss 0.6931471805599453
iteration 6 batch 4990 training_loss 0.6931471805599453
iteration 6 batch 5000 training_loss 0.6931471805599453
iteration 6 batch 5010 training_loss 0.6931471805599453
iteration 6 batch 5020 training_loss 0.6931471805599453
iteration 6 batch 5030 training_loss 0.6931471805599453
iteration 6 batch 5040 training_loss 0.6931471805599453
iteration 6 batch 5050 training_loss 0.6931471805599453
iteration 6 batch 5060 training_loss 0.6931471805599453
iteration 6 batch 5070 training_loss 0.6931471805599453
iteration 6 batch 5080 training_loss 0.6931471805599453
iteration 6 batch 5090 training_loss 0.6931471805599453
iteration 6 batch 5100 training_loss 0.6931471805599453
iteration 6 batch 5110 training_loss 0.6931471805599453
iteration 6 batch 5120 training_loss 0.6931471805599453
iteration 6 batch 5130 training_loss 0.6931471805599453
iteration 6 batch 5140 training_loss 0.6931471805599453
iteration 6 batch 5150 training_loss 0.6931471805599453
iteration 6 batch 5160 training_loss 0.6931471805599453
iteration 6 batch 5170 training_loss 0.6931471805599453
iteration 6 batch 5180 training_loss 0.6931471805599453
iteration 6 batch 5190 training_loss 0.6931471805599453
iteration 6 batch 5200 training_loss 0.6931471805599453
iteration 6 batch 5210 training_loss 0.6931471805599453
iteration 6 batch 5220 training_loss 0.6931471805599453
iteration 6 batch 5230 training_loss 0.6931471805599453
iteration 6 batch 5240 training_loss 0.6931471805599453
iteration 6 batch 5250 training_loss 0.6931471805599453
iteration 6 batch 5260 training_loss 0.6931471805599453
iteration 6 batch 5270 training_loss 0.6931471805599453
iteration 6 batch 5280 training_loss 0.6931471805599453
iteration 6 batch 5290 training_loss 0.6931471805599453
iteration 6 batch 5300 training_loss 0.6931471805599453
iteration 6 batch 5310 training_loss 0.6931471805599453
iteration 6 batch 5320 training_loss 0.6931471805599453
iteration 6 batch 5330 training_loss 0.6931471805599453
iteration 6 batch 5340 training_loss 0.6931471805599453
iteration 6 batch 5350 training_loss 0.6931471805599453
iteration 6 batch 5360 training_loss 0.6931471805599453
iteration 6 batch 5370 training_loss 0.6931471805599453
iteration 6 batch 5380 training_loss 0.6931471805599453
iteration 6 batch 5390 training_loss 0.6931471805599453
iteration 6 batch 5400 training_loss 0.6931471805599453
iteration 6 batch 5410 training_loss 0.6931471805599453
iteration 6 batch 5420 training_loss 0.6916632528527511
iteration 6 batch 5430 training_loss 0.6931471805599453
iteration 6 batch 5440 training_loss 0.6931471805599453
iteration 6 batch 5450 training_loss 0.6931471805599453
iteration 6 batch 5460 training_loss 0.6931471805599453
iteration 6 batch 5470 training_loss 0.6931471805599453
iteration 6 batch 5480 training_loss 0.6931471805599453
iteration 6 batch 5490 training_loss 0.6931471805599453
iteration 6 batch 5500 training_loss 0.6931471805599453
iteration 6 batch 5510 training_loss 0.6931471805599453
iteration 6 batch 5520 training_loss 0.6931471805599453
iteration 6 batch 5530 training_loss 0.6931471805599453
iteration 6 batch 5540 training_loss 0.6931471805599453
iteration 6 batch 5550 training_loss 0.6931471805599453
iteration 6 batch 5560 training_loss 0.6931471805599453
iteration 6 batch 5570 training_loss 0.6931471805599453
iteration 6 batch 5580 training_loss 0.6931471805599453
iteration 6 batch 5590 training_loss 0.6931471805599453
iteration 6 batch 5600 training_loss 0.6931471805599453
iteration 6 batch 5610 training_loss 0.6931471805599453
iteration 6 batch 5620 training_loss 0.6931471805599453
iteration 6 batch 5630 training_loss 0.6931471805599453
iteration 6 batch 5640 training_loss 0.6931471805599453
iteration 6 batch 5650 training_loss 0.6931471805599453
iteration 6 batch 5660 training_loss 0.6931471805599453
iteration 6 batch 5670 training_loss 0.6931471805599453
iteration 6 batch 5680 training_loss 0.6931471805599453
iteration 6 batch 5690 training_loss 0.6931471805599453
iteration 6 batch 5700 training_loss 0.6916632528527511
iteration 6 batch 5710 training_loss 0.6916632528527511
iteration 6 batch 5720 training_loss 0.6931471805599453
iteration 6 batch 5730 training_loss 0.6931471805599453
iteration 6 batch 5740 training_loss 0.6931471805599453
iteration 6 batch 5750 training_loss 0.6931471805599453
iteration 6 batch 5760 training_loss 0.6916632528527511
iteration 6 batch 5770 training_loss 0.6931471805599453
iteration 6 batch 5780 training_loss 0.6931471805599453
iteration 6 batch 5790 training_loss 0.6931471805599453
iteration 6 batch 5800 training_loss 0.6931471805599453
iteration 6 batch 5810 training_loss 0.6931471805599453
iteration 6 batch 5820 training_loss 0.6931471805599453
iteration 6 batch 5830 training_loss 0.6931471805599453
iteration 6 batch 5840 training_loss 0.6916632528527511
iteration 6 batch 5850 training_loss 0.6931471805599453
iteration 6 batch 5860 training_loss 0.6916632528527511
iteration 6 batch 5870 training_loss 0.6931471805599453
iteration 6 batch 5880 training_loss 0.6931471805599453
iteration 6 batch 5890 training_loss 0.6931471805599453
iteration 6 batch 5900 training_loss 0.6931471805599453
iteration 6 batch 5910 training_loss 0.6931471805599453
iteration 6 batch 5920 training_loss 0.6931471805599453
iteration 6 batch 5930 training_loss 0.6931471805599453
iteration 6 batch 5940 training_loss 0.6931471805599453
iteration 6 batch 5950 training_loss 0.6931471805599453
iteration 6 batch 5960 training_loss 0.6931471805599453
iteration 6 batch 5970 training_loss 0.6931471805599453
iteration 6 batch 5980 training_loss 0.6931471805599453
iteration 6 batch 5990 training_loss 0.6931471805599453
iteration 6 batch 6000 training_loss 0.6931471805599453
iteration 6 batch 6010 training_loss 0.6931471805599453
iteration 6 batch 6020 training_loss 0.6931471805599453
iteration 6 batch 6030 training_loss 0.6931471805599453
iteration 6 batch 6040 training_loss 0.6931471805599453
iteration 6 batch 6050 training_loss 0.6931471805599453
iteration 6 batch 6060 training_loss 0.6931471805599453
iteration 6 batch 6070 training_loss 0.6931471805599453
iteration 6 batch 6080 training_loss 0.6931471805599453
iteration 6 batch 6090 training_loss 0.6916632528527511
iteration 6 batch 6100 training_loss 0.6931471805599453
iteration 6 batch 6110 training_loss 0.6931471805599453
iteration 6 batch 6120 training_loss 0.6931471805599453
iteration 6 batch 6130 training_loss 0.6931471805599453
iteration 6 batch 6140 training_loss 0.6916632528527511
iteration 6 batch 6150 training_loss 0.6931471805599453
iteration 6 batch 6160 training_loss 0.6931471805599453
iteration 6 batch 6170 training_loss 0.6931471805599453
iteration 6 batch 6180 training_loss 0.6931471805599453
iteration 6 batch 6190 training_loss 0.6916632528527511
iteration 6 batch 6200 training_loss 0.6931471805599453
iteration 6 batch 6210 training_loss 0.6931471805599453
iteration 6 batch 6220 training_loss 0.6931471805599453
iteration 6 batch 6230 training_loss 0.6931471805599453
iteration 6 batch 6240 training_loss 0.6931471805599453
iteration 6 batch 6250 training_loss 0.6931471805599453
iteration 6 batch 6260 training_loss 0.6931471805599453
iteration 6 batch 6270 training_loss 0.6931471805599453
iteration 6 batch 6280 training_loss 0.6931471805599453
iteration 6 batch 6290 training_loss 0.6916632528527511
iteration 6 batch 6300 training_loss 0.6931471805599453
iteration 6 batch 6310 training_loss 0.6931471805599453
iteration 6 batch 6320 training_loss 0.6931471805599453
iteration 6 batch 6330 training_loss 0.6931471805599453
iteration 6 batch 6340 training_loss 0.6916632528527511
iteration 6 batch 6350 training_loss 0.6916632528527511
iteration 6 batch 6360 training_loss 0.6931471805599453
iteration 6 batch 6370 training_loss 0.6931471805599453
iteration 6 batch 6380 training_loss 0.6931471805599453
iteration 6 batch 6390 training_loss 0.6931471805599453
iteration 6 batch 6400 training_loss 0.6931471805599453
iteration 6 batch 6410 training_loss 0.6931471805599453
iteration 6 batch 6420 training_loss 0.6931471805599453
iteration 6 batch 6430 training_loss 0.6931471805599453
iteration 6 batch 6440 training_loss 0.6916632528527511
iteration 6 batch 6450 training_loss 0.6931471805599453
iteration 6 batch 6460 training_loss 0.6931471805599453
iteration 6 batch 6470 training_loss 0.6931471805599453
iteration 6 batch 6480 training_loss 0.6931471805599453
iteration 6 batch 6490 training_loss 0.6931471805599453
iteration 6 batch 6500 training_loss 0.6931471805599453
iteration 6 batch 6510 training_loss 0.6931471805599453
iteration 6 batch 6520 training_loss 0.6931471805599453
iteration 6 batch 6530 training_loss 0.6931471805599453
iteration 6 batch 6540 training_loss 0.6931471805599453
iteration 6 batch 6550 training_loss 0.6931471805599453
iteration 6 batch 6560 training_loss 0.6931471805599453
iteration 6 batch 6570 training_loss 0.6931471805599453
iteration 6 batch 6580 training_loss 0.6931471805599453
iteration 6 batch 6590 training_loss 0.6931471805599453
iteration 6 batch 6600 training_loss 0.6931471805599453
iteration 6 batch 6610 training_loss 0.6931471805599453
iteration 6 batch 6620 training_loss 0.6931471805599453
iteration 6 batch 6630 training_loss 0.6931471805599453
iteration 6 batch 6640 training_loss 0.6931471805599453
iteration 6 batch 6650 training_loss 0.6931471805599453
iteration 6 batch 6660 training_loss 0.6916632528527511
iteration 6 batch 6670 training_loss 0.6931471805599453
iteration 6 batch 6680 training_loss 0.6931471805599453
iteration 6 batch 6690 training_loss 0.6931471805599453
iteration 6 batch 6700 training_loss 0.6931471805599453
iteration 6 batch 6710 training_loss 0.6931471805599453
iteration 6 batch 6720 training_loss 0.6931471805599453
iteration 6 batch 6730 training_loss 0.6931471805599453
iteration 6 batch 6740 training_loss 0.6931471805599453
iteration 6 batch 6750 training_loss 0.6931471805599453
iteration 6 batch 6760 training_loss 0.6931471805599453
iteration 6 batch 6770 training_loss 0.6916632528527511
iteration 6 batch 6780 training_loss 0.6931471805599453
iteration 6 batch 6790 training_loss 0.6931471805599453
iteration 6 batch 6800 training_loss 0.6931471805599453
iteration 6 batch 6810 training_loss 0.6931471805599453
iteration 6 batch 6820 training_loss 0.6931471805599453
iteration 6 batch 6830 training_loss 0.6931471805599453
iteration 6 batch 6840 training_loss 0.6931471805599453
iteration 6 batch 6850 training_loss 0.6931471805599453
iteration 6 batch 6860 training_loss 0.6931471805599453
iteration 6 batch 6870 training_loss 0.6931471805599453
iteration 6 batch 6880 training_loss 0.6916632528527511
iteration 6 batch 6890 training_loss 0.6931471805599453
iteration 6 batch 6900 training_loss 0.6931471805599453
iteration 6 batch 6910 training_loss 0.6931471805599453
iteration 6 batch 6920 training_loss 0.6931471805599453
iteration 6 batch 6930 training_loss 0.6916632528527511
iteration 6 batch 6940 training_loss 0.6931471805599453
iteration 6 batch 6950 training_loss 0.6931471805599453
iteration 6 batch 6960 training_loss 0.6931471805599453
iteration 6 batch 6970 training_loss 0.6916632528527511
iteration 6 batch 6980 training_loss 0.6931471805599453
iteration 6 batch 6990 training_loss 0.6931471805599453
iteration 6 batch 7000 training_loss 0.6931471805599453
iteration 6 batch 7010 training_loss 0.6931471805599453
iteration 6 batch 7020 training_loss 0.6931471805599453
iteration 6 batch 7030 training_loss 0.6931471805599453
iteration 6 batch 7040 training_loss 0.6931471805599453
iteration 6 batch 7050 training_loss 0.6931471805599453
iteration 6 batch 7060 training_loss 0.6931471805599453
iteration 6 batch 7070 training_loss 0.6931471805599453
iteration 6 batch 7080 training_loss 0.6931471805599453
iteration 6 batch 7090 training_loss 0.6931471805599453
iteration 6 batch 7100 training_loss 0.6931471805599453
iteration 6 batch 7110 training_loss 0.6931471805599453
iteration 6 batch 7120 training_loss 0.6931471805599453
iteration 6 batch 7130 training_loss 0.6931471805599453
iteration 6 batch 7140 training_loss 0.6931471805599453
iteration 6 batch 7150 training_loss 0.6931471805599453
iteration 6 batch 7160 training_loss 0.6931471805599453
iteration 6 batch 7170 training_loss 0.6931471805599453
iteration 6 batch 7180 training_loss 0.6931471805599453
iteration 6 batch 7190 training_loss 0.6931471805599453
iteration 6 batch 7200 training_loss 0.6931471805599453
iteration 6 batch 7210 training_loss 0.6931471805599453
iteration 6 batch 7220 training_loss 0.6931471805599453
iteration 6 batch 7230 training_loss 0.6931471805599453
iteration 6 batch 7240 training_loss 0.6931471805599453
iteration 6 batch 7250 training_loss 0.6931471805599453
iteration 6 batch 7260 training_loss 0.6931471805599453
iteration 6 batch 7270 training_loss 0.6931471805599453
iteration 6 batch 7280 training_loss 0.6916632528527511
iteration 6 batch 7290 training_loss 0.6931471805599453
iteration 6 batch 7300 training_loss 0.6916632528527511
iteration 6 batch 7310 training_loss 0.6931471805599453
iteration 6 batch 7320 training_loss 0.6931471805599453
iteration 6 batch 7330 training_loss 0.6931471805599453
iteration 6 batch 7340 training_loss 0.6916632528527511
iteration 6 batch 7350 training_loss 0.6931471805599453
iteration 6 batch 7360 training_loss 0.6916632528527511
iteration 6 batch 7370 training_loss 0.6931471805599453
iteration 6 batch 7380 training_loss 0.6916632528527511
iteration 6 batch 7390 training_loss 0.6931471805599453
iteration 6 batch 7400 training_loss 0.6931471805599453
iteration 6 batch 7410 training_loss 0.6931471805599453
iteration 6 batch 7420 training_loss 0.6931471805599453
iteration 6 batch 7430 training_loss 0.6931471805599453
iteration 6 batch 7440 training_loss 0.6931471805599453
iteration 6 batch 7450 training_loss 0.6931471805599453
iteration 6 batch 7460 training_loss 0.6931471805599453
iteration 6 batch 7470 training_loss 0.6931471805599453
iteration 6 batch 7480 training_loss 0.6931471805599453
iteration 6 batch 7490 training_loss 0.6931471805599453
iteration 6 batch 7500 training_loss 0.6931471805599453
iteration 6 batch 7510 training_loss 0.6931471805599453
iteration 6 batch 7520 training_loss 0.6931471805599453
iteration 6 batch 7530 training_loss 0.6931471805599453
iteration 6 batch 7540 training_loss 0.6931471805599453
iteration 6 batch 7550 training_loss 0.6931471805599453
iteration 6 batch 7560 training_loss 0.6931471805599453
iteration 6 batch 7570 training_loss 0.6931471805599453
iteration 6 batch 7580 training_loss 0.6931471805599453
iteration 6 batch 7590 training_loss 0.6931471805599453
iteration 6 batch 7600 training_loss 0.6931471805599453
iteration 6 batch 7610 training_loss 0.6931471805599453
iteration 6 batch 7620 training_loss 0.6931471805599453
iteration 6 batch 7630 training_loss 0.6931471805599453
iteration 6 batch 7640 training_loss 0.6931471805599453
iteration 6 batch 7650 training_loss 0.6931471805599453
iteration 6 batch 7660 training_loss 0.6931471805599453
iteration 6 batch 7670 training_loss 0.6931471805599453
iteration 6 batch 7680 training_loss 0.6931471805599453
iteration 6 batch 7690 training_loss 0.6931471805599453
iteration 6 batch 7700 training_loss 0.6931471805599453
iteration 6 batch 7710 training_loss 0.6931471805599453
iteration 6 batch 7720 training_loss 0.6931471805599453
iteration 6 batch 7730 training_loss 0.6931471805599453
iteration 6 batch 7740 training_loss 0.6916632528527511
iteration 6 batch 7750 training_loss 0.6931471805599453
iteration 6 batch 7760 training_loss 0.6931471805599453
iteration 6 batch 7770 training_loss 0.6931471805599453
iteration 6 batch 7780 training_loss 0.6931471805599453
iteration 6 batch 7790 training_loss 0.6916632528527511
iteration 6 batch 7800 training_loss 0.6931471805599453
iteration 6 batch 7810 training_loss 0.6931471805599453
iteration 6 batch 7820 training_loss 0.6931471805599453
iteration 6 batch 7830 training_loss 0.6931471805599453
iteration 6 batch 7840 training_loss 0.6931471805599453
iteration 6 batch 7850 training_loss 0.6931471805599453
iteration 6 batch 7860 training_loss 0.6931471805599453
iteration 6 batch 7870 training_loss 0.6931471805599453
iteration 6 batch 7880 training_loss 0.6931471805599453
iteration 6 batch 7890 training_loss 0.6931471805599453
iteration 6 batch 7900 training_loss 0.6931471805599453
iteration 6 batch 7910 training_loss 0.6931471805599453
iteration 6 batch 7920 training_loss 0.6931471805599453
iteration 6 batch 7930 training_loss 0.6931471805599453
iteration 6 batch 7940 training_loss 0.6931471805599453
iteration 6 batch 7950 training_loss 0.6931471805599453
iteration 6 batch 7960 training_loss 0.6916632528527511
iteration 6 batch 7970 training_loss 0.6931471805599453
iteration 6 batch 7980 training_loss 0.6931471805599453
iteration 6 batch 7990 training_loss 0.6931471805599453
iteration 6 batch 8000 training_loss 0.6931471805599453
iteration 6 batch 8010 training_loss 0.6931471805599453
iteration 6 batch 8020 training_loss 0.6931471805599453
iteration 6 batch 8030 training_loss 0.6931471805599453
iteration 6 batch 8040 training_loss 0.6931471805599453
iteration 6 batch 8050 training_loss 0.6916632528527511
iteration 6 batch 8060 training_loss 0.6931471805599453
iteration 6 batch 8070 training_loss 0.6931471805599453
iteration 6 batch 8080 training_loss 0.6931471805599453
iteration 6 batch 8090 training_loss 0.6931471805599453
iteration 6 batch 8100 training_loss 0.6931471805599453
iteration 6 batch 8110 training_loss 0.6931471805599453
iteration 6 batch 8120 training_loss 0.6931471805599453
iteration 6 batch 8130 training_loss 0.6931471805599453
iteration 6 batch 8140 training_loss 0.6931471805599453
iteration 6 batch 8150 training_loss 0.6931471805599453
iteration 6 batch 8160 training_loss 0.6931471805599453
iteration 6 batch 8170 training_loss 0.6931471805599453
iteration 6 batch 8180 training_loss 0.6931471805599453
iteration 6 batch 8190 training_loss 0.6931471805599453
iteration 6 batch 8200 training_loss 0.6931471805599453
iteration 6 batch 8210 training_loss 0.6931471805599453
iteration 6 batch 8220 training_loss 0.6931471805599453
iteration 6 batch 8230 training_loss 0.6931471805599453
iteration 6 batch 8240 training_loss 0.6931471805599453
iteration 6 batch 8250 training_loss 0.6931471805599453
iteration 6 batch 8260 training_loss 0.6931471805599453
iteration 6 batch 8270 training_loss 0.6931471805599453
iteration 6 batch 8280 training_loss 0.6931471805599453
iteration 6 batch 8290 training_loss 0.6931471805599453
iteration 6 batch 8300 training_loss 0.6931471805599453
iteration 6 batch 8310 training_loss 0.6931471805599453
iteration 6 batch 8320 training_loss 0.6931471805599453
iteration 6 batch 8330 training_loss 0.6931471805599453
iteration 6 batch 8340 training_loss 0.6931471805599453
iteration 6 batch 8350 training_loss 0.6931471805599453
iteration 6 batch 8360 training_loss 0.6931471805599453
iteration 6 batch 8370 training_loss 0.6916632528527511
iteration 6 batch 8380 training_loss 0.6931471805599453
iteration 6 batch 8390 training_loss 0.6931471805599453
iteration 6 batch 8400 training_loss 0.6931471805599453
iteration 6 batch 8410 training_loss 0.6931471805599453
iteration 6 batch 8420 training_loss 0.6931471805599453
iteration 6 batch 8430 training_loss 0.6931471805599453
iteration 6 batch 8440 training_loss 0.6931471805599453
iteration 6 batch 8450 training_loss 0.6931471805599453
iteration 6 batch 8460 training_loss 0.6916632528527511
iteration 6 batch 8470 training_loss 0.6931471805599453
iteration 6 batch 8480 training_loss 0.6931471805599453
iteration 6 batch 8490 training_loss 0.6931471805599453
iteration 6 batch 8500 training_loss 0.6931471805599453
iteration 6 batch 8510 training_loss 0.6931471805599453
iteration 6 batch 8520 training_loss 0.6931471805599453
iteration 6 batch 8530 training_loss 0.6931471805599453
iteration 6 batch 8540 training_loss 0.6931471805599453
iteration 6 batch 8550 training_loss 0.6931471805599453
iteration 6 batch 8560 training_loss 0.6931471805599453
iteration 6 batch 8570 training_loss 0.6931471805599453
iteration 6 batch 8580 training_loss 0.6931471805599453
iteration 6 batch 8590 training_loss 0.6931471805599453
iteration 6 batch 8600 training_loss 0.6931471805599453
iteration 6 batch 8610 training_loss 0.6931471805599453
iteration 6 batch 8620 training_loss 0.6931471805599453
iteration 6 batch 8630 training_loss 0.6931471805599453
iteration 6 batch 8640 training_loss 0.6931471805599453
iteration 6 batch 8650 training_loss 0.6931471805599453
iteration 6 batch 8660 training_loss 0.6931471805599453
iteration 6 batch 8670 training_loss 0.6931471805599453
iteration 6 batch 8680 training_loss 0.6931471805599453
iteration 6 batch 8690 training_loss 0.6931471805599453
iteration 6 batch 8700 training_loss 0.6931471805599453
iteration 6 batch 8710 training_loss 0.6931471805599453
iteration 6 batch 8720 training_loss 0.6931471805599453
iteration 6 batch 8730 training_loss 0.6931471805599453
iteration 6 batch 8740 training_loss 0.6931471805599453
iteration 6 batch 8750 training_loss 0.6931471805599453
iteration 6 batch 8760 training_loss 0.6931471805599453
iteration 6 batch 8770 training_loss 0.6931471805599453
iteration 6 batch 8780 training_loss 0.6931471805599453
iteration 6 batch 8790 training_loss 0.6931471805599453
iteration 6 batch 8800 training_loss 0.6931471805599453
iteration 6 batch 8810 training_loss 0.6931471805599453
iteration 6 batch 8820 training_loss 0.6931471805599453
iteration 6 batch 8830 training_loss 0.6931471805599453
iteration 6 batch 8840 training_loss 0.6931471805599453
iteration 6 batch 8850 training_loss 0.6931471805599453
iteration 6 batch 8860 training_loss 0.6931471805599453
iteration 6 batch 8870 training_loss 0.6916632528527511
iteration 6 batch 8880 training_loss 0.6931471805599453
iteration 6 batch 8890 training_loss 0.6931471805599453
iteration 6 batch 8900 training_loss 0.6931471805599453
iteration 6 batch 8910 training_loss 0.6931471805599453
iteration 6 batch 8920 training_loss 0.6931471805599453
iteration 6 batch 8930 training_loss 0.6916632528527511
iteration 6 batch 8940 training_loss 0.6931471805599453
iteration 6 batch 8950 training_loss 0.6931471805599453
iteration 6 batch 8960 training_loss 0.6931471805599453
iteration 6 batch 8970 training_loss 0.6931471805599453
iteration 6 batch 8980 training_loss 0.6931471805599453
iteration 6 batch 8990 training_loss 0.6931471805599453
iteration 6 batch 9000 training_loss 0.6931471805599453
iteration 6 batch 9010 training_loss 0.6931471805599453
iteration 6 batch 9020 training_loss 0.6931471805599453
iteration 6 batch 9030 training_loss 0.6931471805599453
iteration 6 batch 9040 training_loss 0.6931471805599453
iteration 6 batch 9050 training_loss 0.6931471805599453
iteration 6 batch 9060 training_loss 0.6931471805599453
iteration 6 batch 9070 training_loss 0.6931471805599453
iteration 6 batch 9080 training_loss 0.6931471805599453
iteration 6 batch 9090 training_loss 0.6931471805599453
iteration 6 batch 9100 training_loss 0.6931471805599453
iteration 6 batch 9110 training_loss 0.6931471805599453
iteration 6 batch 9120 training_loss 0.6931471805599453
iteration 6 batch 9130 training_loss 0.6931471805599453
iteration 6 batch 9140 training_loss 0.6916632528527511
iteration 6 batch 9150 training_loss 0.6931471805599453
iteration 6 batch 9160 training_loss 0.6931471805599453
iteration 6 batch 9170 training_loss 0.6931471805599453
iteration 6 batch 9180 training_loss 0.6931471805599453
iteration 6 batch 9190 training_loss 0.6931471805599453
iteration 6 batch 9200 training_loss 0.6916632528527511
iteration 6 batch 9210 training_loss 0.6931471805599453
iteration 6 batch 9220 training_loss 0.6931471805599453
iteration 6 batch 9230 training_loss 0.6931471805599453
iteration 6 batch 9240 training_loss 0.6931471805599453
iteration 6 batch 9250 training_loss 0.6931471805599453
iteration 6 batch 9260 training_loss 0.6931471805599453
iteration 6 batch 9270 training_loss 0.6931471805599453
iteration 6 batch 9280 training_loss 0.6931471805599453
iteration 6 batch 9290 training_loss 0.6931471805599453
iteration 6 batch 9300 training_loss 0.6931471805599453
iteration 6 batch 9310 training_loss 0.6931471805599453
iteration 6 batch 9320 training_loss 0.6931471805599453
iteration 6 batch 9330 training_loss 0.6931471805599453
iteration 6 batch 9340 training_loss 0.6931471805599453
iteration 6 batch 9350 training_loss 0.6931471805599453
iteration 6 batch 9360 training_loss 0.6931471805599453
iteration 6 batch 9370 training_loss 0.6931471805599453
iteration 6 batch 9380 training_loss 0.6931471805599453
iteration 6 batch 9390 training_loss 0.6931471805599453
iteration 6 batch 9400 training_loss 0.6931471805599453
iteration 6 batch 9410 training_loss 0.6931471805599453
iteration 6 batch 9420 training_loss 0.6931471805599453
iteration 6 batch 9430 training_loss 0.6931471805599453
iteration 6 batch 9440 training_loss 0.6931471805599453
iteration 6 batch 9450 training_loss 0.6931471805599453
iteration 6 batch 9460 training_loss 0.6931471805599453
iteration 6 batch 9470 training_loss 0.6931471805599453
iteration 6 batch 9480 training_loss 0.6916632528527511
iteration 6 batch 9490 training_loss 0.6931471805599453
iteration 6 batch 9500 training_loss 0.6931471805599453
iteration 6 batch 9510 training_loss 0.6931471805599453
iteration 6 batch 9520 training_loss 0.6931471805599453
iteration 6 batch 9530 training_loss 0.6931471805599453
iteration 6 batch 9540 training_loss 0.6931471805599453
iteration 6 batch 9550 training_loss 0.6931471805599453
iteration 6 batch 9560 training_loss 0.6931471805599453
iteration 6 batch 9570 training_loss 0.6931471805599453
iteration 6 batch 9580 training_loss 0.6931471805599453
iteration 6 batch 9590 training_loss 0.6931471805599453
iteration 6 batch 9600 training_loss 0.6931471805599453
iteration 6 batch 9610 training_loss 0.6931471805599453
iteration 6 batch 9620 training_loss 0.6931471805599453
iteration 6 batch 9630 training_loss 0.6931471805599453
iteration 6 batch 9640 training_loss 0.6931471805599453
iteration 6 batch 9650 training_loss 0.6931471805599453
iteration 6 batch 9660 training_loss 0.6931471805599453
iteration 6 batch 9670 training_loss 0.6931471805599453
iteration 6 batch 9680 training_loss 0.6931471805599453
iteration 6 batch 9690 training_loss 0.6931471805599453
iteration 6 batch 9700 training_loss 0.6931471805599453
iteration 6 batch 9710 training_loss 0.6931471805599453
iteration 6 batch 9720 training_loss 0.6931471805599453
iteration 6 batch 9730 training_loss 0.6931471805599453
iteration 6 batch 9740 training_loss 0.6931471805599453
iteration 6 batch 9750 training_loss 0.6931471805599453
iteration 6 batch 9760 training_loss 0.6931471805599453
iteration 6 batch 9770 training_loss 0.6931471805599453
iteration 6 batch 9780 training_loss 0.6931471805599453
iteration 6 batch 9790 training_loss 0.6931471805599453
iteration 6 batch 9800 training_loss 0.6931471805599453
iteration 6 batch 9810 training_loss 0.6931471805599453
iteration 6 batch 9820 training_loss 0.6931471805599453
iteration 6 batch 9830 training_loss 0.6931471805599453
iteration 6 batch 9840 training_loss 0.6931471805599453
iteration 6 batch 9850 training_loss 0.6931471805599453
iteration 6 batch 9860 training_loss 0.6931471805599453
iteration 6 batch 9870 training_loss 0.6916632528527511
iteration 6 batch 9880 training_loss 0.6931471805599453
iteration 6 batch 9890 training_loss 0.6931471805599453
iteration 6 batch 9900 training_loss 0.6931471805599453
iteration 6 batch 9910 training_loss 0.6931471805599453
iteration 6 batch 9920 training_loss 0.6931471805599453
iteration 6 batch 9930 training_loss 0.6931471805599453
iteration 6 batch 9940 training_loss 0.6931471805599453
iteration 6 batch 9950 training_loss 0.6931471805599453
iteration 6 batch 9960 training_loss 0.6931471805599453
iteration 6 batch 9970 training_loss 0.6931471805599453
iteration 6 batch 9980 training_loss 0.6931471805599453
iteration 6 batch 9990 training_loss 0.6916632528527511
iteration 6 batch 10000 training_loss 0.6931471805599453
iteration 6 batch 10010 training_loss 0.6931471805599453
iteration 6 batch 10020 training_loss 0.6916632528527511
iteration 6 batch 10030 training_loss 0.6931471805599453
iteration 6 batch 10040 training_loss 0.6931471805599453
iteration 6 batch 10050 training_loss 0.6931471805599453
iteration 6 batch 10060 training_loss 0.6931471805599453
iteration 6 batch 10070 training_loss 0.6931471805599453
iteration 6 batch 10080 training_loss 0.6931471805599453
iteration 6 batch 10090 training_loss 0.6931471805599453
iteration 6 batch 10100 training_loss 0.6931471805599453
iteration 6 batch 10110 training_loss 0.6931471805599453
iteration 6 batch 10120 training_loss 0.6931471805599453
iteration 6 batch 10130 training_loss 0.6931471805599453
iteration 6 batch 10140 training_loss 0.6931471805599453
iteration 6 batch 10150 training_loss 0.6931471805599453
iteration 6 batch 10160 training_loss 0.6916632528527511
iteration 6 batch 10170 training_loss 0.6916632528527511
iteration 6 batch 10180 training_loss 0.6931471805599453
iteration 6 batch 10190 training_loss 0.6931471805599453
iteration 6 batch 10200 training_loss 0.6916632528527511
iteration 6 batch 10210 training_loss 0.6931471805599453
iteration 6 batch 10220 training_loss 0.6931471805599453
iteration 6 batch 10230 training_loss 0.6931471805599453
iteration 6 batch 10240 training_loss 0.6931471805599453
iteration 6 batch 10250 training_loss 0.6916632528527511
iteration 6 batch 10260 training_loss 0.6931471805599453
iteration 6 batch 10270 training_loss 0.6931471805599453
iteration 6 batch 10280 training_loss 0.6931471805599453
iteration 6 batch 10290 training_loss 0.6931471805599453
iteration 6 batch 10300 training_loss 0.6931471805599453
iteration 6 batch 10310 training_loss 0.6931471805599453
iteration 6 batch 10320 training_loss 0.6931471805599453
iteration 6 batch 10330 training_loss 0.6931471805599453
iteration 6 batch 10340 training_loss 0.6931471805599453
iteration 6 batch 10350 training_loss 0.6931471805599453
iteration 6 batch 10360 training_loss 0.6931471805599453
iteration 6 batch 10370 training_loss 0.6931471805599453
iteration 6 batch 10380 training_loss 0.6931471805599453
iteration 6 batch 10390 training_loss 0.6931471805599453
iteration 6 batch 10400 training_loss 0.6931471805599453
iteration 6 batch 10410 training_loss 0.6931471805599453
iteration 6 batch 10420 training_loss 0.6931471805599453
iteration 6 batch 10430 training_loss 0.6931471805599453
iteration 6 batch 10440 training_loss 0.6931471805599453
iteration 6 batch 10450 training_loss 0.6931471805599453
iteration 6 batch 10460 training_loss 0.6916632528527511
iteration 6 batch 10470 training_loss 0.6931471805599453
iteration 6 batch 10480 training_loss 0.6931471805599453
iteration 6 batch 10490 training_loss 0.6931471805599453
iteration 6 batch 10500 training_loss 0.6931471805599453
iteration 6 batch 10510 training_loss 0.6931471805599453
iteration 6 batch 10520 training_loss 0.6931471805599453
iteration 6 batch 10530 training_loss 0.6931471805599453
iteration 6 batch 10540 training_loss 0.6931471805599453
iteration 6 batch 10550 training_loss 0.6931471805599453
iteration 6 batch 10560 training_loss 0.6931471805599453
iteration 6 batch 10570 training_loss 0.6931471805599453
iteration 6 batch 10580 training_loss 0.6916632528527511
iteration 6 batch 10590 training_loss 0.6931471805599453
iteration 6 batch 10600 training_loss 0.6931471805599453
iteration 6 batch 10610 training_loss 0.6931471805599453
iteration 6 batch 10620 training_loss 0.6931471805599453
iteration 6 batch 10630 training_loss 0.6931471805599453
iteration 6 batch 10640 training_loss 0.6916632528527511
iteration 6 batch 10650 training_loss 0.6931471805599453
iteration 6 batch 10660 training_loss 0.6931471805599453
iteration 6 batch 10670 training_loss 0.6931471805599453
iteration 6 batch 10680 training_loss 0.6931471805599453
iteration 6 batch 10690 training_loss 0.6931471805599453
iteration 6 batch 10700 training_loss 0.6931471805599453
iteration 6 batch 10710 training_loss 0.6931471805599453
iteration 6 batch 10720 training_loss 0.6931471805599453
iteration 6 batch 10730 training_loss 0.6931471805599453
iteration 6 batch 10740 training_loss 0.6931471805599453
iteration 6 batch 10750 training_loss 0.6916632528527511
iteration 6 batch 10760 training_loss 0.6931471805599453
iteration 6 batch 10770 training_loss 0.6931471805599453
iteration 6 batch 10780 training_loss 0.6931471805599453
iteration 6 batch 10790 training_loss 0.6931471805599453
iteration 6 batch 10800 training_loss 0.6931471805599453
iteration 6 batch 10810 training_loss 0.6931471805599453
iteration 6 batch 10820 training_loss 0.6931471805599453
iteration 6 batch 10830 training_loss 0.6931471805599453
iteration 6 batch 10840 training_loss 0.6931471805599453
iteration 6 batch 10850 training_loss 0.6931471805599453
iteration 6 batch 10860 training_loss 0.6931471805599453
iteration 6 batch 10870 training_loss 0.6931471805599453
iteration 6 batch 10880 training_loss 0.6931471805599453
iteration 6 batch 10890 training_loss 0.6931471805599453
iteration 6 batch 10900 training_loss 0.6931471805599453
iteration 6 batch 10910 training_loss 0.6931471805599453
iteration 6 batch 10920 training_loss 0.6931471805599453
iteration 6 batch 10930 training_loss 0.6931471805599453
iteration 6 batch 10940 training_loss 0.6931471805599453
iteration 6 batch 10950 training_loss 0.6931471805599453
iteration 6 batch 10960 training_loss 0.6931471805599453
iteration 6 batch 10970 training_loss 0.6931471805599453
iteration 6 batch 10980 training_loss 0.6931471805599453
iteration 6 batch 10990 training_loss 0.6931471805599453
iteration 6 batch 11000 training_loss 0.6931471805599453
iteration 6 batch 11010 training_loss 0.6931471805599453
iteration 6 batch 11020 training_loss 0.6931471805599453
iteration 6 batch 11030 training_loss 0.6931471805599453
iteration 6 batch 11040 training_loss 0.6931471805599453
iteration 6 batch 11050 training_loss 0.6931471805599453
iteration 6 batch 11060 training_loss 0.6931471805599453
iteration 6 batch 11070 training_loss 0.6931471805599453
iteration 6 batch 11080 training_loss 0.6931471805599453
iteration 6 batch 11090 training_loss 0.6931471805599453
iteration 6 batch 11100 training_loss 0.6931471805599453
iteration 6 batch 11110 training_loss 0.6931471805599453
iteration 6 batch 11120 training_loss 0.6931471805599453
iteration 6 batch 11130 training_loss 0.6931471805599453
iteration 6 batch 11140 training_loss 0.6931471805599453
iteration 6 batch 11150 training_loss 0.6931471805599453
iteration 6 batch 11160 training_loss 0.6931471805599453
iteration 6 batch 11170 training_loss 0.6931471805599453
iteration 6 batch 11180 training_loss 0.6931471805599453
iteration 6 batch 11190 training_loss 0.6931471805599453
iteration 6 batch 11200 training_loss 0.6931471805599453
iteration 6 batch 11210 training_loss 0.6931471805599453
iteration 6 batch 11220 training_loss 0.6931471805599453
iteration 6 batch 11230 training_loss 0.6931471805599453
iteration 6 batch 11240 training_loss 0.6931471805599453
iteration 6 batch 11250 training_loss 0.6931471805599453
iteration 6 batch 11260 training_loss 0.6931471805599453
iteration 6 batch 11270 training_loss 0.6931471805599453
iteration 6 batch 11280 training_loss 0.6931471805599453
iteration 6 batch 11290 training_loss 0.6931471805599453
iteration 6 batch 11300 training_loss 0.6931471805599453
iteration 6 batch 11310 training_loss 0.6931471805599453
iteration 6 batch 11320 training_loss 0.6916632528527511
iteration 6 batch 11330 training_loss 0.6931471805599453
iteration 6 batch 11340 training_loss 0.6931471805599453
iteration 6 batch 11350 training_loss 0.6931471805599453
iteration 6 batch 11360 training_loss 0.6931471805599453
iteration 6 batch 11370 training_loss 0.6916632528527511
iteration 6 batch 11380 training_loss 0.6931471805599453
iteration 6 batch 11390 training_loss 0.6931471805599453
iteration 6 batch 11400 training_loss 0.6931471805599453
iteration 6 batch 11410 training_loss 0.6931471805599453
iteration 6 batch 11420 training_loss 0.6931471805599453
iteration 6 batch 11430 training_loss 0.6931471805599453
iteration 6 batch 11440 training_loss 0.6931471805599453
iteration 6 batch 11450 training_loss 0.6931471805599453
iteration 6 batch 11460 training_loss 0.6916632528527511
iteration 6 batch 11470 training_loss 0.6916632528527511
iteration 6 batch 11480 training_loss 0.6931471805599453
iteration 6 batch 11490 training_loss 0.6931471805599453
iteration 6 batch 11500 training_loss 0.6931471805599453
iteration 6 batch 11510 training_loss 0.6931471805599453
iteration 6 batch 11520 training_loss 0.6931471805599453
iteration 6 batch 11530 training_loss 0.6931471805599453
iteration 6 batch 11540 training_loss 0.6931471805599453
iteration 6 batch 11550 training_loss 0.6931471805599453
iteration 6 batch 11560 training_loss 0.6931471805599453
iteration 6 batch 11570 training_loss 0.6931471805599453
iteration 6 batch 11580 training_loss 0.6931471805599453
iteration 6 batch 11590 training_loss 0.6931471805599453
iteration 6 batch 11600 training_loss 0.6931471805599453
iteration 6 batch 11610 training_loss 0.6931471805599453
iteration 6 batch 11620 training_loss 0.6931471805599453
iteration 6 batch 11630 training_loss 0.6931471805599453
iteration 6 batch 11640 training_loss 0.6931471805599453
iteration 6 batch 11650 training_loss 0.6931471805599453
iteration 6 batch 11660 training_loss 0.6931471805599453
iteration 6 batch 11670 training_loss 0.6931471805599453
iteration 6 batch 11680 training_loss 0.6931471805599453
iteration 6 batch 11690 training_loss 0.6931471805599453
iteration 6 batch 11700 training_loss 0.6931471805599453
iteration 6 batch 11710 training_loss 0.6916632528527511
iteration 6 batch 11720 training_loss 0.6931471805599453
iteration 6 batch 11730 training_loss 0.6931471805599453
iteration 6 batch 11740 training_loss 0.6916632528527511
iteration 6 batch 11750 training_loss 0.6931471805599453
iteration 6 batch 11760 training_loss 0.6931471805599453
iteration 6 batch 11770 training_loss 0.6931471805599453
iteration 6 batch 11780 training_loss 0.6931471805599453
iteration 6 batch 11790 training_loss 0.6931471805599453
iteration 6 batch 11800 training_loss 0.6931471805599453
iteration 6 batch 11810 training_loss 0.6931471805599453
iteration 6 batch 11820 training_loss 0.6931471805599453
iteration 6 batch 11830 training_loss 0.6931471805599453
iteration 6 batch 11840 training_loss 0.6931471805599453
iteration 6 batch 11850 training_loss 0.6931471805599453
iteration 6 batch 11860 training_loss 0.6931471805599453
iteration 6 batch 11870 training_loss 0.6931471805599453
iteration 6 batch 11880 training_loss 0.6931471805599453
iteration 6 batch 11890 training_loss 0.6931471805599453
iteration 6 batch 11900 training_loss 0.6931471805599453
iteration 6 batch 11910 training_loss 0.6931471805599453
iteration 6 batch 11920 training_loss 0.6931471805599453
iteration 6 batch 11930 training_loss 0.6931471805599453
iteration 6 batch 11940 training_loss 0.6931471805599453
iteration 6 batch 11950 training_loss 0.6931471805599453
iteration 6 batch 11960 training_loss 0.6931471805599453
iteration 6 batch 11970 training_loss 0.6931471805599453
iteration 6 batch 11980 training_loss 0.6931471805599453
iteration 6 batch 11990 training_loss 0.6931471805599453
iteration 6 batch 12000 training_loss 0.6931471805599453
iteration 6 batch 12010 training_loss 0.6931471805599453
iteration 6 batch 12020 training_loss 0.6931471805599453
iteration 6 batch 12030 training_loss 0.6931471805599453
iteration 6 batch 12040 training_loss 0.6931471805599453
iteration 6 batch 12050 training_loss 0.6931471805599453
iteration 6 batch 12060 training_loss 0.6931471805599453
iteration 6 batch 12070 training_loss 0.6931471805599453
iteration 6 batch 12080 training_loss 0.6931471805599453
iteration 6 batch 12090 training_loss 0.6931471805599453
iteration 6 batch 12100 training_loss 0.6931471805599453
iteration 6 batch 12110 training_loss 0.6931471805599453
iteration 6 batch 12120 training_loss 0.6931471805599453
iteration 6 batch 12130 training_loss 0.6931471805599453
iteration 6 batch 12140 training_loss 0.6931471805599453
iteration 6 batch 12150 training_loss 0.6931471805599453
iteration 6 batch 12160 training_loss 0.6931471805599453
iteration 6 batch 12170 training_loss 0.6931471805599453
iteration 6 batch 12180 training_loss 0.6931471805599453
iteration 6 batch 12190 training_loss 0.6931471805599453
iteration 6 batch 12200 training_loss 0.6931471805599453
iteration 6 batch 12210 training_loss 0.6916632528527511
iteration 6 batch 12220 training_loss 0.6931471805599453
iteration 6 batch 12230 training_loss 0.6931471805599453
iteration 6 batch 12240 training_loss 0.6931471805599453
iteration 6 batch 12250 training_loss 0.6931471805599453
iteration 6 batch 12260 training_loss 0.6931471805599453
iteration 6 batch 12270 training_loss 0.6931471805599453
iteration 6 batch 12280 training_loss 0.6916632528527511
iteration 6 batch 12290 training_loss 0.6931471805599453
iteration 6 batch 12300 training_loss 0.6916632528527511
iteration 6 batch 12310 training_loss 0.6931471805599453
iteration 6 batch 12320 training_loss 0.6931471805599453
iteration 6 batch 12330 training_loss 0.6931471805599453
iteration 6 batch 12340 training_loss 0.6931471805599453
iteration 6 batch 12350 training_loss 0.6931471805599453
iteration 6 batch 12360 training_loss 0.6931471805599453
iteration 6 batch 12370 training_loss 0.6931471805599453
iteration 6 batch 12380 training_loss 0.6931471805599453
iteration 6 batch 12390 training_loss 0.6931471805599453
iteration 6 batch 12400 training_loss 0.6931471805599453
iteration 6 batch 12410 training_loss 0.6931471805599453
iteration 6 batch 12420 training_loss 0.6931471805599453
iteration 6 batch 12430 training_loss 0.6916632528527511
iteration 6 batch 12440 training_loss 0.6916632528527511
iteration 6 batch 12450 training_loss 0.6931471805599453
iteration 6 batch 12460 training_loss 0.6931471805599453
iteration 6 batch 12470 training_loss 0.6931471805599453
iteration 6 batch 12480 training_loss 0.6916632528527511
iteration 6 batch 12490 training_loss 0.6931471805599453
iteration 6 batch 12500 training_loss 0.6931471805599453
iteration 6 batch 12510 training_loss 0.6931471805599453
iteration 6 batch 12520 training_loss 0.6931471805599453
iteration 6 batch 12530 training_loss 0.6931471805599453
iteration 6 batch 12540 training_loss 0.6931471805599453
iteration 6 batch 12550 training_loss 0.6931471805599453
iteration 6 batch 12560 training_loss 0.6901793251455568
iteration 6 batch 12570 training_loss 0.6916632528527511
iteration 6 batch 12580 training_loss 0.6931471805599453
iteration 6 batch 12590 training_loss 0.6931471805599453
iteration 6 batch 12600 training_loss 0.6931471805599453
iteration 6 batch 12610 training_loss 0.6931471805599453
iteration 6 batch 12620 training_loss 0.6931471805599453
iteration 6 batch 12630 training_loss 0.6931471805599453
iteration 6 batch 12640 training_loss 0.6931471805599453
iteration 6 batch 12650 training_loss 0.6931471805599453
iteration 6 batch 12660 training_loss 0.6931471805599453
iteration 6 batch 12670 training_loss 0.6931471805599453
iteration 6 batch 12680 training_loss 0.6931471805599453
iteration 6 batch 12690 training_loss 0.6931471805599453
iteration 6 batch 12700 training_loss 0.6931471805599453
iteration 6 batch 12710 training_loss 0.6931471805599453
iteration 6 batch 12720 training_loss 0.6931471805599453
iteration 6 batch 12730 training_loss 0.6931471805599453
iteration 6 batch 12740 training_loss 0.6931471805599453
iteration 6 batch 12750 training_loss 0.6931471805599453
iteration 6 batch 12760 training_loss 0.6931471805599453
iteration 6 batch 12770 training_loss 0.6916632528527511
iteration 6 batch 12780 training_loss 0.6931471805599453
iteration 6 batch 12790 training_loss 0.6931471805599453
iteration 6 batch 12800 training_loss 0.6931471805599453
iteration 6 batch 12810 training_loss 0.6931471805599453
iteration 6 batch 12820 training_loss 0.6931471805599453
iteration 6 batch 12830 training_loss 0.6931471805599453
iteration 6 batch 12840 training_loss 0.6931471805599453
iteration 6 batch 12850 training_loss 0.6931471805599453
iteration 6 batch 12860 training_loss 0.6931471805599453
iteration 6 batch 12870 training_loss 0.6931471805599453
iteration 6 batch 12880 training_loss 0.6931471805599453
iteration 6 batch 12890 training_loss 0.6931471805599453
iteration 6 batch 12900 training_loss 0.6931471805599453
iteration 6 batch 12910 training_loss 0.6931471805599453
iteration 6 batch 12920 training_loss 0.6931471805599453
iteration 6 batch 12930 training_loss 0.6931471805599453
iteration 6 batch 12940 training_loss 0.6931471805599453
iteration 6 batch 12950 training_loss 0.6931471805599453
iteration 6 batch 12960 training_loss 0.6931471805599453
iteration 6 batch 12970 training_loss 0.6931471805599453
iteration 6 batch 12980 training_loss 0.6931471805599453
iteration 6 batch 12990 training_loss 0.6931471805599453
iteration 6 batch 13000 training_loss 0.6931471805599453
iteration 6 batch 13010 training_loss 0.6931471805599453
iteration 6 batch 13020 training_loss 0.6931471805599453
iteration 6 batch 13030 training_loss 0.6931471805599453
iteration 6 batch 13040 training_loss 0.6931471805599453
iteration 6 batch 13050 training_loss 0.6931471805599453
iteration 6 batch 13060 training_loss 0.6931471805599453
iteration 6 batch 13070 training_loss 0.6931471805599453
iteration 6 batch 13080 training_loss 0.6931471805599453
iteration 6 batch 13090 training_loss 0.6931471805599453
iteration 6 batch 13100 training_loss 0.6916632528527511
iteration 6 batch 13110 training_loss 0.6931471805599453
iteration 6 batch 13120 training_loss 0.6931471805599453
iteration 6 batch 13130 training_loss 0.6931471805599453
iteration 6 batch 13140 training_loss 0.6931471805599453
iteration 6 batch 13150 training_loss 0.6931471805599453
iteration 6 batch 13160 training_loss 0.6931471805599453
iteration 6 batch 13170 training_loss 0.6931471805599453
iteration 6 batch 13180 training_loss 0.6931471805599453
iteration 6 batch 13190 training_loss 0.6931471805599453
iteration 6 batch 13200 training_loss 0.6931471805599453
iteration 6 batch 13210 training_loss 0.6931471805599453
iteration 6 batch 13220 training_loss 0.6931471805599453
iteration 6 batch 13230 training_loss 0.6916632528527511
iteration 6 batch 13240 training_loss 0.6931471805599453
iteration 6 batch 13250 training_loss 0.6931471805599453
iteration 6 batch 13260 training_loss 0.6931471805599453
iteration 6 batch 13270 training_loss 0.6931471805599453
iteration 6 batch 13280 training_loss 0.6931471805599453
iteration 6 batch 13290 training_loss 0.6931471805599453
iteration 6 batch 13300 training_loss 0.6916632528527511
iteration 6 batch 13310 training_loss 0.6931471805599453
iteration 6 batch 13320 training_loss 0.6916632528527511
iteration 6 batch 13330 training_loss 0.6931471805599453
iteration 6 batch 13340 training_loss 0.6931471805599453
iteration 6 batch 13350 training_loss 0.6901793251455568
iteration 6 batch 13360 training_loss 0.6931471805599453
iteration 6 batch 13370 training_loss 0.6931471805599453
iteration 6 batch 13380 training_loss 0.6931471805599453
iteration 6 batch 13390 training_loss 0.6931471805599453
iteration 6 batch 13400 training_loss 0.6931471805599453
iteration 6 batch 13410 training_loss 0.6931471805599453
iteration 6 batch 13420 training_loss 0.6931471805599453
iteration 6 batch 13430 training_loss 0.6931471805599453
iteration 6 batch 13440 training_loss 0.6916632528527511
iteration 6 batch 13450 training_loss 0.6931471805599453
iteration 6 batch 13460 training_loss 0.6931471805599453
iteration 6 batch 13470 training_loss 0.6931471805599453
iteration 6 batch 13480 training_loss 0.6931471805599453
iteration 6 batch 13490 training_loss 0.6931471805599453
iteration 6 batch 13500 training_loss 0.6931471805599453
iteration 6 batch 13510 training_loss 0.6931471805599453
iteration 6 batch 13520 training_loss 0.6931471805599453
iteration 6 batch 13530 training_loss 0.6931471805599453
iteration 6 batch 13540 training_loss 0.6931471805599453
iteration 6 batch 13550 training_loss 0.6931471805599453
iteration 6 batch 13560 training_loss 0.6931471805599453
iteration 6 batch 13570 training_loss 0.6931471805599453
iteration 6 batch 13580 training_loss 0.6931471805599453
iteration 6 batch 13590 training_loss 0.6931471805599453
iteration 6 batch 13600 training_loss 0.6931471805599453
iteration 6 batch 13610 training_loss 0.6931471805599453
iteration 6 batch 13620 training_loss 0.6931471805599453
iteration 6 batch 13630 training_loss 0.6931471805599453
iteration 6 batch 13640 training_loss 0.6931471805599453
iteration 6 batch 13650 training_loss 0.6931471805599453
iteration 6 batch 13660 training_loss 0.6931471805599453
iteration 6 batch 13670 training_loss 0.6931471805599453
iteration 6 batch 13680 training_loss 0.6931471805599453
iteration 6 batch 13690 training_loss 0.6931471805599453
iteration 6 batch 13700 training_loss 0.6931471805599453
iteration 6 batch 13710 training_loss 0.6931471805599453
iteration 6 batch 13720 training_loss 0.6931471805599453
iteration 6 batch 13730 training_loss 0.6916632528527511
iteration 6 batch 13740 training_loss 0.6931471805599453
iteration 6 batch 13750 training_loss 0.6931471805599453
iteration 6 batch 13760 training_loss 0.6931471805599453
iteration 6 batch 13770 training_loss 0.6931471805599453
iteration 6 batch 13780 training_loss 0.6931471805599453
iteration 6 batch 13790 training_loss 0.6916632528527511
iteration 6 batch 13800 training_loss 0.6931471805599453
iteration 6 batch 13810 training_loss 0.6931471805599453
iteration 6 batch 13820 training_loss 0.6916632528527511
iteration 6 batch 13830 training_loss 0.6931471805599453
iteration 6 batch 13840 training_loss 0.6931471805599453
iteration 6 batch 13850 training_loss 0.6931471805599453
iteration 6 batch 13860 training_loss 0.6931471805599453
iteration 6 batch 13870 training_loss 0.6931471805599453
iteration 6 batch 13880 training_loss 0.6931471805599453
iteration 6 batch 13890 training_loss 0.6931471805599453
iteration 6 batch 13900 training_loss 0.6931471805599453
iteration 6 batch 13910 training_loss 0.6931471805599453
iteration 6 batch 13920 training_loss 0.6931471805599453
iteration 6 batch 13930 training_loss 0.6931471805599453
iteration 6 batch 13940 training_loss 0.6931471805599453
iteration 6 batch 13950 training_loss 0.6931471805599453
iteration 6 batch 13960 training_loss 0.6931471805599453
iteration 6 batch 13970 training_loss 0.6931471805599453
iteration 6 batch 13980 training_loss 0.6931471805599453
iteration 6 batch 13990 training_loss 0.6931471805599453
iteration 6 batch 14000 training_loss 0.6931471805599453
iteration 6 batch 14010 training_loss 0.6931471805599453
iteration 6 batch 14020 training_loss 0.6931471805599453
iteration 6 batch 14030 training_loss 0.6931471805599453
iteration 6 batch 14040 training_loss 0.6931471805599453
iteration 6 batch 14050 training_loss 0.6931471805599453
iteration 6 batch 14060 training_loss 0.6931471805599453
iteration 6 batch 14070 training_loss 0.6931471805599453
iteration 6 batch 14080 training_loss 0.6931471805599453
iteration 6 batch 14090 training_loss 0.6931471805599453
iteration 6 batch 14100 training_loss 0.6931471805599453
iteration 6 batch 14110 training_loss 0.6931471805599453
iteration 6 batch 14120 training_loss 0.6931471805599453
iteration 6 batch 14130 training_loss 0.6931471805599453
iteration 6 batch 14140 training_loss 0.6931471805599453
iteration 6 batch 14150 training_loss 0.6931471805599453
iteration 6 batch 14160 training_loss 0.6931471805599453
iteration 6 batch 14170 training_loss 0.6916632528527511
iteration 6 batch 14180 training_loss 0.6931471805599453
iteration 6 batch 14190 training_loss 0.6931471805599453
iteration 6 batch 14200 training_loss 0.6931471805599453
iteration 6 batch 14210 training_loss 0.6931471805599453
iteration 6 batch 14220 training_loss 0.6931471805599453
iteration 6 batch 14230 training_loss 0.6931471805599453
iteration 6 batch 14240 training_loss 0.6931471805599453
iteration 6 batch 14250 training_loss 0.6931471805599453
iteration 6 batch 14260 training_loss 0.6931471805599453
iteration 6 batch 14270 training_loss 0.6931471805599453
iteration 6 batch 14280 training_loss 0.6931471805599453
iteration 6 batch 14290 training_loss 0.6931471805599453
iteration 6 batch 14300 training_loss 0.6931471805599453
iteration 6 batch 14310 training_loss 0.6931471805599453
iteration 6 batch 14320 training_loss 0.6931471805599453
iteration 6 batch 14330 training_loss 0.6931471805599453
iteration 6 batch 14340 training_loss 0.6931471805599453
iteration 6 batch 14350 training_loss 0.6931471805599453
iteration 6 batch 14360 training_loss 0.6931471805599453
iteration 6 batch 14370 training_loss 0.6931471805599453
iteration 6 batch 14380 training_loss 0.6931471805599453
iteration 6 batch 14390 training_loss 0.6931471805599453
iteration 6 batch 14400 training_loss 0.6931471805599453
iteration 6 batch 14410 training_loss 0.6931471805599453
iteration 6 batch 14420 training_loss 0.6931471805599453
iteration 6 batch 14430 training_loss 0.6931471805599453
iteration 6 batch 14440 training_loss 0.6931471805599453
iteration 6 batch 14450 training_loss 0.6931471805599453
iteration 6 batch 14460 training_loss 0.6931471805599453
iteration 6 batch 14470 training_loss 0.6931471805599453
iteration 6 batch 14480 training_loss 0.6931471805599453
iteration 6 batch 14490 training_loss 0.6931471805599453
iteration 6 batch 14500 training_loss 0.6931471805599453
iteration 6 batch 14510 training_loss 0.6931471805599453
iteration 6 batch 14520 training_loss 0.6931471805599453
iteration 6 batch 14530 training_loss 0.6931471805599453
iteration 6 batch 14540 training_loss 0.6931471805599453
iteration 6 batch 14550 training_loss 0.6931471805599453
iteration 6 batch 14560 training_loss 0.6916632528527511
iteration 6 batch 14570 training_loss 0.6931471805599453
iteration 6 batch 14580 training_loss 0.6931471805599453
iteration 6 batch 14590 training_loss 0.6931471805599453
iteration 6 batch 14600 training_loss 0.6931471805599453
iteration 6 batch 14610 training_loss 0.6931471805599453
iteration 6 batch 14620 training_loss 0.6931471805599453
iteration 6 batch 14630 training_loss 0.6931471805599453
iteration 6 batch 14640 training_loss 0.6931471805599453
iteration 6 batch 14650 training_loss 0.6931471805599453
iteration 6 batch 14660 training_loss 0.6931471805599453
iteration 6 batch 14670 training_loss 0.6931471805599453
iteration 6 batch 14680 training_loss 0.6931471805599453
iteration 6 batch 14690 training_loss 0.6931471805599453
iteration 6 batch 14700 training_loss 0.6931471805599453
iteration 6 batch 14710 training_loss 0.6931471805599453
iteration 6 batch 14720 training_loss 0.6931471805599453
iteration 6 batch 14730 training_loss 0.6931471805599453
iteration 6 batch 14740 training_loss 0.6931471805599453
iteration 6 batch 14750 training_loss 0.6931471805599453
iteration 6 batch 14760 training_loss 0.6931471805599453
iteration 6 batch 14770 training_loss 0.6931471805599453
iteration 6 batch 14780 training_loss 0.6931471805599453
iteration 6 batch 14790 training_loss 0.6931471805599453
iteration 6 batch 14800 training_loss 0.6931471805599453
iteration 6 batch 14810 training_loss 0.6931471805599453
iteration 6 batch 14820 training_loss 0.6931471805599453
iteration 6 batch 14830 training_loss 0.6931471805599453
iteration 6 batch 14840 training_loss 0.6931471805599453
iteration 6 batch 14850 training_loss 0.6931471805599453
iteration 6 batch 14860 training_loss 0.6931471805599453
iteration 6 batch 14870 training_loss 0.6931471805599453
iteration 6 batch 14880 training_loss 0.6931471805599453
iteration 6 batch 14890 training_loss 0.6931471805599453
iteration 6 batch 14900 training_loss 0.6931471805599453
iteration 6 batch 14910 training_loss 0.6931471805599453
iteration 6 batch 14920 training_loss 0.6931471805599453
iteration 6 batch 14930 training_loss 0.6931471805599453
iteration 6 batch 14940 training_loss 0.6931471805599453
iteration 6 batch 14950 training_loss 0.6931471805599453
iteration 6 batch 14960 training_loss 0.6931471805599453
iteration 6 batch 14970 training_loss 0.6931471805599453
iteration 6 batch 14980 training_loss 0.6931471805599453
iteration 6 batch 14990 training_loss 0.6931471805599453
iteration 6 batch 15000 training_loss 0.6931471805599453
iteration 6 batch 15010 training_loss 0.6931471805599453
iteration 6 batch 15020 training_loss 0.6931471805599453
iteration 6 batch 15030 training_loss 0.6931471805599453
iteration 6 batch 15040 training_loss 0.6931471805599453
iteration 6 batch 15050 training_loss 0.6931471805599453
iteration 6 batch 15060 training_loss 0.6931471805599453
iteration 6 batch 15070 training_loss 0.6931471805599453
iteration 6 batch 15080 training_loss 0.6931471805599453
iteration 6 batch 15090 training_loss 0.6931471805599453
iteration 6 batch 15100 training_loss 0.6916632528527511
iteration 6 batch 15110 training_loss 0.6931471805599453
iteration 6 batch 15120 training_loss 0.6931471805599453
iteration 6 batch 15130 training_loss 0.6931471805599453
iteration 6 batch 15140 training_loss 0.6931471805599453
iteration 6 batch 15150 training_loss 0.6931471805599453
iteration 6 batch 15160 training_loss 0.6931471805599453
iteration 6 batch 15170 training_loss 0.6931471805599453
iteration 6 batch 15180 training_loss 0.6931471805599453
iteration 6 batch 15190 training_loss 0.6931471805599453
iteration 6 batch 15200 training_loss 0.6931471805599453
iteration 6 batch 15210 training_loss 0.6931471805599453
iteration 6 batch 15220 training_loss 0.6931471805599453
iteration 6 batch 15230 training_loss 0.6931471805599453
iteration 6 batch 15240 training_loss 0.6931471805599453
iteration 6 batch 15250 training_loss 0.6931471805599453
iteration 6 batch 15260 training_loss 0.6931471805599453
iteration 6 batch 15270 training_loss 0.6931471805599453
iteration 6 batch 15280 training_loss 0.6931471805599453
iteration 6 batch 15290 training_loss 0.6931471805599453
iteration 6 batch 15300 training_loss 0.6931471805599453
iteration 6 batch 15310 training_loss 0.6931471805599453
iteration 6 batch 15320 training_loss 0.6931471805599453
iteration 6 batch 15330 training_loss 0.6931471805599453
iteration 6 batch 15340 training_loss 0.6931471805599453
iteration 6 batch 15350 training_loss 0.6931471805599453
iteration 6 batch 15360 training_loss 0.6931471805599453
iteration 6 batch 15370 training_loss 0.6931471805599453
iteration 6 batch 15380 training_loss 0.6931471805599453
iteration 6 batch 15390 training_loss 0.6931471805599453
iteration 6 batch 15400 training_loss 0.6931471805599453
iteration 6 batch 15410 training_loss 0.6931471805599453
iteration 6 batch 15420 training_loss 0.6931471805599453
iteration 6 batch 15430 training_loss 0.6931471805599453
iteration 6 batch 15440 training_loss 0.6916632528527511
iteration 6 batch 15450 training_loss 0.6931471805599453
iteration 6 batch 15460 training_loss 0.6931471805599453
iteration 6 batch 15470 training_loss 0.6931471805599453
iteration 6 batch 15480 training_loss 0.6931471805599453
iteration 6 batch 15490 training_loss 0.6931471805599453
iteration 6 batch 15500 training_loss 0.6931471805599453
iteration 6 batch 15510 training_loss 0.6931471805599453
iteration 6 batch 15520 training_loss 0.6931471805599453
iteration 6 batch 15530 training_loss 0.6931471805599453
iteration 6 batch 15540 training_loss 0.6931471805599453
iteration 6 batch 15550 training_loss 0.6931471805599453
iteration 6 batch 15560 training_loss 0.6931471805599453
iteration 6 batch 15570 training_loss 0.6931471805599453
iteration 6 batch 15580 training_loss 0.6931471805599453
iteration 6 batch 15590 training_loss 0.6916632528527511
iteration 6 batch 15600 training_loss 0.6931471805599453
iteration 6 batch 15610 training_loss 0.6931471805599453
iteration 6 batch 15620 training_loss 0.6931471805599453
iteration 6 batch 15630 training_loss 0.6931471805599453
iteration 6 batch 15640 training_loss 0.6931471805599453
iteration 6 batch 15650 training_loss 0.6931471805599453
iteration 6 batch 15660 training_loss 0.6931471805599453
iteration 6 batch 15670 training_loss 0.6931471805599453
iteration 6 batch 15680 training_loss 0.6931471805599453
iteration 6 batch 15690 training_loss 0.6931471805599453
iteration 6 batch 15700 training_loss 0.6931471805599453
iteration 6 batch 15710 training_loss 0.6931471805599453
iteration 6 batch 15720 training_loss 0.6931471805599453
iteration 6 batch 15730 training_loss 0.6931471805599453
iteration 6 batch 15740 training_loss 0.6931471805599453
iteration 6 batch 15750 training_loss 0.6931471805599453
iteration 6 batch 15760 training_loss 0.6931471805599453
iteration 6 batch 15770 training_loss 0.6931471805599453
iteration 6 batch 15780 training_loss 0.6931471805599453
iteration 6 batch 15790 training_loss 0.6931471805599453
iteration 6 batch 15800 training_loss 0.6931471805599453
iteration 6 batch 15810 training_loss 0.6931471805599453
iteration 6 batch 15820 training_loss 0.6931471805599453
iteration 6 batch 15830 training_loss 0.6931471805599453
iteration 6 batch 15840 training_loss 0.6931471805599453
iteration 6 batch 15850 training_loss 0.6931471805599453
iteration 6 batch 15860 training_loss 0.6931471805599453
iteration 6 batch 15870 training_loss 0.6931471805599453
iteration 6 batch 15880 training_loss 0.6931471805599453
iteration 6 batch 15890 training_loss 0.6931471805599453
iteration 6 batch 15900 training_loss 0.6931471805599453
iteration 6 batch 15910 training_loss 0.6931471805599453
iteration 6 batch 15920 training_loss 0.6931471805599453
iteration 6 batch 15930 training_loss 0.6931471805599453
iteration 6 batch 15940 training_loss 0.6931471805599453
iteration 6 batch 15950 training_loss 0.6931471805599453
iteration 6 batch 15960 training_loss 0.6931471805599453
iteration 6 batch 15970 training_loss 0.6931471805599453
iteration 6 batch 15980 training_loss 0.6931471805599453
iteration 6 batch 15990 training_loss 0.6931471805599453
iteration 6 batch 16000 training_loss 0.6931471805599453
iteration 6 batch 16010 training_loss 0.6931471805599453
iteration 6 batch 16020 training_loss 0.6931471805599453
iteration 6 batch 16030 training_loss 0.6931471805599453
iteration 6 batch 16040 training_loss 0.6931471805599453
iteration 6 batch 16050 training_loss 0.6931471805599453
iteration 6 batch 16060 training_loss 0.6931471805599453
iteration 6 batch 16070 training_loss 0.6931471805599453
iteration 6 batch 16080 training_loss 0.6931471805599453
iteration 6 batch 16090 training_loss 0.6931471805599453
iteration 6 batch 16100 training_loss 0.6931471805599453
iteration 6 batch 16110 training_loss 0.6931471805599453
iteration 6 batch 16120 training_loss 0.6931471805599453
iteration 6 batch 16130 training_loss 0.6931471805599453
iteration 6 batch 16140 training_loss 0.6931471805599453
iteration 6 batch 16150 training_loss 0.6931471805599453
iteration 6 batch 16160 training_loss 0.6916632528527511
iteration 6 batch 16170 training_loss 0.6931471805599453
iteration 6 batch 16180 training_loss 0.6931471805599453
iteration 6 batch 16190 training_loss 0.6931471805599453
iteration 6 batch 16200 training_loss 0.6931471805599453
iteration 6 batch 16210 training_loss 0.6931471805599453
iteration 6 batch 16220 training_loss 0.6931471805599453
iteration 6 batch 16230 training_loss 0.6931471805599453
iteration 6 batch 16240 training_loss 0.6931471805599453
iteration 6 batch 16250 training_loss 0.6931471805599453
iteration 6 batch 16260 training_loss 0.6931471805599453
iteration 6 batch 16270 training_loss 0.6931471805599453
iteration 6 batch 16280 training_loss 0.6931471805599453
iteration 6 batch 16290 training_loss 0.6931471805599453
iteration 6 batch 16300 training_loss 0.6931471805599453
iteration 6 batch 16310 training_loss 0.6931471805599453
iteration 6 batch 16320 training_loss 0.6931471805599453
iteration 6 batch 16330 training_loss 0.6931471805599453
iteration 6 batch 16340 training_loss 0.6931471805599453
iteration 6 batch 16350 training_loss 0.6931471805599453
iteration 6 batch 16360 training_loss 0.6901793251455568
iteration 6 batch 16370 training_loss 0.6931471805599453
iteration 6 batch 16380 training_loss 0.6931471805599453
iteration 6 batch 16390 training_loss 0.6931471805599453
iteration 6 batch 16400 training_loss 0.6931471805599453
iteration 6 batch 16410 training_loss 0.6931471805599453
iteration 6 batch 16420 training_loss 0.6931471805599453
iteration 6 batch 16430 training_loss 0.6931471805599453
iteration 6 batch 16440 training_loss 0.6931471805599453
iteration 6 batch 16450 training_loss 0.6931471805599453
iteration 6 batch 16460 training_loss 0.6931471805599453
iteration 6 batch 16470 training_loss 0.6916632528527511
iteration 6 batch 16480 training_loss 0.6931471805599453
iteration 6 batch 16490 training_loss 0.6931471805599453
iteration 6 batch 16500 training_loss 0.6931471805599453
iteration 6 batch 16510 training_loss 0.6916632528527511
iteration 6 batch 16520 training_loss 0.6931471805599453
iteration 6 batch 16530 training_loss 0.6931471805599453
iteration 6 batch 16540 training_loss 0.6931471805599453
iteration 6 batch 16550 training_loss 0.6931471805599453
iteration 6 batch 16560 training_loss 0.6916632528527511
iteration 6 batch 16570 training_loss 0.6931471805599453
iteration 6 batch 16580 training_loss 0.6931471805599453
iteration 6 batch 16590 training_loss 0.6931471805599453
iteration 6 batch 16600 training_loss 0.6931471805599453
iteration 6 batch 16610 training_loss 0.6931471805599453
iteration 6 batch 16620 training_loss 0.6931471805599453
iteration 6 batch 16630 training_loss 0.6931471805599453
iteration 6 batch 16640 training_loss 0.6931471805599453
iteration 6 batch 16650 training_loss 0.6931471805599453
iteration 6 batch 16660 training_loss 0.6931471805599453
iteration 6 batch 16670 training_loss 0.6931471805599453
iteration 6 batch 16680 training_loss 0.6931471805599453
iteration 6 batch 16690 training_loss 0.6931471805599453
iteration 6 batch 16700 training_loss 0.6931471805599453
iteration 6 batch 16710 training_loss 0.6916632528527511
iteration 6 batch 16720 training_loss 0.6931471805599453
iteration 6 batch 16730 training_loss 0.6931471805599453
iteration 6 batch 16740 training_loss 0.6931471805599453
iteration 6 batch 16750 training_loss 0.6931471805599453
iteration 6 batch 16760 training_loss 0.6931471805599453
iteration 6 batch 16770 training_loss 0.6931471805599453
iteration 6 batch 16780 training_loss 0.6931471805599453
iteration 6 batch 16790 training_loss 0.6931471805599453
iteration 6 batch 16800 training_loss 0.6931471805599453
iteration 6 batch 16810 training_loss 0.6931471805599453
iteration 6 batch 16820 training_loss 0.6931471805599453
iteration 6 batch 16830 training_loss 0.6931471805599453
iteration 6 batch 16840 training_loss 0.6931471805599453
iteration 6 batch 16850 training_loss 0.6931471805599453
iteration 6 batch 16860 training_loss 0.6931471805599453
iteration 6 batch 16870 training_loss 0.6931471805599453
iteration 6 batch 16880 training_loss 0.6931471805599453
iteration 6 batch 16890 training_loss 0.6931471805599453
iteration 6 batch 16900 training_loss 0.6931471805599453
iteration 6 batch 16910 training_loss 0.6931471805599453
iteration 6 batch 16920 training_loss 0.6931471805599453
iteration 6 batch 16930 training_loss 0.6931471805599453
iteration 6 batch 16940 training_loss 0.6916632528527511
iteration 6 batch 16950 training_loss 0.6931471805599453
iteration 6 batch 16960 training_loss 0.6931471805599453
iteration 6 batch 16970 training_loss 0.6931471805599453
iteration 6 batch 16980 training_loss 0.6931471805599453
iteration 6 batch 16990 training_loss 0.6931471805599453
iteration 6 batch 17000 training_loss 0.6931471805599453
iteration 6 batch 17010 training_loss 0.6931471805599453
iteration 6 batch 17020 training_loss 0.6931471805599453
iteration 6 batch 17030 training_loss 0.6931471805599453
iteration 6 batch 17040 training_loss 0.6931471805599453
iteration 6 batch 17050 training_loss 0.6931471805599453
iteration 6 batch 17060 training_loss 0.6931471805599453
iteration 6 batch 17070 training_loss 0.6931471805599453
iteration 6 batch 17080 training_loss 0.6931471805599453
iteration 6 batch 17090 training_loss 0.6931471805599453
iteration 6 batch 17100 training_loss 0.6931471805599453
iteration 6 batch 17110 training_loss 0.6916632528527511
iteration 6 batch 17120 training_loss 0.6931471805599453
iteration 6 batch 17130 training_loss 0.6931471805599453
iteration 6 batch 17140 training_loss 0.6931471805599453
iteration 6 batch 17150 training_loss 0.6931471805599453
iteration 6 batch 17160 training_loss 0.6931471805599453
iteration 6 batch 17170 training_loss 0.6931471805599453
iteration 6 batch 17180 training_loss 0.6931471805599453
iteration 6 batch 17190 training_loss 0.6916632528527511
iteration 6 batch 17200 training_loss 0.6931471805599453
iteration 6 batch 17210 training_loss 0.6931471805599453
iteration 6 batch 17220 training_loss 0.6931471805599453
iteration 6 batch 17230 training_loss 0.6931471805599453
iteration 6 batch 17240 training_loss 0.6931471805599453
iteration 6 batch 17250 training_loss 0.6931471805599453
iteration 6 batch 17260 training_loss 0.6931471805599453
iteration 6 batch 17270 training_loss 0.6931471805599453
iteration 6 batch 17280 training_loss 0.6931471805599453
iteration 6 batch 17290 training_loss 0.6931471805599453
iteration 6 batch 17300 training_loss 0.6931471805599453
iteration 6 batch 17310 training_loss 0.6931471805599453
iteration 6 batch 17320 training_loss 0.6931471805599453
iteration 6 batch 17330 training_loss 0.6931471805599453
iteration 6 batch 17340 training_loss 0.6931471805599453
iteration 6 batch 17350 training_loss 0.6931471805599453
iteration 6 batch 17360 training_loss 0.6931471805599453
iteration 6 batch 17370 training_loss 0.6931471805599453
iteration 6 batch 17380 training_loss 0.6931471805599453
iteration 6 batch 17390 training_loss 0.6931471805599453
iteration 6 batch 17400 training_loss 0.6931471805599453
iteration 6 batch 17410 training_loss 0.6916632528527511
iteration 6 batch 17420 training_loss 0.6931471805599453
iteration 6 batch 17430 training_loss 0.6931471805599453
iteration 6 batch 17440 training_loss 0.6916632528527511
iteration 6 batch 17450 training_loss 0.6931471805599453
iteration 6 batch 17460 training_loss 0.6931471805599453
iteration 6 batch 17470 training_loss 0.6931471805599453
iteration 6 batch 17480 training_loss 0.6916632528527511
iteration 6 batch 17490 training_loss 0.6931471805599453
iteration 6 batch 17500 training_loss 0.6931471805599453
iteration 6 batch 17510 training_loss 0.6931471805599453
iteration 6 batch 17520 training_loss 0.6931471805599453
iteration 6 batch 17530 training_loss 0.6931471805599453
iteration 6 batch 17540 training_loss 0.6931471805599453
iteration 6 batch 17550 training_loss 0.6931471805599453
iteration 6 batch 17560 training_loss 0.6931471805599453
iteration 6 batch 17570 training_loss 0.6916632528527511
iteration 6 batch 17580 training_loss 0.6931471805599453
iteration 6 batch 17590 training_loss 0.6931471805599453
iteration 6 batch 17600 training_loss 0.6931471805599453
iteration 6 batch 17610 training_loss 0.6931471805599453
iteration 6 batch 17620 training_loss 0.6931471805599453
iteration 6 batch 17630 training_loss 0.6931471805599453
iteration 6 batch 17640 training_loss 0.6931471805599453
iteration 6 batch 17650 training_loss 0.6931471805599453
iteration 6 batch 17660 training_loss 0.6931471805599453
iteration 6 batch 17670 training_loss 0.6931471805599453
iteration 6 batch 17680 training_loss 0.6916632528527511
iteration 6 batch 17690 training_loss 0.6931471805599453
iteration 6 batch 17700 training_loss 0.6931471805599453
iteration 6 batch 17710 training_loss 0.6931471805599453
iteration 6 batch 17720 training_loss 0.6931471805599453
iteration 6 batch 17730 training_loss 0.6931471805599453
iteration 6 batch 17740 training_loss 0.6931471805599453
iteration 6 batch 17750 training_loss 0.6931471805599453
iteration 6 batch 17760 training_loss 0.6931471805599453
iteration 6 batch 17770 training_loss 0.6931471805599453
iteration 6 batch 17780 training_loss 0.6931471805599453
iteration 6 batch 17790 training_loss 0.6931471805599453
iteration 6 batch 17800 training_loss 0.6931471805599453
iteration 6 batch 17810 training_loss 0.6931471805599453
iteration 6 batch 17820 training_loss 0.6931471805599453
iteration 6 batch 17830 training_loss 0.6931471805599453
iteration 6 batch 17840 training_loss 0.6931471805599453
iteration 6 batch 17850 training_loss 0.6931471805599453
iteration 6 batch 17860 training_loss 0.6931471805599453
iteration 6 batch 17870 training_loss 0.6916632528527511
iteration 6 batch 17880 training_loss 0.6931471805599453
iteration 6 batch 17890 training_loss 0.6931471805599453
iteration 6 batch 17900 training_loss 0.6931471805599453
iteration 6 batch 17910 training_loss 0.6931471805599453
iteration 6 batch 17920 training_loss 0.6931471805599453
iteration 6 batch 17930 training_loss 0.6931471805599453
iteration 6 batch 17940 training_loss 0.6931471805599453
iteration 6 batch 17950 training_loss 0.6931471805599453
iteration 6 batch 17960 training_loss 0.6931471805599453
iteration 6 batch 17970 training_loss 0.6931471805599453
iteration 6 batch 17980 training_loss 0.6931471805599453
iteration 6 batch 17990 training_loss 0.6931471805599453
iteration 6 batch 18000 training_loss 0.6931471805599453
iteration 6 batch 18010 training_loss 0.6916632528527511
iteration 6 batch 18020 training_loss 0.6931471805599453
iteration 6 batch 18030 training_loss 0.6931471805599453
iteration 6 batch 18040 training_loss 0.6931471805599453
iteration 6 batch 18050 training_loss 0.6931471805599453
iteration 6 batch 18060 training_loss 0.6931471805599453
iteration 6 batch 18070 training_loss 0.6916632528527511
iteration 6 batch 18080 training_loss 0.6931471805599453
iteration 6 batch 18090 training_loss 0.6931471805599453
iteration 6 batch 18100 training_loss 0.6931471805599453
iteration 6 batch 18110 training_loss 0.6931471805599453
iteration 6 batch 18120 training_loss 0.6931471805599453
iteration 6 batch 18130 training_loss 0.6931471805599453
iteration 6 batch 18140 training_loss 0.6931471805599453
iteration 6 batch 18150 training_loss 0.6931471805599453
iteration 6 batch 18160 training_loss 0.6916632528527511
iteration 6 batch 18170 training_loss 0.6931471805599453
iteration 6 batch 18180 training_loss 0.6931471805599453
iteration 6 batch 18190 training_loss 0.6931471805599453
iteration 6 batch 18200 training_loss 0.6931471805599453
iteration 6 batch 18210 training_loss 0.6931471805599453
iteration 6 batch 18220 training_loss 0.6931471805599453
iteration 6 batch 18230 training_loss 0.6931471805599453
iteration 6 batch 18240 training_loss 0.6931471805599453
iteration 6 batch 18250 training_loss 0.6931471805599453
iteration 6 batch 18260 training_loss 0.6916632528527511
iteration 6 batch 18270 training_loss 0.6916632528527511
iteration 6 batch 18280 training_loss 0.6931471805599453
iteration 6 batch 18290 training_loss 0.6931471805599453
iteration 6 batch 18300 training_loss 0.6931471805599453
iteration 6 batch 18310 training_loss 0.6931471805599453
iteration 6 batch 18320 training_loss 0.6931471805599453
iteration 6 batch 18330 training_loss 0.6931471805599453
iteration 6 batch 18340 training_loss 0.6931471805599453
iteration 6 batch 18350 training_loss 0.6931471805599453
iteration 6 batch 18360 training_loss 0.6931471805599453
iteration 6 batch 18370 training_loss 0.6931471805599453
iteration 6 batch 18380 training_loss 0.6931471805599453
iteration 6 batch 18390 training_loss 0.6931471805599453
iteration 6 batch 18400 training_loss 0.6931471805599453
iteration 6 batch 18410 training_loss 0.6931471805599453
iteration 6 batch 18420 training_loss 0.6916632528527511
iteration 6 batch 18430 training_loss 0.6931471805599453
iteration 6 batch 18440 training_loss 0.6931471805599453
iteration 6 batch 18450 training_loss 0.6916632528527511
iteration 6 batch 18460 training_loss 0.6931471805599453
iteration 6 batch 18470 training_loss 0.6931471805599453
iteration 6 batch 18480 training_loss 0.6931471805599453
iteration 6 batch 18490 training_loss 0.6931471805599453
iteration 6 batch 18500 training_loss 0.6931471805599453
iteration 6 batch 18510 training_loss 0.6931471805599453
iteration 6 batch 18520 training_loss 0.6931471805599453
iteration 6 batch 18530 training_loss 0.6931471805599453
iteration 6 batch 18540 training_loss 0.6931471805599453
iteration 6 batch 18550 training_loss 0.6931471805599453
iteration 6 batch 18560 training_loss 0.6931471805599453
iteration 6 batch 18570 training_loss 0.6931471805599453
iteration 6 batch 18580 training_loss 0.6931471805599453
iteration 6 batch 18590 training_loss 0.6931471805599453
iteration 6 batch 18600 training_loss 0.6931471805599453
iteration 6 batch 18610 training_loss 0.6931471805599453
iteration 7 batch 0 training_loss 0.6931471805599453
iteration 7 batch 10 training_loss 0.6931471805599453
iteration 7 batch 20 training_loss 0.6931471805599453
iteration 7 batch 30 training_loss 0.6931471805599453
iteration 7 batch 40 training_loss 0.6931471805599453
iteration 7 batch 50 training_loss 0.6931471805599453
iteration 7 batch 60 training_loss 0.6916632528527511
iteration 7 batch 70 training_loss 0.6931471805599453
iteration 7 batch 80 training_loss 0.6931471805599453
iteration 7 batch 90 training_loss 0.6931471805599453
iteration 7 batch 100 training_loss 0.6931471805599453
iteration 7 batch 110 training_loss 0.6931471805599453
iteration 7 batch 120 training_loss 0.6931471805599453
iteration 7 batch 130 training_loss 0.6931471805599453
iteration 7 batch 140 training_loss 0.6931471805599453
iteration 7 batch 150 training_loss 0.6931471805599453
iteration 7 batch 160 training_loss 0.6931471805599453
iteration 7 batch 170 training_loss 0.6931471805599453
iteration 7 batch 180 training_loss 0.6931471805599453
iteration 7 batch 190 training_loss 0.6931471805599453
iteration 7 batch 200 training_loss 0.6931471805599453
iteration 7 batch 210 training_loss 0.6931471805599453
iteration 7 batch 220 training_loss 0.6931471805599453
iteration 7 batch 230 training_loss 0.6931471805599453
iteration 7 batch 240 training_loss 0.6931471805599453
iteration 7 batch 250 training_loss 0.6931471805599453
iteration 7 batch 260 training_loss 0.6931471805599453
iteration 7 batch 270 training_loss 0.6931471805599453
iteration 7 batch 280 training_loss 0.6931471805599453
iteration 7 batch 290 training_loss 0.6931471805599453
iteration 7 batch 300 training_loss 0.6931471805599453
iteration 7 batch 310 training_loss 0.6931471805599453
iteration 7 batch 320 training_loss 0.6931471805599453
iteration 7 batch 330 training_loss 0.6931471805599453
iteration 7 batch 340 training_loss 0.6931471805599453
iteration 7 batch 350 training_loss 0.6931471805599453
iteration 7 batch 360 training_loss 0.6931471805599453
iteration 7 batch 370 training_loss 0.6931471805599453
iteration 7 batch 380 training_loss 0.6931471805599453
iteration 7 batch 390 training_loss 0.6931471805599453
iteration 7 batch 400 training_loss 0.6931471805599453
iteration 7 batch 410 training_loss 0.6931471805599453
iteration 7 batch 420 training_loss 0.6931471805599453
iteration 7 batch 430 training_loss 0.6916632528527511
iteration 7 batch 440 training_loss 0.6931471805599453
iteration 7 batch 450 training_loss 0.6931471805599453
iteration 7 batch 460 training_loss 0.6931471805599453
iteration 7 batch 470 training_loss 0.6931471805599453
iteration 7 batch 480 training_loss 0.6931471805599453
iteration 7 batch 490 training_loss 0.6931471805599453
iteration 7 batch 500 training_loss 0.6931471805599453
iteration 7 batch 510 training_loss 0.6931471805599453
iteration 7 batch 520 training_loss 0.6931471805599453
iteration 7 batch 530 training_loss 0.6931471805599453
iteration 7 batch 540 training_loss 0.6931471805599453
iteration 7 batch 550 training_loss 0.6931471805599453
iteration 7 batch 560 training_loss 0.6931471805599453
iteration 7 batch 570 training_loss 0.6916632528527511
iteration 7 batch 580 training_loss 0.6931471805599453
iteration 7 batch 590 training_loss 0.6931471805599453
iteration 7 batch 600 training_loss 0.6931471805599453
iteration 7 batch 610 training_loss 0.6931471805599453
iteration 7 batch 620 training_loss 0.6931471805599453
iteration 7 batch 630 training_loss 0.6931471805599453
iteration 7 batch 640 training_loss 0.6931471805599453
iteration 7 batch 650 training_loss 0.6931471805599453
iteration 7 batch 660 training_loss 0.6931471805599453
iteration 7 batch 670 training_loss 0.6931471805599453
iteration 7 batch 680 training_loss 0.6931471805599453
iteration 7 batch 690 training_loss 0.6931471805599453
iteration 7 batch 700 training_loss 0.6931471805599453
iteration 7 batch 710 training_loss 0.6931471805599453
iteration 7 batch 720 training_loss 0.6931471805599453
iteration 7 batch 730 training_loss 0.6916632528527511
iteration 7 batch 740 training_loss 0.6931471805599453
iteration 7 batch 750 training_loss 0.6916632528527511
iteration 7 batch 760 training_loss 0.6931471805599453
iteration 7 batch 770 training_loss 0.6931471805599453
iteration 7 batch 780 training_loss 0.6931471805599453
iteration 7 batch 790 training_loss 0.6931471805599453
iteration 7 batch 800 training_loss 0.6916632528527511
iteration 7 batch 810 training_loss 0.6931471805599453
iteration 7 batch 820 training_loss 0.6931471805599453
iteration 7 batch 830 training_loss 0.6931471805599453
iteration 7 batch 840 training_loss 0.6931471805599453
iteration 7 batch 850 training_loss 0.6931471805599453
iteration 7 batch 860 training_loss 0.6931471805599453
iteration 7 batch 870 training_loss 0.6931471805599453
iteration 7 batch 880 training_loss 0.6931471805599453
iteration 7 batch 890 training_loss 0.6931471805599453
iteration 7 batch 900 training_loss 0.6931471805599453
iteration 7 batch 910 training_loss 0.6931471805599453
iteration 7 batch 920 training_loss 0.6931471805599453
iteration 7 batch 930 training_loss 0.6931471805599453
iteration 7 batch 940 training_loss 0.6931471805599453
iteration 7 batch 950 training_loss 0.6931471805599453
iteration 7 batch 960 training_loss 0.6931471805599453
iteration 7 batch 970 training_loss 0.6931471805599453
iteration 7 batch 980 training_loss 0.6931471805599453
iteration 7 batch 990 training_loss 0.6931471805599453
iteration 7 batch 1000 training_loss 0.6931471805599453
iteration 7 batch 1010 training_loss 0.6931471805599453
iteration 7 batch 1020 training_loss 0.6931471805599453
iteration 7 batch 1030 training_loss 0.6931471805599453
iteration 7 batch 1040 training_loss 0.6931471805599453
iteration 7 batch 1050 training_loss 0.6931471805599453
iteration 7 batch 1060 training_loss 0.6931471805599453
iteration 7 batch 1070 training_loss 0.6931471805599453
iteration 7 batch 1080 training_loss 0.6931471805599453
iteration 7 batch 1090 training_loss 0.6931471805599453
iteration 7 batch 1100 training_loss 0.6931471805599453
iteration 7 batch 1110 training_loss 0.6931471805599453
iteration 7 batch 1120 training_loss 0.6931471805599453
iteration 7 batch 1130 training_loss 0.6931471805599453
iteration 7 batch 1140 training_loss 0.6931471805599453
iteration 7 batch 1150 training_loss 0.6931471805599453
iteration 7 batch 1160 training_loss 0.6931471805599453
iteration 7 batch 1170 training_loss 0.6931471805599453
iteration 7 batch 1180 training_loss 0.6931471805599453
iteration 7 batch 1190 training_loss 0.6931471805599453
iteration 7 batch 1200 training_loss 0.6931471805599453
iteration 7 batch 1210 training_loss 0.6931471805599453
iteration 7 batch 1220 training_loss 0.6931471805599453
iteration 7 batch 1230 training_loss 0.6931471805599453
iteration 7 batch 1240 training_loss 0.6931471805599453
iteration 7 batch 1250 training_loss 0.6931471805599453
iteration 7 batch 1260 training_loss 0.6931471805599453
iteration 7 batch 1270 training_loss 0.6931471805599453
iteration 7 batch 1280 training_loss 0.6931471805599453
iteration 7 batch 1290 training_loss 0.6931471805599453
iteration 7 batch 1300 training_loss 0.6931471805599453
iteration 7 batch 1310 training_loss 0.6931471805599453
iteration 7 batch 1320 training_loss 0.6916632528527511
iteration 7 batch 1330 training_loss 0.6931471805599453
iteration 7 batch 1340 training_loss 0.6931471805599453
iteration 7 batch 1350 training_loss 0.6916632528527511
iteration 7 batch 1360 training_loss 0.6931471805599453
iteration 7 batch 1370 training_loss 0.6916632528527511
iteration 7 batch 1380 training_loss 0.6916632528527511
iteration 7 batch 1390 training_loss 0.6931471805599453
iteration 7 batch 1400 training_loss 0.6931471805599453
iteration 7 batch 1410 training_loss 0.6931471805599453
iteration 7 batch 1420 training_loss 0.6931471805599453
iteration 7 batch 1430 training_loss 0.6931471805599453
iteration 7 batch 1440 training_loss 0.6931471805599453
iteration 7 batch 1450 training_loss 0.6931471805599453
iteration 7 batch 1460 training_loss 0.6931471805599453
iteration 7 batch 1470 training_loss 0.6931471805599453
iteration 7 batch 1480 training_loss 0.6931471805599453
iteration 7 batch 1490 training_loss 0.6931471805599453
iteration 7 batch 1500 training_loss 0.6931471805599453
iteration 7 batch 1510 training_loss 0.6931471805599453
iteration 7 batch 1520 training_loss 0.6931471805599453
iteration 7 batch 1530 training_loss 0.6931471805599453
iteration 7 batch 1540 training_loss 0.6931471805599453
iteration 7 batch 1550 training_loss 0.6931471805599453
iteration 7 batch 1560 training_loss 0.6931471805599453
iteration 7 batch 1570 training_loss 0.6931471805599453
iteration 7 batch 1580 training_loss 0.6931471805599453
iteration 7 batch 1590 training_loss 0.6931471805599453
iteration 7 batch 1600 training_loss 0.6931471805599453
iteration 7 batch 1610 training_loss 0.6931471805599453
iteration 7 batch 1620 training_loss 0.6931471805599453
iteration 7 batch 1630 training_loss 0.6931471805599453
iteration 7 batch 1640 training_loss 0.6916632528527511
iteration 7 batch 1650 training_loss 0.6931471805599453
iteration 7 batch 1660 training_loss 0.6916632528527511
iteration 7 batch 1670 training_loss 0.6916632528527511
iteration 7 batch 1680 training_loss 0.6931471805599453
iteration 7 batch 1690 training_loss 0.6931471805599453
iteration 7 batch 1700 training_loss 0.6931471805599453
iteration 7 batch 1710 training_loss 0.6931471805599453
iteration 7 batch 1720 training_loss 0.6931471805599453
iteration 7 batch 1730 training_loss 0.6931471805599453
iteration 7 batch 1740 training_loss 0.6931471805599453
iteration 7 batch 1750 training_loss 0.6931471805599453
iteration 7 batch 1760 training_loss 0.6931471805599453
iteration 7 batch 1770 training_loss 0.6931471805599453
iteration 7 batch 1780 training_loss 0.6931471805599453
iteration 7 batch 1790 training_loss 0.6931471805599453
iteration 7 batch 1800 training_loss 0.6931471805599453
iteration 7 batch 1810 training_loss 0.6931471805599453
iteration 7 batch 1820 training_loss 0.6931471805599453
iteration 7 batch 1830 training_loss 0.6931471805599453
iteration 7 batch 1840 training_loss 0.6931471805599453
iteration 7 batch 1850 training_loss 0.6931471805599453
iteration 7 batch 1860 training_loss 0.6931471805599453
iteration 7 batch 1870 training_loss 0.6931471805599453
iteration 7 batch 1880 training_loss 0.6931471805599453
iteration 7 batch 1890 training_loss 0.6931471805599453
iteration 7 batch 1900 training_loss 0.6931471805599453
iteration 7 batch 1910 training_loss 0.6931471805599453
iteration 7 batch 1920 training_loss 0.6931471805599453
iteration 7 batch 1930 training_loss 0.6931471805599453
iteration 7 batch 1940 training_loss 0.6931471805599453
iteration 7 batch 1950 training_loss 0.6931471805599453
iteration 7 batch 1960 training_loss 0.6931471805599453
iteration 7 batch 1970 training_loss 0.6931471805599453
iteration 7 batch 1980 training_loss 0.6931471805599453
iteration 7 batch 1990 training_loss 0.6931471805599453
iteration 7 batch 2000 training_loss 0.6931471805599453
iteration 7 batch 2010 training_loss 0.6931471805599453
iteration 7 batch 2020 training_loss 0.6931471805599453
iteration 7 batch 2030 training_loss 0.6931471805599453
iteration 7 batch 2040 training_loss 0.6931471805599453
iteration 7 batch 2050 training_loss 0.6931471805599453
iteration 7 batch 2060 training_loss 0.6931471805599453
iteration 7 batch 2070 training_loss 0.6931471805599453
iteration 7 batch 2080 training_loss 0.6931471805599453
iteration 7 batch 2090 training_loss 0.6931471805599453
iteration 7 batch 2100 training_loss 0.6931471805599453
iteration 7 batch 2110 training_loss 0.6931471805599453
iteration 7 batch 2120 training_loss 0.6931471805599453
iteration 7 batch 2130 training_loss 0.6931471805599453
iteration 7 batch 2140 training_loss 0.6931471805599453
iteration 7 batch 2150 training_loss 0.6931471805599453
iteration 7 batch 2160 training_loss 0.6931471805599453
iteration 7 batch 2170 training_loss 0.6931471805599453
iteration 7 batch 2180 training_loss 0.6931471805599453
iteration 7 batch 2190 training_loss 0.6931471805599453
iteration 7 batch 2200 training_loss 0.6931471805599453
iteration 7 batch 2210 training_loss 0.6931471805599453
iteration 7 batch 2220 training_loss 0.6931471805599453
iteration 7 batch 2230 training_loss 0.6931471805599453
iteration 7 batch 2240 training_loss 0.6931471805599453
iteration 7 batch 2250 training_loss 0.6931471805599453
iteration 7 batch 2260 training_loss 0.6931471805599453
iteration 7 batch 2270 training_loss 0.6931471805599453
iteration 7 batch 2280 training_loss 0.6931471805599453
iteration 7 batch 2290 training_loss 0.6931471805599453
iteration 7 batch 2300 training_loss 0.6931471805599453
iteration 7 batch 2310 training_loss 0.6931471805599453
iteration 7 batch 2320 training_loss 0.6916632528527511
iteration 7 batch 2330 training_loss 0.6916632528527511
iteration 7 batch 2340 training_loss 0.6931471805599453
iteration 7 batch 2350 training_loss 0.6931471805599453
iteration 7 batch 2360 training_loss 0.6931471805599453
iteration 7 batch 2370 training_loss 0.6931471805599453
iteration 7 batch 2380 training_loss 0.6931471805599453
iteration 7 batch 2390 training_loss 0.6931471805599453
iteration 7 batch 2400 training_loss 0.6931471805599453
iteration 7 batch 2410 training_loss 0.6931471805599453
iteration 7 batch 2420 training_loss 0.6931471805599453
iteration 7 batch 2430 training_loss 0.6931471805599453
iteration 7 batch 2440 training_loss 0.6931471805599453
iteration 7 batch 2450 training_loss 0.6931471805599453
iteration 7 batch 2460 training_loss 0.6931471805599453
iteration 7 batch 2470 training_loss 0.6931471805599453
iteration 7 batch 2480 training_loss 0.6931471805599453
iteration 7 batch 2490 training_loss 0.6931471805599453
iteration 7 batch 2500 training_loss 0.6931471805599453
iteration 7 batch 2510 training_loss 0.6931471805599453
iteration 7 batch 2520 training_loss 0.6931471805599453
iteration 7 batch 2530 training_loss 0.6916632528527511
iteration 7 batch 2540 training_loss 0.6916632528527511
iteration 7 batch 2550 training_loss 0.6931471805599453
iteration 7 batch 2560 training_loss 0.6931471805599453
iteration 7 batch 2570 training_loss 0.6931471805599453
iteration 7 batch 2580 training_loss 0.6931471805599453
iteration 7 batch 2590 training_loss 0.6931471805599453
iteration 7 batch 2600 training_loss 0.6916632528527511
iteration 7 batch 2610 training_loss 0.6931471805599453
iteration 7 batch 2620 training_loss 0.6931471805599453
iteration 7 batch 2630 training_loss 0.6931471805599453
iteration 7 batch 2640 training_loss 0.6931471805599453
iteration 7 batch 2650 training_loss 0.6931471805599453
iteration 7 batch 2660 training_loss 0.6931471805599453
iteration 7 batch 2670 training_loss 0.6931471805599453
iteration 7 batch 2680 training_loss 0.6931471805599453
iteration 7 batch 2690 training_loss 0.6931471805599453
iteration 7 batch 2700 training_loss 0.6931471805599453
iteration 7 batch 2710 training_loss 0.6931471805599453
iteration 7 batch 2720 training_loss 0.6931471805599453
iteration 7 batch 2730 training_loss 0.6931471805599453
iteration 7 batch 2740 training_loss 0.6931471805599453
iteration 7 batch 2750 training_loss 0.6931471805599453
iteration 7 batch 2760 training_loss 0.6931471805599453
iteration 7 batch 2770 training_loss 0.6931471805599453
iteration 7 batch 2780 training_loss 0.6931471805599453
iteration 7 batch 2790 training_loss 0.6931471805599453
iteration 7 batch 2800 training_loss 0.6916632528527511
iteration 7 batch 2810 training_loss 0.6931471805599453
iteration 7 batch 2820 training_loss 0.6931471805599453
iteration 7 batch 2830 training_loss 0.6931471805599453
iteration 7 batch 2840 training_loss 0.6931471805599453
iteration 7 batch 2850 training_loss 0.6931471805599453
iteration 7 batch 2860 training_loss 0.6931471805599453
iteration 7 batch 2870 training_loss 0.6931471805599453
iteration 7 batch 2880 training_loss 0.6931471805599453
iteration 7 batch 2890 training_loss 0.6931471805599453
iteration 7 batch 2900 training_loss 0.6931471805599453
iteration 7 batch 2910 training_loss 0.6931471805599453
iteration 7 batch 2920 training_loss 0.6931471805599453
iteration 7 batch 2930 training_loss 0.6931471805599453
iteration 7 batch 2940 training_loss 0.6931471805599453
iteration 7 batch 2950 training_loss 0.6931471805599453
iteration 7 batch 2960 training_loss 0.6931471805599453
iteration 7 batch 2970 training_loss 0.6931471805599453
iteration 7 batch 2980 training_loss 0.6931471805599453
iteration 7 batch 2990 training_loss 0.6931471805599453
iteration 7 batch 3000 training_loss 0.6931471805599453
iteration 7 batch 3010 training_loss 0.6916632528527511
iteration 7 batch 3020 training_loss 0.6931471805599453
iteration 7 batch 3030 training_loss 0.6931471805599453
iteration 7 batch 3040 training_loss 0.6931471805599453
iteration 7 batch 3050 training_loss 0.6931471805599453
iteration 7 batch 3060 training_loss 0.6931471805599453
iteration 7 batch 3070 training_loss 0.6931471805599453
iteration 7 batch 3080 training_loss 0.6931471805599453
iteration 7 batch 3090 training_loss 0.6931471805599453
iteration 7 batch 3100 training_loss 0.6931471805599453
iteration 7 batch 3110 training_loss 0.6931471805599453
iteration 7 batch 3120 training_loss 0.6931471805599453
iteration 7 batch 3130 training_loss 0.6931471805599453
iteration 7 batch 3140 training_loss 0.6931471805599453
iteration 7 batch 3150 training_loss 0.6931471805599453
iteration 7 batch 3160 training_loss 0.6916632528527511
iteration 7 batch 3170 training_loss 0.6931471805599453
iteration 7 batch 3180 training_loss 0.6931471805599453
iteration 7 batch 3190 training_loss 0.6931471805599453
iteration 7 batch 3200 training_loss 0.6916632528527511
iteration 7 batch 3210 training_loss 0.6931471805599453
iteration 7 batch 3220 training_loss 0.6931471805599453
iteration 7 batch 3230 training_loss 0.6931471805599453
iteration 7 batch 3240 training_loss 0.6931471805599453
iteration 7 batch 3250 training_loss 0.6931471805599453
iteration 7 batch 3260 training_loss 0.6931471805599453
iteration 7 batch 3270 training_loss 0.6931471805599453
iteration 7 batch 3280 training_loss 0.6931471805599453
iteration 7 batch 3290 training_loss 0.6931471805599453
iteration 7 batch 3300 training_loss 0.6931471805599453
iteration 7 batch 3310 training_loss 0.6901793251455568
iteration 7 batch 3320 training_loss 0.6931471805599453
iteration 7 batch 3330 training_loss 0.6931471805599453
iteration 7 batch 3340 training_loss 0.6931471805599453
iteration 7 batch 3350 training_loss 0.6931471805599453
iteration 7 batch 3360 training_loss 0.6931471805599453
iteration 7 batch 3370 training_loss 0.6931471805599453
iteration 7 batch 3380 training_loss 0.6931471805599453
iteration 7 batch 3390 training_loss 0.6931471805599453
iteration 7 batch 3400 training_loss 0.6931471805599453
iteration 7 batch 3410 training_loss 0.6931471805599453
iteration 7 batch 3420 training_loss 0.6931471805599453
iteration 7 batch 3430 training_loss 0.6931471805599453
iteration 7 batch 3440 training_loss 0.6931471805599453
iteration 7 batch 3450 training_loss 0.6931471805599453
iteration 7 batch 3460 training_loss 0.6931471805599453
iteration 7 batch 3470 training_loss 0.6931471805599453
iteration 7 batch 3480 training_loss 0.6931471805599453
iteration 7 batch 3490 training_loss 0.6931471805599453
iteration 7 batch 3500 training_loss 0.6916632528527511
iteration 7 batch 3510 training_loss 0.6931471805599453
iteration 7 batch 3520 training_loss 0.6931471805599453
iteration 7 batch 3530 training_loss 0.6931471805599453
iteration 7 batch 3540 training_loss 0.6931471805599453
iteration 7 batch 3550 training_loss 0.6931471805599453
iteration 7 batch 3560 training_loss 0.6931471805599453
iteration 7 batch 3570 training_loss 0.6931471805599453
iteration 7 batch 3580 training_loss 0.6916632528527511
iteration 7 batch 3590 training_loss 0.6931471805599453
iteration 7 batch 3600 training_loss 0.6931471805599453
iteration 7 batch 3610 training_loss 0.6931471805599453
iteration 7 batch 3620 training_loss 0.6931471805599453
iteration 7 batch 3630 training_loss 0.6931471805599453
iteration 7 batch 3640 training_loss 0.6931471805599453
iteration 7 batch 3650 training_loss 0.6931471805599453
iteration 7 batch 3660 training_loss 0.6931471805599453
iteration 7 batch 3670 training_loss 0.6931471805599453
iteration 7 batch 3680 training_loss 0.6931471805599453
iteration 7 batch 3690 training_loss 0.6931471805599453
iteration 7 batch 3700 training_loss 0.6931471805599453
iteration 7 batch 3710 training_loss 0.6931471805599453
iteration 7 batch 3720 training_loss 0.6931471805599453
iteration 7 batch 3730 training_loss 0.6916632528527511
iteration 7 batch 3740 training_loss 0.6931471805599453
iteration 7 batch 3750 training_loss 0.6931471805599453
iteration 7 batch 3760 training_loss 0.6931471805599453
iteration 7 batch 3770 training_loss 0.6931471805599453
iteration 7 batch 3780 training_loss 0.6931471805599453
iteration 7 batch 3790 training_loss 0.6931471805599453
iteration 7 batch 3800 training_loss 0.6931471805599453
iteration 7 batch 3810 training_loss 0.6931471805599453
iteration 7 batch 3820 training_loss 0.6931471805599453
iteration 7 batch 3830 training_loss 0.6931471805599453
iteration 7 batch 3840 training_loss 0.6931471805599453
iteration 7 batch 3850 training_loss 0.6931471805599453
iteration 7 batch 3860 training_loss 0.6931471805599453
iteration 7 batch 3870 training_loss 0.6931471805599453
iteration 7 batch 3880 training_loss 0.6931471805599453
iteration 7 batch 3890 training_loss 0.6931471805599453
iteration 7 batch 3900 training_loss 0.6916632528527511
iteration 7 batch 3910 training_loss 0.6916632528527511
iteration 7 batch 3920 training_loss 0.6931471805599453
iteration 7 batch 3930 training_loss 0.6931471805599453
iteration 7 batch 3940 training_loss 0.6931471805599453
iteration 7 batch 3950 training_loss 0.6931471805599453
iteration 7 batch 3960 training_loss 0.6931471805599453
iteration 7 batch 3970 training_loss 0.6931471805599453
iteration 7 batch 3980 training_loss 0.6931471805599453
iteration 7 batch 3990 training_loss 0.6931471805599453
iteration 7 batch 4000 training_loss 0.6931471805599453
iteration 7 batch 4010 training_loss 0.6916632528527511
iteration 7 batch 4020 training_loss 0.6931471805599453
iteration 7 batch 4030 training_loss 0.6931471805599453
iteration 7 batch 4040 training_loss 0.6931471805599453
iteration 7 batch 4050 training_loss 0.6931471805599453
iteration 7 batch 4060 training_loss 0.6931471805599453
iteration 7 batch 4070 training_loss 0.6931471805599453
iteration 7 batch 4080 training_loss 0.6931471805599453
iteration 7 batch 4090 training_loss 0.6931471805599453
iteration 7 batch 4100 training_loss 0.6916632528527511
iteration 7 batch 4110 training_loss 0.6931471805599453
iteration 7 batch 4120 training_loss 0.6931471805599453
iteration 7 batch 4130 training_loss 0.6931471805599453
iteration 7 batch 4140 training_loss 0.6931471805599453
iteration 7 batch 4150 training_loss 0.6931471805599453
iteration 7 batch 4160 training_loss 0.6931471805599453
iteration 7 batch 4170 training_loss 0.6931471805599453
iteration 7 batch 4180 training_loss 0.6931471805599453
iteration 7 batch 4190 training_loss 0.6931471805599453
iteration 7 batch 4200 training_loss 0.6931471805599453
iteration 7 batch 4210 training_loss 0.6931471805599453
iteration 7 batch 4220 training_loss 0.6931471805599453
iteration 7 batch 4230 training_loss 0.6931471805599453
iteration 7 batch 4240 training_loss 0.6931471805599453
iteration 7 batch 4250 training_loss 0.6931471805599453
iteration 7 batch 4260 training_loss 0.6931471805599453
iteration 7 batch 4270 training_loss 0.6931471805599453
iteration 7 batch 4280 training_loss 0.6931471805599453
iteration 7 batch 4290 training_loss 0.6931471805599453
iteration 7 batch 4300 training_loss 0.6931471805599453
iteration 7 batch 4310 training_loss 0.6931471805599453
iteration 7 batch 4320 training_loss 0.6931471805599453
iteration 7 batch 4330 training_loss 0.6931471805599453
iteration 7 batch 4340 training_loss 0.6931471805599453
iteration 7 batch 4350 training_loss 0.6931471805599453
iteration 7 batch 4360 training_loss 0.6931471805599453
iteration 7 batch 4370 training_loss 0.6931471805599453
iteration 7 batch 4380 training_loss 0.6931471805599453
iteration 7 batch 4390 training_loss 0.6931471805599453
iteration 7 batch 4400 training_loss 0.6931471805599453
iteration 7 batch 4410 training_loss 0.6931471805599453
iteration 7 batch 4420 training_loss 0.6931471805599453
iteration 7 batch 4430 training_loss 0.6931471805599453
iteration 7 batch 4440 training_loss 0.6931471805599453
iteration 7 batch 4450 training_loss 0.6931471805599453
iteration 7 batch 4460 training_loss 0.6931471805599453
iteration 7 batch 4470 training_loss 0.6931471805599453
iteration 7 batch 4480 training_loss 0.6931471805599453
iteration 7 batch 4490 training_loss 0.6931471805599453
iteration 7 batch 4500 training_loss 0.6931471805599453
iteration 7 batch 4510 training_loss 0.6931471805599453
iteration 7 batch 4520 training_loss 0.6931471805599453
iteration 7 batch 4530 training_loss 0.6931471805599453
iteration 7 batch 4540 training_loss 0.6931471805599453
iteration 7 batch 4550 training_loss 0.6931471805599453
iteration 7 batch 4560 training_loss 0.6931471805599453
iteration 7 batch 4570 training_loss 0.6931471805599453
iteration 7 batch 4580 training_loss 0.6931471805599453
iteration 7 batch 4590 training_loss 0.6931471805599453
iteration 7 batch 4600 training_loss 0.6931471805599453
iteration 7 batch 4610 training_loss 0.6931471805599453
iteration 7 batch 4620 training_loss 0.6931471805599453
iteration 7 batch 4630 training_loss 0.6931471805599453
iteration 7 batch 4640 training_loss 0.6931471805599453
iteration 7 batch 4650 training_loss 0.6931471805599453
iteration 7 batch 4660 training_loss 0.6916632528527511
iteration 7 batch 4670 training_loss 0.6931471805599453
iteration 7 batch 4680 training_loss 0.6931471805599453
iteration 7 batch 4690 training_loss 0.6931471805599453
iteration 7 batch 4700 training_loss 0.6931471805599453
iteration 7 batch 4710 training_loss 0.6931471805599453
iteration 7 batch 4720 training_loss 0.6931471805599453
iteration 7 batch 4730 training_loss 0.6931471805599453
iteration 7 batch 4740 training_loss 0.6931471805599453
iteration 7 batch 4750 training_loss 0.6931471805599453
iteration 7 batch 4760 training_loss 0.6931471805599453
iteration 7 batch 4770 training_loss 0.6931471805599453
iteration 7 batch 4780 training_loss 0.6931471805599453
iteration 7 batch 4790 training_loss 0.6931471805599453
iteration 7 batch 4800 training_loss 0.6931471805599453
iteration 7 batch 4810 training_loss 0.6931471805599453
iteration 7 batch 4820 training_loss 0.6931471805599453
iteration 7 batch 4830 training_loss 0.6931471805599453
iteration 7 batch 4840 training_loss 0.6931471805599453
iteration 7 batch 4850 training_loss 0.6931471805599453
iteration 7 batch 4860 training_loss 0.6931471805599453
iteration 7 batch 4870 training_loss 0.6931471805599453
iteration 7 batch 4880 training_loss 0.6916632528527511
iteration 7 batch 4890 training_loss 0.6931471805599453
iteration 7 batch 4900 training_loss 0.6931471805599453
iteration 7 batch 4910 training_loss 0.6931471805599453
iteration 7 batch 4920 training_loss 0.6916632528527511
iteration 7 batch 4930 training_loss 0.6916632528527511
iteration 7 batch 4940 training_loss 0.6931471805599453
iteration 7 batch 4950 training_loss 0.6931471805599453
iteration 7 batch 4960 training_loss 0.6931471805599453
iteration 7 batch 4970 training_loss 0.6931471805599453
iteration 7 batch 4980 training_loss 0.6931471805599453
iteration 7 batch 4990 training_loss 0.6931471805599453
iteration 7 batch 5000 training_loss 0.6931471805599453
iteration 7 batch 5010 training_loss 0.6931471805599453
iteration 7 batch 5020 training_loss 0.6931471805599453
iteration 7 batch 5030 training_loss 0.6931471805599453
iteration 7 batch 5040 training_loss 0.6931471805599453
iteration 7 batch 5050 training_loss 0.6931471805599453
iteration 7 batch 5060 training_loss 0.6931471805599453
iteration 7 batch 5070 training_loss 0.6931471805599453
iteration 7 batch 5080 training_loss 0.6931471805599453
iteration 7 batch 5090 training_loss 0.6931471805599453
iteration 7 batch 5100 training_loss 0.6931471805599453
iteration 7 batch 5110 training_loss 0.6931471805599453
iteration 7 batch 5120 training_loss 0.6931471805599453
iteration 7 batch 5130 training_loss 0.6931471805599453
iteration 7 batch 5140 training_loss 0.6931471805599453
iteration 7 batch 5150 training_loss 0.6916632528527511
iteration 7 batch 5160 training_loss 0.6931471805599453
iteration 7 batch 5170 training_loss 0.6931471805599453
iteration 7 batch 5180 training_loss 0.6931471805599453
iteration 7 batch 5190 training_loss 0.6931471805599453
iteration 7 batch 5200 training_loss 0.6931471805599453
iteration 7 batch 5210 training_loss 0.6916632528527511
iteration 7 batch 5220 training_loss 0.6931471805599453
iteration 7 batch 5230 training_loss 0.6931471805599453
iteration 7 batch 5240 training_loss 0.6931471805599453
iteration 7 batch 5250 training_loss 0.6931471805599453
iteration 7 batch 5260 training_loss 0.6931471805599453
iteration 7 batch 5270 training_loss 0.6916632528527511
iteration 7 batch 5280 training_loss 0.6931471805599453
iteration 7 batch 5290 training_loss 0.6931471805599453
iteration 7 batch 5300 training_loss 0.6931471805599453
iteration 7 batch 5310 training_loss 0.6931471805599453
iteration 7 batch 5320 training_loss 0.6931471805599453
iteration 7 batch 5330 training_loss 0.6931471805599453
iteration 7 batch 5340 training_loss 0.6931471805599453
iteration 7 batch 5350 training_loss 0.6931471805599453
iteration 7 batch 5360 training_loss 0.6931471805599453
iteration 7 batch 5370 training_loss 0.6931471805599453
iteration 7 batch 5380 training_loss 0.6931471805599453
iteration 7 batch 5390 training_loss 0.6931471805599453
iteration 7 batch 5400 training_loss 0.6931471805599453
iteration 7 batch 5410 training_loss 0.6931471805599453
iteration 7 batch 5420 training_loss 0.6931471805599453
iteration 7 batch 5430 training_loss 0.6931471805599453
iteration 7 batch 5440 training_loss 0.6931471805599453
iteration 7 batch 5450 training_loss 0.6931471805599453
iteration 7 batch 5460 training_loss 0.6931471805599453
iteration 7 batch 5470 training_loss 0.6931471805599453
iteration 7 batch 5480 training_loss 0.6931471805599453
iteration 7 batch 5490 training_loss 0.6931471805599453
iteration 7 batch 5500 training_loss 0.6931471805599453
iteration 7 batch 5510 training_loss 0.6931471805599453
iteration 7 batch 5520 training_loss 0.6931471805599453
iteration 7 batch 5530 training_loss 0.6931471805599453
iteration 7 batch 5540 training_loss 0.6931471805599453
iteration 7 batch 5550 training_loss 0.6931471805599453
iteration 7 batch 5560 training_loss 0.6931471805599453
iteration 7 batch 5570 training_loss 0.6916632528527511
iteration 7 batch 5580 training_loss 0.6931471805599453
iteration 7 batch 5590 training_loss 0.6931471805599453
iteration 7 batch 5600 training_loss 0.6931471805599453
iteration 7 batch 5610 training_loss 0.6931471805599453
iteration 7 batch 5620 training_loss 0.6931471805599453
iteration 7 batch 5630 training_loss 0.6931471805599453
iteration 7 batch 5640 training_loss 0.6931471805599453
iteration 7 batch 5650 training_loss 0.6931471805599453
iteration 7 batch 5660 training_loss 0.6931471805599453
iteration 7 batch 5670 training_loss 0.6931471805599453
iteration 7 batch 5680 training_loss 0.6931471805599453
iteration 7 batch 5690 training_loss 0.6931471805599453
iteration 7 batch 5700 training_loss 0.6931471805599453
iteration 7 batch 5710 training_loss 0.6931471805599453
iteration 7 batch 5720 training_loss 0.6931471805599453
iteration 7 batch 5730 training_loss 0.6931471805599453
iteration 7 batch 5740 training_loss 0.6931471805599453
iteration 7 batch 5750 training_loss 0.6916632528527511
iteration 7 batch 5760 training_loss 0.6931471805599453
iteration 7 batch 5770 training_loss 0.6931471805599453
iteration 7 batch 5780 training_loss 0.6916632528527511
iteration 7 batch 5790 training_loss 0.6931471805599453
iteration 7 batch 5800 training_loss 0.6931471805599453
iteration 7 batch 5810 training_loss 0.6931471805599453
iteration 7 batch 5820 training_loss 0.6931471805599453
iteration 7 batch 5830 training_loss 0.6931471805599453
iteration 7 batch 5840 training_loss 0.6931471805599453
iteration 7 batch 5850 training_loss 0.6931471805599453
iteration 7 batch 5860 training_loss 0.6931471805599453
iteration 7 batch 5870 training_loss 0.6931471805599453
iteration 7 batch 5880 training_loss 0.6931471805599453
iteration 7 batch 5890 training_loss 0.6931471805599453
iteration 7 batch 5900 training_loss 0.6931471805599453
iteration 7 batch 5910 training_loss 0.6931471805599453
iteration 7 batch 5920 training_loss 0.6931471805599453
iteration 7 batch 5930 training_loss 0.6931471805599453
iteration 7 batch 5940 training_loss 0.6931471805599453
iteration 7 batch 5950 training_loss 0.6916632528527511
iteration 7 batch 5960 training_loss 0.6931471805599453
iteration 7 batch 5970 training_loss 0.6916632528527511
iteration 7 batch 5980 training_loss 0.6931471805599453
iteration 7 batch 5990 training_loss 0.6931471805599453
iteration 7 batch 6000 training_loss 0.6931471805599453
iteration 7 batch 6010 training_loss 0.6931471805599453
iteration 7 batch 6020 training_loss 0.6931471805599453
iteration 7 batch 6030 training_loss 0.6931471805599453
iteration 7 batch 6040 training_loss 0.6931471805599453
iteration 7 batch 6050 training_loss 0.6931471805599453
iteration 7 batch 6060 training_loss 0.6931471805599453
iteration 7 batch 6070 training_loss 0.6931471805599453
iteration 7 batch 6080 training_loss 0.6931471805599453
iteration 7 batch 6090 training_loss 0.6931471805599453
iteration 7 batch 6100 training_loss 0.6931471805599453
iteration 7 batch 6110 training_loss 0.6931471805599453
iteration 7 batch 6120 training_loss 0.6931471805599453
iteration 7 batch 6130 training_loss 0.6916632528527511
iteration 7 batch 6140 training_loss 0.6916632528527511
iteration 7 batch 6150 training_loss 0.6931471805599453
iteration 7 batch 6160 training_loss 0.6916632528527511
iteration 7 batch 6170 training_loss 0.6931471805599453
iteration 7 batch 6180 training_loss 0.6931471805599453
iteration 7 batch 6190 training_loss 0.6916632528527511
iteration 7 batch 6200 training_loss 0.6931471805599453
iteration 7 batch 6210 training_loss 0.6931471805599453
iteration 7 batch 6220 training_loss 0.6931471805599453
iteration 7 batch 6230 training_loss 0.6931471805599453
iteration 7 batch 6240 training_loss 0.6931471805599453
iteration 7 batch 6250 training_loss 0.6931471805599453
iteration 7 batch 6260 training_loss 0.6931471805599453
iteration 7 batch 6270 training_loss 0.6931471805599453
iteration 7 batch 6280 training_loss 0.6931471805599453
iteration 7 batch 6290 training_loss 0.6931471805599453
iteration 7 batch 6300 training_loss 0.6931471805599453
iteration 7 batch 6310 training_loss 0.6931471805599453
iteration 7 batch 6320 training_loss 0.6931471805599453
iteration 7 batch 6330 training_loss 0.6931471805599453
iteration 7 batch 6340 training_loss 0.6931471805599453
iteration 7 batch 6350 training_loss 0.6931471805599453
iteration 7 batch 6360 training_loss 0.6931471805599453
iteration 7 batch 6370 training_loss 0.6931471805599453
iteration 7 batch 6380 training_loss 0.6931471805599453
iteration 7 batch 6390 training_loss 0.6931471805599453
iteration 7 batch 6400 training_loss 0.6916632528527511
iteration 7 batch 6410 training_loss 0.6931471805599453
iteration 7 batch 6420 training_loss 0.6931471805599453
iteration 7 batch 6430 training_loss 0.6931471805599453
iteration 7 batch 6440 training_loss 0.6916632528527511
iteration 7 batch 6450 training_loss 0.6931471805599453
iteration 7 batch 6460 training_loss 0.6931471805599453
iteration 7 batch 6470 training_loss 0.6931471805599453
iteration 7 batch 6480 training_loss 0.6931471805599453
iteration 7 batch 6490 training_loss 0.6931471805599453
iteration 7 batch 6500 training_loss 0.6931471805599453
iteration 7 batch 6510 training_loss 0.6931471805599453
iteration 7 batch 6520 training_loss 0.6916632528527511
iteration 7 batch 6530 training_loss 0.6931471805599453
iteration 7 batch 6540 training_loss 0.6931471805599453
iteration 7 batch 6550 training_loss 0.6931471805599453
iteration 7 batch 6560 training_loss 0.6931471805599453
iteration 7 batch 6570 training_loss 0.6931471805599453
iteration 7 batch 6580 training_loss 0.6931471805599453
iteration 7 batch 6590 training_loss 0.6931471805599453
iteration 7 batch 6600 training_loss 0.6931471805599453
iteration 7 batch 6610 training_loss 0.6931471805599453
iteration 7 batch 6620 training_loss 0.6931471805599453
iteration 7 batch 6630 training_loss 0.6931471805599453
iteration 7 batch 6640 training_loss 0.6931471805599453
iteration 7 batch 6650 training_loss 0.6931471805599453
iteration 7 batch 6660 training_loss 0.6931471805599453
iteration 7 batch 6670 training_loss 0.6931471805599453
iteration 7 batch 6680 training_loss 0.6931471805599453
iteration 7 batch 6690 training_loss 0.6931471805599453
iteration 7 batch 6700 training_loss 0.6931471805599453
iteration 7 batch 6710 training_loss 0.6931471805599453
iteration 7 batch 6720 training_loss 0.6931471805599453
iteration 7 batch 6730 training_loss 0.6916632528527511
iteration 7 batch 6740 training_loss 0.6931471805599453
iteration 7 batch 6750 training_loss 0.6931471805599453
iteration 7 batch 6760 training_loss 0.6931471805599453
iteration 7 batch 6770 training_loss 0.6931471805599453
iteration 7 batch 6780 training_loss 0.6931471805599453
iteration 7 batch 6790 training_loss 0.6931471805599453
iteration 7 batch 6800 training_loss 0.6931471805599453
iteration 7 batch 6810 training_loss 0.6931471805599453
iteration 7 batch 6820 training_loss 0.6931471805599453
iteration 7 batch 6830 training_loss 0.6931471805599453
iteration 7 batch 6840 training_loss 0.6931471805599453
iteration 7 batch 6850 training_loss 0.6931471805599453
iteration 7 batch 6860 training_loss 0.6931471805599453
iteration 7 batch 6870 training_loss 0.6931471805599453
iteration 7 batch 6880 training_loss 0.6916632528527511
iteration 7 batch 6890 training_loss 0.6931471805599453
iteration 7 batch 6900 training_loss 0.6931471805599453
iteration 7 batch 6910 training_loss 0.6931471805599453
iteration 7 batch 6920 training_loss 0.6931471805599453
iteration 7 batch 6930 training_loss 0.6931471805599453
iteration 7 batch 6940 training_loss 0.6931471805599453
iteration 7 batch 6950 training_loss 0.6931471805599453
iteration 7 batch 6960 training_loss 0.6931471805599453
iteration 7 batch 6970 training_loss 0.6931471805599453
iteration 7 batch 6980 training_loss 0.6931471805599453
iteration 7 batch 6990 training_loss 0.6931471805599453
iteration 7 batch 7000 training_loss 0.6931471805599453
iteration 7 batch 7010 training_loss 0.6931471805599453
iteration 7 batch 7020 training_loss 0.6931471805599453
iteration 7 batch 7030 training_loss 0.6931471805599453
iteration 7 batch 7040 training_loss 0.6931471805599453
iteration 7 batch 7050 training_loss 0.6931471805599453
iteration 7 batch 7060 training_loss 0.6931471805599453
iteration 7 batch 7070 training_loss 0.6931471805599453
iteration 7 batch 7080 training_loss 0.6931471805599453
iteration 7 batch 7090 training_loss 0.6931471805599453
iteration 7 batch 7100 training_loss 0.6931471805599453
iteration 7 batch 7110 training_loss 0.6931471805599453
iteration 7 batch 7120 training_loss 0.6931471805599453
iteration 7 batch 7130 training_loss 0.6931471805599453
iteration 7 batch 7140 training_loss 0.6916632528527511
iteration 7 batch 7150 training_loss 0.6931471805599453
iteration 7 batch 7160 training_loss 0.6931471805599453
iteration 7 batch 7170 training_loss 0.6931471805599453
iteration 7 batch 7180 training_loss 0.6916632528527511
iteration 7 batch 7190 training_loss 0.6931471805599453
iteration 7 batch 7200 training_loss 0.6931471805599453
iteration 7 batch 7210 training_loss 0.6931471805599453
iteration 7 batch 7220 training_loss 0.6916632528527511
iteration 7 batch 7230 training_loss 0.6931471805599453
iteration 7 batch 7240 training_loss 0.6931471805599453
iteration 7 batch 7250 training_loss 0.6916632528527511
iteration 7 batch 7260 training_loss 0.6931471805599453
iteration 7 batch 7270 training_loss 0.6931471805599453
iteration 7 batch 7280 training_loss 0.6931471805599453
iteration 7 batch 7290 training_loss 0.6931471805599453
iteration 7 batch 7300 training_loss 0.6931471805599453
iteration 7 batch 7310 training_loss 0.6931471805599453
iteration 7 batch 7320 training_loss 0.6931471805599453
iteration 7 batch 7330 training_loss 0.6931471805599453
iteration 7 batch 7340 training_loss 0.6931471805599453
iteration 7 batch 7350 training_loss 0.6931471805599453
iteration 7 batch 7360 training_loss 0.6931471805599453
iteration 7 batch 7370 training_loss 0.6931471805599453
iteration 7 batch 7380 training_loss 0.6931471805599453
iteration 7 batch 7390 training_loss 0.6931471805599453
iteration 7 batch 7400 training_loss 0.6931471805599453
iteration 7 batch 7410 training_loss 0.6931471805599453
iteration 7 batch 7420 training_loss 0.6931471805599453
iteration 7 batch 7430 training_loss 0.6931471805599453
iteration 7 batch 7440 training_loss 0.6931471805599453
iteration 7 batch 7450 training_loss 0.6931471805599453
iteration 7 batch 7460 training_loss 0.6931471805599453
iteration 7 batch 7470 training_loss 0.6931471805599453
iteration 7 batch 7480 training_loss 0.6931471805599453
iteration 7 batch 7490 training_loss 0.6931471805599453
iteration 7 batch 7500 training_loss 0.6931471805599453
iteration 7 batch 7510 training_loss 0.6931471805599453
iteration 7 batch 7520 training_loss 0.6931471805599453
iteration 7 batch 7530 training_loss 0.6931471805599453
iteration 7 batch 7540 training_loss 0.6931471805599453
iteration 7 batch 7550 training_loss 0.6931471805599453
iteration 7 batch 7560 training_loss 0.6931471805599453
iteration 7 batch 7570 training_loss 0.6931471805599453
iteration 7 batch 7580 training_loss 0.6931471805599453
iteration 7 batch 7590 training_loss 0.6931471805599453
iteration 7 batch 7600 training_loss 0.6931471805599453
iteration 7 batch 7610 training_loss 0.6901793251455568
iteration 7 batch 7620 training_loss 0.6931471805599453
iteration 7 batch 7630 training_loss 0.6931471805599453
iteration 7 batch 7640 training_loss 0.6931471805599453
iteration 7 batch 7650 training_loss 0.6931471805599453
iteration 7 batch 7660 training_loss 0.6931471805599453
iteration 7 batch 7670 training_loss 0.6931471805599453
iteration 7 batch 7680 training_loss 0.6931471805599453
iteration 7 batch 7690 training_loss 0.6931471805599453
iteration 7 batch 7700 training_loss 0.6931471805599453
iteration 7 batch 7710 training_loss 0.6931471805599453
iteration 7 batch 7720 training_loss 0.6931471805599453
iteration 7 batch 7730 training_loss 0.6931471805599453
iteration 7 batch 7740 training_loss 0.6931471805599453
iteration 7 batch 7750 training_loss 0.6931471805599453
iteration 7 batch 7760 training_loss 0.6931471805599453
iteration 7 batch 7770 training_loss 0.6931471805599453
iteration 7 batch 7780 training_loss 0.6931471805599453
iteration 7 batch 7790 training_loss 0.6916632528527511
iteration 7 batch 7800 training_loss 0.6931471805599453
iteration 7 batch 7810 training_loss 0.6931471805599453
iteration 7 batch 7820 training_loss 0.6931471805599453
iteration 7 batch 7830 training_loss 0.6931471805599453
iteration 7 batch 7840 training_loss 0.6931471805599453
iteration 7 batch 7850 training_loss 0.6931471805599453
iteration 7 batch 7860 training_loss 0.6931471805599453
iteration 7 batch 7870 training_loss 0.6931471805599453
iteration 7 batch 7880 training_loss 0.6931471805599453
iteration 7 batch 7890 training_loss 0.6931471805599453
iteration 7 batch 7900 training_loss 0.6931471805599453
iteration 7 batch 7910 training_loss 0.6931471805599453
iteration 7 batch 7920 training_loss 0.6931471805599453
iteration 7 batch 7930 training_loss 0.6931471805599453
iteration 7 batch 7940 training_loss 0.6931471805599453
iteration 7 batch 7950 training_loss 0.6931471805599453
iteration 7 batch 7960 training_loss 0.6931471805599453
iteration 7 batch 7970 training_loss 0.6931471805599453
iteration 7 batch 7980 training_loss 0.6931471805599453
iteration 7 batch 7990 training_loss 0.6931471805599453
iteration 7 batch 8000 training_loss 0.6931471805599453
iteration 7 batch 8010 training_loss 0.6931471805599453
iteration 7 batch 8020 training_loss 0.6931471805599453
iteration 7 batch 8030 training_loss 0.6931471805599453
iteration 7 batch 8040 training_loss 0.6931471805599453
iteration 7 batch 8050 training_loss 0.6931471805599453
iteration 7 batch 8060 training_loss 0.6931471805599453
iteration 7 batch 8070 training_loss 0.6931471805599453
iteration 7 batch 8080 training_loss 0.6931471805599453
iteration 7 batch 8090 training_loss 0.6931471805599453
iteration 7 batch 8100 training_loss 0.6931471805599453
iteration 7 batch 8110 training_loss 0.6916632528527511
iteration 7 batch 8120 training_loss 0.6931471805599453
iteration 7 batch 8130 training_loss 0.6931471805599453
iteration 7 batch 8140 training_loss 0.6931471805599453
iteration 7 batch 8150 training_loss 0.6916632528527511
iteration 7 batch 8160 training_loss 0.6931471805599453
iteration 7 batch 8170 training_loss 0.6931471805599453
iteration 7 batch 8180 training_loss 0.6931471805599453
iteration 7 batch 8190 training_loss 0.6931471805599453
iteration 7 batch 8200 training_loss 0.6931471805599453
iteration 7 batch 8210 training_loss 0.6916632528527511
iteration 7 batch 8220 training_loss 0.6931471805599453
iteration 7 batch 8230 training_loss 0.6931471805599453
iteration 7 batch 8240 training_loss 0.6931471805599453
iteration 7 batch 8250 training_loss 0.6931471805599453
iteration 7 batch 8260 training_loss 0.6931471805599453
iteration 7 batch 8270 training_loss 0.6931471805599453
iteration 7 batch 8280 training_loss 0.6931471805599453
iteration 7 batch 8290 training_loss 0.6931471805599453
iteration 7 batch 8300 training_loss 0.6931471805599453
iteration 7 batch 8310 training_loss 0.6931471805599453
iteration 7 batch 8320 training_loss 0.6931471805599453
iteration 7 batch 8330 training_loss 0.6931471805599453
iteration 7 batch 8340 training_loss 0.6931471805599453
iteration 7 batch 8350 training_loss 0.6931471805599453
iteration 7 batch 8360 training_loss 0.6931471805599453
iteration 7 batch 8370 training_loss 0.6931471805599453
iteration 7 batch 8380 training_loss 0.6931471805599453
iteration 7 batch 8390 training_loss 0.6931471805599453
iteration 7 batch 8400 training_loss 0.6931471805599453
iteration 7 batch 8410 training_loss 0.6931471805599453
iteration 7 batch 8420 training_loss 0.6931471805599453
iteration 7 batch 8430 training_loss 0.6916632528527511
iteration 7 batch 8440 training_loss 0.6931471805599453
iteration 7 batch 8450 training_loss 0.6931471805599453
iteration 7 batch 8460 training_loss 0.6931471805599453
iteration 7 batch 8470 training_loss 0.6931471805599453
iteration 7 batch 8480 training_loss 0.6931471805599453
iteration 7 batch 8490 training_loss 0.6931471805599453
iteration 7 batch 8500 training_loss 0.6931471805599453
iteration 7 batch 8510 training_loss 0.6931471805599453
iteration 7 batch 8520 training_loss 0.6931471805599453
iteration 7 batch 8530 training_loss 0.6931471805599453
iteration 7 batch 8540 training_loss 0.6931471805599453
iteration 7 batch 8550 training_loss 0.6931471805599453
iteration 7 batch 8560 training_loss 0.6916632528527511
iteration 7 batch 8570 training_loss 0.6931471805599453
iteration 7 batch 8580 training_loss 0.6931471805599453
iteration 7 batch 8590 training_loss 0.6916632528527511
iteration 7 batch 8600 training_loss 0.6931471805599453
iteration 7 batch 8610 training_loss 0.6931471805599453
iteration 7 batch 8620 training_loss 0.6931471805599453
iteration 7 batch 8630 training_loss 0.6931471805599453
iteration 7 batch 8640 training_loss 0.6931471805599453
iteration 7 batch 8650 training_loss 0.6931471805599453
iteration 7 batch 8660 training_loss 0.6931471805599453
iteration 7 batch 8670 training_loss 0.6931471805599453
iteration 7 batch 8680 training_loss 0.6931471805599453
iteration 7 batch 8690 training_loss 0.6931471805599453
iteration 7 batch 8700 training_loss 0.6931471805599453
iteration 7 batch 8710 training_loss 0.6931471805599453
iteration 7 batch 8720 training_loss 0.6931471805599453
iteration 7 batch 8730 training_loss 0.6931471805599453
iteration 7 batch 8740 training_loss 0.6931471805599453
iteration 7 batch 8750 training_loss 0.6931471805599453
iteration 7 batch 8760 training_loss 0.6916632528527511
iteration 7 batch 8770 training_loss 0.6931471805599453
iteration 7 batch 8780 training_loss 0.6931471805599453
iteration 7 batch 8790 training_loss 0.6931471805599453
iteration 7 batch 8800 training_loss 0.6931471805599453
iteration 7 batch 8810 training_loss 0.6931471805599453
iteration 7 batch 8820 training_loss 0.6931471805599453
iteration 7 batch 8830 training_loss 0.6931471805599453
iteration 7 batch 8840 training_loss 0.6931471805599453
iteration 7 batch 8850 training_loss 0.6931471805599453
iteration 7 batch 8860 training_loss 0.6931471805599453
iteration 7 batch 8870 training_loss 0.6931471805599453
iteration 7 batch 8880 training_loss 0.6931471805599453
iteration 7 batch 8890 training_loss 0.6931471805599453
iteration 7 batch 8900 training_loss 0.6931471805599453
iteration 7 batch 8910 training_loss 0.6931471805599453
iteration 7 batch 8920 training_loss 0.6931471805599453
iteration 7 batch 8930 training_loss 0.6931471805599453
iteration 7 batch 8940 training_loss 0.6931471805599453
iteration 7 batch 8950 training_loss 0.6931471805599453
iteration 7 batch 8960 training_loss 0.6931471805599453
iteration 7 batch 8970 training_loss 0.6931471805599453
iteration 7 batch 8980 training_loss 0.6931471805599453
iteration 7 batch 8990 training_loss 0.6931471805599453
iteration 7 batch 9000 training_loss 0.6931471805599453
iteration 7 batch 9010 training_loss 0.6931471805599453
iteration 7 batch 9020 training_loss 0.6931471805599453
iteration 7 batch 9030 training_loss 0.6931471805599453
iteration 7 batch 9040 training_loss 0.6931471805599453
iteration 7 batch 9050 training_loss 0.6931471805599453
iteration 7 batch 9060 training_loss 0.6931471805599453
iteration 7 batch 9070 training_loss 0.6916632528527511
iteration 7 batch 9080 training_loss 0.6931471805599453
iteration 7 batch 9090 training_loss 0.6931471805599453
iteration 7 batch 9100 training_loss 0.6931471805599453
iteration 7 batch 9110 training_loss 0.6931471805599453
iteration 7 batch 9120 training_loss 0.6931471805599453
iteration 7 batch 9130 training_loss 0.6931471805599453
iteration 7 batch 9140 training_loss 0.6931471805599453
iteration 7 batch 9150 training_loss 0.6931471805599453
iteration 7 batch 9160 training_loss 0.6931471805599453
iteration 7 batch 9170 training_loss 0.6931471805599453
iteration 7 batch 9180 training_loss 0.6931471805599453
iteration 7 batch 9190 training_loss 0.6931471805599453
iteration 7 batch 9200 training_loss 0.6931471805599453
iteration 7 batch 9210 training_loss 0.6931471805599453
iteration 7 batch 9220 training_loss 0.6931471805599453
iteration 7 batch 9230 training_loss 0.6916632528527511
iteration 7 batch 9240 training_loss 0.6931471805599453
iteration 7 batch 9250 training_loss 0.6931471805599453
iteration 7 batch 9260 training_loss 0.6931471805599453
iteration 7 batch 9270 training_loss 0.6931471805599453
iteration 7 batch 9280 training_loss 0.6931471805599453
iteration 7 batch 9290 training_loss 0.6931471805599453
iteration 7 batch 9300 training_loss 0.6931471805599453
iteration 7 batch 9310 training_loss 0.6931471805599453
iteration 7 batch 9320 training_loss 0.6931471805599453
iteration 7 batch 9330 training_loss 0.6931471805599453
iteration 7 batch 9340 training_loss 0.6931471805599453
iteration 7 batch 9350 training_loss 0.6931471805599453
iteration 7 batch 9360 training_loss 0.6931471805599453
iteration 7 batch 9370 training_loss 0.6931471805599453
iteration 7 batch 9380 training_loss 0.6931471805599453
iteration 7 batch 9390 training_loss 0.6931471805599453
iteration 7 batch 9400 training_loss 0.6931471805599453
iteration 7 batch 9410 training_loss 0.6931471805599453
iteration 7 batch 9420 training_loss 0.6931471805599453
iteration 7 batch 9430 training_loss 0.6931471805599453
iteration 7 batch 9440 training_loss 0.6931471805599453
iteration 7 batch 9450 training_loss 0.6931471805599453
iteration 7 batch 9460 training_loss 0.6931471805599453
iteration 7 batch 9470 training_loss 0.6916632528527511
iteration 7 batch 9480 training_loss 0.6931471805599453
iteration 7 batch 9490 training_loss 0.6931471805599453
iteration 7 batch 9500 training_loss 0.6916632528527511
iteration 7 batch 9510 training_loss 0.6931471805599453
iteration 7 batch 9520 training_loss 0.6931471805599453
iteration 7 batch 9530 training_loss 0.6916632528527511
iteration 7 batch 9540 training_loss 0.6931471805599453
iteration 7 batch 9550 training_loss 0.6931471805599453
iteration 7 batch 9560 training_loss 0.6931471805599453
iteration 7 batch 9570 training_loss 0.6931471805599453
iteration 7 batch 9580 training_loss 0.6931471805599453
iteration 7 batch 9590 training_loss 0.6931471805599453
iteration 7 batch 9600 training_loss 0.6931471805599453
iteration 7 batch 9610 training_loss 0.6931471805599453
iteration 7 batch 9620 training_loss 0.6931471805599453
iteration 7 batch 9630 training_loss 0.6931471805599453
iteration 7 batch 9640 training_loss 0.6931471805599453
iteration 7 batch 9650 training_loss 0.6931471805599453
iteration 7 batch 9660 training_loss 0.6931471805599453
iteration 7 batch 9670 training_loss 0.6931471805599453
iteration 7 batch 9680 training_loss 0.6931471805599453
iteration 7 batch 9690 training_loss 0.6931471805599453
iteration 7 batch 9700 training_loss 0.6931471805599453
iteration 7 batch 9710 training_loss 0.6931471805599453
iteration 7 batch 9720 training_loss 0.6931471805599453
iteration 7 batch 9730 training_loss 0.6931471805599453
iteration 7 batch 9740 training_loss 0.6931471805599453
iteration 7 batch 9750 training_loss 0.6931471805599453
iteration 7 batch 9760 training_loss 0.6931471805599453
iteration 7 batch 9770 training_loss 0.6931471805599453
iteration 7 batch 9780 training_loss 0.6931471805599453
iteration 7 batch 9790 training_loss 0.6931471805599453
iteration 7 batch 9800 training_loss 0.6931471805599453
iteration 7 batch 9810 training_loss 0.6931471805599453
iteration 7 batch 9820 training_loss 0.6931471805599453
iteration 7 batch 9830 training_loss 0.6931471805599453
iteration 7 batch 9840 training_loss 0.6916632528527511
iteration 7 batch 9850 training_loss 0.6931471805599453
iteration 7 batch 9860 training_loss 0.6931471805599453
iteration 7 batch 9870 training_loss 0.6931471805599453
iteration 7 batch 9880 training_loss 0.6931471805599453
iteration 7 batch 9890 training_loss 0.6931471805599453
iteration 7 batch 9900 training_loss 0.6931471805599453
iteration 7 batch 9910 training_loss 0.6931471805599453
iteration 7 batch 9920 training_loss 0.6931471805599453
iteration 7 batch 9930 training_loss 0.6931471805599453
iteration 7 batch 9940 training_loss 0.6931471805599453
iteration 7 batch 9950 training_loss 0.6931471805599453
iteration 7 batch 9960 training_loss 0.6931471805599453
iteration 7 batch 9970 training_loss 0.6931471805599453
iteration 7 batch 9980 training_loss 0.6931471805599453
iteration 7 batch 9990 training_loss 0.6931471805599453
iteration 7 batch 10000 training_loss 0.6931471805599453
iteration 7 batch 10010 training_loss 0.6931471805599453
iteration 7 batch 10020 training_loss 0.6931471805599453
iteration 7 batch 10030 training_loss 0.6931471805599453
iteration 7 batch 10040 training_loss 0.6931471805599453
iteration 7 batch 10050 training_loss 0.6931471805599453
iteration 7 batch 10060 training_loss 0.6931471805599453
iteration 7 batch 10070 training_loss 0.6931471805599453
iteration 7 batch 10080 training_loss 0.6931471805599453
iteration 7 batch 10090 training_loss 0.6931471805599453
iteration 7 batch 10100 training_loss 0.6931471805599453
iteration 7 batch 10110 training_loss 0.6916632528527511
iteration 7 batch 10120 training_loss 0.6931471805599453
iteration 7 batch 10130 training_loss 0.6931471805599453
iteration 7 batch 10140 training_loss 0.6931471805599453
iteration 7 batch 10150 training_loss 0.6931471805599453
iteration 7 batch 10160 training_loss 0.6931471805599453
iteration 7 batch 10170 training_loss 0.6931471805599453
iteration 7 batch 10180 training_loss 0.6931471805599453
iteration 7 batch 10190 training_loss 0.6931471805599453
iteration 7 batch 10200 training_loss 0.6931471805599453
iteration 7 batch 10210 training_loss 0.6931471805599453
iteration 7 batch 10220 training_loss 0.6931471805599453
iteration 7 batch 10230 training_loss 0.6931471805599453
iteration 7 batch 10240 training_loss 0.6931471805599453
iteration 7 batch 10250 training_loss 0.6931471805599453
iteration 7 batch 10260 training_loss 0.6931471805599453
iteration 7 batch 10270 training_loss 0.6931471805599453
iteration 7 batch 10280 training_loss 0.6931471805599453
iteration 7 batch 10290 training_loss 0.6931471805599453
iteration 7 batch 10300 training_loss 0.6931471805599453
iteration 7 batch 10310 training_loss 0.6931471805599453
iteration 7 batch 10320 training_loss 0.6931471805599453
iteration 7 batch 10330 training_loss 0.6931471805599453
iteration 7 batch 10340 training_loss 0.6931471805599453
iteration 7 batch 10350 training_loss 0.6931471805599453
iteration 7 batch 10360 training_loss 0.6931471805599453
iteration 7 batch 10370 training_loss 0.6931471805599453
iteration 7 batch 10380 training_loss 0.6931471805599453
iteration 7 batch 10390 training_loss 0.6931471805599453
iteration 7 batch 10400 training_loss 0.6931471805599453
iteration 7 batch 10410 training_loss 0.6916632528527511
iteration 7 batch 10420 training_loss 0.6931471805599453
iteration 7 batch 10430 training_loss 0.6931471805599453
iteration 7 batch 10440 training_loss 0.6931471805599453
iteration 7 batch 10450 training_loss 0.6931471805599453
iteration 7 batch 10460 training_loss 0.6931471805599453
iteration 7 batch 10470 training_loss 0.6931471805599453
iteration 7 batch 10480 training_loss 0.6931471805599453
iteration 7 batch 10490 training_loss 0.6931471805599453
iteration 7 batch 10500 training_loss 0.6931471805599453
iteration 7 batch 10510 training_loss 0.6901793251455568
iteration 7 batch 10520 training_loss 0.6916632528527511
iteration 7 batch 10530 training_loss 0.6931471805599453
iteration 7 batch 10540 training_loss 0.6931471805599453
iteration 7 batch 10550 training_loss 0.6931471805599453
iteration 7 batch 10560 training_loss 0.6931471805599453
iteration 7 batch 10570 training_loss 0.6931471805599453
iteration 7 batch 10580 training_loss 0.6931471805599453
iteration 7 batch 10590 training_loss 0.6931471805599453
iteration 7 batch 10600 training_loss 0.6916632528527511
iteration 7 batch 10610 training_loss 0.6931471805599453
iteration 7 batch 10620 training_loss 0.6931471805599453
iteration 7 batch 10630 training_loss 0.6931471805599453
iteration 7 batch 10640 training_loss 0.6931471805599453
iteration 7 batch 10650 training_loss 0.6931471805599453
iteration 7 batch 10660 training_loss 0.6931471805599453
iteration 7 batch 10670 training_loss 0.6931471805599453
iteration 7 batch 10680 training_loss 0.6931471805599453
iteration 7 batch 10690 training_loss 0.6931471805599453
iteration 7 batch 10700 training_loss 0.6931471805599453
iteration 7 batch 10710 training_loss 0.6931471805599453
iteration 7 batch 10720 training_loss 0.6931471805599453
iteration 7 batch 10730 training_loss 0.6931471805599453
iteration 7 batch 10740 training_loss 0.6931471805599453
iteration 7 batch 10750 training_loss 0.6931471805599453
iteration 7 batch 10760 training_loss 0.6931471805599453
iteration 7 batch 10770 training_loss 0.6931471805599453
iteration 7 batch 10780 training_loss 0.6931471805599453
iteration 7 batch 10790 training_loss 0.6931471805599453
iteration 7 batch 10800 training_loss 0.6931471805599453
iteration 7 batch 10810 training_loss 0.6931471805599453
iteration 7 batch 10820 training_loss 0.6931471805599453
iteration 7 batch 10830 training_loss 0.6931471805599453
iteration 7 batch 10840 training_loss 0.6931471805599453
iteration 7 batch 10850 training_loss 0.6931471805599453
iteration 7 batch 10860 training_loss 0.6931471805599453
iteration 7 batch 10870 training_loss 0.6931471805599453
iteration 7 batch 10880 training_loss 0.6931471805599453
iteration 7 batch 10890 training_loss 0.6931471805599453
iteration 7 batch 10900 training_loss 0.6931471805599453
iteration 7 batch 10910 training_loss 0.6931471805599453
iteration 7 batch 10920 training_loss 0.6931471805599453
iteration 7 batch 10930 training_loss 0.6931471805599453
iteration 7 batch 10940 training_loss 0.6931471805599453
iteration 7 batch 10950 training_loss 0.6931471805599453
iteration 7 batch 10960 training_loss 0.6931471805599453
iteration 7 batch 10970 training_loss 0.6931471805599453
iteration 7 batch 10980 training_loss 0.6931471805599453
iteration 7 batch 10990 training_loss 0.6931471805599453
iteration 7 batch 11000 training_loss 0.6931471805599453
iteration 7 batch 11010 training_loss 0.6931471805599453
iteration 7 batch 11020 training_loss 0.6931471805599453
iteration 7 batch 11030 training_loss 0.6931471805599453
iteration 7 batch 11040 training_loss 0.6931471805599453
iteration 7 batch 11050 training_loss 0.6931471805599453
iteration 7 batch 11060 training_loss 0.6931471805599453
iteration 7 batch 11070 training_loss 0.6931471805599453
iteration 7 batch 11080 training_loss 0.6931471805599453
iteration 7 batch 11090 training_loss 0.6931471805599453
iteration 7 batch 11100 training_loss 0.6931471805599453
iteration 7 batch 11110 training_loss 0.6931471805599453
iteration 7 batch 11120 training_loss 0.6931471805599453
iteration 7 batch 11130 training_loss 0.6931471805599453
iteration 7 batch 11140 training_loss 0.6931471805599453
iteration 7 batch 11150 training_loss 0.6931471805599453
iteration 7 batch 11160 training_loss 0.6931471805599453
iteration 7 batch 11170 training_loss 0.6931471805599453
iteration 7 batch 11180 training_loss 0.6916632528527511
iteration 7 batch 11190 training_loss 0.6931471805599453
iteration 7 batch 11200 training_loss 0.6931471805599453
iteration 7 batch 11210 training_loss 0.6931471805599453
iteration 7 batch 11220 training_loss 0.6931471805599453
iteration 7 batch 11230 training_loss 0.6931471805599453
iteration 7 batch 11240 training_loss 0.6931471805599453
iteration 7 batch 11250 training_loss 0.6916632528527511
iteration 7 batch 11260 training_loss 0.6931471805599453
iteration 7 batch 11270 training_loss 0.6916632528527511
iteration 7 batch 11280 training_loss 0.6931471805599453
iteration 7 batch 11290 training_loss 0.6931471805599453
iteration 7 batch 11300 training_loss 0.6931471805599453
iteration 7 batch 11310 training_loss 0.6931471805599453
iteration 7 batch 11320 training_loss 0.6931471805599453
iteration 7 batch 11330 training_loss 0.6916632528527511
iteration 7 batch 11340 training_loss 0.6931471805599453
iteration 7 batch 11350 training_loss 0.6931471805599453
iteration 7 batch 11360 training_loss 0.6916632528527511
iteration 7 batch 11370 training_loss 0.6931471805599453
iteration 7 batch 11380 training_loss 0.6931471805599453
iteration 7 batch 11390 training_loss 0.6931471805599453
iteration 7 batch 11400 training_loss 0.6931471805599453
iteration 7 batch 11410 training_loss 0.6931471805599453
iteration 7 batch 11420 training_loss 0.6931471805599453
iteration 7 batch 11430 training_loss 0.6931471805599453
iteration 7 batch 11440 training_loss 0.6931471805599453
iteration 7 batch 11450 training_loss 0.6931471805599453
iteration 7 batch 11460 training_loss 0.6916632528527511
iteration 7 batch 11470 training_loss 0.6931471805599453
iteration 7 batch 11480 training_loss 0.6931471805599453
iteration 7 batch 11490 training_loss 0.6931471805599453
iteration 7 batch 11500 training_loss 0.6931471805599453
iteration 7 batch 11510 training_loss 0.6931471805599453
iteration 7 batch 11520 training_loss 0.6931471805599453
iteration 7 batch 11530 training_loss 0.6931471805599453
iteration 7 batch 11540 training_loss 0.6931471805599453
iteration 7 batch 11550 training_loss 0.6931471805599453
iteration 7 batch 11560 training_loss 0.6931471805599453
iteration 7 batch 11570 training_loss 0.6931471805599453
iteration 7 batch 11580 training_loss 0.6931471805599453
iteration 7 batch 11590 training_loss 0.6931471805599453
iteration 7 batch 11600 training_loss 0.6931471805599453
iteration 7 batch 11610 training_loss 0.6931471805599453
iteration 7 batch 11620 training_loss 0.6931471805599453
iteration 7 batch 11630 training_loss 0.6931471805599453
iteration 7 batch 11640 training_loss 0.6931471805599453
iteration 7 batch 11650 training_loss 0.6931471805599453
iteration 7 batch 11660 training_loss 0.6931471805599453
iteration 7 batch 11670 training_loss 0.6931471805599453
iteration 7 batch 11680 training_loss 0.6931471805599453
iteration 7 batch 11690 training_loss 0.6931471805599453
iteration 7 batch 11700 training_loss 0.6931471805599453
iteration 7 batch 11710 training_loss 0.6931471805599453
iteration 7 batch 11720 training_loss 0.6931471805599453
iteration 7 batch 11730 training_loss 0.6916632528527511
iteration 7 batch 11740 training_loss 0.6931471805599453
iteration 7 batch 11750 training_loss 0.6931471805599453
iteration 7 batch 11760 training_loss 0.6931471805599453
iteration 7 batch 11770 training_loss 0.6931471805599453
iteration 7 batch 11780 training_loss 0.6916632528527511
iteration 7 batch 11790 training_loss 0.6931471805599453
iteration 7 batch 11800 training_loss 0.6931471805599453
iteration 7 batch 11810 training_loss 0.6931471805599453
iteration 7 batch 11820 training_loss 0.6931471805599453
iteration 7 batch 11830 training_loss 0.6931471805599453
iteration 7 batch 11840 training_loss 0.6931471805599453
iteration 7 batch 11850 training_loss 0.6931471805599453
iteration 7 batch 11860 training_loss 0.6931471805599453
iteration 7 batch 11870 training_loss 0.6931471805599453
iteration 7 batch 11880 training_loss 0.6931471805599453
iteration 7 batch 11890 training_loss 0.6931471805599453
iteration 7 batch 11900 training_loss 0.6931471805599453
iteration 7 batch 11910 training_loss 0.6931471805599453
iteration 7 batch 11920 training_loss 0.6931471805599453
iteration 7 batch 11930 training_loss 0.6931471805599453
iteration 7 batch 11940 training_loss 0.6931471805599453
iteration 7 batch 11950 training_loss 0.6931471805599453
iteration 7 batch 11960 training_loss 0.6931471805599453
iteration 7 batch 11970 training_loss 0.6931471805599453
iteration 7 batch 11980 training_loss 0.6916632528527511
iteration 7 batch 11990 training_loss 0.6931471805599453
iteration 7 batch 12000 training_loss 0.6931471805599453
iteration 7 batch 12010 training_loss 0.6931471805599453
iteration 7 batch 12020 training_loss 0.6931471805599453
iteration 7 batch 12030 training_loss 0.6931471805599453
iteration 7 batch 12040 training_loss 0.6931471805599453
iteration 7 batch 12050 training_loss 0.6931471805599453
iteration 7 batch 12060 training_loss 0.6931471805599453
iteration 7 batch 12070 training_loss 0.6931471805599453
iteration 7 batch 12080 training_loss 0.6931471805599453
iteration 7 batch 12090 training_loss 0.6931471805599453
iteration 7 batch 12100 training_loss 0.6931471805599453
iteration 7 batch 12110 training_loss 0.6931471805599453
iteration 7 batch 12120 training_loss 0.6931471805599453
iteration 7 batch 12130 training_loss 0.6931471805599453
iteration 7 batch 12140 training_loss 0.6931471805599453
iteration 7 batch 12150 training_loss 0.6931471805599453
iteration 7 batch 12160 training_loss 0.6931471805599453
iteration 7 batch 12170 training_loss 0.6931471805599453
iteration 7 batch 12180 training_loss 0.6931471805599453
iteration 7 batch 12190 training_loss 0.6931471805599453
iteration 7 batch 12200 training_loss 0.6931471805599453
iteration 7 batch 12210 training_loss 0.6931471805599453
iteration 7 batch 12220 training_loss 0.6931471805599453
iteration 7 batch 12230 training_loss 0.6931471805599453
iteration 7 batch 12240 training_loss 0.6931471805599453
iteration 7 batch 12250 training_loss 0.6931471805599453
iteration 7 batch 12260 training_loss 0.6931471805599453
iteration 7 batch 12270 training_loss 0.6931471805599453
iteration 7 batch 12280 training_loss 0.6931471805599453
iteration 7 batch 12290 training_loss 0.6931471805599453
iteration 7 batch 12300 training_loss 0.6931471805599453
iteration 7 batch 12310 training_loss 0.6931471805599453
iteration 7 batch 12320 training_loss 0.6931471805599453
iteration 7 batch 12330 training_loss 0.6931471805599453
iteration 7 batch 12340 training_loss 0.6931471805599453
iteration 7 batch 12350 training_loss 0.6931471805599453
iteration 7 batch 12360 training_loss 0.6916632528527511
iteration 7 batch 12370 training_loss 0.6931471805599453
iteration 7 batch 12380 training_loss 0.6916632528527511
iteration 7 batch 12390 training_loss 0.6931471805599453
iteration 7 batch 12400 training_loss 0.6931471805599453
iteration 7 batch 12410 training_loss 0.6931471805599453
iteration 7 batch 12420 training_loss 0.6931471805599453
iteration 7 batch 12430 training_loss 0.6931471805599453
iteration 7 batch 12440 training_loss 0.6931471805599453
iteration 7 batch 12450 training_loss 0.6931471805599453
iteration 7 batch 12460 training_loss 0.6916632528527511
iteration 7 batch 12470 training_loss 0.6931471805599453
iteration 7 batch 12480 training_loss 0.6931471805599453
iteration 7 batch 12490 training_loss 0.6931471805599453
iteration 7 batch 12500 training_loss 0.6931471805599453
iteration 7 batch 12510 training_loss 0.6931471805599453
iteration 7 batch 12520 training_loss 0.6931471805599453
iteration 7 batch 12530 training_loss 0.6931471805599453
iteration 7 batch 12540 training_loss 0.6916632528527511
iteration 7 batch 12550 training_loss 0.6931471805599453
iteration 7 batch 12560 training_loss 0.6931471805599453
iteration 7 batch 12570 training_loss 0.6931471805599453
iteration 7 batch 12580 training_loss 0.6931471805599453
iteration 7 batch 12590 training_loss 0.6931471805599453
iteration 7 batch 12600 training_loss 0.6931471805599453
iteration 7 batch 12610 training_loss 0.6931471805599453
iteration 7 batch 12620 training_loss 0.6931471805599453
iteration 7 batch 12630 training_loss 0.6916632528527511
iteration 7 batch 12640 training_loss 0.6931471805599453
iteration 7 batch 12650 training_loss 0.6931471805599453
iteration 7 batch 12660 training_loss 0.6931471805599453
iteration 7 batch 12670 training_loss 0.6931471805599453
iteration 7 batch 12680 training_loss 0.6916632528527511
iteration 7 batch 12690 training_loss 0.6931471805599453
iteration 7 batch 12700 training_loss 0.6931471805599453
iteration 7 batch 12710 training_loss 0.6931471805599453
iteration 7 batch 12720 training_loss 0.6931471805599453
iteration 7 batch 12730 training_loss 0.6931471805599453
iteration 7 batch 12740 training_loss 0.6931471805599453
iteration 7 batch 12750 training_loss 0.6931471805599453
iteration 7 batch 12760 training_loss 0.6931471805599453
iteration 7 batch 12770 training_loss 0.6931471805599453
iteration 7 batch 12780 training_loss 0.6931471805599453
iteration 7 batch 12790 training_loss 0.6916632528527511
iteration 7 batch 12800 training_loss 0.6931471805599453
iteration 7 batch 12810 training_loss 0.6916632528527511
iteration 7 batch 12820 training_loss 0.6931471805599453
iteration 7 batch 12830 training_loss 0.6931471805599453
iteration 7 batch 12840 training_loss 0.6931471805599453
iteration 7 batch 12850 training_loss 0.6931471805599453
iteration 7 batch 12860 training_loss 0.6931471805599453
iteration 7 batch 12870 training_loss 0.6931471805599453
iteration 7 batch 12880 training_loss 0.6931471805599453
iteration 7 batch 12890 training_loss 0.6931471805599453
iteration 7 batch 12900 training_loss 0.6931471805599453
iteration 7 batch 12910 training_loss 0.6931471805599453
iteration 7 batch 12920 training_loss 0.6931471805599453
iteration 7 batch 12930 training_loss 0.6931471805599453
iteration 7 batch 12940 training_loss 0.6931471805599453
iteration 7 batch 12950 training_loss 0.6931471805599453
iteration 7 batch 12960 training_loss 0.6931471805599453
iteration 7 batch 12970 training_loss 0.6916632528527511
iteration 7 batch 12980 training_loss 0.6931471805599453
iteration 7 batch 12990 training_loss 0.6916632528527511
iteration 7 batch 13000 training_loss 0.6931471805599453
iteration 7 batch 13010 training_loss 0.6931471805599453
iteration 7 batch 13020 training_loss 0.6931471805599453
iteration 7 batch 13030 training_loss 0.6931471805599453
iteration 7 batch 13040 training_loss 0.6931471805599453
iteration 7 batch 13050 training_loss 0.6931471805599453
iteration 7 batch 13060 training_loss 0.6931471805599453
iteration 7 batch 13070 training_loss 0.6931471805599453
iteration 7 batch 13080 training_loss 0.6931471805599453
iteration 7 batch 13090 training_loss 0.6931471805599453
iteration 7 batch 13100 training_loss 0.6931471805599453
iteration 7 batch 13110 training_loss 0.6931471805599453
iteration 7 batch 13120 training_loss 0.6931471805599453
iteration 7 batch 13130 training_loss 0.6931471805599453
iteration 7 batch 13140 training_loss 0.6931471805599453
iteration 7 batch 13150 training_loss 0.6931471805599453
iteration 7 batch 13160 training_loss 0.6916632528527511
iteration 7 batch 13170 training_loss 0.6916632528527511
iteration 7 batch 13180 training_loss 0.6931471805599453
iteration 7 batch 13190 training_loss 0.6931471805599453
iteration 7 batch 13200 training_loss 0.6931471805599453
iteration 7 batch 13210 training_loss 0.6931471805599453
iteration 7 batch 13220 training_loss 0.6931471805599453
iteration 7 batch 13230 training_loss 0.6931471805599453
iteration 7 batch 13240 training_loss 0.6931471805599453
iteration 7 batch 13250 training_loss 0.6931471805599453
iteration 7 batch 13260 training_loss 0.6931471805599453
iteration 7 batch 13270 training_loss 0.6931471805599453
iteration 7 batch 13280 training_loss 0.6931471805599453
iteration 7 batch 13290 training_loss 0.6931471805599453
iteration 7 batch 13300 training_loss 0.6931471805599453
iteration 7 batch 13310 training_loss 0.6931471805599453
iteration 7 batch 13320 training_loss 0.6931471805599453
iteration 7 batch 13330 training_loss 0.6931471805599453
iteration 7 batch 13340 training_loss 0.6931471805599453
iteration 7 batch 13350 training_loss 0.6931471805599453
iteration 7 batch 13360 training_loss 0.6931471805599453
iteration 7 batch 13370 training_loss 0.6931471805599453
iteration 7 batch 13380 training_loss 0.6931471805599453
iteration 7 batch 13390 training_loss 0.6931471805599453
iteration 7 batch 13400 training_loss 0.6931471805599453
iteration 7 batch 13410 training_loss 0.6931471805599453
iteration 7 batch 13420 training_loss 0.6931471805599453
iteration 7 batch 13430 training_loss 0.6931471805599453
iteration 7 batch 13440 training_loss 0.6931471805599453
iteration 7 batch 13450 training_loss 0.6931471805599453
iteration 7 batch 13460 training_loss 0.6931471805599453
iteration 7 batch 13470 training_loss 0.6931471805599453
iteration 7 batch 13480 training_loss 0.6931471805599453
iteration 7 batch 13490 training_loss 0.6931471805599453
iteration 7 batch 13500 training_loss 0.6931471805599453
iteration 7 batch 13510 training_loss 0.6931471805599453
iteration 7 batch 13520 training_loss 0.6916632528527511
iteration 7 batch 13530 training_loss 0.6931471805599453
iteration 7 batch 13540 training_loss 0.6931471805599453
iteration 7 batch 13550 training_loss 0.6931471805599453
iteration 7 batch 13560 training_loss 0.6931471805599453
iteration 7 batch 13570 training_loss 0.6931471805599453
iteration 7 batch 13580 training_loss 0.6931471805599453
iteration 7 batch 13590 training_loss 0.6931471805599453
iteration 7 batch 13600 training_loss 0.6931471805599453
iteration 7 batch 13610 training_loss 0.6931471805599453
iteration 7 batch 13620 training_loss 0.6931471805599453
iteration 7 batch 13630 training_loss 0.6931471805599453
iteration 7 batch 13640 training_loss 0.6916632528527511
iteration 7 batch 13650 training_loss 0.6931471805599453
iteration 7 batch 13660 training_loss 0.6931471805599453
iteration 7 batch 13670 training_loss 0.6931471805599453
iteration 7 batch 13680 training_loss 0.6931471805599453
iteration 7 batch 13690 training_loss 0.6931471805599453
iteration 7 batch 13700 training_loss 0.6931471805599453
iteration 7 batch 13710 training_loss 0.6931471805599453
iteration 7 batch 13720 training_loss 0.6931471805599453
iteration 7 batch 13730 training_loss 0.6931471805599453
iteration 7 batch 13740 training_loss 0.6931471805599453
iteration 7 batch 13750 training_loss 0.6931471805599453
iteration 7 batch 13760 training_loss 0.6931471805599453
iteration 7 batch 13770 training_loss 0.6916632528527511
iteration 7 batch 13780 training_loss 0.6931471805599453
iteration 7 batch 13790 training_loss 0.6931471805599453
iteration 7 batch 13800 training_loss 0.6931471805599453
iteration 7 batch 13810 training_loss 0.6931471805599453
iteration 7 batch 13820 training_loss 0.6916632528527511
iteration 7 batch 13830 training_loss 0.6931471805599453
iteration 7 batch 13840 training_loss 0.6931471805599453
iteration 7 batch 13850 training_loss 0.6931471805599453
iteration 7 batch 13860 training_loss 0.6931471805599453
iteration 7 batch 13870 training_loss 0.6931471805599453
iteration 7 batch 13880 training_loss 0.6931471805599453
iteration 7 batch 13890 training_loss 0.6931471805599453
iteration 7 batch 13900 training_loss 0.6931471805599453
iteration 7 batch 13910 training_loss 0.6931471805599453
iteration 7 batch 13920 training_loss 0.6931471805599453
iteration 7 batch 13930 training_loss 0.6931471805599453
iteration 7 batch 13940 training_loss 0.6931471805599453
iteration 7 batch 13950 training_loss 0.6931471805599453
iteration 7 batch 13960 training_loss 0.6931471805599453
iteration 7 batch 13970 training_loss 0.6931471805599453
iteration 7 batch 13980 training_loss 0.6931471805599453
iteration 7 batch 13990 training_loss 0.6931471805599453
iteration 7 batch 14000 training_loss 0.6931471805599453
iteration 7 batch 14010 training_loss 0.6931471805599453
iteration 7 batch 14020 training_loss 0.6931471805599453
iteration 7 batch 14030 training_loss 0.6931471805599453
iteration 7 batch 14040 training_loss 0.6931471805599453
iteration 7 batch 14050 training_loss 0.6931471805599453
iteration 7 batch 14060 training_loss 0.6931471805599453
iteration 7 batch 14070 training_loss 0.6931471805599453
iteration 7 batch 14080 training_loss 0.6931471805599453
iteration 7 batch 14090 training_loss 0.6931471805599453
iteration 7 batch 14100 training_loss 0.6931471805599453
iteration 7 batch 14110 training_loss 0.6931471805599453
iteration 7 batch 14120 training_loss 0.6931471805599453
iteration 7 batch 14130 training_loss 0.6931471805599453
iteration 7 batch 14140 training_loss 0.6931471805599453
iteration 7 batch 14150 training_loss 0.6931471805599453
iteration 7 batch 14160 training_loss 0.6931471805599453
iteration 7 batch 14170 training_loss 0.6931471805599453
iteration 7 batch 14180 training_loss 0.6931471805599453
iteration 7 batch 14190 training_loss 0.6931471805599453
iteration 7 batch 14200 training_loss 0.6931471805599453
iteration 7 batch 14210 training_loss 0.6931471805599453
iteration 7 batch 14220 training_loss 0.6931471805599453
iteration 7 batch 14230 training_loss 0.6931471805599453
iteration 7 batch 14240 training_loss 0.6931471805599453
iteration 7 batch 14250 training_loss 0.6931471805599453
iteration 7 batch 14260 training_loss 0.6931471805599453
iteration 7 batch 14270 training_loss 0.6931471805599453
iteration 7 batch 14280 training_loss 0.6931471805599453
iteration 7 batch 14290 training_loss 0.6931471805599453
iteration 7 batch 14300 training_loss 0.6916632528527511
iteration 7 batch 14310 training_loss 0.6931471805599453
iteration 7 batch 14320 training_loss 0.6916632528527511
iteration 7 batch 14330 training_loss 0.6931471805599453
iteration 7 batch 14340 training_loss 0.6931471805599453
iteration 7 batch 14350 training_loss 0.6931471805599453
iteration 7 batch 14360 training_loss 0.6931471805599453
iteration 7 batch 14370 training_loss 0.6931471805599453
iteration 7 batch 14380 training_loss 0.6931471805599453
iteration 7 batch 14390 training_loss 0.6931471805599453
iteration 7 batch 14400 training_loss 0.6931471805599453
iteration 7 batch 14410 training_loss 0.6931471805599453
iteration 7 batch 14420 training_loss 0.6931471805599453
iteration 7 batch 14430 training_loss 0.6931471805599453
iteration 7 batch 14440 training_loss 0.6931471805599453
iteration 7 batch 14450 training_loss 0.6931471805599453
iteration 7 batch 14460 training_loss 0.6931471805599453
iteration 7 batch 14470 training_loss 0.6931471805599453
iteration 7 batch 14480 training_loss 0.6931471805599453
iteration 7 batch 14490 training_loss 0.6931471805599453
iteration 7 batch 14500 training_loss 0.6931471805599453
iteration 7 batch 14510 training_loss 0.6916632528527511
iteration 7 batch 14520 training_loss 0.6931471805599453
iteration 7 batch 14530 training_loss 0.6931471805599453
iteration 7 batch 14540 training_loss 0.6931471805599453
iteration 7 batch 14550 training_loss 0.6931471805599453
iteration 7 batch 14560 training_loss 0.6931471805599453
iteration 7 batch 14570 training_loss 0.6931471805599453
iteration 7 batch 14580 training_loss 0.6931471805599453
iteration 7 batch 14590 training_loss 0.6931471805599453
iteration 7 batch 14600 training_loss 0.6931471805599453
iteration 7 batch 14610 training_loss 0.6931471805599453
iteration 7 batch 14620 training_loss 0.6931471805599453
iteration 7 batch 14630 training_loss 0.6931471805599453
iteration 7 batch 14640 training_loss 0.6931471805599453
iteration 7 batch 14650 training_loss 0.6931471805599453
iteration 7 batch 14660 training_loss 0.6931471805599453
iteration 7 batch 14670 training_loss 0.6931471805599453
iteration 7 batch 14680 training_loss 0.6931471805599453
iteration 7 batch 14690 training_loss 0.6931471805599453
iteration 7 batch 14700 training_loss 0.6931471805599453
iteration 7 batch 14710 training_loss 0.6931471805599453
iteration 7 batch 14720 training_loss 0.6931471805599453
iteration 7 batch 14730 training_loss 0.6931471805599453
iteration 7 batch 14740 training_loss 0.6931471805599453
iteration 7 batch 14750 training_loss 0.6931471805599453
iteration 7 batch 14760 training_loss 0.6931471805599453
iteration 7 batch 14770 training_loss 0.6931471805599453
iteration 7 batch 14780 training_loss 0.6931471805599453
iteration 7 batch 14790 training_loss 0.6931471805599453
iteration 7 batch 14800 training_loss 0.6916632528527511
iteration 7 batch 14810 training_loss 0.6931471805599453
iteration 7 batch 14820 training_loss 0.6931471805599453
iteration 7 batch 14830 training_loss 0.6931471805599453
iteration 7 batch 14840 training_loss 0.6931471805599453
iteration 7 batch 14850 training_loss 0.6931471805599453
iteration 7 batch 14860 training_loss 0.6931471805599453
iteration 7 batch 14870 training_loss 0.6931471805599453
iteration 7 batch 14880 training_loss 0.6931471805599453
iteration 7 batch 14890 training_loss 0.6931471805599453
iteration 7 batch 14900 training_loss 0.6931471805599453
iteration 7 batch 14910 training_loss 0.6931471805599453
iteration 7 batch 14920 training_loss 0.6931471805599453
iteration 7 batch 14930 training_loss 0.6931471805599453
iteration 7 batch 14940 training_loss 0.6931471805599453
iteration 7 batch 14950 training_loss 0.6931471805599453
iteration 7 batch 14960 training_loss 0.6931471805599453
iteration 7 batch 14970 training_loss 0.6931471805599453
iteration 7 batch 14980 training_loss 0.6931471805599453
iteration 7 batch 14990 training_loss 0.6931471805599453
iteration 7 batch 15000 training_loss 0.6931471805599453
iteration 7 batch 15010 training_loss 0.6931471805599453
iteration 7 batch 15020 training_loss 0.6916632528527511
iteration 7 batch 15030 training_loss 0.6931471805599453
iteration 7 batch 15040 training_loss 0.6931471805599453
iteration 7 batch 15050 training_loss 0.6931471805599453
iteration 7 batch 15060 training_loss 0.6931471805599453
iteration 7 batch 15070 training_loss 0.6931471805599453
iteration 7 batch 15080 training_loss 0.6931471805599453
iteration 7 batch 15090 training_loss 0.6916632528527511
iteration 7 batch 15100 training_loss 0.6931471805599453
iteration 7 batch 15110 training_loss 0.6916632528527511
iteration 7 batch 15120 training_loss 0.6931471805599453
iteration 7 batch 15130 training_loss 0.6931471805599453
iteration 7 batch 15140 training_loss 0.6931471805599453
iteration 7 batch 15150 training_loss 0.6931471805599453
iteration 7 batch 15160 training_loss 0.6931471805599453
iteration 7 batch 15170 training_loss 0.6931471805599453
iteration 7 batch 15180 training_loss 0.6916632528527511
iteration 7 batch 15190 training_loss 0.6931471805599453
iteration 7 batch 15200 training_loss 0.6931471805599453
iteration 7 batch 15210 training_loss 0.6931471805599453
iteration 7 batch 15220 training_loss 0.6931471805599453
iteration 7 batch 15230 training_loss 0.6916632528527511
iteration 7 batch 15240 training_loss 0.6931471805599453
iteration 7 batch 15250 training_loss 0.6931471805599453
iteration 7 batch 15260 training_loss 0.6931471805599453
iteration 7 batch 15270 training_loss 0.6931471805599453
iteration 7 batch 15280 training_loss 0.6931471805599453
iteration 7 batch 15290 training_loss 0.6931471805599453
iteration 7 batch 15300 training_loss 0.6931471805599453
iteration 7 batch 15310 training_loss 0.6931471805599453
iteration 7 batch 15320 training_loss 0.6931471805599453
iteration 7 batch 15330 training_loss 0.6931471805599453
iteration 7 batch 15340 training_loss 0.6931471805599453
iteration 7 batch 15350 training_loss 0.6931471805599453
iteration 7 batch 15360 training_loss 0.6931471805599453
iteration 7 batch 15370 training_loss 0.6931471805599453
iteration 7 batch 15380 training_loss 0.6931471805599453
iteration 7 batch 15390 training_loss 0.6931471805599453
iteration 7 batch 15400 training_loss 0.6931471805599453
iteration 7 batch 15410 training_loss 0.6931471805599453
iteration 7 batch 15420 training_loss 0.6931471805599453
iteration 7 batch 15430 training_loss 0.6931471805599453
iteration 7 batch 15440 training_loss 0.6931471805599453
iteration 7 batch 15450 training_loss 0.6931471805599453
iteration 7 batch 15460 training_loss 0.6931471805599453
iteration 7 batch 15470 training_loss 0.6931471805599453
iteration 7 batch 15480 training_loss 0.6931471805599453
iteration 7 batch 15490 training_loss 0.6931471805599453
iteration 7 batch 15500 training_loss 0.6931471805599453
iteration 7 batch 15510 training_loss 0.6931471805599453
iteration 7 batch 15520 training_loss 0.6931471805599453
iteration 7 batch 15530 training_loss 0.6931471805599453
iteration 7 batch 15540 training_loss 0.6931471805599453
iteration 7 batch 15550 training_loss 0.6931471805599453
iteration 7 batch 15560 training_loss 0.6931471805599453
iteration 7 batch 15570 training_loss 0.6931471805599453
iteration 7 batch 15580 training_loss 0.6931471805599453
iteration 7 batch 15590 training_loss 0.6931471805599453
iteration 7 batch 15600 training_loss 0.6931471805599453
iteration 7 batch 15610 training_loss 0.6931471805599453
iteration 7 batch 15620 training_loss 0.6931471805599453
iteration 7 batch 15630 training_loss 0.6931471805599453
iteration 7 batch 15640 training_loss 0.6931471805599453
iteration 7 batch 15650 training_loss 0.6931471805599453
iteration 7 batch 15660 training_loss 0.6931471805599453
iteration 7 batch 15670 training_loss 0.6931471805599453
iteration 7 batch 15680 training_loss 0.6931471805599453
iteration 7 batch 15690 training_loss 0.6931471805599453
iteration 7 batch 15700 training_loss 0.6931471805599453
iteration 7 batch 15710 training_loss 0.6931471805599453
iteration 7 batch 15720 training_loss 0.6931471805599453
iteration 7 batch 15730 training_loss 0.6931471805599453
iteration 7 batch 15740 training_loss 0.6931471805599453
iteration 7 batch 15750 training_loss 0.6931471805599453
iteration 7 batch 15760 training_loss 0.6931471805599453
iteration 7 batch 15770 training_loss 0.6931471805599453
iteration 7 batch 15780 training_loss 0.6931471805599453
iteration 7 batch 15790 training_loss 0.6931471805599453
iteration 7 batch 15800 training_loss 0.6931471805599453
iteration 7 batch 15810 training_loss 0.6931471805599453
iteration 7 batch 15820 training_loss 0.6931471805599453
iteration 7 batch 15830 training_loss 0.6931471805599453
iteration 7 batch 15840 training_loss 0.6931471805599453
iteration 7 batch 15850 training_loss 0.6931471805599453
iteration 7 batch 15860 training_loss 0.6931471805599453
iteration 7 batch 15870 training_loss 0.6931471805599453
iteration 7 batch 15880 training_loss 0.6931471805599453
iteration 7 batch 15890 training_loss 0.6931471805599453
iteration 7 batch 15900 training_loss 0.6931471805599453
iteration 7 batch 15910 training_loss 0.6931471805599453
iteration 7 batch 15920 training_loss 0.6931471805599453
iteration 7 batch 15930 training_loss 0.6916632528527511
iteration 7 batch 15940 training_loss 0.6931471805599453
iteration 7 batch 15950 training_loss 0.6931471805599453
iteration 7 batch 15960 training_loss 0.6931471805599453
iteration 7 batch 15970 training_loss 0.6931471805599453
iteration 7 batch 15980 training_loss 0.6931471805599453
iteration 7 batch 15990 training_loss 0.6931471805599453
iteration 7 batch 16000 training_loss 0.6931471805599453
iteration 7 batch 16010 training_loss 0.6931471805599453
iteration 7 batch 16020 training_loss 0.6931471805599453
iteration 7 batch 16030 training_loss 0.6931471805599453
iteration 7 batch 16040 training_loss 0.6931471805599453
iteration 7 batch 16050 training_loss 0.6931471805599453
iteration 7 batch 16060 training_loss 0.6931471805599453
iteration 7 batch 16070 training_loss 0.6931471805599453
iteration 7 batch 16080 training_loss 0.6931471805599453
iteration 7 batch 16090 training_loss 0.6931471805599453
iteration 7 batch 16100 training_loss 0.6931471805599453
iteration 7 batch 16110 training_loss 0.6931471805599453
iteration 7 batch 16120 training_loss 0.6931471805599453
iteration 7 batch 16130 training_loss 0.6931471805599453
iteration 7 batch 16140 training_loss 0.6931471805599453
iteration 7 batch 16150 training_loss 0.6931471805599453
iteration 7 batch 16160 training_loss 0.6931471805599453
iteration 7 batch 16170 training_loss 0.6931471805599453
iteration 7 batch 16180 training_loss 0.6931471805599453
iteration 7 batch 16190 training_loss 0.6931471805599453
iteration 7 batch 16200 training_loss 0.6931471805599453
iteration 7 batch 16210 training_loss 0.6931471805599453
iteration 7 batch 16220 training_loss 0.6931471805599453
iteration 7 batch 16230 training_loss 0.6931471805599453
iteration 7 batch 16240 training_loss 0.6931471805599453
iteration 7 batch 16250 training_loss 0.6931471805599453
iteration 7 batch 16260 training_loss 0.6931471805599453
iteration 7 batch 16270 training_loss 0.6931471805599453
iteration 7 batch 16280 training_loss 0.6931471805599453
iteration 7 batch 16290 training_loss 0.6931471805599453
iteration 7 batch 16300 training_loss 0.6931471805599453
iteration 7 batch 16310 training_loss 0.6931471805599453
iteration 7 batch 16320 training_loss 0.6931471805599453
iteration 7 batch 16330 training_loss 0.6931471805599453
iteration 7 batch 16340 training_loss 0.6931471805599453
iteration 7 batch 16350 training_loss 0.6931471805599453
iteration 7 batch 16360 training_loss 0.6931471805599453
iteration 7 batch 16370 training_loss 0.6916632528527511
iteration 7 batch 16380 training_loss 0.6916632528527511
iteration 7 batch 16390 training_loss 0.6931471805599453
iteration 7 batch 16400 training_loss 0.6931471805599453
iteration 7 batch 16410 training_loss 0.6931471805599453
iteration 7 batch 16420 training_loss 0.6931471805599453
iteration 7 batch 16430 training_loss 0.6916632528527511
iteration 7 batch 16440 training_loss 0.6931471805599453
iteration 7 batch 16450 training_loss 0.6931471805599453
iteration 7 batch 16460 training_loss 0.6931471805599453
iteration 7 batch 16470 training_loss 0.6931471805599453
iteration 7 batch 16480 training_loss 0.6931471805599453
iteration 7 batch 16490 training_loss 0.6931471805599453
iteration 7 batch 16500 training_loss 0.6931471805599453
iteration 7 batch 16510 training_loss 0.6931471805599453
iteration 7 batch 16520 training_loss 0.6931471805599453
iteration 7 batch 16530 training_loss 0.6931471805599453
iteration 7 batch 16540 training_loss 0.6931471805599453
iteration 7 batch 16550 training_loss 0.6931471805599453
iteration 7 batch 16560 training_loss 0.6931471805599453
iteration 7 batch 16570 training_loss 0.6931471805599453
iteration 7 batch 16580 training_loss 0.6931471805599453
iteration 7 batch 16590 training_loss 0.6931471805599453
iteration 7 batch 16600 training_loss 0.6931471805599453
iteration 7 batch 16610 training_loss 0.6916632528527511
iteration 7 batch 16620 training_loss 0.6931471805599453
iteration 7 batch 16630 training_loss 0.6931471805599453
iteration 7 batch 16640 training_loss 0.6931471805599453
iteration 7 batch 16650 training_loss 0.6931471805599453
iteration 7 batch 16660 training_loss 0.6916632528527511
iteration 7 batch 16670 training_loss 0.6931471805599453
iteration 7 batch 16680 training_loss 0.6931471805599453
iteration 7 batch 16690 training_loss 0.6931471805599453
iteration 7 batch 16700 training_loss 0.6931471805599453
iteration 7 batch 16710 training_loss 0.6931471805599453
iteration 7 batch 16720 training_loss 0.6931471805599453
iteration 7 batch 16730 training_loss 0.6901793251455568
iteration 7 batch 16740 training_loss 0.6931471805599453
iteration 7 batch 16750 training_loss 0.6931471805599453
iteration 7 batch 16760 training_loss 0.6931471805599453
iteration 7 batch 16770 training_loss 0.6931471805599453
iteration 7 batch 16780 training_loss 0.6931471805599453
iteration 7 batch 16790 training_loss 0.6931471805599453
iteration 7 batch 16800 training_loss 0.6931471805599453
iteration 7 batch 16810 training_loss 0.6931471805599453
iteration 7 batch 16820 training_loss 0.6931471805599453
iteration 7 batch 16830 training_loss 0.6931471805599453
iteration 7 batch 16840 training_loss 0.6931471805599453
iteration 7 batch 16850 training_loss 0.6931471805599453
iteration 7 batch 16860 training_loss 0.6931471805599453
iteration 7 batch 16870 training_loss 0.6931471805599453
iteration 7 batch 16880 training_loss 0.6931471805599453
iteration 7 batch 16890 training_loss 0.6931471805599453
iteration 7 batch 16900 training_loss 0.6931471805599453
iteration 7 batch 16910 training_loss 0.6931471805599453
iteration 7 batch 16920 training_loss 0.6931471805599453
iteration 7 batch 16930 training_loss 0.6931471805599453
iteration 7 batch 16940 training_loss 0.6916632528527511
iteration 7 batch 16950 training_loss 0.6931471805599453
iteration 7 batch 16960 training_loss 0.6931471805599453
iteration 7 batch 16970 training_loss 0.6931471805599453
iteration 7 batch 16980 training_loss 0.6931471805599453
iteration 7 batch 16990 training_loss 0.6931471805599453
iteration 7 batch 17000 training_loss 0.6931471805599453
iteration 7 batch 17010 training_loss 0.6931471805599453
iteration 7 batch 17020 training_loss 0.6931471805599453
iteration 7 batch 17030 training_loss 0.6931471805599453
iteration 7 batch 17040 training_loss 0.6931471805599453
iteration 7 batch 17050 training_loss 0.6931471805599453
iteration 7 batch 17060 training_loss 0.6931471805599453
iteration 7 batch 17070 training_loss 0.6931471805599453
iteration 7 batch 17080 training_loss 0.6931471805599453
iteration 7 batch 17090 training_loss 0.6931471805599453
iteration 7 batch 17100 training_loss 0.6931471805599453
iteration 7 batch 17110 training_loss 0.6931471805599453
iteration 7 batch 17120 training_loss 0.6931471805599453
iteration 7 batch 17130 training_loss 0.6931471805599453
iteration 7 batch 17140 training_loss 0.6931471805599453
iteration 7 batch 17150 training_loss 0.6931471805599453
iteration 7 batch 17160 training_loss 0.6931471805599453
iteration 7 batch 17170 training_loss 0.6931471805599453
iteration 7 batch 17180 training_loss 0.6931471805599453
iteration 7 batch 17190 training_loss 0.6931471805599453
iteration 7 batch 17200 training_loss 0.6931471805599453
iteration 7 batch 17210 training_loss 0.6916632528527511
iteration 7 batch 17220 training_loss 0.6931471805599453
iteration 7 batch 17230 training_loss 0.6931471805599453
iteration 7 batch 17240 training_loss 0.6931471805599453
iteration 7 batch 17250 training_loss 0.6931471805599453
iteration 7 batch 17260 training_loss 0.6931471805599453
iteration 7 batch 17270 training_loss 0.6931471805599453
iteration 7 batch 17280 training_loss 0.6931471805599453
iteration 7 batch 17290 training_loss 0.6931471805599453
iteration 7 batch 17300 training_loss 0.6931471805599453
iteration 7 batch 17310 training_loss 0.6931471805599453
iteration 7 batch 17320 training_loss 0.6931471805599453
iteration 7 batch 17330 training_loss 0.6931471805599453
iteration 7 batch 17340 training_loss 0.6931471805599453
iteration 7 batch 17350 training_loss 0.6931471805599453
iteration 7 batch 17360 training_loss 0.6931471805599453
iteration 7 batch 17370 training_loss 0.6931471805599453
iteration 7 batch 17380 training_loss 0.6931471805599453
iteration 7 batch 17390 training_loss 0.6931471805599453
iteration 7 batch 17400 training_loss 0.6931471805599453
iteration 7 batch 17410 training_loss 0.6916632528527511
iteration 7 batch 17420 training_loss 0.6931471805599453
iteration 7 batch 17430 training_loss 0.6931471805599453
iteration 7 batch 17440 training_loss 0.6931471805599453
iteration 7 batch 17450 training_loss 0.6931471805599453
iteration 7 batch 17460 training_loss 0.6931471805599453
iteration 7 batch 17470 training_loss 0.6931471805599453
iteration 7 batch 17480 training_loss 0.6931471805599453
iteration 7 batch 17490 training_loss 0.6931471805599453
iteration 7 batch 17500 training_loss 0.6931471805599453
iteration 7 batch 17510 training_loss 0.6931471805599453
iteration 7 batch 17520 training_loss 0.6931471805599453
iteration 7 batch 17530 training_loss 0.6931471805599453
iteration 7 batch 17540 training_loss 0.6931471805599453
iteration 7 batch 17550 training_loss 0.6931471805599453
iteration 7 batch 17560 training_loss 0.6931471805599453
iteration 7 batch 17570 training_loss 0.6931471805599453
iteration 7 batch 17580 training_loss 0.6931471805599453
iteration 7 batch 17590 training_loss 0.6931471805599453
iteration 7 batch 17600 training_loss 0.6931471805599453
iteration 7 batch 17610 training_loss 0.6931471805599453
iteration 7 batch 17620 training_loss 0.6931471805599453
iteration 7 batch 17630 training_loss 0.6931471805599453
iteration 7 batch 17640 training_loss 0.6931471805599453
iteration 7 batch 17650 training_loss 0.6931471805599453
iteration 7 batch 17660 training_loss 0.6931471805599453
iteration 7 batch 17670 training_loss 0.6931471805599453
iteration 7 batch 17680 training_loss 0.6931471805599453
iteration 7 batch 17690 training_loss 0.6931471805599453
iteration 7 batch 17700 training_loss 0.6931471805599453
iteration 7 batch 17710 training_loss 0.6931471805599453
iteration 7 batch 17720 training_loss 0.6931471805599453
iteration 7 batch 17730 training_loss 0.6931471805599453
iteration 7 batch 17740 training_loss 0.6931471805599453
iteration 7 batch 17750 training_loss 0.6931471805599453
iteration 7 batch 17760 training_loss 0.6931471805599453
iteration 7 batch 17770 training_loss 0.6916632528527511
iteration 7 batch 17780 training_loss 0.6931471805599453
iteration 7 batch 17790 training_loss 0.6931471805599453
iteration 7 batch 17800 training_loss 0.6931471805599453
iteration 7 batch 17810 training_loss 0.6931471805599453
iteration 7 batch 17820 training_loss 0.6931471805599453
iteration 7 batch 17830 training_loss 0.6931471805599453
iteration 7 batch 17840 training_loss 0.6931471805599453
iteration 7 batch 17850 training_loss 0.6931471805599453
iteration 7 batch 17860 training_loss 0.6916632528527511
iteration 7 batch 17870 training_loss 0.6931471805599453
iteration 7 batch 17880 training_loss 0.6931471805599453
iteration 7 batch 17890 training_loss 0.6931471805599453
iteration 7 batch 17900 training_loss 0.6931471805599453
iteration 7 batch 17910 training_loss 0.6931471805599453
iteration 7 batch 17920 training_loss 0.6931471805599453
iteration 7 batch 17930 training_loss 0.6931471805599453
iteration 7 batch 17940 training_loss 0.6931471805599453
iteration 7 batch 17950 training_loss 0.6931471805599453
iteration 7 batch 17960 training_loss 0.6931471805599453
iteration 7 batch 17970 training_loss 0.6931471805599453
iteration 7 batch 17980 training_loss 0.6931471805599453
iteration 7 batch 17990 training_loss 0.6931471805599453
iteration 7 batch 18000 training_loss 0.6931471805599453
iteration 7 batch 18010 training_loss 0.6931471805599453
iteration 7 batch 18020 training_loss 0.6931471805599453
iteration 7 batch 18030 training_loss 0.6931471805599453
iteration 7 batch 18040 training_loss 0.6931471805599453
iteration 7 batch 18050 training_loss 0.6931471805599453
iteration 7 batch 18060 training_loss 0.6931471805599453
iteration 7 batch 18070 training_loss 0.6931471805599453
iteration 7 batch 18080 training_loss 0.6931471805599453
iteration 7 batch 18090 training_loss 0.6931471805599453
iteration 7 batch 18100 training_loss 0.6931471805599453
iteration 7 batch 18110 training_loss 0.6931471805599453
iteration 7 batch 18120 training_loss 0.6931471805599453
iteration 7 batch 18130 training_loss 0.6931471805599453
iteration 7 batch 18140 training_loss 0.6931471805599453
iteration 7 batch 18150 training_loss 0.6931471805599453
iteration 7 batch 18160 training_loss 0.6931471805599453
iteration 7 batch 18170 training_loss 0.6931471805599453
iteration 7 batch 18180 training_loss 0.6931471805599453
iteration 7 batch 18190 training_loss 0.6931471805599453
iteration 7 batch 18200 training_loss 0.6931471805599453
iteration 7 batch 18210 training_loss 0.6931471805599453
iteration 7 batch 18220 training_loss 0.6931471805599453
iteration 7 batch 18230 training_loss 0.6931471805599453
iteration 7 batch 18240 training_loss 0.6931471805599453
iteration 7 batch 18250 training_loss 0.6931471805599453
iteration 7 batch 18260 training_loss 0.6931471805599453
iteration 7 batch 18270 training_loss 0.6931471805599453
iteration 7 batch 18280 training_loss 0.6931471805599453
iteration 7 batch 18290 training_loss 0.6931471805599453
iteration 7 batch 18300 training_loss 0.6931471805599453
iteration 7 batch 18310 training_loss 0.6931471805599453
iteration 7 batch 18320 training_loss 0.6931471805599453
iteration 7 batch 18330 training_loss 0.6931471805599453
iteration 7 batch 18340 training_loss 0.6931471805599453
iteration 7 batch 18350 training_loss 0.6931471805599453
iteration 7 batch 18360 training_loss 0.6931471805599453
iteration 7 batch 18370 training_loss 0.6931471805599453
iteration 7 batch 18380 training_loss 0.6931471805599453
iteration 7 batch 18390 training_loss 0.6931471805599453
iteration 7 batch 18400 training_loss 0.6931471805599453
iteration 7 batch 18410 training_loss 0.6931471805599453
iteration 7 batch 18420 training_loss 0.6931471805599453
iteration 7 batch 18430 training_loss 0.6931471805599453
iteration 7 batch 18440 training_loss 0.6931471805599453
iteration 7 batch 18450 training_loss 0.6931471805599453
iteration 7 batch 18460 training_loss 0.6916632528527511
iteration 7 batch 18470 training_loss 0.6931471805599453
iteration 7 batch 18480 training_loss 0.6931471805599453
iteration 7 batch 18490 training_loss 0.6931471805599453
iteration 7 batch 18500 training_loss 0.6931471805599453
iteration 7 batch 18510 training_loss 0.6931471805599453
iteration 7 batch 18520 training_loss 0.6931471805599453
iteration 7 batch 18530 training_loss 0.6931471805599453
iteration 7 batch 18540 training_loss 0.6931471805599453
iteration 7 batch 18550 training_loss 0.6931471805599453
iteration 7 batch 18560 training_loss 0.6931471805599453
iteration 7 batch 18570 training_loss 0.6931471805599453
iteration 7 batch 18580 training_loss 0.6931471805599453
iteration 7 batch 18590 training_loss 0.6931471805599453
iteration 7 batch 18600 training_loss 0.6931471805599453
iteration 7 batch 18610 training_loss 0.6931471805599453
iteration 8 batch 0 training_loss 0.6931471805599453
iteration 8 batch 10 training_loss 0.6931471805599453
iteration 8 batch 20 training_loss 0.6931471805599453
iteration 8 batch 30 training_loss 0.6931471805599453
iteration 8 batch 40 training_loss 0.6931471805599453
iteration 8 batch 50 training_loss 0.6931471805599453
iteration 8 batch 60 training_loss 0.6931471805599453
iteration 8 batch 70 training_loss 0.6931471805599453
iteration 8 batch 80 training_loss 0.6931471805599453
iteration 8 batch 90 training_loss 0.6931471805599453
iteration 8 batch 100 training_loss 0.6931471805599453
iteration 8 batch 110 training_loss 0.6931471805599453
iteration 8 batch 120 training_loss 0.6931471805599453
iteration 8 batch 130 training_loss 0.6931471805599453
iteration 8 batch 140 training_loss 0.6916632528527511
iteration 8 batch 150 training_loss 0.6931471805599453
iteration 8 batch 160 training_loss 0.6931471805599453
iteration 8 batch 170 training_loss 0.6931471805599453
iteration 8 batch 180 training_loss 0.6931471805599453
iteration 8 batch 190 training_loss 0.6931471805599453
iteration 8 batch 200 training_loss 0.6931471805599453
iteration 8 batch 210 training_loss 0.6931471805599453
iteration 8 batch 220 training_loss 0.6916632528527511
iteration 8 batch 230 training_loss 0.6931471805599453
iteration 8 batch 240 training_loss 0.6931471805599453
iteration 8 batch 250 training_loss 0.6931471805599453
iteration 8 batch 260 training_loss 0.6931471805599453
iteration 8 batch 270 training_loss 0.6931471805599453
iteration 8 batch 280 training_loss 0.6931471805599453
iteration 8 batch 290 training_loss 0.6931471805599453
iteration 8 batch 300 training_loss 0.6931471805599453
iteration 8 batch 310 training_loss 0.6931471805599453
iteration 8 batch 320 training_loss 0.6931471805599453
iteration 8 batch 330 training_loss 0.6931471805599453
iteration 8 batch 340 training_loss 0.6931471805599453
iteration 8 batch 350 training_loss 0.6916632528527511
iteration 8 batch 360 training_loss 0.6931471805599453
iteration 8 batch 370 training_loss 0.6931471805599453
iteration 8 batch 380 training_loss 0.6931471805599453
iteration 8 batch 390 training_loss 0.6931471805599453
iteration 8 batch 400 training_loss 0.6931471805599453
iteration 8 batch 410 training_loss 0.6931471805599453
iteration 8 batch 420 training_loss 0.6931471805599453
iteration 8 batch 430 training_loss 0.6931471805599453
iteration 8 batch 440 training_loss 0.6931471805599453
iteration 8 batch 450 training_loss 0.6931471805599453
iteration 8 batch 460 training_loss 0.6931471805599453
iteration 8 batch 470 training_loss 0.6931471805599453
iteration 8 batch 480 training_loss 0.6931471805599453
iteration 8 batch 490 training_loss 0.6931471805599453
iteration 8 batch 500 training_loss 0.6931471805599453
iteration 8 batch 510 training_loss 0.6931471805599453
iteration 8 batch 520 training_loss 0.6931471805599453
iteration 8 batch 530 training_loss 0.6916632528527511
iteration 8 batch 540 training_loss 0.6931471805599453
iteration 8 batch 550 training_loss 0.6931471805599453
iteration 8 batch 560 training_loss 0.6931471805599453
iteration 8 batch 570 training_loss 0.6931471805599453
iteration 8 batch 580 training_loss 0.6931471805599453
iteration 8 batch 590 training_loss 0.6931471805599453
iteration 8 batch 600 training_loss 0.6931471805599453
iteration 8 batch 610 training_loss 0.6931471805599453
iteration 8 batch 620 training_loss 0.6931471805599453
iteration 8 batch 630 training_loss 0.6931471805599453
iteration 8 batch 640 training_loss 0.6931471805599453
iteration 8 batch 650 training_loss 0.6931471805599453
iteration 8 batch 660 training_loss 0.6931471805599453
iteration 8 batch 670 training_loss 0.6931471805599453
iteration 8 batch 680 training_loss 0.6931471805599453
iteration 8 batch 690 training_loss 0.6931471805599453
iteration 8 batch 700 training_loss 0.6931471805599453
iteration 8 batch 710 training_loss 0.6931471805599453
iteration 8 batch 720 training_loss 0.6931471805599453
iteration 8 batch 730 training_loss 0.6916632528527511
iteration 8 batch 740 training_loss 0.6931471805599453
iteration 8 batch 750 training_loss 0.6931471805599453
iteration 8 batch 760 training_loss 0.6931471805599453
iteration 8 batch 770 training_loss 0.6931471805599453
iteration 8 batch 780 training_loss 0.6931471805599453
iteration 8 batch 790 training_loss 0.6931471805599453
iteration 8 batch 800 training_loss 0.6931471805599453
iteration 8 batch 810 training_loss 0.6931471805599453
iteration 8 batch 820 training_loss 0.6931471805599453
iteration 8 batch 830 training_loss 0.6931471805599453
iteration 8 batch 840 training_loss 0.6931471805599453
iteration 8 batch 850 training_loss 0.6916632528527511
iteration 8 batch 860 training_loss 0.6931471805599453
iteration 8 batch 870 training_loss 0.6931471805599453
iteration 8 batch 880 training_loss 0.6931471805599453
iteration 8 batch 890 training_loss 0.6931471805599453
iteration 8 batch 900 training_loss 0.6931471805599453
iteration 8 batch 910 training_loss 0.6931471805599453
iteration 8 batch 920 training_loss 0.6931471805599453
iteration 8 batch 930 training_loss 0.6931471805599453
iteration 8 batch 940 training_loss 0.6931471805599453
iteration 8 batch 950 training_loss 0.6931471805599453
iteration 8 batch 960 training_loss 0.6931471805599453
iteration 8 batch 970 training_loss 0.6931471805599453
iteration 8 batch 980 training_loss 0.6931471805599453
iteration 8 batch 990 training_loss 0.6931471805599453
iteration 8 batch 1000 training_loss 0.6931471805599453
iteration 8 batch 1010 training_loss 0.6931471805599453
iteration 8 batch 1020 training_loss 0.6916632528527511
iteration 8 batch 1030 training_loss 0.6931471805599453
iteration 8 batch 1040 training_loss 0.6931471805599453
iteration 8 batch 1050 training_loss 0.6931471805599453
iteration 8 batch 1060 training_loss 0.6916632528527511
iteration 8 batch 1070 training_loss 0.6931471805599453
iteration 8 batch 1080 training_loss 0.6931471805599453
iteration 8 batch 1090 training_loss 0.6931471805599453
iteration 8 batch 1100 training_loss 0.6931471805599453
iteration 8 batch 1110 training_loss 0.6931471805599453
iteration 8 batch 1120 training_loss 0.6931471805599453
iteration 8 batch 1130 training_loss 0.6931471805599453
iteration 8 batch 1140 training_loss 0.6931471805599453
iteration 8 batch 1150 training_loss 0.6931471805599453
iteration 8 batch 1160 training_loss 0.6931471805599453
iteration 8 batch 1170 training_loss 0.6931471805599453
iteration 8 batch 1180 training_loss 0.6916632528527511
iteration 8 batch 1190 training_loss 0.6931471805599453
iteration 8 batch 1200 training_loss 0.6931471805599453
iteration 8 batch 1210 training_loss 0.6931471805599453
iteration 8 batch 1220 training_loss 0.6931471805599453
iteration 8 batch 1230 training_loss 0.6931471805599453
iteration 8 batch 1240 training_loss 0.6931471805599453
iteration 8 batch 1250 training_loss 0.6931471805599453
iteration 8 batch 1260 training_loss 0.6931471805599453
iteration 8 batch 1270 training_loss 0.6931471805599453
iteration 8 batch 1280 training_loss 0.6931471805599453
iteration 8 batch 1290 training_loss 0.6931471805599453
iteration 8 batch 1300 training_loss 0.6931471805599453
iteration 8 batch 1310 training_loss 0.6931471805599453
iteration 8 batch 1320 training_loss 0.6931471805599453
iteration 8 batch 1330 training_loss 0.6931471805599453
iteration 8 batch 1340 training_loss 0.6931471805599453
iteration 8 batch 1350 training_loss 0.6931471805599453
iteration 8 batch 1360 training_loss 0.6931471805599453
iteration 8 batch 1370 training_loss 0.6931471805599453
iteration 8 batch 1380 training_loss 0.6931471805599453
iteration 8 batch 1390 training_loss 0.6931471805599453
iteration 8 batch 1400 training_loss 0.6931471805599453
iteration 8 batch 1410 training_loss 0.6931471805599453
iteration 8 batch 1420 training_loss 0.6931471805599453
iteration 8 batch 1430 training_loss 0.6931471805599453
iteration 8 batch 1440 training_loss 0.6931471805599453
iteration 8 batch 1450 training_loss 0.6931471805599453
iteration 8 batch 1460 training_loss 0.6916632528527511
iteration 8 batch 1470 training_loss 0.6931471805599453
iteration 8 batch 1480 training_loss 0.6931471805599453
iteration 8 batch 1490 training_loss 0.6931471805599453
iteration 8 batch 1500 training_loss 0.6931471805599453
iteration 8 batch 1510 training_loss 0.6931471805599453
iteration 8 batch 1520 training_loss 0.6931471805599453
iteration 8 batch 1530 training_loss 0.6931471805599453
iteration 8 batch 1540 training_loss 0.6931471805599453
iteration 8 batch 1550 training_loss 0.6931471805599453
iteration 8 batch 1560 training_loss 0.6931471805599453
iteration 8 batch 1570 training_loss 0.6931471805599453
iteration 8 batch 1580 training_loss 0.6931471805599453
iteration 8 batch 1590 training_loss 0.6931471805599453
iteration 8 batch 1600 training_loss 0.6931471805599453
iteration 8 batch 1610 training_loss 0.6931471805599453
iteration 8 batch 1620 training_loss 0.6931471805599453
iteration 8 batch 1630 training_loss 0.6931471805599453
iteration 8 batch 1640 training_loss 0.6931471805599453
iteration 8 batch 1650 training_loss 0.6931471805599453
iteration 8 batch 1660 training_loss 0.6931471805599453
iteration 8 batch 1670 training_loss 0.6931471805599453
iteration 8 batch 1680 training_loss 0.6931471805599453
iteration 8 batch 1690 training_loss 0.6931471805599453
iteration 8 batch 1700 training_loss 0.6931471805599453
iteration 8 batch 1710 training_loss 0.6931471805599453
iteration 8 batch 1720 training_loss 0.6931471805599453
iteration 8 batch 1730 training_loss 0.6931471805599453
iteration 8 batch 1740 training_loss 0.6931471805599453
iteration 8 batch 1750 training_loss 0.6931471805599453
iteration 8 batch 1760 training_loss 0.6931471805599453
iteration 8 batch 1770 training_loss 0.6931471805599453
iteration 8 batch 1780 training_loss 0.6916632528527511
iteration 8 batch 1790 training_loss 0.6931471805599453
iteration 8 batch 1800 training_loss 0.6931471805599453
iteration 8 batch 1810 training_loss 0.6931471805599453
iteration 8 batch 1820 training_loss 0.6931471805599453
iteration 8 batch 1830 training_loss 0.6931471805599453
iteration 8 batch 1840 training_loss 0.6931471805599453
iteration 8 batch 1850 training_loss 0.6931471805599453
iteration 8 batch 1860 training_loss 0.6931471805599453
iteration 8 batch 1870 training_loss 0.6931471805599453
iteration 8 batch 1880 training_loss 0.6931471805599453
iteration 8 batch 1890 training_loss 0.6931471805599453
iteration 8 batch 1900 training_loss 0.6931471805599453
iteration 8 batch 1910 training_loss 0.6931471805599453
iteration 8 batch 1920 training_loss 0.6931471805599453
iteration 8 batch 1930 training_loss 0.6931471805599453
iteration 8 batch 1940 training_loss 0.6931471805599453
iteration 8 batch 1950 training_loss 0.6931471805599453
iteration 8 batch 1960 training_loss 0.6931471805599453
iteration 8 batch 1970 training_loss 0.6931471805599453
iteration 8 batch 1980 training_loss 0.6931471805599453
iteration 8 batch 1990 training_loss 0.6931471805599453
iteration 8 batch 2000 training_loss 0.6931471805599453
iteration 8 batch 2010 training_loss 0.6931471805599453
iteration 8 batch 2020 training_loss 0.6931471805599453
iteration 8 batch 2030 training_loss 0.6931471805599453
iteration 8 batch 2040 training_loss 0.6931471805599453
iteration 8 batch 2050 training_loss 0.6931471805599453
iteration 8 batch 2060 training_loss 0.6931471805599453
iteration 8 batch 2070 training_loss 0.6931471805599453
iteration 8 batch 2080 training_loss 0.6916632528527511
iteration 8 batch 2090 training_loss 0.6931471805599453
iteration 8 batch 2100 training_loss 0.6931471805599453
iteration 8 batch 2110 training_loss 0.6931471805599453
iteration 8 batch 2120 training_loss 0.6931471805599453
iteration 8 batch 2130 training_loss 0.6931471805599453
iteration 8 batch 2140 training_loss 0.6931471805599453
iteration 8 batch 2150 training_loss 0.6931471805599453
iteration 8 batch 2160 training_loss 0.6931471805599453
iteration 8 batch 2170 training_loss 0.6931471805599453
iteration 8 batch 2180 training_loss 0.6931471805599453
iteration 8 batch 2190 training_loss 0.6931471805599453
iteration 8 batch 2200 training_loss 0.6931471805599453
iteration 8 batch 2210 training_loss 0.6931471805599453
iteration 8 batch 2220 training_loss 0.6931471805599453
iteration 8 batch 2230 training_loss 0.6931471805599453
iteration 8 batch 2240 training_loss 0.6931471805599453
iteration 8 batch 2250 training_loss 0.6931471805599453
iteration 8 batch 2260 training_loss 0.6931471805599453
iteration 8 batch 2270 training_loss 0.6931471805599453
iteration 8 batch 2280 training_loss 0.6931471805599453
iteration 8 batch 2290 training_loss 0.6931471805599453
iteration 8 batch 2300 training_loss 0.6931471805599453
iteration 8 batch 2310 training_loss 0.6931471805599453
iteration 8 batch 2320 training_loss 0.6931471805599453
iteration 8 batch 2330 training_loss 0.6931471805599453
iteration 8 batch 2340 training_loss 0.6931471805599453
iteration 8 batch 2350 training_loss 0.6931471805599453
iteration 8 batch 2360 training_loss 0.6931471805599453
iteration 8 batch 2370 training_loss 0.6931471805599453
iteration 8 batch 2380 training_loss 0.6931471805599453
iteration 8 batch 2390 training_loss 0.6931471805599453
iteration 8 batch 2400 training_loss 0.6931471805599453
iteration 8 batch 2410 training_loss 0.6931471805599453
iteration 8 batch 2420 training_loss 0.6931471805599453
iteration 8 batch 2430 training_loss 0.6931471805599453
iteration 8 batch 2440 training_loss 0.6931471805599453
iteration 8 batch 2450 training_loss 0.6931471805599453
iteration 8 batch 2460 training_loss 0.6931471805599453
iteration 8 batch 2470 training_loss 0.6931471805599453
iteration 8 batch 2480 training_loss 0.6931471805599453
iteration 8 batch 2490 training_loss 0.6931471805599453
iteration 8 batch 2500 training_loss 0.6931471805599453
iteration 8 batch 2510 training_loss 0.6931471805599453
iteration 8 batch 2520 training_loss 0.6931471805599453
iteration 8 batch 2530 training_loss 0.6931471805599453
iteration 8 batch 2540 training_loss 0.6931471805599453
iteration 8 batch 2550 training_loss 0.6931471805599453
iteration 8 batch 2560 training_loss 0.6931471805599453
iteration 8 batch 2570 training_loss 0.6931471805599453
iteration 8 batch 2580 training_loss 0.6931471805599453
iteration 8 batch 2590 training_loss 0.6931471805599453
iteration 8 batch 2600 training_loss 0.6931471805599453
iteration 8 batch 2610 training_loss 0.6931471805599453
iteration 8 batch 2620 training_loss 0.6931471805599453
iteration 8 batch 2630 training_loss 0.6931471805599453
iteration 8 batch 2640 training_loss 0.6931471805599453
iteration 8 batch 2650 training_loss 0.6931471805599453
iteration 8 batch 2660 training_loss 0.6931471805599453
iteration 8 batch 2670 training_loss 0.6931471805599453
iteration 8 batch 2680 training_loss 0.6931471805599453
iteration 8 batch 2690 training_loss 0.6931471805599453
iteration 8 batch 2700 training_loss 0.6931471805599453
iteration 8 batch 2710 training_loss 0.6931471805599453
iteration 8 batch 2720 training_loss 0.6931471805599453
iteration 8 batch 2730 training_loss 0.6931471805599453
iteration 8 batch 2740 training_loss 0.6931471805599453
iteration 8 batch 2750 training_loss 0.6931471805599453
iteration 8 batch 2760 training_loss 0.6931471805599453
iteration 8 batch 2770 training_loss 0.6931471805599453
iteration 8 batch 2780 training_loss 0.6931471805599453
iteration 8 batch 2790 training_loss 0.6931471805599453
iteration 8 batch 2800 training_loss 0.6931471805599453
iteration 8 batch 2810 training_loss 0.6931471805599453
iteration 8 batch 2820 training_loss 0.6931471805599453
iteration 8 batch 2830 training_loss 0.6931471805599453
iteration 8 batch 2840 training_loss 0.6931471805599453
iteration 8 batch 2850 training_loss 0.6931471805599453
iteration 8 batch 2860 training_loss 0.6931471805599453
iteration 8 batch 2870 training_loss 0.6931471805599453
iteration 8 batch 2880 training_loss 0.6931471805599453
iteration 8 batch 2890 training_loss 0.6931471805599453
iteration 8 batch 2900 training_loss 0.6931471805599453
iteration 8 batch 2910 training_loss 0.6931471805599453
iteration 8 batch 2920 training_loss 0.6931471805599453
iteration 8 batch 2930 training_loss 0.6931471805599453
iteration 8 batch 2940 training_loss 0.6931471805599453
iteration 8 batch 2950 training_loss 0.6931471805599453
iteration 8 batch 2960 training_loss 0.6931471805599453
iteration 8 batch 2970 training_loss 0.6931471805599453
iteration 8 batch 2980 training_loss 0.6931471805599453
iteration 8 batch 2990 training_loss 0.6931471805599453
iteration 8 batch 3000 training_loss 0.6931471805599453
iteration 8 batch 3010 training_loss 0.6931471805599453
iteration 8 batch 3020 training_loss 0.6931471805599453
iteration 8 batch 3030 training_loss 0.6931471805599453
iteration 8 batch 3040 training_loss 0.6931471805599453
iteration 8 batch 3050 training_loss 0.6931471805599453
iteration 8 batch 3060 training_loss 0.6931471805599453
iteration 8 batch 3070 training_loss 0.6931471805599453
iteration 8 batch 3080 training_loss 0.6931471805599453
iteration 8 batch 3090 training_loss 0.6931471805599453
iteration 8 batch 3100 training_loss 0.6931471805599453
iteration 8 batch 3110 training_loss 0.6931471805599453
iteration 8 batch 3120 training_loss 0.6931471805599453
iteration 8 batch 3130 training_loss 0.6931471805599453
iteration 8 batch 3140 training_loss 0.6931471805599453
iteration 8 batch 3150 training_loss 0.6931471805599453
iteration 8 batch 3160 training_loss 0.6916632528527511
iteration 8 batch 3170 training_loss 0.6931471805599453
iteration 8 batch 3180 training_loss 0.6931471805599453
iteration 8 batch 3190 training_loss 0.6931471805599453
iteration 8 batch 3200 training_loss 0.6931471805599453
iteration 8 batch 3210 training_loss 0.6931471805599453
iteration 8 batch 3220 training_loss 0.6931471805599453
iteration 8 batch 3230 training_loss 0.6931471805599453
iteration 8 batch 3240 training_loss 0.6931471805599453
iteration 8 batch 3250 training_loss 0.6931471805599453
iteration 8 batch 3260 training_loss 0.6931471805599453
iteration 8 batch 3270 training_loss 0.6916632528527511
iteration 8 batch 3280 training_loss 0.6931471805599453
iteration 8 batch 3290 training_loss 0.6931471805599453
iteration 8 batch 3300 training_loss 0.6931471805599453
iteration 8 batch 3310 training_loss 0.6931471805599453
iteration 8 batch 3320 training_loss 0.6931471805599453
iteration 8 batch 3330 training_loss 0.6931471805599453
iteration 8 batch 3340 training_loss 0.6931471805599453
iteration 8 batch 3350 training_loss 0.6931471805599453
iteration 8 batch 3360 training_loss 0.6931471805599453
iteration 8 batch 3370 training_loss 0.6931471805599453
iteration 8 batch 3380 training_loss 0.6931471805599453
iteration 8 batch 3390 training_loss 0.6931471805599453
iteration 8 batch 3400 training_loss 0.6931471805599453
iteration 8 batch 3410 training_loss 0.6916632528527511
iteration 8 batch 3420 training_loss 0.6931471805599453
iteration 8 batch 3430 training_loss 0.6931471805599453
iteration 8 batch 3440 training_loss 0.6931471805599453
iteration 8 batch 3450 training_loss 0.6931471805599453
iteration 8 batch 3460 training_loss 0.6931471805599453
iteration 8 batch 3470 training_loss 0.6931471805599453
iteration 8 batch 3480 training_loss 0.6931471805599453
iteration 8 batch 3490 training_loss 0.6931471805599453
iteration 8 batch 3500 training_loss 0.6931471805599453
iteration 8 batch 3510 training_loss 0.6931471805599453
iteration 8 batch 3520 training_loss 0.6931471805599453
iteration 8 batch 3530 training_loss 0.6931471805599453
iteration 8 batch 3540 training_loss 0.6931471805599453
iteration 8 batch 3550 training_loss 0.6931471805599453
iteration 8 batch 3560 training_loss 0.6931471805599453
iteration 8 batch 3570 training_loss 0.6916632528527511
iteration 8 batch 3580 training_loss 0.6931471805599453
iteration 8 batch 3590 training_loss 0.6931471805599453
iteration 8 batch 3600 training_loss 0.6931471805599453
iteration 8 batch 3610 training_loss 0.6931471805599453
iteration 8 batch 3620 training_loss 0.6931471805599453
iteration 8 batch 3630 training_loss 0.6931471805599453
iteration 8 batch 3640 training_loss 0.6931471805599453
iteration 8 batch 3650 training_loss 0.6931471805599453
iteration 8 batch 3660 training_loss 0.6931471805599453
iteration 8 batch 3670 training_loss 0.6931471805599453
iteration 8 batch 3680 training_loss 0.6931471805599453
iteration 8 batch 3690 training_loss 0.6931471805599453
iteration 8 batch 3700 training_loss 0.6931471805599453
iteration 8 batch 3710 training_loss 0.6931471805599453
iteration 8 batch 3720 training_loss 0.6931471805599453
iteration 8 batch 3730 training_loss 0.6931471805599453
iteration 8 batch 3740 training_loss 0.6931471805599453
iteration 8 batch 3750 training_loss 0.6931471805599453
iteration 8 batch 3760 training_loss 0.6931471805599453
iteration 8 batch 3770 training_loss 0.6931471805599453
iteration 8 batch 3780 training_loss 0.6931471805599453
iteration 8 batch 3790 training_loss 0.6931471805599453
iteration 8 batch 3800 training_loss 0.6931471805599453
iteration 8 batch 3810 training_loss 0.6931471805599453
iteration 8 batch 3820 training_loss 0.6916632528527511
iteration 8 batch 3830 training_loss 0.6931471805599453
iteration 8 batch 3840 training_loss 0.6931471805599453
iteration 8 batch 3850 training_loss 0.6931471805599453
iteration 8 batch 3860 training_loss 0.6931471805599453
iteration 8 batch 3870 training_loss 0.6931471805599453
iteration 8 batch 3880 training_loss 0.6931471805599453
iteration 8 batch 3890 training_loss 0.6931471805599453
iteration 8 batch 3900 training_loss 0.6931471805599453
iteration 8 batch 3910 training_loss 0.6931471805599453
iteration 8 batch 3920 training_loss 0.6931471805599453
iteration 8 batch 3930 training_loss 0.6931471805599453
iteration 8 batch 3940 training_loss 0.6931471805599453
iteration 8 batch 3950 training_loss 0.6931471805599453
iteration 8 batch 3960 training_loss 0.6931471805599453
iteration 8 batch 3970 training_loss 0.6931471805599453
iteration 8 batch 3980 training_loss 0.6931471805599453
iteration 8 batch 3990 training_loss 0.6931471805599453
iteration 8 batch 4000 training_loss 0.6931471805599453
iteration 8 batch 4010 training_loss 0.6931471805599453
iteration 8 batch 4020 training_loss 0.6931471805599453
iteration 8 batch 4030 training_loss 0.6931471805599453
iteration 8 batch 4040 training_loss 0.6931471805599453
iteration 8 batch 4050 training_loss 0.6931471805599453
iteration 8 batch 4060 training_loss 0.6916632528527511
iteration 8 batch 4070 training_loss 0.6931471805599453
iteration 8 batch 4080 training_loss 0.6931471805599453
iteration 8 batch 4090 training_loss 0.6931471805599453
iteration 8 batch 4100 training_loss 0.6931471805599453
iteration 8 batch 4110 training_loss 0.6931471805599453
iteration 8 batch 4120 training_loss 0.6931471805599453
iteration 8 batch 4130 training_loss 0.6931471805599453
iteration 8 batch 4140 training_loss 0.6931471805599453
iteration 8 batch 4150 training_loss 0.6931471805599453
iteration 8 batch 4160 training_loss 0.6931471805599453
iteration 8 batch 4170 training_loss 0.6931471805599453
iteration 8 batch 4180 training_loss 0.6931471805599453
iteration 8 batch 4190 training_loss 0.6931471805599453
iteration 8 batch 4200 training_loss 0.6931471805599453
iteration 8 batch 4210 training_loss 0.6916632528527511
iteration 8 batch 4220 training_loss 0.6931471805599453
iteration 8 batch 4230 training_loss 0.6931471805599453
iteration 8 batch 4240 training_loss 0.6931471805599453
iteration 8 batch 4250 training_loss 0.6931471805599453
iteration 8 batch 4260 training_loss 0.6931471805599453
iteration 8 batch 4270 training_loss 0.6931471805599453
iteration 8 batch 4280 training_loss 0.6931471805599453
iteration 8 batch 4290 training_loss 0.6931471805599453
iteration 8 batch 4300 training_loss 0.6931471805599453
iteration 8 batch 4310 training_loss 0.6931471805599453
iteration 8 batch 4320 training_loss 0.6931471805599453
iteration 8 batch 4330 training_loss 0.6931471805599453
iteration 8 batch 4340 training_loss 0.6931471805599453
iteration 8 batch 4350 training_loss 0.6931471805599453
iteration 8 batch 4360 training_loss 0.6931471805599453
iteration 8 batch 4370 training_loss 0.6931471805599453
iteration 8 batch 4380 training_loss 0.6931471805599453
iteration 8 batch 4390 training_loss 0.6931471805599453
iteration 8 batch 4400 training_loss 0.6931471805599453
iteration 8 batch 4410 training_loss 0.6916632528527511
iteration 8 batch 4420 training_loss 0.6931471805599453
iteration 8 batch 4430 training_loss 0.6931471805599453
iteration 8 batch 4440 training_loss 0.6931471805599453
iteration 8 batch 4450 training_loss 0.6931471805599453
iteration 8 batch 4460 training_loss 0.6931471805599453
iteration 8 batch 4470 training_loss 0.6931471805599453
iteration 8 batch 4480 training_loss 0.6931471805599453
iteration 8 batch 4490 training_loss 0.6931471805599453
iteration 8 batch 4500 training_loss 0.6931471805599453
iteration 8 batch 4510 training_loss 0.6931471805599453
iteration 8 batch 4520 training_loss 0.6931471805599453
iteration 8 batch 4530 training_loss 0.6931471805599453
iteration 8 batch 4540 training_loss 0.6931471805599453
iteration 8 batch 4550 training_loss 0.6931471805599453
iteration 8 batch 4560 training_loss 0.6931471805599453
iteration 8 batch 4570 training_loss 0.6931471805599453
iteration 8 batch 4580 training_loss 0.6931471805599453
iteration 8 batch 4590 training_loss 0.6931471805599453
iteration 8 batch 4600 training_loss 0.6931471805599453
iteration 8 batch 4610 training_loss 0.6931471805599453
iteration 8 batch 4620 training_loss 0.6931471805599453
iteration 8 batch 4630 training_loss 0.6931471805599453
iteration 8 batch 4640 training_loss 0.6931471805599453
iteration 8 batch 4650 training_loss 0.6916632528527511
iteration 8 batch 4660 training_loss 0.6931471805599453
iteration 8 batch 4670 training_loss 0.6931471805599453
iteration 8 batch 4680 training_loss 0.6916632528527511
iteration 8 batch 4690 training_loss 0.6931471805599453
iteration 8 batch 4700 training_loss 0.6931471805599453
iteration 8 batch 4710 training_loss 0.6931471805599453
iteration 8 batch 4720 training_loss 0.6931471805599453
iteration 8 batch 4730 training_loss 0.6931471805599453
iteration 8 batch 4740 training_loss 0.6931471805599453
iteration 8 batch 4750 training_loss 0.6931471805599453
iteration 8 batch 4760 training_loss 0.6931471805599453
iteration 8 batch 4770 training_loss 0.6931471805599453
iteration 8 batch 4780 training_loss 0.6916632528527511
iteration 8 batch 4790 training_loss 0.6931471805599453
iteration 8 batch 4800 training_loss 0.6931471805599453
iteration 8 batch 4810 training_loss 0.6931471805599453
iteration 8 batch 4820 training_loss 0.6931471805599453
iteration 8 batch 4830 training_loss 0.6931471805599453
iteration 8 batch 4840 training_loss 0.6916632528527511
iteration 8 batch 4850 training_loss 0.6931471805599453
iteration 8 batch 4860 training_loss 0.6931471805599453
iteration 8 batch 4870 training_loss 0.6931471805599453
iteration 8 batch 4880 training_loss 0.6916632528527511
iteration 8 batch 4890 training_loss 0.6931471805599453
iteration 8 batch 4900 training_loss 0.6916632528527511
iteration 8 batch 4910 training_loss 0.6931471805599453
iteration 8 batch 4920 training_loss 0.6931471805599453
iteration 8 batch 4930 training_loss 0.6931471805599453
iteration 8 batch 4940 training_loss 0.6931471805599453
iteration 8 batch 4950 training_loss 0.6931471805599453
iteration 8 batch 4960 training_loss 0.6931471805599453
iteration 8 batch 4970 training_loss 0.6931471805599453
iteration 8 batch 4980 training_loss 0.6931471805599453
iteration 8 batch 4990 training_loss 0.6931471805599453
iteration 8 batch 5000 training_loss 0.6931471805599453
iteration 8 batch 5010 training_loss 0.6931471805599453
iteration 8 batch 5020 training_loss 0.6931471805599453
iteration 8 batch 5030 training_loss 0.6931471805599453
iteration 8 batch 5040 training_loss 0.6931471805599453
iteration 8 batch 5050 training_loss 0.6931471805599453
iteration 8 batch 5060 training_loss 0.6931471805599453
iteration 8 batch 5070 training_loss 0.6931471805599453
iteration 8 batch 5080 training_loss 0.6931471805599453
iteration 8 batch 5090 training_loss 0.6931471805599453
iteration 8 batch 5100 training_loss 0.6916632528527511
iteration 8 batch 5110 training_loss 0.6931471805599453
iteration 8 batch 5120 training_loss 0.6931471805599453
iteration 8 batch 5130 training_loss 0.6931471805599453
iteration 8 batch 5140 training_loss 0.6931471805599453
iteration 8 batch 5150 training_loss 0.6931471805599453
iteration 8 batch 5160 training_loss 0.6931471805599453
iteration 8 batch 5170 training_loss 0.6931471805599453
iteration 8 batch 5180 training_loss 0.6931471805599453
iteration 8 batch 5190 training_loss 0.6931471805599453
iteration 8 batch 5200 training_loss 0.6931471805599453
iteration 8 batch 5210 training_loss 0.6931471805599453
iteration 8 batch 5220 training_loss 0.6931471805599453
iteration 8 batch 5230 training_loss 0.6931471805599453
iteration 8 batch 5240 training_loss 0.6931471805599453
iteration 8 batch 5250 training_loss 0.6931471805599453
iteration 8 batch 5260 training_loss 0.6931471805599453
iteration 8 batch 5270 training_loss 0.6931471805599453
iteration 8 batch 5280 training_loss 0.6916632528527511
iteration 8 batch 5290 training_loss 0.6931471805599453
iteration 8 batch 5300 training_loss 0.6931471805599453
iteration 8 batch 5310 training_loss 0.6931471805599453
iteration 8 batch 5320 training_loss 0.6931471805599453
iteration 8 batch 5330 training_loss 0.6931471805599453
iteration 8 batch 5340 training_loss 0.6931471805599453
iteration 8 batch 5350 training_loss 0.6931471805599453
iteration 8 batch 5360 training_loss 0.6931471805599453
iteration 8 batch 5370 training_loss 0.6931471805599453
iteration 8 batch 5380 training_loss 0.6931471805599453
iteration 8 batch 5390 training_loss 0.6931471805599453
iteration 8 batch 5400 training_loss 0.6931471805599453
iteration 8 batch 5410 training_loss 0.6931471805599453
iteration 8 batch 5420 training_loss 0.6931471805599453
iteration 8 batch 5430 training_loss 0.6931471805599453
iteration 8 batch 5440 training_loss 0.6931471805599453
iteration 8 batch 5450 training_loss 0.6931471805599453
iteration 8 batch 5460 training_loss 0.6931471805599453
iteration 8 batch 5470 training_loss 0.6931471805599453
iteration 8 batch 5480 training_loss 0.6931471805599453
iteration 8 batch 5490 training_loss 0.6931471805599453
iteration 8 batch 5500 training_loss 0.6931471805599453
iteration 8 batch 5510 training_loss 0.6931471805599453
iteration 8 batch 5520 training_loss 0.6931471805599453
iteration 8 batch 5530 training_loss 0.6931471805599453
iteration 8 batch 5540 training_loss 0.6931471805599453
iteration 8 batch 5550 training_loss 0.6931471805599453
iteration 8 batch 5560 training_loss 0.6931471805599453
iteration 8 batch 5570 training_loss 0.6931471805599453
iteration 8 batch 5580 training_loss 0.6931471805599453
iteration 8 batch 5590 training_loss 0.6931471805599453
iteration 8 batch 5600 training_loss 0.6931471805599453
iteration 8 batch 5610 training_loss 0.6931471805599453
iteration 8 batch 5620 training_loss 0.6931471805599453
iteration 8 batch 5630 training_loss 0.6931471805599453
iteration 8 batch 5640 training_loss 0.6931471805599453
iteration 8 batch 5650 training_loss 0.6931471805599453
iteration 8 batch 5660 training_loss 0.6931471805599453
iteration 8 batch 5670 training_loss 0.6916632528527511
iteration 8 batch 5680 training_loss 0.6931471805599453
iteration 8 batch 5690 training_loss 0.6916632528527511
iteration 8 batch 5700 training_loss 0.6931471805599453
iteration 8 batch 5710 training_loss 0.6931471805599453
iteration 8 batch 5720 training_loss 0.6931471805599453
iteration 8 batch 5730 training_loss 0.6931471805599453
iteration 8 batch 5740 training_loss 0.6931471805599453
iteration 8 batch 5750 training_loss 0.6931471805599453
iteration 8 batch 5760 training_loss 0.6931471805599453
iteration 8 batch 5770 training_loss 0.6931471805599453
iteration 8 batch 5780 training_loss 0.6931471805599453
iteration 8 batch 5790 training_loss 0.6931471805599453
iteration 8 batch 5800 training_loss 0.6931471805599453
iteration 8 batch 5810 training_loss 0.6931471805599453
iteration 8 batch 5820 training_loss 0.6931471805599453
iteration 8 batch 5830 training_loss 0.6931471805599453
iteration 8 batch 5840 training_loss 0.6931471805599453
iteration 8 batch 5850 training_loss 0.6931471805599453
iteration 8 batch 5860 training_loss 0.6931471805599453
iteration 8 batch 5870 training_loss 0.6931471805599453
iteration 8 batch 5880 training_loss 0.6931471805599453
iteration 8 batch 5890 training_loss 0.6931471805599453
iteration 8 batch 5900 training_loss 0.6931471805599453
iteration 8 batch 5910 training_loss 0.6931471805599453
iteration 8 batch 5920 training_loss 0.6931471805599453
iteration 8 batch 5930 training_loss 0.6931471805599453
iteration 8 batch 5940 training_loss 0.6931471805599453
iteration 8 batch 5950 training_loss 0.6931471805599453
iteration 8 batch 5960 training_loss 0.6931471805599453
iteration 8 batch 5970 training_loss 0.6931471805599453
iteration 8 batch 5980 training_loss 0.6931471805599453
iteration 8 batch 5990 training_loss 0.6931471805599453
iteration 8 batch 6000 training_loss 0.6931471805599453
iteration 8 batch 6010 training_loss 0.6931471805599453
iteration 8 batch 6020 training_loss 0.6931471805599453
iteration 8 batch 6030 training_loss 0.6931471805599453
iteration 8 batch 6040 training_loss 0.6931471805599453
iteration 8 batch 6050 training_loss 0.6916632528527511
iteration 8 batch 6060 training_loss 0.6931471805599453
iteration 8 batch 6070 training_loss 0.6931471805599453
iteration 8 batch 6080 training_loss 0.6931471805599453
iteration 8 batch 6090 training_loss 0.6931471805599453
iteration 8 batch 6100 training_loss 0.6931471805599453
iteration 8 batch 6110 training_loss 0.6931471805599453
iteration 8 batch 6120 training_loss 0.6931471805599453
iteration 8 batch 6130 training_loss 0.6931471805599453
iteration 8 batch 6140 training_loss 0.6931471805599453
iteration 8 batch 6150 training_loss 0.6931471805599453
iteration 8 batch 6160 training_loss 0.6931471805599453
iteration 8 batch 6170 training_loss 0.6931471805599453
iteration 8 batch 6180 training_loss 0.6931471805599453
iteration 8 batch 6190 training_loss 0.6931471805599453
iteration 8 batch 6200 training_loss 0.6931471805599453
iteration 8 batch 6210 training_loss 0.6931471805599453
iteration 8 batch 6220 training_loss 0.6931471805599453
iteration 8 batch 6230 training_loss 0.6931471805599453
iteration 8 batch 6240 training_loss 0.6931471805599453
iteration 8 batch 6250 training_loss 0.6931471805599453
iteration 8 batch 6260 training_loss 0.6931471805599453
iteration 8 batch 6270 training_loss 0.6931471805599453
iteration 8 batch 6280 training_loss 0.6931471805599453
iteration 8 batch 6290 training_loss 0.6931471805599453
iteration 8 batch 6300 training_loss 0.6931471805599453
iteration 8 batch 6310 training_loss 0.6931471805599453
iteration 8 batch 6320 training_loss 0.6931471805599453
iteration 8 batch 6330 training_loss 0.6931471805599453
iteration 8 batch 6340 training_loss 0.6931471805599453
iteration 8 batch 6350 training_loss 0.6931471805599453
iteration 8 batch 6360 training_loss 0.6931471805599453
iteration 8 batch 6370 training_loss 0.6931471805599453
iteration 8 batch 6380 training_loss 0.6931471805599453
iteration 8 batch 6390 training_loss 0.6931471805599453
iteration 8 batch 6400 training_loss 0.6931471805599453
iteration 8 batch 6410 training_loss 0.6931471805599453
iteration 8 batch 6420 training_loss 0.6931471805599453
iteration 8 batch 6430 training_loss 0.6931471805599453
iteration 8 batch 6440 training_loss 0.6931471805599453
iteration 8 batch 6450 training_loss 0.6931471805599453
iteration 8 batch 6460 training_loss 0.6931471805599453
iteration 8 batch 6470 training_loss 0.6931471805599453
iteration 8 batch 6480 training_loss 0.6931471805599453
iteration 8 batch 6490 training_loss 0.6931471805599453
iteration 8 batch 6500 training_loss 0.6931471805599453
iteration 8 batch 6510 training_loss 0.6931471805599453
iteration 8 batch 6520 training_loss 0.6931471805599453
iteration 8 batch 6530 training_loss 0.6931471805599453
iteration 8 batch 6540 training_loss 0.6931471805599453
iteration 8 batch 6550 training_loss 0.6931471805599453
iteration 8 batch 6560 training_loss 0.6931471805599453
iteration 8 batch 6570 training_loss 0.6931471805599453
iteration 8 batch 6580 training_loss 0.6931471805599453
iteration 8 batch 6590 training_loss 0.6931471805599453
iteration 8 batch 6600 training_loss 0.6931471805599453
iteration 8 batch 6610 training_loss 0.6931471805599453
iteration 8 batch 6620 training_loss 0.6931471805599453
iteration 8 batch 6630 training_loss 0.6931471805599453
iteration 8 batch 6640 training_loss 0.6931471805599453
iteration 8 batch 6650 training_loss 0.6931471805599453
iteration 8 batch 6660 training_loss 0.6931471805599453
iteration 8 batch 6670 training_loss 0.6931471805599453
iteration 8 batch 6680 training_loss 0.6931471805599453
iteration 8 batch 6690 training_loss 0.6931471805599453
iteration 8 batch 6700 training_loss 0.6931471805599453
iteration 8 batch 6710 training_loss 0.6931471805599453
iteration 8 batch 6720 training_loss 0.6931471805599453
iteration 8 batch 6730 training_loss 0.6931471805599453
iteration 8 batch 6740 training_loss 0.6931471805599453
iteration 8 batch 6750 training_loss 0.6931471805599453
iteration 8 batch 6760 training_loss 0.6931471805599453
iteration 8 batch 6770 training_loss 0.6931471805599453
iteration 8 batch 6780 training_loss 0.6931471805599453
iteration 8 batch 6790 training_loss 0.6931471805599453
iteration 8 batch 6800 training_loss 0.6931471805599453
iteration 8 batch 6810 training_loss 0.6931471805599453
iteration 8 batch 6820 training_loss 0.6931471805599453
iteration 8 batch 6830 training_loss 0.6931471805599453
iteration 8 batch 6840 training_loss 0.6931471805599453
iteration 8 batch 6850 training_loss 0.6931471805599453
iteration 8 batch 6860 training_loss 0.6931471805599453
iteration 8 batch 6870 training_loss 0.6931471805599453
iteration 8 batch 6880 training_loss 0.6931471805599453
iteration 8 batch 6890 training_loss 0.6931471805599453
iteration 8 batch 6900 training_loss 0.6931471805599453
iteration 8 batch 6910 training_loss 0.6931471805599453
iteration 8 batch 6920 training_loss 0.6931471805599453
iteration 8 batch 6930 training_loss 0.6931471805599453
iteration 8 batch 6940 training_loss 0.6916632528527511
iteration 8 batch 6950 training_loss 0.6931471805599453
iteration 8 batch 6960 training_loss 0.6931471805599453
iteration 8 batch 6970 training_loss 0.6931471805599453
iteration 8 batch 6980 training_loss 0.6931471805599453
iteration 8 batch 6990 training_loss 0.6931471805599453
iteration 8 batch 7000 training_loss 0.6931471805599453
iteration 8 batch 7010 training_loss 0.6931471805599453
iteration 8 batch 7020 training_loss 0.6916632528527511
iteration 8 batch 7030 training_loss 0.6931471805599453
iteration 8 batch 7040 training_loss 0.6931471805599453
iteration 8 batch 7050 training_loss 0.6931471805599453
iteration 8 batch 7060 training_loss 0.6931471805599453
iteration 8 batch 7070 training_loss 0.6931471805599453
iteration 8 batch 7080 training_loss 0.6931471805599453
iteration 8 batch 7090 training_loss 0.6931471805599453
iteration 8 batch 7100 training_loss 0.6931471805599453
iteration 8 batch 7110 training_loss 0.6916632528527511
iteration 8 batch 7120 training_loss 0.6931471805599453
iteration 8 batch 7130 training_loss 0.6931471805599453
iteration 8 batch 7140 training_loss 0.6931471805599453
iteration 8 batch 7150 training_loss 0.6931471805599453
iteration 8 batch 7160 training_loss 0.6931471805599453
iteration 8 batch 7170 training_loss 0.6931471805599453
iteration 8 batch 7180 training_loss 0.6931471805599453
iteration 8 batch 7190 training_loss 0.6931471805599453
iteration 8 batch 7200 training_loss 0.6931471805599453
iteration 8 batch 7210 training_loss 0.6931471805599453
iteration 8 batch 7220 training_loss 0.6931471805599453
iteration 8 batch 7230 training_loss 0.6931471805599453
iteration 8 batch 7240 training_loss 0.6931471805599453
iteration 8 batch 7250 training_loss 0.6931471805599453
iteration 8 batch 7260 training_loss 0.6931471805599453
iteration 8 batch 7270 training_loss 0.6931471805599453
iteration 8 batch 7280 training_loss 0.6931471805599453
iteration 8 batch 7290 training_loss 0.6931471805599453
iteration 8 batch 7300 training_loss 0.6931471805599453
iteration 8 batch 7310 training_loss 0.6931471805599453
iteration 8 batch 7320 training_loss 0.6931471805599453
iteration 8 batch 7330 training_loss 0.6916632528527511
iteration 8 batch 7340 training_loss 0.6931471805599453
iteration 8 batch 7350 training_loss 0.6931471805599453
iteration 8 batch 7360 training_loss 0.6916632528527511
iteration 8 batch 7370 training_loss 0.6931471805599453
iteration 8 batch 7380 training_loss 0.6931471805599453
iteration 8 batch 7390 training_loss 0.6931471805599453
iteration 8 batch 7400 training_loss 0.6931471805599453
iteration 8 batch 7410 training_loss 0.6931471805599453
iteration 8 batch 7420 training_loss 0.6931471805599453
iteration 8 batch 7430 training_loss 0.6931471805599453
iteration 8 batch 7440 training_loss 0.6931471805599453
iteration 8 batch 7450 training_loss 0.6931471805599453
iteration 8 batch 7460 training_loss 0.6931471805599453
iteration 8 batch 7470 training_loss 0.6931471805599453
iteration 8 batch 7480 training_loss 0.6931471805599453
iteration 8 batch 7490 training_loss 0.6931471805599453
iteration 8 batch 7500 training_loss 0.6931471805599453
iteration 8 batch 7510 training_loss 0.6931471805599453
iteration 8 batch 7520 training_loss 0.6931471805599453
iteration 8 batch 7530 training_loss 0.6931471805599453
iteration 8 batch 7540 training_loss 0.6931471805599453
iteration 8 batch 7550 training_loss 0.6931471805599453
iteration 8 batch 7560 training_loss 0.6931471805599453
iteration 8 batch 7570 training_loss 0.6931471805599453
iteration 8 batch 7580 training_loss 0.6931471805599453
iteration 8 batch 7590 training_loss 0.6931471805599453
iteration 8 batch 7600 training_loss 0.6931471805599453
iteration 8 batch 7610 training_loss 0.6931471805599453
iteration 8 batch 7620 training_loss 0.6931471805599453
iteration 8 batch 7630 training_loss 0.6931471805599453
iteration 8 batch 7640 training_loss 0.6931471805599453
iteration 8 batch 7650 training_loss 0.6931471805599453
iteration 8 batch 7660 training_loss 0.6931471805599453
iteration 8 batch 7670 training_loss 0.6931471805599453
iteration 8 batch 7680 training_loss 0.6916632528527511
iteration 8 batch 7690 training_loss 0.6931471805599453
iteration 8 batch 7700 training_loss 0.6931471805599453
iteration 8 batch 7710 training_loss 0.6931471805599453
iteration 8 batch 7720 training_loss 0.6931471805599453
iteration 8 batch 7730 training_loss 0.6916632528527511
iteration 8 batch 7740 training_loss 0.6931471805599453
iteration 8 batch 7750 training_loss 0.6931471805599453
iteration 8 batch 7760 training_loss 0.6931471805599453
iteration 8 batch 7770 training_loss 0.6931471805599453
iteration 8 batch 7780 training_loss 0.6931471805599453
iteration 8 batch 7790 training_loss 0.6931471805599453
iteration 8 batch 7800 training_loss 0.6931471805599453
iteration 8 batch 7810 training_loss 0.6931471805599453
iteration 8 batch 7820 training_loss 0.6931471805599453
iteration 8 batch 7830 training_loss 0.6931471805599453
iteration 8 batch 7840 training_loss 0.6931471805599453
iteration 8 batch 7850 training_loss 0.6931471805599453
iteration 8 batch 7860 training_loss 0.6931471805599453
iteration 8 batch 7870 training_loss 0.6931471805599453
iteration 8 batch 7880 training_loss 0.6931471805599453
iteration 8 batch 7890 training_loss 0.6931471805599453
iteration 8 batch 7900 training_loss 0.6931471805599453
iteration 8 batch 7910 training_loss 0.6931471805599453
iteration 8 batch 7920 training_loss 0.6931471805599453
iteration 8 batch 7930 training_loss 0.6931471805599453
iteration 8 batch 7940 training_loss 0.6931471805599453
iteration 8 batch 7950 training_loss 0.6931471805599453
iteration 8 batch 7960 training_loss 0.6931471805599453
iteration 8 batch 7970 training_loss 0.6931471805599453
iteration 8 batch 7980 training_loss 0.6931471805599453
iteration 8 batch 7990 training_loss 0.6931471805599453
iteration 8 batch 8000 training_loss 0.6916632528527511
iteration 8 batch 8010 training_loss 0.6931471805599453
iteration 8 batch 8020 training_loss 0.6916632528527511
iteration 8 batch 8030 training_loss 0.6931471805599453
iteration 8 batch 8040 training_loss 0.6931471805599453
iteration 8 batch 8050 training_loss 0.6931471805599453
iteration 8 batch 8060 training_loss 0.6931471805599453
iteration 8 batch 8070 training_loss 0.6931471805599453
iteration 8 batch 8080 training_loss 0.6931471805599453
iteration 8 batch 8090 training_loss 0.6931471805599453
iteration 8 batch 8100 training_loss 0.6931471805599453
iteration 8 batch 8110 training_loss 0.6931471805599453
iteration 8 batch 8120 training_loss 0.6931471805599453
iteration 8 batch 8130 training_loss 0.6931471805599453
iteration 8 batch 8140 training_loss 0.6931471805599453
iteration 8 batch 8150 training_loss 0.6931471805599453
iteration 8 batch 8160 training_loss 0.6931471805599453
iteration 8 batch 8170 training_loss 0.6931471805599453
iteration 8 batch 8180 training_loss 0.6931471805599453
iteration 8 batch 8190 training_loss 0.6931471805599453
iteration 8 batch 8200 training_loss 0.6931471805599453
iteration 8 batch 8210 training_loss 0.6931471805599453
iteration 8 batch 8220 training_loss 0.6931471805599453
iteration 8 batch 8230 training_loss 0.6916632528527511
iteration 8 batch 8240 training_loss 0.6931471805599453
iteration 8 batch 8250 training_loss 0.6931471805599453
iteration 8 batch 8260 training_loss 0.6931471805599453
iteration 8 batch 8270 training_loss 0.6931471805599453
iteration 8 batch 8280 training_loss 0.6931471805599453
iteration 8 batch 8290 training_loss 0.6931471805599453
iteration 8 batch 8300 training_loss 0.6931471805599453
iteration 8 batch 8310 training_loss 0.6931471805599453
iteration 8 batch 8320 training_loss 0.6931471805599453
iteration 8 batch 8330 training_loss 0.6931471805599453
iteration 8 batch 8340 training_loss 0.6931471805599453
iteration 8 batch 8350 training_loss 0.6916632528527511
iteration 8 batch 8360 training_loss 0.6931471805599453
iteration 8 batch 8370 training_loss 0.6931471805599453
iteration 8 batch 8380 training_loss 0.6931471805599453
iteration 8 batch 8390 training_loss 0.6931471805599453
iteration 8 batch 8400 training_loss 0.6931471805599453
iteration 8 batch 8410 training_loss 0.6931471805599453
iteration 8 batch 8420 training_loss 0.6931471805599453
iteration 8 batch 8430 training_loss 0.6931471805599453
iteration 8 batch 8440 training_loss 0.6931471805599453
iteration 8 batch 8450 training_loss 0.6931471805599453
iteration 8 batch 8460 training_loss 0.6931471805599453
iteration 8 batch 8470 training_loss 0.6931471805599453
iteration 8 batch 8480 training_loss 0.6931471805599453
iteration 8 batch 8490 training_loss 0.6916632528527511
iteration 8 batch 8500 training_loss 0.6931471805599453
iteration 8 batch 8510 training_loss 0.6931471805599453
iteration 8 batch 8520 training_loss 0.6931471805599453
iteration 8 batch 8530 training_loss 0.6931471805599453
iteration 8 batch 8540 training_loss 0.6931471805599453
iteration 8 batch 8550 training_loss 0.6931471805599453
iteration 8 batch 8560 training_loss 0.6931471805599453
iteration 8 batch 8570 training_loss 0.6931471805599453
iteration 8 batch 8580 training_loss 0.6931471805599453
iteration 8 batch 8590 training_loss 0.6931471805599453
iteration 8 batch 8600 training_loss 0.6916632528527511
iteration 8 batch 8610 training_loss 0.6931471805599453
iteration 8 batch 8620 training_loss 0.6916632528527511
iteration 8 batch 8630 training_loss 0.6931471805599453
iteration 8 batch 8640 training_loss 0.6931471805599453
iteration 8 batch 8650 training_loss 0.6931471805599453
iteration 8 batch 8660 training_loss 0.6931471805599453
iteration 8 batch 8670 training_loss 0.6931471805599453
iteration 8 batch 8680 training_loss 0.6931471805599453
iteration 8 batch 8690 training_loss 0.6931471805599453
iteration 8 batch 8700 training_loss 0.6916632528527511
iteration 8 batch 8710 training_loss 0.6931471805599453
iteration 8 batch 8720 training_loss 0.6931471805599453
iteration 8 batch 8730 training_loss 0.6931471805599453
iteration 8 batch 8740 training_loss 0.6931471805599453
iteration 8 batch 8750 training_loss 0.6931471805599453
iteration 8 batch 8760 training_loss 0.6931471805599453
iteration 8 batch 8770 training_loss 0.6931471805599453
iteration 8 batch 8780 training_loss 0.6931471805599453
iteration 8 batch 8790 training_loss 0.6931471805599453
iteration 8 batch 8800 training_loss 0.6931471805599453
iteration 8 batch 8810 training_loss 0.6931471805599453
iteration 8 batch 8820 training_loss 0.6931471805599453
iteration 8 batch 8830 training_loss 0.6931471805599453
iteration 8 batch 8840 training_loss 0.6931471805599453
iteration 8 batch 8850 training_loss 0.6931471805599453
iteration 8 batch 8860 training_loss 0.6931471805599453
iteration 8 batch 8870 training_loss 0.6916632528527511
iteration 8 batch 8880 training_loss 0.6931471805599453
iteration 8 batch 8890 training_loss 0.6931471805599453
iteration 8 batch 8900 training_loss 0.6931471805599453
iteration 8 batch 8910 training_loss 0.6931471805599453
iteration 8 batch 8920 training_loss 0.6931471805599453
iteration 8 batch 8930 training_loss 0.6931471805599453
iteration 8 batch 8940 training_loss 0.6931471805599453
iteration 8 batch 8950 training_loss 0.6931471805599453
iteration 8 batch 8960 training_loss 0.6931471805599453
iteration 8 batch 8970 training_loss 0.6931471805599453
iteration 8 batch 8980 training_loss 0.6931471805599453
iteration 8 batch 8990 training_loss 0.6931471805599453
iteration 8 batch 9000 training_loss 0.6931471805599453
iteration 8 batch 9010 training_loss 0.6931471805599453
iteration 8 batch 9020 training_loss 0.6931471805599453
iteration 8 batch 9030 training_loss 0.6916632528527511
iteration 8 batch 9040 training_loss 0.6931471805599453
iteration 8 batch 9050 training_loss 0.6931471805599453
iteration 8 batch 9060 training_loss 0.6931471805599453
iteration 8 batch 9070 training_loss 0.6931471805599453
iteration 8 batch 9080 training_loss 0.6931471805599453
iteration 8 batch 9090 training_loss 0.6931471805599453
iteration 8 batch 9100 training_loss 0.6931471805599453
iteration 8 batch 9110 training_loss 0.6931471805599453
iteration 8 batch 9120 training_loss 0.6931471805599453
iteration 8 batch 9130 training_loss 0.6931471805599453
iteration 8 batch 9140 training_loss 0.6931471805599453
iteration 8 batch 9150 training_loss 0.6931471805599453
iteration 8 batch 9160 training_loss 0.6931471805599453
iteration 8 batch 9170 training_loss 0.6931471805599453
iteration 8 batch 9180 training_loss 0.6931471805599453
iteration 8 batch 9190 training_loss 0.6916632528527511
iteration 8 batch 9200 training_loss 0.6931471805599453
iteration 8 batch 9210 training_loss 0.6931471805599453
iteration 8 batch 9220 training_loss 0.6931471805599453
iteration 8 batch 9230 training_loss 0.6931471805599453
iteration 8 batch 9240 training_loss 0.6931471805599453
iteration 8 batch 9250 training_loss 0.6931471805599453
iteration 8 batch 9260 training_loss 0.6931471805599453
iteration 8 batch 9270 training_loss 0.6931471805599453
iteration 8 batch 9280 training_loss 0.6931471805599453
iteration 8 batch 9290 training_loss 0.6931471805599453
iteration 8 batch 9300 training_loss 0.6931471805599453
iteration 8 batch 9310 training_loss 0.6931471805599453
iteration 8 batch 9320 training_loss 0.6931471805599453
iteration 8 batch 9330 training_loss 0.6931471805599453
iteration 8 batch 9340 training_loss 0.6931471805599453
iteration 8 batch 9350 training_loss 0.6931471805599453
iteration 8 batch 9360 training_loss 0.6931471805599453
iteration 8 batch 9370 training_loss 0.6931471805599453
iteration 8 batch 9380 training_loss 0.6931471805599453
iteration 8 batch 9390 training_loss 0.6931471805599453
iteration 8 batch 9400 training_loss 0.6931471805599453
iteration 8 batch 9410 training_loss 0.6931471805599453
iteration 8 batch 9420 training_loss 0.6931471805599453
iteration 8 batch 9430 training_loss 0.6931471805599453
iteration 8 batch 9440 training_loss 0.6931471805599453
iteration 8 batch 9450 training_loss 0.6931471805599453
iteration 8 batch 9460 training_loss 0.6931471805599453
iteration 8 batch 9470 training_loss 0.6931471805599453
iteration 8 batch 9480 training_loss 0.6931471805599453
iteration 8 batch 9490 training_loss 0.6931471805599453
iteration 8 batch 9500 training_loss 0.6916632528527511
iteration 8 batch 9510 training_loss 0.6931471805599453
iteration 8 batch 9520 training_loss 0.6931471805599453
iteration 8 batch 9530 training_loss 0.6931471805599453
iteration 8 batch 9540 training_loss 0.6931471805599453
iteration 8 batch 9550 training_loss 0.6931471805599453
iteration 8 batch 9560 training_loss 0.6916632528527511
iteration 8 batch 9570 training_loss 0.6931471805599453
iteration 8 batch 9580 training_loss 0.6931471805599453
iteration 8 batch 9590 training_loss 0.6931471805599453
iteration 8 batch 9600 training_loss 0.6931471805599453
iteration 8 batch 9610 training_loss 0.6931471805599453
iteration 8 batch 9620 training_loss 0.6931471805599453
iteration 8 batch 9630 training_loss 0.6931471805599453
iteration 8 batch 9640 training_loss 0.6931471805599453
iteration 8 batch 9650 training_loss 0.6931471805599453
iteration 8 batch 9660 training_loss 0.6916632528527511
iteration 8 batch 9670 training_loss 0.6931471805599453
iteration 8 batch 9680 training_loss 0.6931471805599453
iteration 8 batch 9690 training_loss 0.6931471805599453
iteration 8 batch 9700 training_loss 0.6931471805599453
iteration 8 batch 9710 training_loss 0.6931471805599453
iteration 8 batch 9720 training_loss 0.6931471805599453
iteration 8 batch 9730 training_loss 0.6931471805599453
iteration 8 batch 9740 training_loss 0.6931471805599453
iteration 8 batch 9750 training_loss 0.6931471805599453
iteration 8 batch 9760 training_loss 0.6931471805599453
iteration 8 batch 9770 training_loss 0.6931471805599453
iteration 8 batch 9780 training_loss 0.6931471805599453
iteration 8 batch 9790 training_loss 0.6931471805599453
iteration 8 batch 9800 training_loss 0.6931471805599453
iteration 8 batch 9810 training_loss 0.6931471805599453
iteration 8 batch 9820 training_loss 0.6931471805599453
iteration 8 batch 9830 training_loss 0.6931471805599453
iteration 8 batch 9840 training_loss 0.6931471805599453
iteration 8 batch 9850 training_loss 0.6931471805599453
iteration 8 batch 9860 training_loss 0.6931471805599453
iteration 8 batch 9870 training_loss 0.6931471805599453
iteration 8 batch 9880 training_loss 0.6931471805599453
iteration 8 batch 9890 training_loss 0.6931471805599453
iteration 8 batch 9900 training_loss 0.6931471805599453
iteration 8 batch 9910 training_loss 0.6931471805599453
iteration 8 batch 9920 training_loss 0.6931471805599453
iteration 8 batch 9930 training_loss 0.6931471805599453
iteration 8 batch 9940 training_loss 0.6931471805599453
iteration 8 batch 9950 training_loss 0.6931471805599453
iteration 8 batch 9960 training_loss 0.6931471805599453
iteration 8 batch 9970 training_loss 0.6931471805599453
iteration 8 batch 9980 training_loss 0.6931471805599453
iteration 8 batch 9990 training_loss 0.6916632528527511
iteration 8 batch 10000 training_loss 0.6931471805599453
iteration 8 batch 10010 training_loss 0.6931471805599453
iteration 8 batch 10020 training_loss 0.6931471805599453
iteration 8 batch 10030 training_loss 0.6931471805599453
iteration 8 batch 10040 training_loss 0.6916632528527511
iteration 8 batch 10050 training_loss 0.6931471805599453
iteration 8 batch 10060 training_loss 0.6931471805599453
iteration 8 batch 10070 training_loss 0.6931471805599453
iteration 8 batch 10080 training_loss 0.6931471805599453
iteration 8 batch 10090 training_loss 0.6931471805599453
iteration 8 batch 10100 training_loss 0.6931471805599453
iteration 8 batch 10110 training_loss 0.6931471805599453
iteration 8 batch 10120 training_loss 0.6931471805599453
iteration 8 batch 10130 training_loss 0.6931471805599453
iteration 8 batch 10140 training_loss 0.6931471805599453
iteration 8 batch 10150 training_loss 0.6931471805599453
iteration 8 batch 10160 training_loss 0.6931471805599453
iteration 8 batch 10170 training_loss 0.6931471805599453
iteration 8 batch 10180 training_loss 0.6931471805599453
iteration 8 batch 10190 training_loss 0.6931471805599453
iteration 8 batch 10200 training_loss 0.6931471805599453
iteration 8 batch 10210 training_loss 0.6931471805599453
iteration 8 batch 10220 training_loss 0.6931471805599453
iteration 8 batch 10230 training_loss 0.6931471805599453
iteration 8 batch 10240 training_loss 0.6931471805599453
iteration 8 batch 10250 training_loss 0.6931471805599453
iteration 8 batch 10260 training_loss 0.6931471805599453
iteration 8 batch 10270 training_loss 0.6931471805599453
iteration 8 batch 10280 training_loss 0.6931471805599453
iteration 8 batch 10290 training_loss 0.6931471805599453
iteration 8 batch 10300 training_loss 0.6931471805599453
iteration 8 batch 10310 training_loss 0.6931471805599453
iteration 8 batch 10320 training_loss 0.6931471805599453
iteration 8 batch 10330 training_loss 0.6931471805599453
iteration 8 batch 10340 training_loss 0.6931471805599453
iteration 8 batch 10350 training_loss 0.6931471805599453
iteration 8 batch 10360 training_loss 0.6931471805599453
iteration 8 batch 10370 training_loss 0.6931471805599453
iteration 8 batch 10380 training_loss 0.6931471805599453
iteration 8 batch 10390 training_loss 0.6931471805599453
iteration 8 batch 10400 training_loss 0.6931471805599453
iteration 8 batch 10410 training_loss 0.6916632528527511
iteration 8 batch 10420 training_loss 0.6931471805599453
iteration 8 batch 10430 training_loss 0.6931471805599453
iteration 8 batch 10440 training_loss 0.6931471805599453
iteration 8 batch 10450 training_loss 0.6931471805599453
iteration 8 batch 10460 training_loss 0.6931471805599453
iteration 8 batch 10470 training_loss 0.6931471805599453
iteration 8 batch 10480 training_loss 0.6931471805599453
iteration 8 batch 10490 training_loss 0.6916632528527511
iteration 8 batch 10500 training_loss 0.6931471805599453
iteration 8 batch 10510 training_loss 0.6931471805599453
iteration 8 batch 10520 training_loss 0.6931471805599453
iteration 8 batch 10530 training_loss 0.6931471805599453
iteration 8 batch 10540 training_loss 0.6931471805599453
iteration 8 batch 10550 training_loss 0.6931471805599453
iteration 8 batch 10560 training_loss 0.6931471805599453
iteration 8 batch 10570 training_loss 0.6931471805599453
iteration 8 batch 10580 training_loss 0.6931471805599453
iteration 8 batch 10590 training_loss 0.6931471805599453
iteration 8 batch 10600 training_loss 0.6931471805599453
iteration 8 batch 10610 training_loss 0.6931471805599453
iteration 8 batch 10620 training_loss 0.6931471805599453
iteration 8 batch 10630 training_loss 0.6916632528527511
iteration 8 batch 10640 training_loss 0.6931471805599453
iteration 8 batch 10650 training_loss 0.6931471805599453
iteration 8 batch 10660 training_loss 0.6931471805599453
iteration 8 batch 10670 training_loss 0.6931471805599453
iteration 8 batch 10680 training_loss 0.6931471805599453
iteration 8 batch 10690 training_loss 0.6931471805599453
iteration 8 batch 10700 training_loss 0.6931471805599453
iteration 8 batch 10710 training_loss 0.6931471805599453
iteration 8 batch 10720 training_loss 0.6931471805599453
iteration 8 batch 10730 training_loss 0.6931471805599453
iteration 8 batch 10740 training_loss 0.6931471805599453
iteration 8 batch 10750 training_loss 0.6931471805599453
iteration 8 batch 10760 training_loss 0.6931471805599453
iteration 8 batch 10770 training_loss 0.6931471805599453
iteration 8 batch 10780 training_loss 0.6931471805599453
iteration 8 batch 10790 training_loss 0.6931471805599453
iteration 8 batch 10800 training_loss 0.6931471805599453
iteration 8 batch 10810 training_loss 0.6931471805599453
iteration 8 batch 10820 training_loss 0.6931471805599453
iteration 8 batch 10830 training_loss 0.6916632528527511
iteration 8 batch 10840 training_loss 0.6931471805599453
iteration 8 batch 10850 training_loss 0.6931471805599453
iteration 8 batch 10860 training_loss 0.6931471805599453
iteration 8 batch 10870 training_loss 0.6931471805599453
iteration 8 batch 10880 training_loss 0.6931471805599453
iteration 8 batch 10890 training_loss 0.6931471805599453
iteration 8 batch 10900 training_loss 0.6931471805599453
iteration 8 batch 10910 training_loss 0.6931471805599453
iteration 8 batch 10920 training_loss 0.6931471805599453
iteration 8 batch 10930 training_loss 0.6931471805599453
iteration 8 batch 10940 training_loss 0.6931471805599453
iteration 8 batch 10950 training_loss 0.6931471805599453
iteration 8 batch 10960 training_loss 0.6931471805599453
iteration 8 batch 10970 training_loss 0.6931471805599453
iteration 8 batch 10980 training_loss 0.6931471805599453
iteration 8 batch 10990 training_loss 0.6931471805599453
iteration 8 batch 11000 training_loss 0.6931471805599453
iteration 8 batch 11010 training_loss 0.6931471805599453
iteration 8 batch 11020 training_loss 0.6931471805599453
iteration 8 batch 11030 training_loss 0.6916632528527511
iteration 8 batch 11040 training_loss 0.6931471805599453
iteration 8 batch 11050 training_loss 0.6931471805599453
iteration 8 batch 11060 training_loss 0.6931471805599453
iteration 8 batch 11070 training_loss 0.6931471805599453
iteration 8 batch 11080 training_loss 0.6931471805599453
iteration 8 batch 11090 training_loss 0.6931471805599453
iteration 8 batch 11100 training_loss 0.6931471805599453
iteration 8 batch 11110 training_loss 0.6931471805599453
iteration 8 batch 11120 training_loss 0.6931471805599453
iteration 8 batch 11130 training_loss 0.6916632528527511
iteration 8 batch 11140 training_loss 0.6931471805599453
iteration 8 batch 11150 training_loss 0.6931471805599453
iteration 8 batch 11160 training_loss 0.6931471805599453
iteration 8 batch 11170 training_loss 0.6931471805599453
iteration 8 batch 11180 training_loss 0.6931471805599453
iteration 8 batch 11190 training_loss 0.6931471805599453
iteration 8 batch 11200 training_loss 0.6931471805599453
iteration 8 batch 11210 training_loss 0.6931471805599453
iteration 8 batch 11220 training_loss 0.6931471805599453
iteration 8 batch 11230 training_loss 0.6931471805599453
iteration 8 batch 11240 training_loss 0.6931471805599453
iteration 8 batch 11250 training_loss 0.6931471805599453
iteration 8 batch 11260 training_loss 0.6931471805599453
iteration 8 batch 11270 training_loss 0.6916632528527511
iteration 8 batch 11280 training_loss 0.6931471805599453
iteration 8 batch 11290 training_loss 0.6931471805599453
iteration 8 batch 11300 training_loss 0.6931471805599453
iteration 8 batch 11310 training_loss 0.6931471805599453
iteration 8 batch 11320 training_loss 0.6931471805599453
iteration 8 batch 11330 training_loss 0.6931471805599453
iteration 8 batch 11340 training_loss 0.6931471805599453
iteration 8 batch 11350 training_loss 0.6931471805599453
iteration 8 batch 11360 training_loss 0.6931471805599453
iteration 8 batch 11370 training_loss 0.6931471805599453
iteration 8 batch 11380 training_loss 0.6931471805599453
iteration 8 batch 11390 training_loss 0.6931471805599453
iteration 8 batch 11400 training_loss 0.6931471805599453
iteration 8 batch 11410 training_loss 0.6931471805599453
iteration 8 batch 11420 training_loss 0.6931471805599453
iteration 8 batch 11430 training_loss 0.6931471805599453
iteration 8 batch 11440 training_loss 0.6931471805599453
iteration 8 batch 11450 training_loss 0.6931471805599453
iteration 8 batch 11460 training_loss 0.6916632528527511
iteration 8 batch 11470 training_loss 0.6931471805599453
iteration 8 batch 11480 training_loss 0.6931471805599453
iteration 8 batch 11490 training_loss 0.6931471805599453
iteration 8 batch 11500 training_loss 0.6931471805599453
iteration 8 batch 11510 training_loss 0.6931471805599453
iteration 8 batch 11520 training_loss 0.6931471805599453
iteration 8 batch 11530 training_loss 0.6931471805599453
iteration 8 batch 11540 training_loss 0.6931471805599453
iteration 8 batch 11550 training_loss 0.6931471805599453
iteration 8 batch 11560 training_loss 0.6931471805599453
iteration 8 batch 11570 training_loss 0.6931471805599453
iteration 8 batch 11580 training_loss 0.6931471805599453
iteration 8 batch 11590 training_loss 0.6931471805599453
iteration 8 batch 11600 training_loss 0.6931471805599453
iteration 8 batch 11610 training_loss 0.6931471805599453
iteration 8 batch 11620 training_loss 0.6931471805599453
iteration 8 batch 11630 training_loss 0.6931471805599453
iteration 8 batch 11640 training_loss 0.6931471805599453
iteration 8 batch 11650 training_loss 0.6931471805599453
iteration 8 batch 11660 training_loss 0.6931471805599453
iteration 8 batch 11670 training_loss 0.6931471805599453
iteration 8 batch 11680 training_loss 0.6931471805599453
iteration 8 batch 11690 training_loss 0.6931471805599453
iteration 8 batch 11700 training_loss 0.6931471805599453
iteration 8 batch 11710 training_loss 0.6931471805599453
iteration 8 batch 11720 training_loss 0.6931471805599453
iteration 8 batch 11730 training_loss 0.6931471805599453
iteration 8 batch 11740 training_loss 0.6931471805599453
iteration 8 batch 11750 training_loss 0.6916632528527511
iteration 8 batch 11760 training_loss 0.6931471805599453
iteration 8 batch 11770 training_loss 0.6931471805599453
iteration 8 batch 11780 training_loss 0.6931471805599453
iteration 8 batch 11790 training_loss 0.6931471805599453
iteration 8 batch 11800 training_loss 0.6931471805599453
iteration 8 batch 11810 training_loss 0.6931471805599453
iteration 8 batch 11820 training_loss 0.6931471805599453
iteration 8 batch 11830 training_loss 0.6931471805599453
iteration 8 batch 11840 training_loss 0.6931471805599453
iteration 8 batch 11850 training_loss 0.6916632528527511
iteration 8 batch 11860 training_loss 0.6931471805599453
iteration 8 batch 11870 training_loss 0.6931471805599453
iteration 8 batch 11880 training_loss 0.6931471805599453
iteration 8 batch 11890 training_loss 0.6931471805599453
iteration 8 batch 11900 training_loss 0.6931471805599453
iteration 8 batch 11910 training_loss 0.6931471805599453
iteration 8 batch 11920 training_loss 0.6931471805599453
iteration 8 batch 11930 training_loss 0.6916632528527511
iteration 8 batch 11940 training_loss 0.6931471805599453
iteration 8 batch 11950 training_loss 0.6931471805599453
iteration 8 batch 11960 training_loss 0.6931471805599453
iteration 8 batch 11970 training_loss 0.6931471805599453
iteration 8 batch 11980 training_loss 0.6916632528527511
iteration 8 batch 11990 training_loss 0.6931471805599453
iteration 8 batch 12000 training_loss 0.6931471805599453
iteration 8 batch 12010 training_loss 0.6931471805599453
iteration 8 batch 12020 training_loss 0.6931471805599453
iteration 8 batch 12030 training_loss 0.6931471805599453
iteration 8 batch 12040 training_loss 0.6931471805599453
iteration 8 batch 12050 training_loss 0.6931471805599453
iteration 8 batch 12060 training_loss 0.6931471805599453
iteration 8 batch 12070 training_loss 0.6931471805599453
iteration 8 batch 12080 training_loss 0.6931471805599453
iteration 8 batch 12090 training_loss 0.6931471805599453
iteration 8 batch 12100 training_loss 0.6931471805599453
iteration 8 batch 12110 training_loss 0.6931471805599453
iteration 8 batch 12120 training_loss 0.6931471805599453
iteration 8 batch 12130 training_loss 0.6931471805599453
iteration 8 batch 12140 training_loss 0.6931471805599453
iteration 8 batch 12150 training_loss 0.6931471805599453
iteration 8 batch 12160 training_loss 0.6931471805599453
iteration 8 batch 12170 training_loss 0.6931471805599453
iteration 8 batch 12180 training_loss 0.6931471805599453
iteration 8 batch 12190 training_loss 0.6931471805599453
iteration 8 batch 12200 training_loss 0.6931471805599453
iteration 8 batch 12210 training_loss 0.6931471805599453
iteration 8 batch 12220 training_loss 0.6931471805599453
iteration 8 batch 12230 training_loss 0.6931471805599453
iteration 8 batch 12240 training_loss 0.6931471805599453
iteration 8 batch 12250 training_loss 0.6931471805599453
iteration 8 batch 12260 training_loss 0.6931471805599453
iteration 8 batch 12270 training_loss 0.6931471805599453
iteration 8 batch 12280 training_loss 0.6931471805599453
iteration 8 batch 12290 training_loss 0.6931471805599453
iteration 8 batch 12300 training_loss 0.6931471805599453
iteration 8 batch 12310 training_loss 0.6931471805599453
iteration 8 batch 12320 training_loss 0.6931471805599453
iteration 8 batch 12330 training_loss 0.6931471805599453
iteration 8 batch 12340 training_loss 0.6931471805599453
iteration 8 batch 12350 training_loss 0.6916632528527511
iteration 8 batch 12360 training_loss 0.6931471805599453
iteration 8 batch 12370 training_loss 0.6931471805599453
iteration 8 batch 12380 training_loss 0.6916632528527511
iteration 8 batch 12390 training_loss 0.6931471805599453
iteration 8 batch 12400 training_loss 0.6931471805599453
iteration 8 batch 12410 training_loss 0.6916632528527511
iteration 8 batch 12420 training_loss 0.6931471805599453
iteration 8 batch 12430 training_loss 0.6931471805599453
iteration 8 batch 12440 training_loss 0.6931471805599453
iteration 8 batch 12450 training_loss 0.6931471805599453
iteration 8 batch 12460 training_loss 0.6916632528527511
iteration 8 batch 12470 training_loss 0.6931471805599453
iteration 8 batch 12480 training_loss 0.6931471805599453
iteration 8 batch 12490 training_loss 0.6931471805599453
iteration 8 batch 12500 training_loss 0.6931471805599453
iteration 8 batch 12510 training_loss 0.6931471805599453
iteration 8 batch 12520 training_loss 0.6931471805599453
iteration 8 batch 12530 training_loss 0.6931471805599453
iteration 8 batch 12540 training_loss 0.6931471805599453
iteration 8 batch 12550 training_loss 0.6931471805599453
iteration 8 batch 12560 training_loss 0.6916632528527511
iteration 8 batch 12570 training_loss 0.6931471805599453
iteration 8 batch 12580 training_loss 0.6916632528527511
iteration 8 batch 12590 training_loss 0.6931471805599453
iteration 8 batch 12600 training_loss 0.6931471805599453
iteration 8 batch 12610 training_loss 0.6931471805599453
iteration 8 batch 12620 training_loss 0.6931471805599453
iteration 8 batch 12630 training_loss 0.6931471805599453
iteration 8 batch 12640 training_loss 0.6916632528527511
iteration 8 batch 12650 training_loss 0.6931471805599453
iteration 8 batch 12660 training_loss 0.6931471805599453
iteration 8 batch 12670 training_loss 0.6931471805599453
iteration 8 batch 12680 training_loss 0.6931471805599453
iteration 8 batch 12690 training_loss 0.6931471805599453
iteration 8 batch 12700 training_loss 0.6931471805599453
iteration 8 batch 12710 training_loss 0.6931471805599453
iteration 8 batch 12720 training_loss 0.6931471805599453
iteration 8 batch 12730 training_loss 0.6931471805599453
iteration 8 batch 12740 training_loss 0.6931471805599453
iteration 8 batch 12750 training_loss 0.6931471805599453
iteration 8 batch 12760 training_loss 0.6931471805599453
iteration 8 batch 12770 training_loss 0.6931471805599453
iteration 8 batch 12780 training_loss 0.6931471805599453
iteration 8 batch 12790 training_loss 0.6931471805599453
iteration 8 batch 12800 training_loss 0.6931471805599453
iteration 8 batch 12810 training_loss 0.6931471805599453
iteration 8 batch 12820 training_loss 0.6931471805599453
iteration 8 batch 12830 training_loss 0.6931471805599453
iteration 8 batch 12840 training_loss 0.6931471805599453
iteration 8 batch 12850 training_loss 0.6931471805599453
iteration 8 batch 12860 training_loss 0.6931471805599453
iteration 8 batch 12870 training_loss 0.6931471805599453
iteration 8 batch 12880 training_loss 0.6931471805599453
iteration 8 batch 12890 training_loss 0.6931471805599453
iteration 8 batch 12900 training_loss 0.6931471805599453
iteration 8 batch 12910 training_loss 0.6931471805599453
iteration 8 batch 12920 training_loss 0.6931471805599453
iteration 8 batch 12930 training_loss 0.6931471805599453
iteration 8 batch 12940 training_loss 0.6931471805599453
iteration 8 batch 12950 training_loss 0.6931471805599453
iteration 8 batch 12960 training_loss 0.6931471805599453
iteration 8 batch 12970 training_loss 0.6931471805599453
iteration 8 batch 12980 training_loss 0.6931471805599453
iteration 8 batch 12990 training_loss 0.6931471805599453
iteration 8 batch 13000 training_loss 0.6931471805599453
iteration 8 batch 13010 training_loss 0.6931471805599453
iteration 8 batch 13020 training_loss 0.6931471805599453
iteration 8 batch 13030 training_loss 0.6931471805599453
iteration 8 batch 13040 training_loss 0.6931471805599453
iteration 8 batch 13050 training_loss 0.6931471805599453
iteration 8 batch 13060 training_loss 0.6931471805599453
iteration 8 batch 13070 training_loss 0.6931471805599453
iteration 8 batch 13080 training_loss 0.6931471805599453
iteration 8 batch 13090 training_loss 0.6931471805599453
iteration 8 batch 13100 training_loss 0.6931471805599453
iteration 8 batch 13110 training_loss 0.6931471805599453
iteration 8 batch 13120 training_loss 0.6931471805599453
iteration 8 batch 13130 training_loss 0.6931471805599453
iteration 8 batch 13140 training_loss 0.6931471805599453
iteration 8 batch 13150 training_loss 0.6931471805599453
iteration 8 batch 13160 training_loss 0.6931471805599453
iteration 8 batch 13170 training_loss 0.6931471805599453
iteration 8 batch 13180 training_loss 0.6931471805599453
iteration 8 batch 13190 training_loss 0.6931471805599453
iteration 8 batch 13200 training_loss 0.6931471805599453
iteration 8 batch 13210 training_loss 0.6931471805599453
iteration 8 batch 13220 training_loss 0.6931471805599453
iteration 8 batch 13230 training_loss 0.6931471805599453
iteration 8 batch 13240 training_loss 0.6931471805599453
iteration 8 batch 13250 training_loss 0.6931471805599453
iteration 8 batch 13260 training_loss 0.6931471805599453
iteration 8 batch 13270 training_loss 0.6931471805599453
iteration 8 batch 13280 training_loss 0.6931471805599453
iteration 8 batch 13290 training_loss 0.6931471805599453
iteration 8 batch 13300 training_loss 0.6931471805599453
iteration 8 batch 13310 training_loss 0.6931471805599453
iteration 8 batch 13320 training_loss 0.6931471805599453
iteration 8 batch 13330 training_loss 0.6916632528527511
iteration 8 batch 13340 training_loss 0.6931471805599453
iteration 8 batch 13350 training_loss 0.6931471805599453
iteration 8 batch 13360 training_loss 0.6931471805599453
iteration 8 batch 13370 training_loss 0.6931471805599453
iteration 8 batch 13380 training_loss 0.6931471805599453
iteration 8 batch 13390 training_loss 0.6931471805599453
iteration 8 batch 13400 training_loss 0.6931471805599453
iteration 8 batch 13410 training_loss 0.6931471805599453
iteration 8 batch 13420 training_loss 0.6931471805599453
iteration 8 batch 13430 training_loss 0.6931471805599453
iteration 8 batch 13440 training_loss 0.6931471805599453
iteration 8 batch 13450 training_loss 0.6931471805599453
iteration 8 batch 13460 training_loss 0.6931471805599453
iteration 8 batch 13470 training_loss 0.6901793251455568
iteration 8 batch 13480 training_loss 0.6931471805599453
iteration 8 batch 13490 training_loss 0.6931471805599453
iteration 8 batch 13500 training_loss 0.6931471805599453
iteration 8 batch 13510 training_loss 0.6916632528527511
iteration 8 batch 13520 training_loss 0.6931471805599453
iteration 8 batch 13530 training_loss 0.6931471805599453
iteration 8 batch 13540 training_loss 0.6931471805599453
iteration 8 batch 13550 training_loss 0.6916632528527511
iteration 8 batch 13560 training_loss 0.6931471805599453
iteration 8 batch 13570 training_loss 0.6931471805599453
iteration 8 batch 13580 training_loss 0.6931471805599453
iteration 8 batch 13590 training_loss 0.6931471805599453
iteration 8 batch 13600 training_loss 0.6931471805599453
iteration 8 batch 13610 training_loss 0.6931471805599453
iteration 8 batch 13620 training_loss 0.6931471805599453
iteration 8 batch 13630 training_loss 0.6931471805599453
iteration 8 batch 13640 training_loss 0.6931471805599453
iteration 8 batch 13650 training_loss 0.6931471805599453
iteration 8 batch 13660 training_loss 0.6931471805599453
iteration 8 batch 13670 training_loss 0.6931471805599453
iteration 8 batch 13680 training_loss 0.6931471805599453
iteration 8 batch 13690 training_loss 0.6931471805599453
iteration 8 batch 13700 training_loss 0.6916632528527511
iteration 8 batch 13710 training_loss 0.6931471805599453
iteration 8 batch 13720 training_loss 0.6931471805599453
iteration 8 batch 13730 training_loss 0.6931471805599453
iteration 8 batch 13740 training_loss 0.6931471805599453
iteration 8 batch 13750 training_loss 0.6916632528527511
iteration 8 batch 13760 training_loss 0.6931471805599453
iteration 8 batch 13770 training_loss 0.6931471805599453
iteration 8 batch 13780 training_loss 0.6931471805599453
iteration 8 batch 13790 training_loss 0.6931471805599453
iteration 8 batch 13800 training_loss 0.6931471805599453
iteration 8 batch 13810 training_loss 0.6931471805599453
iteration 8 batch 13820 training_loss 0.6931471805599453
iteration 8 batch 13830 training_loss 0.6931471805599453
iteration 8 batch 13840 training_loss 0.6931471805599453
iteration 8 batch 13850 training_loss 0.6931471805599453
iteration 8 batch 13860 training_loss 0.6931471805599453
iteration 8 batch 13870 training_loss 0.6931471805599453
iteration 8 batch 13880 training_loss 0.6931471805599453
iteration 8 batch 13890 training_loss 0.6931471805599453
iteration 8 batch 13900 training_loss 0.6931471805599453
iteration 8 batch 13910 training_loss 0.6931471805599453
iteration 8 batch 13920 training_loss 0.6931471805599453
iteration 8 batch 13930 training_loss 0.6931471805599453
iteration 8 batch 13940 training_loss 0.6931471805599453
iteration 8 batch 13950 training_loss 0.6931471805599453
iteration 8 batch 13960 training_loss 0.6931471805599453
iteration 8 batch 13970 training_loss 0.6931471805599453
iteration 8 batch 13980 training_loss 0.6931471805599453
iteration 8 batch 13990 training_loss 0.6931471805599453
iteration 8 batch 14000 training_loss 0.6931471805599453
iteration 8 batch 14010 training_loss 0.6931471805599453
iteration 8 batch 14020 training_loss 0.6916632528527511
iteration 8 batch 14030 training_loss 0.6931471805599453
iteration 8 batch 14040 training_loss 0.6931471805599453
iteration 8 batch 14050 training_loss 0.6931471805599453
iteration 8 batch 14060 training_loss 0.6931471805599453
iteration 8 batch 14070 training_loss 0.6931471805599453
iteration 8 batch 14080 training_loss 0.6916632528527511
iteration 8 batch 14090 training_loss 0.6931471805599453
iteration 8 batch 14100 training_loss 0.6931471805599453
iteration 8 batch 14110 training_loss 0.6931471805599453
iteration 8 batch 14120 training_loss 0.6931471805599453
iteration 8 batch 14130 training_loss 0.6931471805599453
iteration 8 batch 14140 training_loss 0.6931471805599453
iteration 8 batch 14150 training_loss 0.6931471805599453
iteration 8 batch 14160 training_loss 0.6931471805599453
iteration 8 batch 14170 training_loss 0.6931471805599453
iteration 8 batch 14180 training_loss 0.6916632528527511
iteration 8 batch 14190 training_loss 0.6931471805599453
iteration 8 batch 14200 training_loss 0.6931471805599453
iteration 8 batch 14210 training_loss 0.6931471805599453
iteration 8 batch 14220 training_loss 0.6931471805599453
iteration 8 batch 14230 training_loss 0.6931471805599453
iteration 8 batch 14240 training_loss 0.6931471805599453
iteration 8 batch 14250 training_loss 0.6931471805599453
iteration 8 batch 14260 training_loss 0.6931471805599453
iteration 8 batch 14270 training_loss 0.6931471805599453
iteration 8 batch 14280 training_loss 0.6931471805599453
iteration 8 batch 14290 training_loss 0.6931471805599453
iteration 8 batch 14300 training_loss 0.6931471805599453
iteration 8 batch 14310 training_loss 0.6931471805599453
iteration 8 batch 14320 training_loss 0.6931471805599453
iteration 8 batch 14330 training_loss 0.6931471805599453
iteration 8 batch 14340 training_loss 0.6931471805599453
iteration 8 batch 14350 training_loss 0.6931471805599453
iteration 8 batch 14360 training_loss 0.6931471805599453
iteration 8 batch 14370 training_loss 0.6931471805599453
iteration 8 batch 14380 training_loss 0.6931471805599453
iteration 8 batch 14390 training_loss 0.6931471805599453
iteration 8 batch 14400 training_loss 0.6931471805599453
iteration 8 batch 14410 training_loss 0.6931471805599453
iteration 8 batch 14420 training_loss 0.6931471805599453
iteration 8 batch 14430 training_loss 0.6916632528527511
iteration 8 batch 14440 training_loss 0.6916632528527511
iteration 8 batch 14450 training_loss 0.6931471805599453
iteration 8 batch 14460 training_loss 0.6931471805599453
iteration 8 batch 14470 training_loss 0.6931471805599453
iteration 8 batch 14480 training_loss 0.6916632528527511
iteration 8 batch 14490 training_loss 0.6931471805599453
iteration 8 batch 14500 training_loss 0.6931471805599453
iteration 8 batch 14510 training_loss 0.6931471805599453
iteration 8 batch 14520 training_loss 0.6931471805599453
iteration 8 batch 14530 training_loss 0.6931471805599453
iteration 8 batch 14540 training_loss 0.6931471805599453
iteration 8 batch 14550 training_loss 0.6931471805599453
iteration 8 batch 14560 training_loss 0.6931471805599453
iteration 8 batch 14570 training_loss 0.6931471805599453
iteration 8 batch 14580 training_loss 0.6931471805599453
iteration 8 batch 14590 training_loss 0.6931471805599453
iteration 8 batch 14600 training_loss 0.6931471805599453
iteration 8 batch 14610 training_loss 0.6931471805599453
iteration 8 batch 14620 training_loss 0.6931471805599453
iteration 8 batch 14630 training_loss 0.6931471805599453
iteration 8 batch 14640 training_loss 0.6931471805599453
iteration 8 batch 14650 training_loss 0.6931471805599453
iteration 8 batch 14660 training_loss 0.6931471805599453
iteration 8 batch 14670 training_loss 0.6931471805599453
iteration 8 batch 14680 training_loss 0.6931471805599453
iteration 8 batch 14690 training_loss 0.6931471805599453
iteration 8 batch 14700 training_loss 0.6931471805599453
iteration 8 batch 14710 training_loss 0.6916632528527511
iteration 8 batch 14720 training_loss 0.6931471805599453
iteration 8 batch 14730 training_loss 0.6931471805599453
iteration 8 batch 14740 training_loss 0.6931471805599453
iteration 8 batch 14750 training_loss 0.6931471805599453
iteration 8 batch 14760 training_loss 0.6931471805599453
iteration 8 batch 14770 training_loss 0.6931471805599453
iteration 8 batch 14780 training_loss 0.6931471805599453
iteration 8 batch 14790 training_loss 0.6931471805599453
iteration 8 batch 14800 training_loss 0.6931471805599453
iteration 8 batch 14810 training_loss 0.6931471805599453
iteration 8 batch 14820 training_loss 0.6931471805599453
iteration 8 batch 14830 training_loss 0.6916632528527511
iteration 8 batch 14840 training_loss 0.6931471805599453
iteration 8 batch 14850 training_loss 0.6916632528527511
iteration 8 batch 14860 training_loss 0.6931471805599453
iteration 8 batch 14870 training_loss 0.6931471805599453
iteration 8 batch 14880 training_loss 0.6931471805599453
iteration 8 batch 14890 training_loss 0.6931471805599453
iteration 8 batch 14900 training_loss 0.6931471805599453
iteration 8 batch 14910 training_loss 0.6931471805599453
iteration 8 batch 14920 training_loss 0.6931471805599453
iteration 8 batch 14930 training_loss 0.6931471805599453
iteration 8 batch 14940 training_loss 0.6931471805599453
iteration 8 batch 14950 training_loss 0.6931471805599453
iteration 8 batch 14960 training_loss 0.6931471805599453
iteration 8 batch 14970 training_loss 0.6931471805599453
iteration 8 batch 14980 training_loss 0.6931471805599453
iteration 8 batch 14990 training_loss 0.6931471805599453
iteration 8 batch 15000 training_loss 0.6931471805599453
iteration 8 batch 15010 training_loss 0.6931471805599453
iteration 8 batch 15020 training_loss 0.6931471805599453
iteration 8 batch 15030 training_loss 0.6931471805599453
iteration 8 batch 15040 training_loss 0.6931471805599453
iteration 8 batch 15050 training_loss 0.6931471805599453
iteration 8 batch 15060 training_loss 0.6931471805599453
iteration 8 batch 15070 training_loss 0.6931471805599453
iteration 8 batch 15080 training_loss 0.6931471805599453
iteration 8 batch 15090 training_loss 0.6931471805599453
iteration 8 batch 15100 training_loss 0.6931471805599453
iteration 8 batch 15110 training_loss 0.6931471805599453
iteration 8 batch 15120 training_loss 0.6916632528527511
iteration 8 batch 15130 training_loss 0.6931471805599453
iteration 8 batch 15140 training_loss 0.6931471805599453
iteration 8 batch 15150 training_loss 0.6931471805599453
iteration 8 batch 15160 training_loss 0.6931471805599453
iteration 8 batch 15170 training_loss 0.6916632528527511
iteration 8 batch 15180 training_loss 0.6916632528527511
iteration 8 batch 15190 training_loss 0.6931471805599453
iteration 8 batch 15200 training_loss 0.6931471805599453
iteration 8 batch 15210 training_loss 0.6931471805599453
iteration 8 batch 15220 training_loss 0.6931471805599453
iteration 8 batch 15230 training_loss 0.6931471805599453
iteration 8 batch 15240 training_loss 0.6931471805599453
iteration 8 batch 15250 training_loss 0.6931471805599453
iteration 8 batch 15260 training_loss 0.6916632528527511
iteration 8 batch 15270 training_loss 0.6916632528527511
iteration 8 batch 15280 training_loss 0.6931471805599453
iteration 8 batch 15290 training_loss 0.6931471805599453
iteration 8 batch 15300 training_loss 0.6931471805599453
iteration 8 batch 15310 training_loss 0.6931471805599453
iteration 8 batch 15320 training_loss 0.6931471805599453
iteration 8 batch 15330 training_loss 0.6931471805599453
iteration 8 batch 15340 training_loss 0.6931471805599453
iteration 8 batch 15350 training_loss 0.6931471805599453
iteration 8 batch 15360 training_loss 0.6931471805599453
iteration 8 batch 15370 training_loss 0.6931471805599453
iteration 8 batch 15380 training_loss 0.6931471805599453
iteration 8 batch 15390 training_loss 0.6931471805599453
iteration 8 batch 15400 training_loss 0.6931471805599453
iteration 8 batch 15410 training_loss 0.6931471805599453
iteration 8 batch 15420 training_loss 0.6931471805599453
iteration 8 batch 15430 training_loss 0.6931471805599453
iteration 8 batch 15440 training_loss 0.6931471805599453
iteration 8 batch 15450 training_loss 0.6931471805599453
iteration 8 batch 15460 training_loss 0.6931471805599453
iteration 8 batch 15470 training_loss 0.6931471805599453
iteration 8 batch 15480 training_loss 0.6931471805599453
iteration 8 batch 15490 training_loss 0.6931471805599453
iteration 8 batch 15500 training_loss 0.6916632528527511
iteration 8 batch 15510 training_loss 0.6931471805599453
iteration 8 batch 15520 training_loss 0.6931471805599453
iteration 8 batch 15530 training_loss 0.6931471805599453
iteration 8 batch 15540 training_loss 0.6931471805599453
iteration 8 batch 15550 training_loss 0.6931471805599453
iteration 8 batch 15560 training_loss 0.6931471805599453
iteration 8 batch 15570 training_loss 0.6931471805599453
iteration 8 batch 15580 training_loss 0.6931471805599453
iteration 8 batch 15590 training_loss 0.6931471805599453
iteration 8 batch 15600 training_loss 0.6931471805599453
iteration 8 batch 15610 training_loss 0.6931471805599453
iteration 8 batch 15620 training_loss 0.6931471805599453
iteration 8 batch 15630 training_loss 0.6931471805599453
iteration 8 batch 15640 training_loss 0.6931471805599453
iteration 8 batch 15650 training_loss 0.6931471805599453
iteration 8 batch 15660 training_loss 0.6931471805599453
iteration 8 batch 15670 training_loss 0.6931471805599453
iteration 8 batch 15680 training_loss 0.6931471805599453
iteration 8 batch 15690 training_loss 0.6931471805599453
iteration 8 batch 15700 training_loss 0.6931471805599453
iteration 8 batch 15710 training_loss 0.6931471805599453
iteration 8 batch 15720 training_loss 0.6931471805599453
iteration 8 batch 15730 training_loss 0.6931471805599453
iteration 8 batch 15740 training_loss 0.6931471805599453
iteration 8 batch 15750 training_loss 0.6931471805599453
iteration 8 batch 15760 training_loss 0.6931471805599453
iteration 8 batch 15770 training_loss 0.6931471805599453
iteration 8 batch 15780 training_loss 0.6931471805599453
iteration 8 batch 15790 training_loss 0.6931471805599453
iteration 8 batch 15800 training_loss 0.6931471805599453
iteration 8 batch 15810 training_loss 0.6931471805599453
iteration 8 batch 15820 training_loss 0.6931471805599453
iteration 8 batch 15830 training_loss 0.6931471805599453
iteration 8 batch 15840 training_loss 0.6931471805599453
iteration 8 batch 15850 training_loss 0.6931471805599453
iteration 8 batch 15860 training_loss 0.6931471805599453
iteration 8 batch 15870 training_loss 0.6931471805599453
iteration 8 batch 15880 training_loss 0.6931471805599453
iteration 8 batch 15890 training_loss 0.6931471805599453
iteration 8 batch 15900 training_loss 0.6931471805599453
iteration 8 batch 15910 training_loss 0.6931471805599453
iteration 8 batch 15920 training_loss 0.6931471805599453
iteration 8 batch 15930 training_loss 0.6916632528527511
iteration 8 batch 15940 training_loss 0.6931471805599453
iteration 8 batch 15950 training_loss 0.6931471805599453
iteration 8 batch 15960 training_loss 0.6931471805599453
iteration 8 batch 15970 training_loss 0.6931471805599453
iteration 8 batch 15980 training_loss 0.6916632528527511
iteration 8 batch 15990 training_loss 0.6931471805599453
iteration 8 batch 16000 training_loss 0.6931471805599453
iteration 8 batch 16010 training_loss 0.6931471805599453
iteration 8 batch 16020 training_loss 0.6931471805599453
iteration 8 batch 16030 training_loss 0.6931471805599453
iteration 8 batch 16040 training_loss 0.6931471805599453
iteration 8 batch 16050 training_loss 0.6916632528527511
iteration 8 batch 16060 training_loss 0.6931471805599453
iteration 8 batch 16070 training_loss 0.6931471805599453
iteration 8 batch 16080 training_loss 0.6931471805599453
iteration 8 batch 16090 training_loss 0.6931471805599453
iteration 8 batch 16100 training_loss 0.6931471805599453
iteration 8 batch 16110 training_loss 0.6916632528527511
iteration 8 batch 16120 training_loss 0.6931471805599453
iteration 8 batch 16130 training_loss 0.6931471805599453
iteration 8 batch 16140 training_loss 0.6931471805599453
iteration 8 batch 16150 training_loss 0.6931471805599453
iteration 8 batch 16160 training_loss 0.6931471805599453
iteration 8 batch 16170 training_loss 0.6931471805599453
iteration 8 batch 16180 training_loss 0.6931471805599453
iteration 8 batch 16190 training_loss 0.6931471805599453
iteration 8 batch 16200 training_loss 0.6931471805599453
iteration 8 batch 16210 training_loss 0.6931471805599453
iteration 8 batch 16220 training_loss 0.6931471805599453
iteration 8 batch 16230 training_loss 0.6931471805599453
iteration 8 batch 16240 training_loss 0.6931471805599453
iteration 8 batch 16250 training_loss 0.6931471805599453
iteration 8 batch 16260 training_loss 0.6931471805599453
iteration 8 batch 16270 training_loss 0.6931471805599453
iteration 8 batch 16280 training_loss 0.6931471805599453
iteration 8 batch 16290 training_loss 0.6931471805599453
iteration 8 batch 16300 training_loss 0.6931471805599453
iteration 8 batch 16310 training_loss 0.6931471805599453
iteration 8 batch 16320 training_loss 0.6931471805599453
iteration 8 batch 16330 training_loss 0.6931471805599453
iteration 8 batch 16340 training_loss 0.6931471805599453
iteration 8 batch 16350 training_loss 0.6931471805599453
iteration 8 batch 16360 training_loss 0.6931471805599453
iteration 8 batch 16370 training_loss 0.6931471805599453
iteration 8 batch 16380 training_loss 0.6931471805599453
iteration 8 batch 16390 training_loss 0.6931471805599453
iteration 8 batch 16400 training_loss 0.6931471805599453
iteration 8 batch 16410 training_loss 0.6931471805599453
iteration 8 batch 16420 training_loss 0.6931471805599453
iteration 8 batch 16430 training_loss 0.6931471805599453
iteration 8 batch 16440 training_loss 0.6931471805599453
iteration 8 batch 16450 training_loss 0.6931471805599453
iteration 8 batch 16460 training_loss 0.6931471805599453
iteration 8 batch 16470 training_loss 0.6931471805599453
iteration 8 batch 16480 training_loss 0.6931471805599453
iteration 8 batch 16490 training_loss 0.6931471805599453
iteration 8 batch 16500 training_loss 0.6931471805599453
iteration 8 batch 16510 training_loss 0.6931471805599453
iteration 8 batch 16520 training_loss 0.6931471805599453
iteration 8 batch 16530 training_loss 0.6931471805599453
iteration 8 batch 16540 training_loss 0.6931471805599453
iteration 8 batch 16550 training_loss 0.6931471805599453
iteration 8 batch 16560 training_loss 0.6931471805599453
iteration 8 batch 16570 training_loss 0.6931471805599453
iteration 8 batch 16580 training_loss 0.6931471805599453
iteration 8 batch 16590 training_loss 0.6931471805599453
iteration 8 batch 16600 training_loss 0.6931471805599453
iteration 8 batch 16610 training_loss 0.6931471805599453
iteration 8 batch 16620 training_loss 0.6931471805599453
iteration 8 batch 16630 training_loss 0.6931471805599453
iteration 8 batch 16640 training_loss 0.6931471805599453
iteration 8 batch 16650 training_loss 0.6931471805599453
iteration 8 batch 16660 training_loss 0.6931471805599453
iteration 8 batch 16670 training_loss 0.6931471805599453
iteration 8 batch 16680 training_loss 0.6931471805599453
iteration 8 batch 16690 training_loss 0.6931471805599453
iteration 8 batch 16700 training_loss 0.6931471805599453
iteration 8 batch 16710 training_loss 0.6931471805599453
iteration 8 batch 16720 training_loss 0.6931471805599453
iteration 8 batch 16730 training_loss 0.6931471805599453
iteration 8 batch 16740 training_loss 0.6931471805599453
iteration 8 batch 16750 training_loss 0.6931471805599453
iteration 8 batch 16760 training_loss 0.6931471805599453
iteration 8 batch 16770 training_loss 0.6931471805599453
iteration 8 batch 16780 training_loss 0.6931471805599453
iteration 8 batch 16790 training_loss 0.6931471805599453
iteration 8 batch 16800 training_loss 0.6931471805599453
iteration 8 batch 16810 training_loss 0.6931471805599453
iteration 8 batch 16820 training_loss 0.6931471805599453
iteration 8 batch 16830 training_loss 0.6931471805599453
iteration 8 batch 16840 training_loss 0.6931471805599453
iteration 8 batch 16850 training_loss 0.6931471805599453
iteration 8 batch 16860 training_loss 0.6931471805599453
iteration 8 batch 16870 training_loss 0.6931471805599453
iteration 8 batch 16880 training_loss 0.6931471805599453
iteration 8 batch 16890 training_loss 0.6931471805599453
iteration 8 batch 16900 training_loss 0.6931471805599453
iteration 8 batch 16910 training_loss 0.6931471805599453
iteration 8 batch 16920 training_loss 0.6931471805599453
iteration 8 batch 16930 training_loss 0.6931471805599453
iteration 8 batch 16940 training_loss 0.6931471805599453
iteration 8 batch 16950 training_loss 0.6931471805599453
iteration 8 batch 16960 training_loss 0.6931471805599453
iteration 8 batch 16970 training_loss 0.6931471805599453
iteration 8 batch 16980 training_loss 0.6931471805599453
iteration 8 batch 16990 training_loss 0.6931471805599453
iteration 8 batch 17000 training_loss 0.6931471805599453
iteration 8 batch 17010 training_loss 0.6931471805599453
iteration 8 batch 17020 training_loss 0.6931471805599453
iteration 8 batch 17030 training_loss 0.6931471805599453
iteration 8 batch 17040 training_loss 0.6931471805599453
iteration 8 batch 17050 training_loss 0.6916632528527511
iteration 8 batch 17060 training_loss 0.6931471805599453
iteration 8 batch 17070 training_loss 0.6916632528527511
iteration 8 batch 17080 training_loss 0.6931471805599453
iteration 8 batch 17090 training_loss 0.6931471805599453
iteration 8 batch 17100 training_loss 0.6931471805599453
iteration 8 batch 17110 training_loss 0.6931471805599453
iteration 8 batch 17120 training_loss 0.6931471805599453
iteration 8 batch 17130 training_loss 0.6931471805599453
iteration 8 batch 17140 training_loss 0.6916632528527511
iteration 8 batch 17150 training_loss 0.6931471805599453
iteration 8 batch 17160 training_loss 0.6916632528527511
iteration 8 batch 17170 training_loss 0.6931471805599453
iteration 8 batch 17180 training_loss 0.6931471805599453
iteration 8 batch 17190 training_loss 0.6931471805599453
iteration 8 batch 17200 training_loss 0.6931471805599453
iteration 8 batch 17210 training_loss 0.6931471805599453
iteration 8 batch 17220 training_loss 0.6931471805599453
iteration 8 batch 17230 training_loss 0.6931471805599453
iteration 8 batch 17240 training_loss 0.6931471805599453
iteration 8 batch 17250 training_loss 0.6931471805599453
iteration 8 batch 17260 training_loss 0.6916632528527511
iteration 8 batch 17270 training_loss 0.6931471805599453
iteration 8 batch 17280 training_loss 0.6931471805599453
iteration 8 batch 17290 training_loss 0.6931471805599453
iteration 8 batch 17300 training_loss 0.6931471805599453
iteration 8 batch 17310 training_loss 0.6931471805599453
iteration 8 batch 17320 training_loss 0.6931471805599453
iteration 8 batch 17330 training_loss 0.6931471805599453
iteration 8 batch 17340 training_loss 0.6931471805599453
iteration 8 batch 17350 training_loss 0.6931471805599453
iteration 8 batch 17360 training_loss 0.6916632528527511
iteration 8 batch 17370 training_loss 0.6931471805599453
iteration 8 batch 17380 training_loss 0.6931471805599453
iteration 8 batch 17390 training_loss 0.6916632528527511
iteration 8 batch 17400 training_loss 0.6931471805599453
iteration 8 batch 17410 training_loss 0.6931471805599453
iteration 8 batch 17420 training_loss 0.6916632528527511
iteration 8 batch 17430 training_loss 0.6916632528527511
iteration 8 batch 17440 training_loss 0.6931471805599453
iteration 8 batch 17450 training_loss 0.6931471805599453
iteration 8 batch 17460 training_loss 0.6931471805599453
iteration 8 batch 17470 training_loss 0.6931471805599453
iteration 8 batch 17480 training_loss 0.6931471805599453
iteration 8 batch 17490 training_loss 0.6931471805599453
iteration 8 batch 17500 training_loss 0.6931471805599453
iteration 8 batch 17510 training_loss 0.6931471805599453
iteration 8 batch 17520 training_loss 0.6931471805599453
iteration 8 batch 17530 training_loss 0.6931471805599453
iteration 8 batch 17540 training_loss 0.6931471805599453
iteration 8 batch 17550 training_loss 0.6931471805599453
iteration 8 batch 17560 training_loss 0.6931471805599453
iteration 8 batch 17570 training_loss 0.6931471805599453
iteration 8 batch 17580 training_loss 0.6931471805599453
iteration 8 batch 17590 training_loss 0.6916632528527511
iteration 8 batch 17600 training_loss 0.6931471805599453
iteration 8 batch 17610 training_loss 0.6931471805599453
iteration 8 batch 17620 training_loss 0.6931471805599453
iteration 8 batch 17630 training_loss 0.6931471805599453
iteration 8 batch 17640 training_loss 0.6931471805599453
iteration 8 batch 17650 training_loss 0.6931471805599453
iteration 8 batch 17660 training_loss 0.6931471805599453
iteration 8 batch 17670 training_loss 0.6931471805599453
iteration 8 batch 17680 training_loss 0.6931471805599453
iteration 8 batch 17690 training_loss 0.6931471805599453
iteration 8 batch 17700 training_loss 0.6931471805599453
iteration 8 batch 17710 training_loss 0.6931471805599453
iteration 8 batch 17720 training_loss 0.6931471805599453
iteration 8 batch 17730 training_loss 0.6916632528527511
iteration 8 batch 17740 training_loss 0.6931471805599453
iteration 8 batch 17750 training_loss 0.6931471805599453
iteration 8 batch 17760 training_loss 0.6931471805599453
iteration 8 batch 17770 training_loss 0.6931471805599453
iteration 8 batch 17780 training_loss 0.6931471805599453
iteration 8 batch 17790 training_loss 0.6931471805599453
iteration 8 batch 17800 training_loss 0.6931471805599453
iteration 8 batch 17810 training_loss 0.6931471805599453
iteration 8 batch 17820 training_loss 0.6916632528527511
iteration 8 batch 17830 training_loss 0.6931471805599453
iteration 8 batch 17840 training_loss 0.6931471805599453
iteration 8 batch 17850 training_loss 0.6931471805599453
iteration 8 batch 17860 training_loss 0.6931471805599453
iteration 8 batch 17870 training_loss 0.6931471805599453
iteration 8 batch 17880 training_loss 0.6931471805599453
iteration 8 batch 17890 training_loss 0.6931471805599453
iteration 8 batch 17900 training_loss 0.6931471805599453
iteration 8 batch 17910 training_loss 0.6931471805599453
iteration 8 batch 17920 training_loss 0.6931471805599453
iteration 8 batch 17930 training_loss 0.6931471805599453
iteration 8 batch 17940 training_loss 0.6931471805599453
iteration 8 batch 17950 training_loss 0.6931471805599453
iteration 8 batch 17960 training_loss 0.6931471805599453
iteration 8 batch 17970 training_loss 0.6931471805599453
iteration 8 batch 17980 training_loss 0.6916632528527511
iteration 8 batch 17990 training_loss 0.6931471805599453
iteration 8 batch 18000 training_loss 0.6931471805599453
iteration 8 batch 18010 training_loss 0.6931471805599453
iteration 8 batch 18020 training_loss 0.6931471805599453
iteration 8 batch 18030 training_loss 0.6931471805599453
iteration 8 batch 18040 training_loss 0.6931471805599453
iteration 8 batch 18050 training_loss 0.6931471805599453
iteration 8 batch 18060 training_loss 0.6931471805599453
iteration 8 batch 18070 training_loss 0.6931471805599453
iteration 8 batch 18080 training_loss 0.6931471805599453
iteration 8 batch 18090 training_loss 0.6931471805599453
iteration 8 batch 18100 training_loss 0.6931471805599453
iteration 8 batch 18110 training_loss 0.6931471805599453
iteration 8 batch 18120 training_loss 0.6916632528527511
iteration 8 batch 18130 training_loss 0.6931471805599453
iteration 8 batch 18140 training_loss 0.6931471805599453
iteration 8 batch 18150 training_loss 0.6931471805599453
iteration 8 batch 18160 training_loss 0.6931471805599453
iteration 8 batch 18170 training_loss 0.6931471805599453
iteration 8 batch 18180 training_loss 0.6931471805599453
iteration 8 batch 18190 training_loss 0.6931471805599453
iteration 8 batch 18200 training_loss 0.6931471805599453
iteration 8 batch 18210 training_loss 0.6931471805599453
iteration 8 batch 18220 training_loss 0.6931471805599453
iteration 8 batch 18230 training_loss 0.6931471805599453
iteration 8 batch 18240 training_loss 0.6931471805599453
iteration 8 batch 18250 training_loss 0.6931471805599453
iteration 8 batch 18260 training_loss 0.6931471805599453
iteration 8 batch 18270 training_loss 0.6931471805599453
iteration 8 batch 18280 training_loss 0.6931471805599453
iteration 8 batch 18290 training_loss 0.6931471805599453
iteration 8 batch 18300 training_loss 0.6931471805599453
iteration 8 batch 18310 training_loss 0.6931471805599453
iteration 8 batch 18320 training_loss 0.6931471805599453
iteration 8 batch 18330 training_loss 0.6931471805599453
iteration 8 batch 18340 training_loss 0.6931471805599453
iteration 8 batch 18350 training_loss 0.6931471805599453
iteration 8 batch 18360 training_loss 0.6931471805599453
iteration 8 batch 18370 training_loss 0.6931471805599453
iteration 8 batch 18380 training_loss 0.6931471805599453
iteration 8 batch 18390 training_loss 0.6931471805599453
iteration 8 batch 18400 training_loss 0.6931471805599453
iteration 8 batch 18410 training_loss 0.6931471805599453
iteration 8 batch 18420 training_loss 0.6931471805599453
iteration 8 batch 18430 training_loss 0.6931471805599453
iteration 8 batch 18440 training_loss 0.6931471805599453
iteration 8 batch 18450 training_loss 0.6931471805599453
iteration 8 batch 18460 training_loss 0.6931471805599453
iteration 8 batch 18470 training_loss 0.6931471805599453
iteration 8 batch 18480 training_loss 0.6931471805599453
iteration 8 batch 18490 training_loss 0.6931471805599453
iteration 8 batch 18500 training_loss 0.6931471805599453
iteration 8 batch 18510 training_loss 0.6931471805599453
iteration 8 batch 18520 training_loss 0.6931471805599453
iteration 8 batch 18530 training_loss 0.6931471805599453
iteration 8 batch 18540 training_loss 0.6931471805599453
iteration 8 batch 18550 training_loss 0.6931471805599453
iteration 8 batch 18560 training_loss 0.6931471805599453
iteration 8 batch 18570 training_loss 0.6931471805599453
iteration 8 batch 18580 training_loss 0.6931471805599453
iteration 8 batch 18590 training_loss 0.6931471805599453
iteration 8 batch 18600 training_loss 0.6916632528527511
iteration 8 batch 18610 training_loss 0.6931471805599453
iteration 9 batch 0 training_loss 0.6931471805599453
iteration 9 batch 10 training_loss 0.6931471805599453
iteration 9 batch 20 training_loss 0.6931471805599453
iteration 9 batch 30 training_loss 0.6931471805599453
iteration 9 batch 40 training_loss 0.6931471805599453
iteration 9 batch 50 training_loss 0.6931471805599453
iteration 9 batch 60 training_loss 0.6931471805599453
iteration 9 batch 70 training_loss 0.6931471805599453
iteration 9 batch 80 training_loss 0.6931471805599453
iteration 9 batch 90 training_loss 0.6931471805599453
iteration 9 batch 100 training_loss 0.6931471805599453
iteration 9 batch 110 training_loss 0.6931471805599453
iteration 9 batch 120 training_loss 0.6916632528527511
iteration 9 batch 130 training_loss 0.6931471805599453
iteration 9 batch 140 training_loss 0.6931471805599453
iteration 9 batch 150 training_loss 0.6931471805599453
iteration 9 batch 160 training_loss 0.6931471805599453
iteration 9 batch 170 training_loss 0.6931471805599453
iteration 9 batch 180 training_loss 0.6916632528527511
iteration 9 batch 190 training_loss 0.6931471805599453
iteration 9 batch 200 training_loss 0.6931471805599453
iteration 9 batch 210 training_loss 0.6931471805599453
iteration 9 batch 220 training_loss 0.6916632528527511
iteration 9 batch 230 training_loss 0.6931471805599453
iteration 9 batch 240 training_loss 0.6931471805599453
iteration 9 batch 250 training_loss 0.6931471805599453
iteration 9 batch 260 training_loss 0.6931471805599453
iteration 9 batch 270 training_loss 0.6916632528527511
iteration 9 batch 280 training_loss 0.6931471805599453
iteration 9 batch 290 training_loss 0.6931471805599453
iteration 9 batch 300 training_loss 0.6931471805599453
iteration 9 batch 310 training_loss 0.6931471805599453
iteration 9 batch 320 training_loss 0.6931471805599453
iteration 9 batch 330 training_loss 0.6931471805599453
iteration 9 batch 340 training_loss 0.6916632528527511
iteration 9 batch 350 training_loss 0.6931471805599453
iteration 9 batch 360 training_loss 0.6931471805599453
iteration 9 batch 370 training_loss 0.6931471805599453
iteration 9 batch 380 training_loss 0.6931471805599453
iteration 9 batch 390 training_loss 0.6931471805599453
iteration 9 batch 400 training_loss 0.6916632528527511
iteration 9 batch 410 training_loss 0.6931471805599453
iteration 9 batch 420 training_loss 0.6931471805599453
iteration 9 batch 430 training_loss 0.6931471805599453
iteration 9 batch 440 training_loss 0.6931471805599453
iteration 9 batch 450 training_loss 0.6931471805599453
iteration 9 batch 460 training_loss 0.6931471805599453
iteration 9 batch 470 training_loss 0.6931471805599453
iteration 9 batch 480 training_loss 0.6931471805599453
iteration 9 batch 490 training_loss 0.6931471805599453
iteration 9 batch 500 training_loss 0.6916632528527511
iteration 9 batch 510 training_loss 0.6931471805599453
iteration 9 batch 520 training_loss 0.6931471805599453
iteration 9 batch 530 training_loss 0.6931471805599453
iteration 9 batch 540 training_loss 0.6931471805599453
iteration 9 batch 550 training_loss 0.6931471805599453
iteration 9 batch 560 training_loss 0.6931471805599453
iteration 9 batch 570 training_loss 0.6931471805599453
iteration 9 batch 580 training_loss 0.6916632528527511
iteration 9 batch 590 training_loss 0.6931471805599453
iteration 9 batch 600 training_loss 0.6931471805599453
iteration 9 batch 610 training_loss 0.6931471805599453
iteration 9 batch 620 training_loss 0.6931471805599453
iteration 9 batch 630 training_loss 0.6931471805599453
iteration 9 batch 640 training_loss 0.6931471805599453
iteration 9 batch 650 training_loss 0.6931471805599453
iteration 9 batch 660 training_loss 0.6931471805599453
iteration 9 batch 670 training_loss 0.6931471805599453
iteration 9 batch 680 training_loss 0.6931471805599453
iteration 9 batch 690 training_loss 0.6931471805599453
iteration 9 batch 700 training_loss 0.6931471805599453
iteration 9 batch 710 training_loss 0.6931471805599453
iteration 9 batch 720 training_loss 0.6931471805599453
iteration 9 batch 730 training_loss 0.6931471805599453
iteration 9 batch 740 training_loss 0.6931471805599453
iteration 9 batch 750 training_loss 0.6931471805599453
iteration 9 batch 760 training_loss 0.6931471805599453
iteration 9 batch 770 training_loss 0.6931471805599453
iteration 9 batch 780 training_loss 0.6931471805599453
iteration 9 batch 790 training_loss 0.6931471805599453
iteration 9 batch 800 training_loss 0.6931471805599453
iteration 9 batch 810 training_loss 0.6931471805599453
iteration 9 batch 820 training_loss 0.6931471805599453
iteration 9 batch 830 training_loss 0.6931471805599453
iteration 9 batch 840 training_loss 0.6931471805599453
iteration 9 batch 850 training_loss 0.6931471805599453
iteration 9 batch 860 training_loss 0.6931471805599453
iteration 9 batch 870 training_loss 0.6931471805599453
iteration 9 batch 880 training_loss 0.6931471805599453
iteration 9 batch 890 training_loss 0.6931471805599453
iteration 9 batch 900 training_loss 0.6931471805599453
iteration 9 batch 910 training_loss 0.6931471805599453
iteration 9 batch 920 training_loss 0.6931471805599453
iteration 9 batch 930 training_loss 0.6931471805599453
iteration 9 batch 940 training_loss 0.6931471805599453
iteration 9 batch 950 training_loss 0.6931471805599453
iteration 9 batch 960 training_loss 0.6931471805599453
iteration 9 batch 970 training_loss 0.6931471805599453
iteration 9 batch 980 training_loss 0.6931471805599453
iteration 9 batch 990 training_loss 0.6931471805599453
iteration 9 batch 1000 training_loss 0.6931471805599453
iteration 9 batch 1010 training_loss 0.6931471805599453
iteration 9 batch 1020 training_loss 0.6916632528527511
iteration 9 batch 1030 training_loss 0.6931471805599453
iteration 9 batch 1040 training_loss 0.6931471805599453
iteration 9 batch 1050 training_loss 0.6916632528527511
iteration 9 batch 1060 training_loss 0.6931471805599453
iteration 9 batch 1070 training_loss 0.6931471805599453
iteration 9 batch 1080 training_loss 0.6931471805599453
iteration 9 batch 1090 training_loss 0.6931471805599453
iteration 9 batch 1100 training_loss 0.6931471805599453
iteration 9 batch 1110 training_loss 0.6931471805599453
iteration 9 batch 1120 training_loss 0.6931471805599453
iteration 9 batch 1130 training_loss 0.6931471805599453
iteration 9 batch 1140 training_loss 0.6931471805599453
iteration 9 batch 1150 training_loss 0.6931471805599453
iteration 9 batch 1160 training_loss 0.6931471805599453
iteration 9 batch 1170 training_loss 0.6931471805599453
iteration 9 batch 1180 training_loss 0.6931471805599453
iteration 9 batch 1190 training_loss 0.6931471805599453
iteration 9 batch 1200 training_loss 0.6931471805599453
iteration 9 batch 1210 training_loss 0.6931471805599453
iteration 9 batch 1220 training_loss 0.6931471805599453
iteration 9 batch 1230 training_loss 0.6931471805599453
iteration 9 batch 1240 training_loss 0.6931471805599453
iteration 9 batch 1250 training_loss 0.6931471805599453
iteration 9 batch 1260 training_loss 0.6931471805599453
iteration 9 batch 1270 training_loss 0.6931471805599453
iteration 9 batch 1280 training_loss 0.6931471805599453
iteration 9 batch 1290 training_loss 0.6931471805599453
iteration 9 batch 1300 training_loss 0.6931471805599453
iteration 9 batch 1310 training_loss 0.6931471805599453
iteration 9 batch 1320 training_loss 0.6931471805599453
iteration 9 batch 1330 training_loss 0.6931471805599453
iteration 9 batch 1340 training_loss 0.6931471805599453
iteration 9 batch 1350 training_loss 0.6931471805599453
iteration 9 batch 1360 training_loss 0.6931471805599453
iteration 9 batch 1370 training_loss 0.6931471805599453
iteration 9 batch 1380 training_loss 0.6931471805599453
iteration 9 batch 1390 training_loss 0.6931471805599453
iteration 9 batch 1400 training_loss 0.6931471805599453
iteration 9 batch 1410 training_loss 0.6931471805599453
iteration 9 batch 1420 training_loss 0.6931471805599453
iteration 9 batch 1430 training_loss 0.6931471805599453
iteration 9 batch 1440 training_loss 0.6916632528527511
iteration 9 batch 1450 training_loss 0.6931471805599453
iteration 9 batch 1460 training_loss 0.6931471805599453
iteration 9 batch 1470 training_loss 0.6931471805599453
iteration 9 batch 1480 training_loss 0.6931471805599453
iteration 9 batch 1490 training_loss 0.6931471805599453
iteration 9 batch 1500 training_loss 0.6931471805599453
iteration 9 batch 1510 training_loss 0.6931471805599453
iteration 9 batch 1520 training_loss 0.6931471805599453
iteration 9 batch 1530 training_loss 0.6931471805599453
iteration 9 batch 1540 training_loss 0.6931471805599453
iteration 9 batch 1550 training_loss 0.6931471805599453
iteration 9 batch 1560 training_loss 0.6931471805599453
iteration 9 batch 1570 training_loss 0.6931471805599453
iteration 9 batch 1580 training_loss 0.6931471805599453
iteration 9 batch 1590 training_loss 0.6931471805599453
iteration 9 batch 1600 training_loss 0.6931471805599453
iteration 9 batch 1610 training_loss 0.6931471805599453
iteration 9 batch 1620 training_loss 0.6931471805599453
iteration 9 batch 1630 training_loss 0.6931471805599453
iteration 9 batch 1640 training_loss 0.6931471805599453
iteration 9 batch 1650 training_loss 0.6931471805599453
iteration 9 batch 1660 training_loss 0.6931471805599453
iteration 9 batch 1670 training_loss 0.6931471805599453
iteration 9 batch 1680 training_loss 0.6931471805599453
iteration 9 batch 1690 training_loss 0.6931471805599453
iteration 9 batch 1700 training_loss 0.6931471805599453
iteration 9 batch 1710 training_loss 0.6931471805599453
iteration 9 batch 1720 training_loss 0.6916632528527511
iteration 9 batch 1730 training_loss 0.6931471805599453
iteration 9 batch 1740 training_loss 0.6931471805599453
iteration 9 batch 1750 training_loss 0.6931471805599453
iteration 9 batch 1760 training_loss 0.6931471805599453
iteration 9 batch 1770 training_loss 0.6931471805599453
iteration 9 batch 1780 training_loss 0.6931471805599453
iteration 9 batch 1790 training_loss 0.6931471805599453
iteration 9 batch 1800 training_loss 0.6931471805599453
iteration 9 batch 1810 training_loss 0.6931471805599453
iteration 9 batch 1820 training_loss 0.6931471805599453
iteration 9 batch 1830 training_loss 0.6931471805599453
iteration 9 batch 1840 training_loss 0.6931471805599453
iteration 9 batch 1850 training_loss 0.6931471805599453
iteration 9 batch 1860 training_loss 0.6931471805599453
iteration 9 batch 1870 training_loss 0.6931471805599453
iteration 9 batch 1880 training_loss 0.6931471805599453
iteration 9 batch 1890 training_loss 0.6931471805599453
iteration 9 batch 1900 training_loss 0.6931471805599453
iteration 9 batch 1910 training_loss 0.6931471805599453
iteration 9 batch 1920 training_loss 0.6931471805599453
iteration 9 batch 1930 training_loss 0.6931471805599453
iteration 9 batch 1940 training_loss 0.6931471805599453
iteration 9 batch 1950 training_loss 0.6931471805599453
iteration 9 batch 1960 training_loss 0.6931471805599453
iteration 9 batch 1970 training_loss 0.6931471805599453
iteration 9 batch 1980 training_loss 0.6931471805599453
iteration 9 batch 1990 training_loss 0.6931471805599453
iteration 9 batch 2000 training_loss 0.6931471805599453
iteration 9 batch 2010 training_loss 0.6931471805599453
iteration 9 batch 2020 training_loss 0.6931471805599453
iteration 9 batch 2030 training_loss 0.6931471805599453
iteration 9 batch 2040 training_loss 0.6931471805599453
iteration 9 batch 2050 training_loss 0.6931471805599453
iteration 9 batch 2060 training_loss 0.6931471805599453
iteration 9 batch 2070 training_loss 0.6931471805599453
iteration 9 batch 2080 training_loss 0.6931471805599453
iteration 9 batch 2090 training_loss 0.6931471805599453
iteration 9 batch 2100 training_loss 0.6931471805599453
iteration 9 batch 2110 training_loss 0.6931471805599453
iteration 9 batch 2120 training_loss 0.6931471805599453
iteration 9 batch 2130 training_loss 0.6931471805599453
iteration 9 batch 2140 training_loss 0.6931471805599453
iteration 9 batch 2150 training_loss 0.6931471805599453
iteration 9 batch 2160 training_loss 0.6931471805599453
iteration 9 batch 2170 training_loss 0.6916632528527511
iteration 9 batch 2180 training_loss 0.6931471805599453
iteration 9 batch 2190 training_loss 0.6931471805599453
iteration 9 batch 2200 training_loss 0.6931471805599453
iteration 9 batch 2210 training_loss 0.6931471805599453
iteration 9 batch 2220 training_loss 0.6931471805599453
iteration 9 batch 2230 training_loss 0.6931471805599453
iteration 9 batch 2240 training_loss 0.6931471805599453
iteration 9 batch 2250 training_loss 0.6931471805599453
iteration 9 batch 2260 training_loss 0.6931471805599453
iteration 9 batch 2270 training_loss 0.6931471805599453
iteration 9 batch 2280 training_loss 0.6931471805599453
iteration 9 batch 2290 training_loss 0.6916632528527511
iteration 9 batch 2300 training_loss 0.6931471805599453
iteration 9 batch 2310 training_loss 0.6931471805599453
iteration 9 batch 2320 training_loss 0.6931471805599453
iteration 9 batch 2330 training_loss 0.6931471805599453
iteration 9 batch 2340 training_loss 0.6931471805599453
iteration 9 batch 2350 training_loss 0.6931471805599453
iteration 9 batch 2360 training_loss 0.6931471805599453
iteration 9 batch 2370 training_loss 0.6916632528527511
iteration 9 batch 2380 training_loss 0.6931471805599453
iteration 9 batch 2390 training_loss 0.6931471805599453
iteration 9 batch 2400 training_loss 0.6931471805599453
iteration 9 batch 2410 training_loss 0.6916632528527511
iteration 9 batch 2420 training_loss 0.6931471805599453
iteration 9 batch 2430 training_loss 0.6931471805599453
iteration 9 batch 2440 training_loss 0.6931471805599453
iteration 9 batch 2450 training_loss 0.6916632528527511
iteration 9 batch 2460 training_loss 0.6931471805599453
iteration 9 batch 2470 training_loss 0.6931471805599453
iteration 9 batch 2480 training_loss 0.6931471805599453
iteration 9 batch 2490 training_loss 0.6931471805599453
iteration 9 batch 2500 training_loss 0.6931471805599453
iteration 9 batch 2510 training_loss 0.6931471805599453
iteration 9 batch 2520 training_loss 0.6931471805599453
iteration 9 batch 2530 training_loss 0.6931471805599453
iteration 9 batch 2540 training_loss 0.6916632528527511
iteration 9 batch 2550 training_loss 0.6931471805599453
iteration 9 batch 2560 training_loss 0.6931471805599453
iteration 9 batch 2570 training_loss 0.6931471805599453
iteration 9 batch 2580 training_loss 0.6931471805599453
iteration 9 batch 2590 training_loss 0.6931471805599453
iteration 9 batch 2600 training_loss 0.6931471805599453
iteration 9 batch 2610 training_loss 0.6931471805599453
iteration 9 batch 2620 training_loss 0.6931471805599453
iteration 9 batch 2630 training_loss 0.6931471805599453
iteration 9 batch 2640 training_loss 0.6931471805599453
iteration 9 batch 2650 training_loss 0.6931471805599453
iteration 9 batch 2660 training_loss 0.6931471805599453
iteration 9 batch 2670 training_loss 0.6931471805599453
iteration 9 batch 2680 training_loss 0.6931471805599453
iteration 9 batch 2690 training_loss 0.6931471805599453
iteration 9 batch 2700 training_loss 0.6931471805599453
iteration 9 batch 2710 training_loss 0.6931471805599453
iteration 9 batch 2720 training_loss 0.6931471805599453
iteration 9 batch 2730 training_loss 0.6931471805599453
iteration 9 batch 2740 training_loss 0.6916632528527511
iteration 9 batch 2750 training_loss 0.6931471805599453
iteration 9 batch 2760 training_loss 0.6931471805599453
iteration 9 batch 2770 training_loss 0.6931471805599453
iteration 9 batch 2780 training_loss 0.6931471805599453
iteration 9 batch 2790 training_loss 0.6931471805599453
iteration 9 batch 2800 training_loss 0.6931471805599453
iteration 9 batch 2810 training_loss 0.6916632528527511
iteration 9 batch 2820 training_loss 0.6931471805599453
iteration 9 batch 2830 training_loss 0.6931471805599453
iteration 9 batch 2840 training_loss 0.6931471805599453
iteration 9 batch 2850 training_loss 0.6931471805599453
iteration 9 batch 2860 training_loss 0.6931471805599453
iteration 9 batch 2870 training_loss 0.6931471805599453
iteration 9 batch 2880 training_loss 0.6916632528527511
iteration 9 batch 2890 training_loss 0.6931471805599453
iteration 9 batch 2900 training_loss 0.6931471805599453
iteration 9 batch 2910 training_loss 0.6931471805599453
iteration 9 batch 2920 training_loss 0.6931471805599453
iteration 9 batch 2930 training_loss 0.6931471805599453
iteration 9 batch 2940 training_loss 0.6916632528527511
iteration 9 batch 2950 training_loss 0.6931471805599453
iteration 9 batch 2960 training_loss 0.6931471805599453
iteration 9 batch 2970 training_loss 0.6931471805599453
iteration 9 batch 2980 training_loss 0.6931471805599453
iteration 9 batch 2990 training_loss 0.6931471805599453
iteration 9 batch 3000 training_loss 0.6931471805599453
iteration 9 batch 3010 training_loss 0.6931471805599453
iteration 9 batch 3020 training_loss 0.6931471805599453
iteration 9 batch 3030 training_loss 0.6931471805599453
iteration 9 batch 3040 training_loss 0.6931471805599453
iteration 9 batch 3050 training_loss 0.6931471805599453
iteration 9 batch 3060 training_loss 0.6931471805599453
iteration 9 batch 3070 training_loss 0.6916632528527511
iteration 9 batch 3080 training_loss 0.6931471805599453
iteration 9 batch 3090 training_loss 0.6916632528527511
iteration 9 batch 3100 training_loss 0.6931471805599453
iteration 9 batch 3110 training_loss 0.6931471805599453
iteration 9 batch 3120 training_loss 0.6931471805599453
iteration 9 batch 3130 training_loss 0.6931471805599453
iteration 9 batch 3140 training_loss 0.6931471805599453
iteration 9 batch 3150 training_loss 0.6931471805599453
iteration 9 batch 3160 training_loss 0.6931471805599453
iteration 9 batch 3170 training_loss 0.6931471805599453
iteration 9 batch 3180 training_loss 0.6931471805599453
iteration 9 batch 3190 training_loss 0.6931471805599453
iteration 9 batch 3200 training_loss 0.6931471805599453
iteration 9 batch 3210 training_loss 0.6931471805599453
iteration 9 batch 3220 training_loss 0.6931471805599453
iteration 9 batch 3230 training_loss 0.6931471805599453
iteration 9 batch 3240 training_loss 0.6931471805599453
iteration 9 batch 3250 training_loss 0.6931471805599453
iteration 9 batch 3260 training_loss 0.6931471805599453
iteration 9 batch 3270 training_loss 0.6931471805599453
iteration 9 batch 3280 training_loss 0.6931471805599453
iteration 9 batch 3290 training_loss 0.6931471805599453
iteration 9 batch 3300 training_loss 0.6916632528527511
iteration 9 batch 3310 training_loss 0.6931471805599453
iteration 9 batch 3320 training_loss 0.6931471805599453
iteration 9 batch 3330 training_loss 0.6931471805599453
iteration 9 batch 3340 training_loss 0.6931471805599453
iteration 9 batch 3350 training_loss 0.6931471805599453
iteration 9 batch 3360 training_loss 0.6931471805599453
iteration 9 batch 3370 training_loss 0.6931471805599453
iteration 9 batch 3380 training_loss 0.6931471805599453
iteration 9 batch 3390 training_loss 0.6931471805599453
iteration 9 batch 3400 training_loss 0.6931471805599453
iteration 9 batch 3410 training_loss 0.6931471805599453
iteration 9 batch 3420 training_loss 0.6931471805599453
iteration 9 batch 3430 training_loss 0.6931471805599453
iteration 9 batch 3440 training_loss 0.6931471805599453
iteration 9 batch 3450 training_loss 0.6931471805599453
iteration 9 batch 3460 training_loss 0.6931471805599453
iteration 9 batch 3470 training_loss 0.6931471805599453
iteration 9 batch 3480 training_loss 0.6931471805599453
iteration 9 batch 3490 training_loss 0.6931471805599453
iteration 9 batch 3500 training_loss 0.6931471805599453
iteration 9 batch 3510 training_loss 0.6931471805599453
iteration 9 batch 3520 training_loss 0.6931471805599453
iteration 9 batch 3530 training_loss 0.6931471805599453
iteration 9 batch 3540 training_loss 0.6931471805599453
iteration 9 batch 3550 training_loss 0.6931471805599453
iteration 9 batch 3560 training_loss 0.6931471805599453
iteration 9 batch 3570 training_loss 0.6931471805599453
iteration 9 batch 3580 training_loss 0.6931471805599453
iteration 9 batch 3590 training_loss 0.6931471805599453
iteration 9 batch 3600 training_loss 0.6931471805599453
iteration 9 batch 3610 training_loss 0.6916632528527511
iteration 9 batch 3620 training_loss 0.6931471805599453
iteration 9 batch 3630 training_loss 0.6931471805599453
iteration 9 batch 3640 training_loss 0.6931471805599453
iteration 9 batch 3650 training_loss 0.6931471805599453
iteration 9 batch 3660 training_loss 0.6931471805599453
iteration 9 batch 3670 training_loss 0.6931471805599453
iteration 9 batch 3680 training_loss 0.6931471805599453
iteration 9 batch 3690 training_loss 0.6931471805599453
iteration 9 batch 3700 training_loss 0.6931471805599453
iteration 9 batch 3710 training_loss 0.6931471805599453
iteration 9 batch 3720 training_loss 0.6931471805599453
iteration 9 batch 3730 training_loss 0.6931471805599453
iteration 9 batch 3740 training_loss 0.6931471805599453
iteration 9 batch 3750 training_loss 0.6931471805599453
iteration 9 batch 3760 training_loss 0.6931471805599453
iteration 9 batch 3770 training_loss 0.6931471805599453
iteration 9 batch 3780 training_loss 0.6931471805599453
iteration 9 batch 3790 training_loss 0.6931471805599453
iteration 9 batch 3800 training_loss 0.6931471805599453
iteration 9 batch 3810 training_loss 0.6931471805599453
iteration 9 batch 3820 training_loss 0.6931471805599453
iteration 9 batch 3830 training_loss 0.6931471805599453
iteration 9 batch 3840 training_loss 0.6931471805599453
iteration 9 batch 3850 training_loss 0.6931471805599453
iteration 9 batch 3860 training_loss 0.6931471805599453
iteration 9 batch 3870 training_loss 0.6931471805599453
iteration 9 batch 3880 training_loss 0.6931471805599453
iteration 9 batch 3890 training_loss 0.6931471805599453
iteration 9 batch 3900 training_loss 0.6931471805599453
iteration 9 batch 3910 training_loss 0.6931471805599453
iteration 9 batch 3920 training_loss 0.6931471805599453
iteration 9 batch 3930 training_loss 0.6931471805599453
iteration 9 batch 3940 training_loss 0.6931471805599453
iteration 9 batch 3950 training_loss 0.6931471805599453
iteration 9 batch 3960 training_loss 0.6931471805599453
iteration 9 batch 3970 training_loss 0.6931471805599453
iteration 9 batch 3980 training_loss 0.6931471805599453
iteration 9 batch 3990 training_loss 0.6931471805599453
iteration 9 batch 4000 training_loss 0.6931471805599453
iteration 9 batch 4010 training_loss 0.6931471805599453
iteration 9 batch 4020 training_loss 0.6931471805599453
iteration 9 batch 4030 training_loss 0.6931471805599453
iteration 9 batch 4040 training_loss 0.6931471805599453
iteration 9 batch 4050 training_loss 0.6931471805599453
iteration 9 batch 4060 training_loss 0.6931471805599453
iteration 9 batch 4070 training_loss 0.6931471805599453
iteration 9 batch 4080 training_loss 0.6931471805599453
iteration 9 batch 4090 training_loss 0.6931471805599453
iteration 9 batch 4100 training_loss 0.6931471805599453
iteration 9 batch 4110 training_loss 0.6931471805599453
iteration 9 batch 4120 training_loss 0.6931471805599453
iteration 9 batch 4130 training_loss 0.6931471805599453
iteration 9 batch 4140 training_loss 0.6931471805599453
iteration 9 batch 4150 training_loss 0.6931471805599453
iteration 9 batch 4160 training_loss 0.6931471805599453
iteration 9 batch 4170 training_loss 0.6931471805599453
iteration 9 batch 4180 training_loss 0.6931471805599453
iteration 9 batch 4190 training_loss 0.6931471805599453
iteration 9 batch 4200 training_loss 0.6931471805599453
iteration 9 batch 4210 training_loss 0.6931471805599453
iteration 9 batch 4220 training_loss 0.6931471805599453
iteration 9 batch 4230 training_loss 0.6931471805599453
iteration 9 batch 4240 training_loss 0.6931471805599453
iteration 9 batch 4250 training_loss 0.6931471805599453
iteration 9 batch 4260 training_loss 0.6931471805599453
iteration 9 batch 4270 training_loss 0.6931471805599453
iteration 9 batch 4280 training_loss 0.6931471805599453
iteration 9 batch 4290 training_loss 0.6931471805599453
iteration 9 batch 4300 training_loss 0.6931471805599453
iteration 9 batch 4310 training_loss 0.6931471805599453
iteration 9 batch 4320 training_loss 0.6931471805599453
iteration 9 batch 4330 training_loss 0.6931471805599453
iteration 9 batch 4340 training_loss 0.6931471805599453
iteration 9 batch 4350 training_loss 0.6931471805599453
iteration 9 batch 4360 training_loss 0.6916632528527511
iteration 9 batch 4370 training_loss 0.6931471805599453
iteration 9 batch 4380 training_loss 0.6931471805599453
iteration 9 batch 4390 training_loss 0.6931471805599453
iteration 9 batch 4400 training_loss 0.6931471805599453
iteration 9 batch 4410 training_loss 0.6931471805599453
iteration 9 batch 4420 training_loss 0.6931471805599453
iteration 9 batch 4430 training_loss 0.6931471805599453
iteration 9 batch 4440 training_loss 0.6931471805599453
iteration 9 batch 4450 training_loss 0.6931471805599453
iteration 9 batch 4460 training_loss 0.6916632528527511
iteration 9 batch 4470 training_loss 0.6931471805599453
iteration 9 batch 4480 training_loss 0.6931471805599453
iteration 9 batch 4490 training_loss 0.6931471805599453
iteration 9 batch 4500 training_loss 0.6931471805599453
iteration 9 batch 4510 training_loss 0.6931471805599453
iteration 9 batch 4520 training_loss 0.6931471805599453
iteration 9 batch 4530 training_loss 0.6931471805599453
iteration 9 batch 4540 training_loss 0.6931471805599453
iteration 9 batch 4550 training_loss 0.6916632528527511
iteration 9 batch 4560 training_loss 0.6931471805599453
iteration 9 batch 4570 training_loss 0.6931471805599453
iteration 9 batch 4580 training_loss 0.6931471805599453
iteration 9 batch 4590 training_loss 0.6931471805599453
iteration 9 batch 4600 training_loss 0.6931471805599453
iteration 9 batch 4610 training_loss 0.6931471805599453
iteration 9 batch 4620 training_loss 0.6931471805599453
iteration 9 batch 4630 training_loss 0.6931471805599453
iteration 9 batch 4640 training_loss 0.6931471805599453
iteration 9 batch 4650 training_loss 0.6916632528527511
iteration 9 batch 4660 training_loss 0.6931471805599453
iteration 9 batch 4670 training_loss 0.6931471805599453
iteration 9 batch 4680 training_loss 0.6931471805599453
iteration 9 batch 4690 training_loss 0.6931471805599453
iteration 9 batch 4700 training_loss 0.6931471805599453
iteration 9 batch 4710 training_loss 0.6931471805599453
iteration 9 batch 4720 training_loss 0.6931471805599453
iteration 9 batch 4730 training_loss 0.6931471805599453
iteration 9 batch 4740 training_loss 0.6931471805599453
iteration 9 batch 4750 training_loss 0.6931471805599453
iteration 9 batch 4760 training_loss 0.6931471805599453
iteration 9 batch 4770 training_loss 0.6931471805599453
iteration 9 batch 4780 training_loss 0.6931471805599453
iteration 9 batch 4790 training_loss 0.6931471805599453
iteration 9 batch 4800 training_loss 0.6931471805599453
iteration 9 batch 4810 training_loss 0.6931471805599453
iteration 9 batch 4820 training_loss 0.6931471805599453
iteration 9 batch 4830 training_loss 0.6931471805599453
iteration 9 batch 4840 training_loss 0.6931471805599453
iteration 9 batch 4850 training_loss 0.6931471805599453
iteration 9 batch 4860 training_loss 0.6931471805599453
iteration 9 batch 4870 training_loss 0.6931471805599453
iteration 9 batch 4880 training_loss 0.6931471805599453
iteration 9 batch 4890 training_loss 0.6931471805599453
iteration 9 batch 4900 training_loss 0.6931471805599453
iteration 9 batch 4910 training_loss 0.6931471805599453
iteration 9 batch 4920 training_loss 0.6931471805599453
iteration 9 batch 4930 training_loss 0.6931471805599453
iteration 9 batch 4940 training_loss 0.6931471805599453
iteration 9 batch 4950 training_loss 0.6931471805599453
iteration 9 batch 4960 training_loss 0.6931471805599453
iteration 9 batch 4970 training_loss 0.6931471805599453
iteration 9 batch 4980 training_loss 0.6931471805599453
iteration 9 batch 4990 training_loss 0.6931471805599453
iteration 9 batch 5000 training_loss 0.6931471805599453
iteration 9 batch 5010 training_loss 0.6931471805599453
iteration 9 batch 5020 training_loss 0.6931471805599453
iteration 9 batch 5030 training_loss 0.6931471805599453
iteration 9 batch 5040 training_loss 0.6931471805599453
iteration 9 batch 5050 training_loss 0.6931471805599453
iteration 9 batch 5060 training_loss 0.6931471805599453
iteration 9 batch 5070 training_loss 0.6931471805599453
iteration 9 batch 5080 training_loss 0.6931471805599453
iteration 9 batch 5090 training_loss 0.6931471805599453
iteration 9 batch 5100 training_loss 0.6931471805599453
iteration 9 batch 5110 training_loss 0.6931471805599453
iteration 9 batch 5120 training_loss 0.6931471805599453
iteration 9 batch 5130 training_loss 0.6931471805599453
iteration 9 batch 5140 training_loss 0.6931471805599453
iteration 9 batch 5150 training_loss 0.6931471805599453
iteration 9 batch 5160 training_loss 0.6931471805599453
iteration 9 batch 5170 training_loss 0.6916632528527511
iteration 9 batch 5180 training_loss 0.6931471805599453
iteration 9 batch 5190 training_loss 0.6931471805599453
iteration 9 batch 5200 training_loss 0.6931471805599453
iteration 9 batch 5210 training_loss 0.6931471805599453
iteration 9 batch 5220 training_loss 0.6931471805599453
iteration 9 batch 5230 training_loss 0.6931471805599453
iteration 9 batch 5240 training_loss 0.6931471805599453
iteration 9 batch 5250 training_loss 0.6931471805599453
iteration 9 batch 5260 training_loss 0.6931471805599453
iteration 9 batch 5270 training_loss 0.6931471805599453
iteration 9 batch 5280 training_loss 0.6931471805599453
iteration 9 batch 5290 training_loss 0.6931471805599453
iteration 9 batch 5300 training_loss 0.6931471805599453
iteration 9 batch 5310 training_loss 0.6931471805599453
iteration 9 batch 5320 training_loss 0.6931471805599453
iteration 9 batch 5330 training_loss 0.6931471805599453
iteration 9 batch 5340 training_loss 0.6931471805599453
iteration 9 batch 5350 training_loss 0.6931471805599453
iteration 9 batch 5360 training_loss 0.6931471805599453
iteration 9 batch 5370 training_loss 0.6931471805599453
iteration 9 batch 5380 training_loss 0.6916632528527511
iteration 9 batch 5390 training_loss 0.6931471805599453
iteration 9 batch 5400 training_loss 0.6931471805599453
iteration 9 batch 5410 training_loss 0.6931471805599453
iteration 9 batch 5420 training_loss 0.6931471805599453
iteration 9 batch 5430 training_loss 0.6931471805599453
iteration 9 batch 5440 training_loss 0.6931471805599453
iteration 9 batch 5450 training_loss 0.6931471805599453
iteration 9 batch 5460 training_loss 0.6931471805599453
iteration 9 batch 5470 training_loss 0.6931471805599453
iteration 9 batch 5480 training_loss 0.6931471805599453
iteration 9 batch 5490 training_loss 0.6931471805599453
iteration 9 batch 5500 training_loss 0.6931471805599453
iteration 9 batch 5510 training_loss 0.6931471805599453
iteration 9 batch 5520 training_loss 0.6931471805599453
iteration 9 batch 5530 training_loss 0.6931471805599453
iteration 9 batch 5540 training_loss 0.6931471805599453
iteration 9 batch 5550 training_loss 0.6931471805599453
iteration 9 batch 5560 training_loss 0.6931471805599453
iteration 9 batch 5570 training_loss 0.6931471805599453
iteration 9 batch 5580 training_loss 0.6931471805599453
iteration 9 batch 5590 training_loss 0.6931471805599453
iteration 9 batch 5600 training_loss 0.6931471805599453
iteration 9 batch 5610 training_loss 0.6931471805599453
iteration 9 batch 5620 training_loss 0.6931471805599453
iteration 9 batch 5630 training_loss 0.6931471805599453
iteration 9 batch 5640 training_loss 0.6931471805599453
iteration 9 batch 5650 training_loss 0.6931471805599453
iteration 9 batch 5660 training_loss 0.6931471805599453
iteration 9 batch 5670 training_loss 0.6931471805599453
iteration 9 batch 5680 training_loss 0.6931471805599453
iteration 9 batch 5690 training_loss 0.6931471805599453
iteration 9 batch 5700 training_loss 0.6931471805599453
iteration 9 batch 5710 training_loss 0.6931471805599453
iteration 9 batch 5720 training_loss 0.6931471805599453
iteration 9 batch 5730 training_loss 0.6931471805599453
iteration 9 batch 5740 training_loss 0.6931471805599453
iteration 9 batch 5750 training_loss 0.6931471805599453
iteration 9 batch 5760 training_loss 0.6931471805599453
iteration 9 batch 5770 training_loss 0.6931471805599453
iteration 9 batch 5780 training_loss 0.6916632528527511
iteration 9 batch 5790 training_loss 0.6916632528527511
iteration 9 batch 5800 training_loss 0.6931471805599453
iteration 9 batch 5810 training_loss 0.6931471805599453
iteration 9 batch 5820 training_loss 0.6931471805599453
iteration 9 batch 5830 training_loss 0.6931471805599453
iteration 9 batch 5840 training_loss 0.6916632528527511
iteration 9 batch 5850 training_loss 0.6931471805599453
iteration 9 batch 5860 training_loss 0.6931471805599453
iteration 9 batch 5870 training_loss 0.6931471805599453
iteration 9 batch 5880 training_loss 0.6931471805599453
iteration 9 batch 5890 training_loss 0.6931471805599453
iteration 9 batch 5900 training_loss 0.6931471805599453
iteration 9 batch 5910 training_loss 0.6931471805599453
iteration 9 batch 5920 training_loss 0.6931471805599453
iteration 9 batch 5930 training_loss 0.6931471805599453
iteration 9 batch 5940 training_loss 0.6931471805599453
iteration 9 batch 5950 training_loss 0.6931471805599453
iteration 9 batch 5960 training_loss 0.6931471805599453
iteration 9 batch 5970 training_loss 0.6931471805599453
iteration 9 batch 5980 training_loss 0.6931471805599453
iteration 9 batch 5990 training_loss 0.6931471805599453
iteration 9 batch 6000 training_loss 0.6931471805599453
iteration 9 batch 6010 training_loss 0.6931471805599453
iteration 9 batch 6020 training_loss 0.6931471805599453
iteration 9 batch 6030 training_loss 0.6931471805599453
iteration 9 batch 6040 training_loss 0.6931471805599453
iteration 9 batch 6050 training_loss 0.6931471805599453
iteration 9 batch 6060 training_loss 0.6931471805599453
iteration 9 batch 6070 training_loss 0.6931471805599453
iteration 9 batch 6080 training_loss 0.6931471805599453
iteration 9 batch 6090 training_loss 0.6931471805599453
iteration 9 batch 6100 training_loss 0.6931471805599453
iteration 9 batch 6110 training_loss 0.6931471805599453
iteration 9 batch 6120 training_loss 0.6931471805599453
iteration 9 batch 6130 training_loss 0.6931471805599453
iteration 9 batch 6140 training_loss 0.6931471805599453
iteration 9 batch 6150 training_loss 0.6931471805599453
iteration 9 batch 6160 training_loss 0.6931471805599453
iteration 9 batch 6170 training_loss 0.6931471805599453
iteration 9 batch 6180 training_loss 0.6916632528527511
iteration 9 batch 6190 training_loss 0.6931471805599453
iteration 9 batch 6200 training_loss 0.6931471805599453
iteration 9 batch 6210 training_loss 0.6931471805599453
iteration 9 batch 6220 training_loss 0.6931471805599453
iteration 9 batch 6230 training_loss 0.6931471805599453
iteration 9 batch 6240 training_loss 0.6931471805599453
iteration 9 batch 6250 training_loss 0.6931471805599453
iteration 9 batch 6260 training_loss 0.6931471805599453
iteration 9 batch 6270 training_loss 0.6931471805599453
iteration 9 batch 6280 training_loss 0.6916632528527511
iteration 9 batch 6290 training_loss 0.6931471805599453
iteration 9 batch 6300 training_loss 0.6931471805599453
iteration 9 batch 6310 training_loss 0.6931471805599453
iteration 9 batch 6320 training_loss 0.6931471805599453
iteration 9 batch 6330 training_loss 0.6931471805599453
iteration 9 batch 6340 training_loss 0.6931471805599453
iteration 9 batch 6350 training_loss 0.6931471805599453
iteration 9 batch 6360 training_loss 0.6931471805599453
iteration 9 batch 6370 training_loss 0.6931471805599453
iteration 9 batch 6380 training_loss 0.6931471805599453
iteration 9 batch 6390 training_loss 0.6931471805599453
iteration 9 batch 6400 training_loss 0.6931471805599453
iteration 9 batch 6410 training_loss 0.6931471805599453
iteration 9 batch 6420 training_loss 0.6931471805599453
iteration 9 batch 6430 training_loss 0.6931471805599453
iteration 9 batch 6440 training_loss 0.6931471805599453
iteration 9 batch 6450 training_loss 0.6931471805599453
iteration 9 batch 6460 training_loss 0.6931471805599453
iteration 9 batch 6470 training_loss 0.6931471805599453
iteration 9 batch 6480 training_loss 0.6931471805599453
iteration 9 batch 6490 training_loss 0.6931471805599453
iteration 9 batch 6500 training_loss 0.6931471805599453
iteration 9 batch 6510 training_loss 0.6916632528527511
iteration 9 batch 6520 training_loss 0.6931471805599453
iteration 9 batch 6530 training_loss 0.6931471805599453
iteration 9 batch 6540 training_loss 0.6931471805599453
iteration 9 batch 6550 training_loss 0.6931471805599453
iteration 9 batch 6560 training_loss 0.6931471805599453
iteration 9 batch 6570 training_loss 0.6931471805599453
iteration 9 batch 6580 training_loss 0.6931471805599453
iteration 9 batch 6590 training_loss 0.6931471805599453
iteration 9 batch 6600 training_loss 0.6931471805599453
iteration 9 batch 6610 training_loss 0.6931471805599453
iteration 9 batch 6620 training_loss 0.6931471805599453
iteration 9 batch 6630 training_loss 0.6931471805599453
iteration 9 batch 6640 training_loss 0.6931471805599453
iteration 9 batch 6650 training_loss 0.6931471805599453
iteration 9 batch 6660 training_loss 0.6931471805599453
iteration 9 batch 6670 training_loss 0.6931471805599453
iteration 9 batch 6680 training_loss 0.6931471805599453
iteration 9 batch 6690 training_loss 0.6931471805599453
iteration 9 batch 6700 training_loss 0.6931471805599453
iteration 9 batch 6710 training_loss 0.6931471805599453
iteration 9 batch 6720 training_loss 0.6931471805599453
iteration 9 batch 6730 training_loss 0.6916632528527511
iteration 9 batch 6740 training_loss 0.6931471805599453
iteration 9 batch 6750 training_loss 0.6931471805599453
iteration 9 batch 6760 training_loss 0.6931471805599453
iteration 9 batch 6770 training_loss 0.6931471805599453
iteration 9 batch 6780 training_loss 0.6916632528527511
iteration 9 batch 6790 training_loss 0.6931471805599453
iteration 9 batch 6800 training_loss 0.6931471805599453
iteration 9 batch 6810 training_loss 0.6931471805599453
iteration 9 batch 6820 training_loss 0.6931471805599453
iteration 9 batch 6830 training_loss 0.6931471805599453
iteration 9 batch 6840 training_loss 0.6931471805599453
iteration 9 batch 6850 training_loss 0.6931471805599453
iteration 9 batch 6860 training_loss 0.6931471805599453
iteration 9 batch 6870 training_loss 0.6931471805599453
iteration 9 batch 6880 training_loss 0.6931471805599453
iteration 9 batch 6890 training_loss 0.6931471805599453
iteration 9 batch 6900 training_loss 0.6931471805599453
iteration 9 batch 6910 training_loss 0.6931471805599453
iteration 9 batch 6920 training_loss 0.6916632528527511
iteration 9 batch 6930 training_loss 0.6931471805599453
iteration 9 batch 6940 training_loss 0.6931471805599453
iteration 9 batch 6950 training_loss 0.6931471805599453
iteration 9 batch 6960 training_loss 0.6931471805599453
iteration 9 batch 6970 training_loss 0.6931471805599453
iteration 9 batch 6980 training_loss 0.6931471805599453
iteration 9 batch 6990 training_loss 0.6931471805599453
iteration 9 batch 7000 training_loss 0.6931471805599453
iteration 9 batch 7010 training_loss 0.6931471805599453
iteration 9 batch 7020 training_loss 0.6931471805599453
iteration 9 batch 7030 training_loss 0.6931471805599453
iteration 9 batch 7040 training_loss 0.6931471805599453
iteration 9 batch 7050 training_loss 0.6931471805599453
iteration 9 batch 7060 training_loss 0.6916632528527511
iteration 9 batch 7070 training_loss 0.6931471805599453
iteration 9 batch 7080 training_loss 0.6931471805599453
iteration 9 batch 7090 training_loss 0.6916632528527511
iteration 9 batch 7100 training_loss 0.6931471805599453
iteration 9 batch 7110 training_loss 0.6931471805599453
iteration 9 batch 7120 training_loss 0.6931471805599453
iteration 9 batch 7130 training_loss 0.6931471805599453
iteration 9 batch 7140 training_loss 0.6931471805599453
iteration 9 batch 7150 training_loss 0.6931471805599453
iteration 9 batch 7160 training_loss 0.6931471805599453
iteration 9 batch 7170 training_loss 0.6931471805599453
iteration 9 batch 7180 training_loss 0.6931471805599453
iteration 9 batch 7190 training_loss 0.6931471805599453
iteration 9 batch 7200 training_loss 0.6931471805599453
iteration 9 batch 7210 training_loss 0.6931471805599453
iteration 9 batch 7220 training_loss 0.6931471805599453
iteration 9 batch 7230 training_loss 0.6931471805599453
iteration 9 batch 7240 training_loss 0.6931471805599453
iteration 9 batch 7250 training_loss 0.6931471805599453
iteration 9 batch 7260 training_loss 0.6931471805599453
iteration 9 batch 7270 training_loss 0.6931471805599453
iteration 9 batch 7280 training_loss 0.6931471805599453
iteration 9 batch 7290 training_loss 0.6931471805599453
iteration 9 batch 7300 training_loss 0.6916632528527511
iteration 9 batch 7310 training_loss 0.6931471805599453
iteration 9 batch 7320 training_loss 0.6931471805599453
iteration 9 batch 7330 training_loss 0.6931471805599453
iteration 9 batch 7340 training_loss 0.6931471805599453
iteration 9 batch 7350 training_loss 0.6931471805599453
iteration 9 batch 7360 training_loss 0.6931471805599453
iteration 9 batch 7370 training_loss 0.6931471805599453
iteration 9 batch 7380 training_loss 0.6931471805599453
iteration 9 batch 7390 training_loss 0.6931471805599453
iteration 9 batch 7400 training_loss 0.6931471805599453
iteration 9 batch 7410 training_loss 0.6931471805599453
iteration 9 batch 7420 training_loss 0.6931471805599453
iteration 9 batch 7430 training_loss 0.6931471805599453
iteration 9 batch 7440 training_loss 0.6931471805599453
iteration 9 batch 7450 training_loss 0.6931471805599453
iteration 9 batch 7460 training_loss 0.6931471805599453
iteration 9 batch 7470 training_loss 0.6931471805599453
iteration 9 batch 7480 training_loss 0.6931471805599453
iteration 9 batch 7490 training_loss 0.6916632528527511
iteration 9 batch 7500 training_loss 0.6931471805599453
iteration 9 batch 7510 training_loss 0.6916632528527511
iteration 9 batch 7520 training_loss 0.6931471805599453
iteration 9 batch 7530 training_loss 0.6931471805599453
iteration 9 batch 7540 training_loss 0.6931471805599453
iteration 9 batch 7550 training_loss 0.6916632528527511
iteration 9 batch 7560 training_loss 0.6931471805599453
iteration 9 batch 7570 training_loss 0.6931471805599453
iteration 9 batch 7580 training_loss 0.6931471805599453
iteration 9 batch 7590 training_loss 0.6931471805599453
iteration 9 batch 7600 training_loss 0.6931471805599453
iteration 9 batch 7610 training_loss 0.6931471805599453
iteration 9 batch 7620 training_loss 0.6931471805599453
iteration 9 batch 7630 training_loss 0.6931471805599453
iteration 9 batch 7640 training_loss 0.6931471805599453
iteration 9 batch 7650 training_loss 0.6931471805599453
iteration 9 batch 7660 training_loss 0.6931471805599453
iteration 9 batch 7670 training_loss 0.6931471805599453
iteration 9 batch 7680 training_loss 0.6931471805599453
iteration 9 batch 7690 training_loss 0.6931471805599453
iteration 9 batch 7700 training_loss 0.6916632528527511
iteration 9 batch 7710 training_loss 0.6931471805599453
iteration 9 batch 7720 training_loss 0.6931471805599453
iteration 9 batch 7730 training_loss 0.6931471805599453
iteration 9 batch 7740 training_loss 0.6931471805599453
iteration 9 batch 7750 training_loss 0.6931471805599453
iteration 9 batch 7760 training_loss 0.6931471805599453
iteration 9 batch 7770 training_loss 0.6931471805599453
iteration 9 batch 7780 training_loss 0.6931471805599453
iteration 9 batch 7790 training_loss 0.6931471805599453
iteration 9 batch 7800 training_loss 0.6931471805599453
iteration 9 batch 7810 training_loss 0.6931471805599453
iteration 9 batch 7820 training_loss 0.6931471805599453
iteration 9 batch 7830 training_loss 0.6931471805599453
iteration 9 batch 7840 training_loss 0.6931471805599453
iteration 9 batch 7850 training_loss 0.6931471805599453
iteration 9 batch 7860 training_loss 0.6931471805599453
iteration 9 batch 7870 training_loss 0.6931471805599453
iteration 9 batch 7880 training_loss 0.6931471805599453
iteration 9 batch 7890 training_loss 0.6931471805599453
iteration 9 batch 7900 training_loss 0.6931471805599453
iteration 9 batch 7910 training_loss 0.6931471805599453
iteration 9 batch 7920 training_loss 0.6931471805599453
iteration 9 batch 7930 training_loss 0.6931471805599453
iteration 9 batch 7940 training_loss 0.6931471805599453
iteration 9 batch 7950 training_loss 0.6931471805599453
iteration 9 batch 7960 training_loss 0.6931471805599453
iteration 9 batch 7970 training_loss 0.6916632528527511
iteration 9 batch 7980 training_loss 0.6931471805599453
iteration 9 batch 7990 training_loss 0.6931471805599453
iteration 9 batch 8000 training_loss 0.6931471805599453
iteration 9 batch 8010 training_loss 0.6931471805599453
iteration 9 batch 8020 training_loss 0.6931471805599453
iteration 9 batch 8030 training_loss 0.6931471805599453
iteration 9 batch 8040 training_loss 0.6931471805599453
iteration 9 batch 8050 training_loss 0.6931471805599453
iteration 9 batch 8060 training_loss 0.6931471805599453
iteration 9 batch 8070 training_loss 0.6931471805599453
iteration 9 batch 8080 training_loss 0.6931471805599453
iteration 9 batch 8090 training_loss 0.6931471805599453
iteration 9 batch 8100 training_loss 0.6916632528527511
iteration 9 batch 8110 training_loss 0.6931471805599453
iteration 9 batch 8120 training_loss 0.6931471805599453
iteration 9 batch 8130 training_loss 0.6931471805599453
iteration 9 batch 8140 training_loss 0.6931471805599453
iteration 9 batch 8150 training_loss 0.6931471805599453
iteration 9 batch 8160 training_loss 0.6931471805599453
iteration 9 batch 8170 training_loss 0.6931471805599453
iteration 9 batch 8180 training_loss 0.6931471805599453
iteration 9 batch 8190 training_loss 0.6931471805599453
iteration 9 batch 8200 training_loss 0.6931471805599453
iteration 9 batch 8210 training_loss 0.6931471805599453
iteration 9 batch 8220 training_loss 0.6931471805599453
iteration 9 batch 8230 training_loss 0.6931471805599453
iteration 9 batch 8240 training_loss 0.6931471805599453
iteration 9 batch 8250 training_loss 0.6931471805599453
iteration 9 batch 8260 training_loss 0.6901793251455568
iteration 9 batch 8270 training_loss 0.6931471805599453
iteration 9 batch 8280 training_loss 0.6931471805599453
iteration 9 batch 8290 training_loss 0.6931471805599453
iteration 9 batch 8300 training_loss 0.6931471805599453
iteration 9 batch 8310 training_loss 0.6931471805599453
iteration 9 batch 8320 training_loss 0.6931471805599453
iteration 9 batch 8330 training_loss 0.6931471805599453
iteration 9 batch 8340 training_loss 0.6931471805599453
iteration 9 batch 8350 training_loss 0.6931471805599453
iteration 9 batch 8360 training_loss 0.6931471805599453
iteration 9 batch 8370 training_loss 0.6931471805599453
iteration 9 batch 8380 training_loss 0.6931471805599453
iteration 9 batch 8390 training_loss 0.6931471805599453
iteration 9 batch 8400 training_loss 0.6931471805599453
iteration 9 batch 8410 training_loss 0.6931471805599453
iteration 9 batch 8420 training_loss 0.6931471805599453
iteration 9 batch 8430 training_loss 0.6931471805599453
iteration 9 batch 8440 training_loss 0.6931471805599453
iteration 9 batch 8450 training_loss 0.6931471805599453
iteration 9 batch 8460 training_loss 0.6931471805599453
iteration 9 batch 8470 training_loss 0.6931471805599453
iteration 9 batch 8480 training_loss 0.6931471805599453
iteration 9 batch 8490 training_loss 0.6931471805599453
iteration 9 batch 8500 training_loss 0.6931471805599453
iteration 9 batch 8510 training_loss 0.6931471805599453
iteration 9 batch 8520 training_loss 0.6931471805599453
iteration 9 batch 8530 training_loss 0.6931471805599453
iteration 9 batch 8540 training_loss 0.6931471805599453
iteration 9 batch 8550 training_loss 0.6931471805599453
iteration 9 batch 8560 training_loss 0.6916632528527511
iteration 9 batch 8570 training_loss 0.6931471805599453
iteration 9 batch 8580 training_loss 0.6931471805599453
iteration 9 batch 8590 training_loss 0.6931471805599453
iteration 9 batch 8600 training_loss 0.6931471805599453
iteration 9 batch 8610 training_loss 0.6931471805599453
iteration 9 batch 8620 training_loss 0.6931471805599453
iteration 9 batch 8630 training_loss 0.6931471805599453
iteration 9 batch 8640 training_loss 0.6931471805599453
iteration 9 batch 8650 training_loss 0.6931471805599453
iteration 9 batch 8660 training_loss 0.6931471805599453
iteration 9 batch 8670 training_loss 0.6931471805599453
iteration 9 batch 8680 training_loss 0.6931471805599453
iteration 9 batch 8690 training_loss 0.6916632528527511
iteration 9 batch 8700 training_loss 0.6916632528527511
iteration 9 batch 8710 training_loss 0.6931471805599453
iteration 9 batch 8720 training_loss 0.6931471805599453
iteration 9 batch 8730 training_loss 0.6931471805599453
iteration 9 batch 8740 training_loss 0.6931471805599453
iteration 9 batch 8750 training_loss 0.6916632528527511
iteration 9 batch 8760 training_loss 0.6931471805599453
iteration 9 batch 8770 training_loss 0.6931471805599453
iteration 9 batch 8780 training_loss 0.6931471805599453
iteration 9 batch 8790 training_loss 0.6931471805599453
iteration 9 batch 8800 training_loss 0.6931471805599453
iteration 9 batch 8810 training_loss 0.6931471805599453
iteration 9 batch 8820 training_loss 0.6931471805599453
iteration 9 batch 8830 training_loss 0.6931471805599453
iteration 9 batch 8840 training_loss 0.6931471805599453
iteration 9 batch 8850 training_loss 0.6931471805599453
iteration 9 batch 8860 training_loss 0.6931471805599453
iteration 9 batch 8870 training_loss 0.6931471805599453
iteration 9 batch 8880 training_loss 0.6931471805599453
iteration 9 batch 8890 training_loss 0.6931471805599453
iteration 9 batch 8900 training_loss 0.6931471805599453
iteration 9 batch 8910 training_loss 0.6931471805599453
iteration 9 batch 8920 training_loss 0.6931471805599453
iteration 9 batch 8930 training_loss 0.6931471805599453
iteration 9 batch 8940 training_loss 0.6931471805599453
iteration 9 batch 8950 training_loss 0.6931471805599453
iteration 9 batch 8960 training_loss 0.6931471805599453
iteration 9 batch 8970 training_loss 0.6931471805599453
iteration 9 batch 8980 training_loss 0.6916632528527511
iteration 9 batch 8990 training_loss 0.6931471805599453
iteration 9 batch 9000 training_loss 0.6931471805599453
iteration 9 batch 9010 training_loss 0.6931471805599453
iteration 9 batch 9020 training_loss 0.6931471805599453
iteration 9 batch 9030 training_loss 0.6931471805599453
iteration 9 batch 9040 training_loss 0.6931471805599453
iteration 9 batch 9050 training_loss 0.6931471805599453
iteration 9 batch 9060 training_loss 0.6931471805599453
iteration 9 batch 9070 training_loss 0.6931471805599453
iteration 9 batch 9080 training_loss 0.6931471805599453
iteration 9 batch 9090 training_loss 0.6931471805599453
iteration 9 batch 9100 training_loss 0.6931471805599453
iteration 9 batch 9110 training_loss 0.6931471805599453
iteration 9 batch 9120 training_loss 0.6931471805599453
iteration 9 batch 9130 training_loss 0.6931471805599453
iteration 9 batch 9140 training_loss 0.6931471805599453
iteration 9 batch 9150 training_loss 0.6931471805599453
iteration 9 batch 9160 training_loss 0.6931471805599453
iteration 9 batch 9170 training_loss 0.6931471805599453
iteration 9 batch 9180 training_loss 0.6931471805599453
iteration 9 batch 9190 training_loss 0.6931471805599453
iteration 9 batch 9200 training_loss 0.6931471805599453
iteration 9 batch 9210 training_loss 0.6931471805599453
iteration 9 batch 9220 training_loss 0.6931471805599453
iteration 9 batch 9230 training_loss 0.6916632528527511
iteration 9 batch 9240 training_loss 0.6931471805599453
iteration 9 batch 9250 training_loss 0.6931471805599453
iteration 9 batch 9260 training_loss 0.6931471805599453
iteration 9 batch 9270 training_loss 0.6931471805599453
iteration 9 batch 9280 training_loss 0.6931471805599453
iteration 9 batch 9290 training_loss 0.6931471805599453
iteration 9 batch 9300 training_loss 0.6931471805599453
iteration 9 batch 9310 training_loss 0.6931471805599453
iteration 9 batch 9320 training_loss 0.6931471805599453
iteration 9 batch 9330 training_loss 0.6931471805599453
iteration 9 batch 9340 training_loss 0.6931471805599453
iteration 9 batch 9350 training_loss 0.6931471805599453
iteration 9 batch 9360 training_loss 0.6931471805599453
iteration 9 batch 9370 training_loss 0.6931471805599453
iteration 9 batch 9380 training_loss 0.6931471805599453
iteration 9 batch 9390 training_loss 0.6931471805599453
iteration 9 batch 9400 training_loss 0.6931471805599453
iteration 9 batch 9410 training_loss 0.6931471805599453
iteration 9 batch 9420 training_loss 0.6916632528527511
iteration 9 batch 9430 training_loss 0.6916632528527511
iteration 9 batch 9440 training_loss 0.6931471805599453
iteration 9 batch 9450 training_loss 0.6931471805599453
iteration 9 batch 9460 training_loss 0.6931471805599453
iteration 9 batch 9470 training_loss 0.6931471805599453
iteration 9 batch 9480 training_loss 0.6931471805599453
iteration 9 batch 9490 training_loss 0.6931471805599453
iteration 9 batch 9500 training_loss 0.6916632528527511
iteration 9 batch 9510 training_loss 0.6931471805599453
iteration 9 batch 9520 training_loss 0.6931471805599453
iteration 9 batch 9530 training_loss 0.6931471805599453
iteration 9 batch 9540 training_loss 0.6931471805599453
iteration 9 batch 9550 training_loss 0.6931471805599453
iteration 9 batch 9560 training_loss 0.6931471805599453
iteration 9 batch 9570 training_loss 0.6931471805599453
iteration 9 batch 9580 training_loss 0.6931471805599453
iteration 9 batch 9590 training_loss 0.6931471805599453
iteration 9 batch 9600 training_loss 0.6931471805599453
iteration 9 batch 9610 training_loss 0.6931471805599453
iteration 9 batch 9620 training_loss 0.6931471805599453
iteration 9 batch 9630 training_loss 0.6931471805599453
iteration 9 batch 9640 training_loss 0.6931471805599453
iteration 9 batch 9650 training_loss 0.6931471805599453
iteration 9 batch 9660 training_loss 0.6931471805599453
iteration 9 batch 9670 training_loss 0.6931471805599453
iteration 9 batch 9680 training_loss 0.6931471805599453
iteration 9 batch 9690 training_loss 0.6931471805599453
iteration 9 batch 9700 training_loss 0.6931471805599453
iteration 9 batch 9710 training_loss 0.6931471805599453
iteration 9 batch 9720 training_loss 0.6931471805599453
iteration 9 batch 9730 training_loss 0.6931471805599453
iteration 9 batch 9740 training_loss 0.6931471805599453
iteration 9 batch 9750 training_loss 0.6931471805599453
iteration 9 batch 9760 training_loss 0.6931471805599453
iteration 9 batch 9770 training_loss 0.6931471805599453
iteration 9 batch 9780 training_loss 0.6931471805599453
iteration 9 batch 9790 training_loss 0.6931471805599453
iteration 9 batch 9800 training_loss 0.6931471805599453
iteration 9 batch 9810 training_loss 0.6931471805599453
iteration 9 batch 9820 training_loss 0.6931471805599453
iteration 9 batch 9830 training_loss 0.6931471805599453
iteration 9 batch 9840 training_loss 0.6931471805599453
iteration 9 batch 9850 training_loss 0.6931471805599453
iteration 9 batch 9860 training_loss 0.6931471805599453
iteration 9 batch 9870 training_loss 0.6931471805599453
iteration 9 batch 9880 training_loss 0.6931471805599453
iteration 9 batch 9890 training_loss 0.6931471805599453
iteration 9 batch 9900 training_loss 0.6931471805599453
iteration 9 batch 9910 training_loss 0.6931471805599453
iteration 9 batch 9920 training_loss 0.6931471805599453
iteration 9 batch 9930 training_loss 0.6931471805599453
iteration 9 batch 9940 training_loss 0.6931471805599453
iteration 9 batch 9950 training_loss 0.6931471805599453
iteration 9 batch 9960 training_loss 0.6931471805599453
iteration 9 batch 9970 training_loss 0.6931471805599453
iteration 9 batch 9980 training_loss 0.6931471805599453
iteration 9 batch 9990 training_loss 0.6931471805599453
iteration 9 batch 10000 training_loss 0.6931471805599453
iteration 9 batch 10010 training_loss 0.6931471805599453
iteration 9 batch 10020 training_loss 0.6931471805599453
iteration 9 batch 10030 training_loss 0.6931471805599453
iteration 9 batch 10040 training_loss 0.6931471805599453
iteration 9 batch 10050 training_loss 0.6931471805599453
iteration 9 batch 10060 training_loss 0.6931471805599453
iteration 9 batch 10070 training_loss 0.6931471805599453
iteration 9 batch 10080 training_loss 0.6931471805599453
iteration 9 batch 10090 training_loss 0.6931471805599453
iteration 9 batch 10100 training_loss 0.6931471805599453
iteration 9 batch 10110 training_loss 0.6931471805599453
iteration 9 batch 10120 training_loss 0.6931471805599453
iteration 9 batch 10130 training_loss 0.6931471805599453
iteration 9 batch 10140 training_loss 0.6931471805599453
iteration 9 batch 10150 training_loss 0.6931471805599453
iteration 9 batch 10160 training_loss 0.6931471805599453
iteration 9 batch 10170 training_loss 0.6931471805599453
iteration 9 batch 10180 training_loss 0.6931471805599453
iteration 9 batch 10190 training_loss 0.6931471805599453
iteration 9 batch 10200 training_loss 0.6931471805599453
iteration 9 batch 10210 training_loss 0.6931471805599453
iteration 9 batch 10220 training_loss 0.6931471805599453
iteration 9 batch 10230 training_loss 0.6931471805599453
iteration 9 batch 10240 training_loss 0.6931471805599453
iteration 9 batch 10250 training_loss 0.6931471805599453
iteration 9 batch 10260 training_loss 0.6931471805599453
iteration 9 batch 10270 training_loss 0.6931471805599453
iteration 9 batch 10280 training_loss 0.6931471805599453
iteration 9 batch 10290 training_loss 0.6931471805599453
iteration 9 batch 10300 training_loss 0.6931471805599453